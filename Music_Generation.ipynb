{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b53e2f4a-4723-45b7-b322-3ab4b9b8b918",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-04 12:27:58.981861: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-04 12:27:59.978721: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-04 12:27:59.978756: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-04 12:28:03.492738: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-04 12:28:03.493830: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-04 12:28:03.493849: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import argparse\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, TimeDistributed, Activation, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df5348dd-5cc6-448b-9f04-279ee9443dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./input.txt\") as f:\n",
    "    input_text = f.read()\n",
    "char_to_idx = {ch: i for (i, ch) in enumerate(sorted(list(set(input_text))))}\n",
    "idx_to_char = {i: ch for (ch, i) in char_to_idx.items()}\n",
    "\n",
    "vocab_size = len(char_to_idx)\n",
    "T = np.asarray([char_to_idx[c] for c in input_text], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08aa9afc-d9d7-4c0f-bae7-fa4382509e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "SEQ_LENGTH = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25c2e386-db3e-4a26-ad2d-d5f02007c186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_batches(T, BATCH_SIZE):\n",
    "    NUM_CHAR_EACH_ROW = T.shape[0]//BATCH_SIZE\n",
    "    \n",
    "    for start in range(0, NUM_CHAR_EACH_ROW - SEQ_LENGTH, SEQ_LENGTH):\n",
    "        X = np.zeros((BATCH_SIZE, SEQ_LENGTH))\n",
    "        Y = np.zeros((BATCH_SIZE, SEQ_LENGTH, vocab_size))\n",
    "        for row in range(16):\n",
    "            for col in range(64):\n",
    "                X[row, col] = T[row*NUM_CHAR_EACH_ROW + start + col]\n",
    "                Y[row, col, T[row*NUM_CHAR_EACH_ROW + start + col + 1]] = 1\n",
    "        yield X , Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c956ef43-c530-42b9-95bd-7965ca0ce014",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = \"./Model_torch_weights\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40164140-c381-4624-bbbd-e7bcc1e774e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(BATCH_SIZE, SEQ_LENGTH, vocab_size):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 512, batch_input_shape=(BATCH_SIZE, SEQ_LENGTH)))\n",
    "    for i in range(3):\n",
    "        model.add(LSTM(256, return_sequences= True, stateful=True))\n",
    "        model.add(Dropout(0.2))\n",
    "    model.add(TimeDistributed(Dense(vocab_size)))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    return model\n",
    "def save_weights(model, epoch):\n",
    "    if not os.path.exists(MODEL_DIR):\n",
    "        os.makedirs(MODEL_DIR)\n",
    "    model.save_weights(os.path.join(MODEL_DIR, f\"weights.{epoch}.h5\"))\n",
    "def load_weights(model, epoch):\n",
    "    model.load_weights(os.path.join(MODEL_DIR, f\"weights.{epoch}.h5\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73f459fe-730d-41ed-a596-70bc3676a4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-04 12:41:46.877545: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-04 12:41:46.878696: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-04 12:41:46.878769: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (default): /proc/driver/nvidia/version does not exist\n",
      "2023-02-04 12:41:46.880386: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = build_model(BATCH_SIZE, SEQ_LENGTH, vocab_size)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "851060d6-542b-4998-a9d2-8dec6fcb4bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_weights(model, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb3d2d0-9a23-41e0-8d8b-2149d08267f4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100\n",
      "Batch 1: loss = 4.4547119140625, acc = 0.013671875\n",
      "Batch 2: loss = 4.43332576751709, acc = 0.1259765625\n",
      "Batch 3: loss = 4.385631561279297, acc = 0.1142578125\n",
      "Batch 4: loss = 4.174156665802002, acc = 0.1455078125\n",
      "Batch 5: loss = 3.715034246444702, acc = 0.1611328125\n",
      "Batch 6: loss = 3.813836097717285, acc = 0.142578125\n",
      "Batch 7: loss = 3.6775920391082764, acc = 0.1298828125\n",
      "Batch 8: loss = 3.62931489944458, acc = 0.0732421875\n",
      "Batch 9: loss = 3.704057216644287, acc = 0.0732421875\n",
      "Batch 10: loss = 3.6648497581481934, acc = 0.0654296875\n",
      "Batch 11: loss = 3.4651412963867188, acc = 0.0947265625\n",
      "Batch 12: loss = 3.478306770324707, acc = 0.1455078125\n",
      "Batch 13: loss = 3.5541069507598877, acc = 0.140625\n",
      "Batch 14: loss = 3.5442323684692383, acc = 0.150390625\n",
      "Batch 15: loss = 3.580540657043457, acc = 0.1357421875\n",
      "Batch 16: loss = 3.4498682022094727, acc = 0.1552734375\n",
      "Batch 17: loss = 3.3879833221435547, acc = 0.166015625\n",
      "Batch 18: loss = 3.341151475906372, acc = 0.162109375\n",
      "Batch 19: loss = 3.560152053833008, acc = 0.1240234375\n",
      "Batch 20: loss = 3.538940906524658, acc = 0.103515625\n",
      "Batch 21: loss = 3.5627710819244385, acc = 0.0986328125\n",
      "Batch 22: loss = 3.528696060180664, acc = 0.087890625\n",
      "Batch 23: loss = 3.359048366546631, acc = 0.1220703125\n",
      "Batch 24: loss = 3.50431227684021, acc = 0.1181640625\n",
      "Batch 25: loss = 3.5304489135742188, acc = 0.1220703125\n",
      "Batch 26: loss = 3.5293869972229004, acc = 0.126953125\n",
      "Batch 27: loss = 3.2806296348571777, acc = 0.1787109375\n",
      "Batch 28: loss = 3.3821263313293457, acc = 0.1591796875\n",
      "Batch 29: loss = 3.571208953857422, acc = 0.1337890625\n",
      "Batch 30: loss = 3.564394950866699, acc = 0.1318359375\n",
      "Batch 31: loss = 3.3915557861328125, acc = 0.158203125\n",
      "Batch 32: loss = 3.4529261589050293, acc = 0.138671875\n",
      "Batch 33: loss = 3.4892163276672363, acc = 0.1376953125\n",
      "Batch 34: loss = 3.417862892150879, acc = 0.134765625\n",
      "Batch 35: loss = 3.386681079864502, acc = 0.1337890625\n",
      "Batch 36: loss = 3.584414482116699, acc = 0.12109375\n",
      "Batch 37: loss = 3.500476837158203, acc = 0.111328125\n",
      "Batch 38: loss = 3.472564697265625, acc = 0.1162109375\n",
      "Batch 39: loss = 3.4383249282836914, acc = 0.10546875\n",
      "Batch 40: loss = 3.4593334197998047, acc = 0.12890625\n",
      "Batch 41: loss = 3.498955488204956, acc = 0.1201171875\n",
      "Batch 42: loss = 3.3268980979919434, acc = 0.1591796875\n",
      "Batch 43: loss = 3.4007105827331543, acc = 0.1455078125\n",
      "Batch 44: loss = 3.8535423278808594, acc = 0.111328125\n",
      "Batch 45: loss = 3.607064962387085, acc = 0.1259765625\n",
      "Batch 46: loss = 3.3958282470703125, acc = 0.146484375\n",
      "Batch 47: loss = 3.3686447143554688, acc = 0.1533203125\n",
      "Batch 48: loss = 3.4131364822387695, acc = 0.1552734375\n",
      "Batch 49: loss = 3.5323097705841064, acc = 0.1171875\n",
      "Batch 50: loss = 3.430614948272705, acc = 0.1416015625\n",
      "Batch 51: loss = 3.3643031120300293, acc = 0.1455078125\n",
      "Batch 52: loss = 3.289538860321045, acc = 0.166015625\n",
      "Batch 53: loss = 3.447035551071167, acc = 0.1328125\n",
      "Batch 54: loss = 3.558460235595703, acc = 0.1220703125\n",
      "Batch 55: loss = 3.53777813911438, acc = 0.130859375\n",
      "Batch 56: loss = 3.320211887359619, acc = 0.1376953125\n",
      "Batch 57: loss = 3.254422903060913, acc = 0.1748046875\n",
      "Batch 58: loss = 3.4855825901031494, acc = 0.12890625\n",
      "Batch 59: loss = 3.561995506286621, acc = 0.130859375\n",
      "Batch 60: loss = 3.3843066692352295, acc = 0.1455078125\n",
      "Batch 61: loss = 3.390876293182373, acc = 0.1494140625\n",
      "Batch 62: loss = 3.1664161682128906, acc = 0.171875\n",
      "Batch 63: loss = 3.452333450317383, acc = 0.1484375\n",
      "Batch 64: loss = 3.429642677307129, acc = 0.126953125\n",
      "Batch 65: loss = 3.2361929416656494, acc = 0.1552734375\n",
      "Batch 66: loss = 3.2703020572662354, acc = 0.1533203125\n",
      "Batch 67: loss = 3.3527283668518066, acc = 0.1455078125\n",
      "Batch 68: loss = 3.382415294647217, acc = 0.1416015625\n",
      "Batch 69: loss = 3.2782139778137207, acc = 0.1533203125\n",
      "Batch 70: loss = 3.154097318649292, acc = 0.1767578125\n",
      "Batch 71: loss = 3.3381783962249756, acc = 0.1435546875\n",
      "Batch 72: loss = 3.3591489791870117, acc = 0.1513671875\n",
      "Batch 73: loss = 3.2502939701080322, acc = 0.162109375\n",
      "Batch 74: loss = 3.167238712310791, acc = 0.1748046875\n",
      "Batch 75: loss = 3.1683945655822754, acc = 0.166015625\n",
      "Batch 76: loss = 3.2916817665100098, acc = 0.15625\n",
      "Batch 77: loss = 3.2002549171447754, acc = 0.16796875\n",
      "Batch 78: loss = 3.1617650985717773, acc = 0.1513671875\n",
      "Batch 79: loss = 3.1907033920288086, acc = 0.166015625\n",
      "Batch 80: loss = 3.0229225158691406, acc = 0.18359375\n",
      "Batch 81: loss = 3.2452502250671387, acc = 0.16015625\n",
      "Batch 82: loss = 3.293822765350342, acc = 0.14453125\n",
      "Batch 83: loss = 3.1838274002075195, acc = 0.16796875\n",
      "Batch 84: loss = 3.167590618133545, acc = 0.173828125\n",
      "Batch 85: loss = 3.0404372215270996, acc = 0.1943359375\n",
      "Batch 86: loss = 3.2231810092926025, acc = 0.1591796875\n",
      "Batch 87: loss = 3.3683488368988037, acc = 0.140625\n",
      "Batch 88: loss = 3.1740546226501465, acc = 0.1796875\n",
      "Batch 89: loss = 3.2314224243164062, acc = 0.158203125\n",
      "Batch 90: loss = 3.261218309402466, acc = 0.1630859375\n",
      "Batch 91: loss = 3.0901870727539062, acc = 0.189453125\n",
      "Batch 92: loss = 3.175351858139038, acc = 0.158203125\n",
      "Batch 93: loss = 3.231067657470703, acc = 0.158203125\n",
      "Batch 94: loss = 3.1075329780578613, acc = 0.1708984375\n",
      "Batch 95: loss = 3.0900745391845703, acc = 0.1787109375\n",
      "Batch 96: loss = 3.036998748779297, acc = 0.1787109375\n",
      "Batch 97: loss = 3.2223682403564453, acc = 0.1474609375\n",
      "Batch 98: loss = 3.223034143447876, acc = 0.1669921875\n",
      "Batch 99: loss = 3.04398250579834, acc = 0.1845703125\n",
      "Batch 100: loss = 3.0608251094818115, acc = 0.18359375\n",
      "Batch 101: loss = 3.178323745727539, acc = 0.1611328125\n",
      "Batch 102: loss = 3.226008892059326, acc = 0.16015625\n",
      "Batch 103: loss = 3.164958953857422, acc = 0.1728515625\n",
      "Batch 104: loss = 3.098918914794922, acc = 0.1884765625\n",
      "Batch 105: loss = 3.0506176948547363, acc = 0.19140625\n",
      "Batch 106: loss = 3.087975025177002, acc = 0.1806640625\n",
      "Batch 107: loss = 3.1293463706970215, acc = 0.1650390625\n",
      "Batch 108: loss = 3.060086488723755, acc = 0.1884765625\n",
      "Batch 109: loss = 3.0118961334228516, acc = 0.1865234375\n",
      "Batch 110: loss = 3.1053290367126465, acc = 0.169921875\n",
      "Batch 111: loss = 3.1028552055358887, acc = 0.17578125\n",
      "Batch 112: loss = 3.116239070892334, acc = 0.1806640625\n",
      "Batch 113: loss = 3.0701441764831543, acc = 0.1806640625\n",
      "Batch 114: loss = 3.169541835784912, acc = 0.171875\n",
      "Batch 115: loss = 3.114993095397949, acc = 0.1708984375\n",
      "Batch 116: loss = 3.0638675689697266, acc = 0.177734375\n",
      "Batch 117: loss = 3.2224512100219727, acc = 0.1689453125\n",
      "Batch 118: loss = 3.0675344467163086, acc = 0.1826171875\n",
      "Batch 119: loss = 2.9772610664367676, acc = 0.2001953125\n",
      "Batch 120: loss = 3.052194118499756, acc = 0.185546875\n",
      "Batch 121: loss = 3.0672340393066406, acc = 0.19140625\n",
      "Batch 122: loss = 3.1223514080047607, acc = 0.1708984375\n",
      "Batch 123: loss = 3.10166072845459, acc = 0.171875\n",
      "Batch 124: loss = 3.0005202293395996, acc = 0.1787109375\n",
      "Batch 125: loss = 3.0113277435302734, acc = 0.189453125\n",
      "Batch 126: loss = 3.0986104011535645, acc = 0.17578125\n",
      "\n",
      "Epoch 2/100\n",
      "Batch 1: loss = 3.0952677726745605, acc = 0.1845703125\n",
      "Batch 2: loss = 2.9444594383239746, acc = 0.1982421875\n",
      "Batch 3: loss = 3.080305576324463, acc = 0.1796875\n",
      "Batch 4: loss = 3.0578067302703857, acc = 0.19140625\n",
      "Batch 5: loss = 3.0261664390563965, acc = 0.2197265625\n",
      "Batch 6: loss = 3.118495464324951, acc = 0.1806640625\n",
      "Batch 7: loss = 3.060089111328125, acc = 0.19921875\n",
      "Batch 8: loss = 3.0021109580993652, acc = 0.2041015625\n",
      "Batch 9: loss = 3.0172066688537598, acc = 0.19921875\n",
      "Batch 10: loss = 2.9118106365203857, acc = 0.2255859375\n",
      "Batch 11: loss = 2.928057909011841, acc = 0.228515625\n",
      "Batch 12: loss = 2.972632884979248, acc = 0.2265625\n",
      "Batch 13: loss = 2.9607152938842773, acc = 0.2158203125\n",
      "Batch 14: loss = 2.9487738609313965, acc = 0.208984375\n",
      "Batch 15: loss = 2.9414734840393066, acc = 0.2158203125\n",
      "Batch 16: loss = 2.8922109603881836, acc = 0.2373046875\n",
      "Batch 17: loss = 2.859628200531006, acc = 0.2451171875\n",
      "Batch 18: loss = 2.910482406616211, acc = 0.2216796875\n",
      "Batch 19: loss = 2.9586780071258545, acc = 0.208984375\n",
      "Batch 20: loss = 2.9197421073913574, acc = 0.2158203125\n",
      "Batch 21: loss = 2.9586434364318848, acc = 0.203125\n",
      "Batch 22: loss = 2.912508487701416, acc = 0.19921875\n",
      "Batch 23: loss = 2.7945470809936523, acc = 0.2421875\n",
      "Batch 24: loss = 2.882063865661621, acc = 0.2333984375\n",
      "Batch 25: loss = 2.8569586277008057, acc = 0.248046875\n",
      "Batch 26: loss = 2.862396240234375, acc = 0.228515625\n",
      "Batch 27: loss = 2.747981548309326, acc = 0.25390625\n",
      "Batch 28: loss = 2.7847115993499756, acc = 0.228515625\n",
      "Batch 29: loss = 2.857707977294922, acc = 0.228515625\n",
      "Batch 30: loss = 2.861504554748535, acc = 0.2529296875\n",
      "Batch 31: loss = 2.7906246185302734, acc = 0.2568359375\n",
      "Batch 32: loss = 2.8643555641174316, acc = 0.2548828125\n",
      "Batch 33: loss = 2.835577964782715, acc = 0.2490234375\n",
      "Batch 34: loss = 2.790945053100586, acc = 0.25390625\n",
      "Batch 35: loss = 2.7244319915771484, acc = 0.2490234375\n",
      "Batch 36: loss = 2.9471559524536133, acc = 0.236328125\n",
      "Batch 37: loss = 2.8703393936157227, acc = 0.224609375\n",
      "Batch 38: loss = 2.787815570831299, acc = 0.2294921875\n",
      "Batch 39: loss = 2.771696090698242, acc = 0.2421875\n",
      "Batch 40: loss = 2.711160898208618, acc = 0.2685546875\n",
      "Batch 41: loss = 2.741938829421997, acc = 0.2578125\n",
      "Batch 42: loss = 2.613853931427002, acc = 0.2890625\n",
      "Batch 43: loss = 2.578148126602173, acc = 0.3037109375\n",
      "Batch 44: loss = 2.7196338176727295, acc = 0.25390625\n",
      "Batch 45: loss = 2.6939868927001953, acc = 0.271484375\n",
      "Batch 46: loss = 2.601475715637207, acc = 0.2880859375\n",
      "Batch 47: loss = 2.5911269187927246, acc = 0.2978515625\n",
      "Batch 48: loss = 2.5453450679779053, acc = 0.2900390625\n",
      "Batch 49: loss = 2.6586384773254395, acc = 0.2548828125\n",
      "Batch 50: loss = 2.5631120204925537, acc = 0.27734375\n",
      "Batch 51: loss = 2.5158286094665527, acc = 0.2734375\n",
      "Batch 52: loss = 2.5274031162261963, acc = 0.3046875\n",
      "Batch 53: loss = 2.663874864578247, acc = 0.2724609375\n",
      "Batch 54: loss = 2.7185592651367188, acc = 0.25\n",
      "Batch 55: loss = 2.7207021713256836, acc = 0.259765625\n",
      "Batch 56: loss = 2.5074050426483154, acc = 0.2861328125\n",
      "Batch 57: loss = 2.478489875793457, acc = 0.302734375\n",
      "Batch 58: loss = 2.6090614795684814, acc = 0.2724609375\n",
      "Batch 59: loss = 2.670332908630371, acc = 0.2578125\n",
      "Batch 60: loss = 2.520983934402466, acc = 0.2919921875\n",
      "Batch 61: loss = 2.641153335571289, acc = 0.2783203125\n",
      "Batch 62: loss = 2.396294593811035, acc = 0.3349609375\n",
      "Batch 63: loss = 2.621023416519165, acc = 0.287109375\n",
      "Batch 64: loss = 2.4915173053741455, acc = 0.2861328125\n",
      "Batch 65: loss = 2.3967533111572266, acc = 0.3203125\n",
      "Batch 66: loss = 2.4148597717285156, acc = 0.318359375\n",
      "Batch 67: loss = 2.5810039043426514, acc = 0.28125\n",
      "Batch 68: loss = 2.5054399967193604, acc = 0.294921875\n",
      "Batch 69: loss = 2.4019393920898438, acc = 0.318359375\n",
      "Batch 70: loss = 2.363391399383545, acc = 0.3291015625\n",
      "Batch 71: loss = 2.4700889587402344, acc = 0.318359375\n",
      "Batch 72: loss = 2.5135185718536377, acc = 0.302734375\n",
      "Batch 73: loss = 2.384737014770508, acc = 0.337890625\n",
      "Batch 74: loss = 2.2806553840637207, acc = 0.3408203125\n",
      "Batch 75: loss = 2.270880699157715, acc = 0.3515625\n",
      "Batch 76: loss = 2.40657377243042, acc = 0.32421875\n",
      "Batch 77: loss = 2.3405160903930664, acc = 0.33984375\n",
      "Batch 78: loss = 2.2427186965942383, acc = 0.3388671875\n",
      "Batch 79: loss = 2.2256786823272705, acc = 0.3583984375\n",
      "Batch 80: loss = 2.0473406314849854, acc = 0.4111328125\n",
      "Batch 81: loss = 2.334428548812866, acc = 0.3388671875\n",
      "Batch 82: loss = 2.4240875244140625, acc = 0.3330078125\n",
      "Batch 83: loss = 2.2784228324890137, acc = 0.345703125\n",
      "Batch 84: loss = 2.2180237770080566, acc = 0.373046875\n",
      "Batch 85: loss = 2.04205060005188, acc = 0.40234375\n",
      "Batch 86: loss = 2.3615198135375977, acc = 0.349609375\n",
      "Batch 87: loss = 2.527860164642334, acc = 0.3203125\n",
      "Batch 88: loss = 2.3023629188537598, acc = 0.3603515625\n",
      "Batch 89: loss = 2.457176685333252, acc = 0.326171875\n",
      "Batch 90: loss = 2.4570236206054688, acc = 0.3291015625\n",
      "Batch 91: loss = 2.148879289627075, acc = 0.380859375\n",
      "Batch 92: loss = 2.2480146884918213, acc = 0.349609375\n",
      "Batch 93: loss = 2.313535690307617, acc = 0.349609375\n",
      "Batch 94: loss = 2.136590003967285, acc = 0.3671875\n",
      "Batch 95: loss = 2.0771355628967285, acc = 0.376953125\n",
      "Batch 96: loss = 2.0844106674194336, acc = 0.39453125\n",
      "Batch 97: loss = 2.323272705078125, acc = 0.3359375\n",
      "Batch 98: loss = 2.323866128921509, acc = 0.345703125\n",
      "Batch 99: loss = 2.060234546661377, acc = 0.404296875\n",
      "Batch 100: loss = 1.985610842704773, acc = 0.439453125\n",
      "Batch 101: loss = 2.2576332092285156, acc = 0.375\n",
      "Batch 102: loss = 2.36295223236084, acc = 0.357421875\n",
      "Batch 103: loss = 2.231536388397217, acc = 0.365234375\n",
      "Batch 104: loss = 2.1027939319610596, acc = 0.380859375\n",
      "Batch 105: loss = 2.0687897205352783, acc = 0.4013671875\n",
      "Batch 106: loss = 2.168736457824707, acc = 0.388671875\n",
      "Batch 107: loss = 2.124875545501709, acc = 0.3798828125\n",
      "Batch 108: loss = 2.105180501937866, acc = 0.40234375\n",
      "Batch 109: loss = 2.02024507522583, acc = 0.3984375\n",
      "Batch 110: loss = 2.1675524711608887, acc = 0.37890625\n",
      "Batch 111: loss = 2.188523769378662, acc = 0.3984375\n",
      "Batch 112: loss = 2.172602653503418, acc = 0.3779296875\n",
      "Batch 113: loss = 2.0799524784088135, acc = 0.3876953125\n",
      "Batch 114: loss = 2.2892653942108154, acc = 0.369140625\n",
      "Batch 115: loss = 2.2271175384521484, acc = 0.38671875\n",
      "Batch 116: loss = 2.1739540100097656, acc = 0.3955078125\n",
      "Batch 117: loss = 2.3251471519470215, acc = 0.345703125\n",
      "Batch 118: loss = 2.1275601387023926, acc = 0.3935546875\n",
      "Batch 119: loss = 2.0169265270233154, acc = 0.4111328125\n",
      "Batch 120: loss = 2.13983154296875, acc = 0.3935546875\n",
      "Batch 121: loss = 2.0460636615753174, acc = 0.396484375\n",
      "Batch 122: loss = 2.2715725898742676, acc = 0.337890625\n",
      "Batch 123: loss = 2.1686816215515137, acc = 0.3740234375\n",
      "Batch 124: loss = 2.0117979049682617, acc = 0.421875\n",
      "Batch 125: loss = 2.0002365112304688, acc = 0.416015625\n",
      "Batch 126: loss = 2.206024646759033, acc = 0.369140625\n",
      "\n",
      "Epoch 3/100\n",
      "Batch 1: loss = 2.4209656715393066, acc = 0.357421875\n",
      "Batch 2: loss = 2.037609100341797, acc = 0.412109375\n",
      "Batch 3: loss = 2.183851718902588, acc = 0.3798828125\n",
      "Batch 4: loss = 2.0341062545776367, acc = 0.3896484375\n",
      "Batch 5: loss = 2.1285619735717773, acc = 0.3955078125\n",
      "Batch 6: loss = 2.1819510459899902, acc = 0.400390625\n",
      "Batch 7: loss = 2.2142553329467773, acc = 0.380859375\n",
      "Batch 8: loss = 2.0510878562927246, acc = 0.3994140625\n",
      "Batch 9: loss = 2.095407009124756, acc = 0.3837890625\n",
      "Batch 10: loss = 1.9727476835250854, acc = 0.42578125\n",
      "Batch 11: loss = 1.991207242012024, acc = 0.416015625\n",
      "Batch 12: loss = 2.082271099090576, acc = 0.42578125\n",
      "Batch 13: loss = 2.0544426441192627, acc = 0.4111328125\n",
      "Batch 14: loss = 2.0124154090881348, acc = 0.4130859375\n",
      "Batch 15: loss = 2.0813894271850586, acc = 0.41015625\n",
      "Batch 16: loss = 2.0612220764160156, acc = 0.408203125\n",
      "Batch 17: loss = 2.0301270484924316, acc = 0.423828125\n",
      "Batch 18: loss = 2.0654640197753906, acc = 0.4033203125\n",
      "Batch 19: loss = 2.180342674255371, acc = 0.380859375\n",
      "Batch 20: loss = 2.0284628868103027, acc = 0.4140625\n",
      "Batch 21: loss = 2.1902005672454834, acc = 0.373046875\n",
      "Batch 22: loss = 2.0412840843200684, acc = 0.41796875\n",
      "Batch 23: loss = 1.9307054281234741, acc = 0.4345703125\n",
      "Batch 24: loss = 2.1012277603149414, acc = 0.3974609375\n",
      "Batch 25: loss = 1.9896098375320435, acc = 0.4296875\n",
      "Batch 26: loss = 1.99663507938385, acc = 0.431640625\n",
      "Batch 27: loss = 1.8677289485931396, acc = 0.4609375\n",
      "Batch 28: loss = 1.8807648420333862, acc = 0.4521484375\n",
      "Batch 29: loss = 1.9809634685516357, acc = 0.4453125\n",
      "Batch 30: loss = 1.9749152660369873, acc = 0.4501953125\n",
      "Batch 31: loss = 2.007693290710449, acc = 0.439453125\n",
      "Batch 32: loss = 2.165644645690918, acc = 0.396484375\n",
      "Batch 33: loss = 2.076392889022827, acc = 0.400390625\n",
      "Batch 34: loss = 1.967922329902649, acc = 0.4375\n",
      "Batch 35: loss = 1.9301596879959106, acc = 0.447265625\n",
      "Batch 36: loss = 2.173705577850342, acc = 0.390625\n",
      "Batch 37: loss = 2.1035561561584473, acc = 0.423828125\n",
      "Batch 38: loss = 1.9997215270996094, acc = 0.4228515625\n",
      "Batch 39: loss = 1.9646615982055664, acc = 0.439453125\n",
      "Batch 40: loss = 1.9404922723770142, acc = 0.427734375\n",
      "Batch 41: loss = 1.9180463552474976, acc = 0.4501953125\n",
      "Batch 42: loss = 1.7676717042922974, acc = 0.4736328125\n",
      "Batch 43: loss = 1.847419261932373, acc = 0.439453125\n",
      "Batch 44: loss = 1.9595444202423096, acc = 0.4228515625\n",
      "Batch 45: loss = 1.873680591583252, acc = 0.4404296875\n",
      "Batch 46: loss = 1.8725855350494385, acc = 0.439453125\n",
      "Batch 47: loss = 1.8745696544647217, acc = 0.4453125\n",
      "Batch 48: loss = 1.8062609434127808, acc = 0.4462890625\n",
      "Batch 49: loss = 1.8939439058303833, acc = 0.45703125\n",
      "Batch 50: loss = 1.8698279857635498, acc = 0.447265625\n",
      "Batch 51: loss = 1.860893964767456, acc = 0.4501953125\n",
      "Batch 52: loss = 1.8905599117279053, acc = 0.44140625\n",
      "Batch 53: loss = 1.9663136005401611, acc = 0.4208984375\n",
      "Batch 54: loss = 2.0093045234680176, acc = 0.44140625\n",
      "Batch 55: loss = 2.0163159370422363, acc = 0.431640625\n",
      "Batch 56: loss = 1.794457197189331, acc = 0.455078125\n",
      "Batch 57: loss = 1.8371706008911133, acc = 0.431640625\n",
      "Batch 58: loss = 1.9198129177093506, acc = 0.4404296875\n",
      "Batch 59: loss = 1.8627972602844238, acc = 0.462890625\n",
      "Batch 60: loss = 1.8591477870941162, acc = 0.4482421875\n",
      "Batch 61: loss = 2.038088321685791, acc = 0.4287109375\n",
      "Batch 62: loss = 1.9046522378921509, acc = 0.4326171875\n",
      "Batch 63: loss = 2.088628053665161, acc = 0.4130859375\n",
      "Batch 64: loss = 1.7714893817901611, acc = 0.4990234375\n",
      "Batch 65: loss = 1.8291895389556885, acc = 0.4755859375\n",
      "Batch 66: loss = 1.8405544757843018, acc = 0.4697265625\n",
      "Batch 67: loss = 1.9047118425369263, acc = 0.4658203125\n",
      "Batch 68: loss = 1.8285975456237793, acc = 0.4833984375\n",
      "Batch 69: loss = 1.7192379236221313, acc = 0.490234375\n",
      "Batch 70: loss = 1.8432185649871826, acc = 0.451171875\n",
      "Batch 71: loss = 1.8415108919143677, acc = 0.4619140625\n",
      "Batch 72: loss = 1.831573486328125, acc = 0.4716796875\n",
      "Batch 73: loss = 1.816296100616455, acc = 0.46484375\n",
      "Batch 74: loss = 1.718787431716919, acc = 0.4677734375\n",
      "Batch 75: loss = 1.8254380226135254, acc = 0.439453125\n",
      "Batch 76: loss = 1.8682594299316406, acc = 0.4501953125\n",
      "Batch 77: loss = 1.7233130931854248, acc = 0.5009765625\n",
      "Batch 78: loss = 1.6574890613555908, acc = 0.5146484375\n",
      "Batch 79: loss = 1.61410391330719, acc = 0.517578125\n",
      "Batch 80: loss = 1.5755935907363892, acc = 0.5107421875\n",
      "Batch 81: loss = 1.7349777221679688, acc = 0.498046875\n",
      "Batch 82: loss = 1.7442948818206787, acc = 0.4970703125\n",
      "Batch 83: loss = 1.7356088161468506, acc = 0.4970703125\n",
      "Batch 84: loss = 1.6865510940551758, acc = 0.5234375\n",
      "Batch 85: loss = 1.6539415121078491, acc = 0.4921875\n",
      "Batch 86: loss = 1.806467890739441, acc = 0.48046875\n",
      "Batch 87: loss = 1.7879620790481567, acc = 0.505859375\n",
      "Batch 88: loss = 1.906886339187622, acc = 0.466796875\n",
      "Batch 89: loss = 1.9105010032653809, acc = 0.4677734375\n",
      "Batch 90: loss = 1.9345146417617798, acc = 0.46875\n",
      "Batch 91: loss = 1.7975984811782837, acc = 0.4736328125\n",
      "Batch 92: loss = 1.7048004865646362, acc = 0.5078125\n",
      "Batch 93: loss = 1.7240338325500488, acc = 0.515625\n",
      "Batch 94: loss = 1.6822108030319214, acc = 0.51171875\n",
      "Batch 95: loss = 1.6889654397964478, acc = 0.48046875\n",
      "Batch 96: loss = 1.6893080472946167, acc = 0.4951171875\n",
      "Batch 97: loss = 1.7862094640731812, acc = 0.4873046875\n",
      "Batch 98: loss = 1.7533642053604126, acc = 0.5126953125\n",
      "Batch 99: loss = 1.651850938796997, acc = 0.4921875\n",
      "Batch 100: loss = 1.6276519298553467, acc = 0.505859375\n",
      "Batch 101: loss = 1.815993309020996, acc = 0.4716796875\n",
      "Batch 102: loss = 1.8813812732696533, acc = 0.466796875\n",
      "Batch 103: loss = 1.841051697731018, acc = 0.470703125\n",
      "Batch 104: loss = 1.6576061248779297, acc = 0.5126953125\n",
      "Batch 105: loss = 1.7280372381210327, acc = 0.4892578125\n",
      "Batch 106: loss = 1.7592718601226807, acc = 0.4921875\n",
      "Batch 107: loss = 1.694413185119629, acc = 0.482421875\n",
      "Batch 108: loss = 1.6915562152862549, acc = 0.501953125\n",
      "Batch 109: loss = 1.6538293361663818, acc = 0.494140625\n",
      "Batch 110: loss = 1.7569385766983032, acc = 0.4912109375\n",
      "Batch 111: loss = 1.8061128854751587, acc = 0.4560546875\n",
      "Batch 112: loss = 1.7118321657180786, acc = 0.4853515625\n",
      "Batch 113: loss = 1.6610636711120605, acc = 0.5009765625\n",
      "Batch 114: loss = 1.8090465068817139, acc = 0.4912109375\n",
      "Batch 115: loss = 1.8131415843963623, acc = 0.48046875\n",
      "Batch 116: loss = 1.8144869804382324, acc = 0.47265625\n",
      "Batch 117: loss = 1.7768373489379883, acc = 0.4990234375\n",
      "Batch 118: loss = 1.6899659633636475, acc = 0.505859375\n",
      "Batch 119: loss = 1.7209259271621704, acc = 0.484375\n",
      "Batch 120: loss = 1.8327457904815674, acc = 0.458984375\n",
      "Batch 121: loss = 1.6425116062164307, acc = 0.4912109375\n",
      "Batch 122: loss = 1.77126145362854, acc = 0.4697265625\n",
      "Batch 123: loss = 1.6798408031463623, acc = 0.505859375\n",
      "Batch 124: loss = 1.703330636024475, acc = 0.4873046875\n",
      "Batch 125: loss = 1.6866965293884277, acc = 0.498046875\n",
      "Batch 126: loss = 1.79217529296875, acc = 0.48828125\n",
      "\n",
      "Epoch 4/100\n",
      "Batch 1: loss = 2.1264119148254395, acc = 0.4296875\n",
      "Batch 2: loss = 1.7419729232788086, acc = 0.4873046875\n",
      "Batch 3: loss = 1.828988790512085, acc = 0.4716796875\n",
      "Batch 4: loss = 1.6509931087493896, acc = 0.498046875\n",
      "Batch 5: loss = 1.8482455015182495, acc = 0.453125\n",
      "Batch 6: loss = 1.9041385650634766, acc = 0.4638671875\n",
      "Batch 7: loss = 1.8816630840301514, acc = 0.4658203125\n",
      "Batch 8: loss = 1.6793038845062256, acc = 0.4990234375\n",
      "Batch 9: loss = 1.6960200071334839, acc = 0.50390625\n",
      "Batch 10: loss = 1.579503059387207, acc = 0.5439453125\n",
      "Batch 11: loss = 1.703002691268921, acc = 0.5078125\n",
      "Batch 12: loss = 1.8770503997802734, acc = 0.4833984375\n",
      "Batch 13: loss = 1.7623356580734253, acc = 0.484375\n",
      "Batch 14: loss = 1.649993658065796, acc = 0.4951171875\n",
      "Batch 15: loss = 1.7063744068145752, acc = 0.5078125\n",
      "Batch 16: loss = 1.780799150466919, acc = 0.4697265625\n",
      "Batch 17: loss = 1.7462174892425537, acc = 0.5009765625\n",
      "Batch 18: loss = 1.830538034439087, acc = 0.4765625\n",
      "Batch 19: loss = 1.8305952548980713, acc = 0.48046875\n",
      "Batch 20: loss = 1.6462150812149048, acc = 0.5107421875\n",
      "Batch 21: loss = 1.8566386699676514, acc = 0.4814453125\n",
      "Batch 22: loss = 1.6852576732635498, acc = 0.4990234375\n",
      "Batch 23: loss = 1.6876025199890137, acc = 0.4921875\n",
      "Batch 24: loss = 1.7900432348251343, acc = 0.4658203125\n",
      "Batch 25: loss = 1.6512222290039062, acc = 0.521484375\n",
      "Batch 26: loss = 1.6585184335708618, acc = 0.525390625\n",
      "Batch 27: loss = 1.6212644577026367, acc = 0.5029296875\n",
      "Batch 28: loss = 1.5995442867279053, acc = 0.5234375\n",
      "Batch 29: loss = 1.623046636581421, acc = 0.5302734375\n",
      "Batch 30: loss = 1.6752464771270752, acc = 0.5146484375\n",
      "Batch 31: loss = 1.7455030679702759, acc = 0.501953125\n",
      "Batch 32: loss = 1.9258379936218262, acc = 0.4521484375\n",
      "Batch 33: loss = 1.7605292797088623, acc = 0.4921875\n",
      "Batch 34: loss = 1.6787605285644531, acc = 0.494140625\n",
      "Batch 35: loss = 1.690425157546997, acc = 0.48828125\n",
      "Batch 36: loss = 1.8048503398895264, acc = 0.482421875\n",
      "Batch 37: loss = 1.7598538398742676, acc = 0.5\n",
      "Batch 38: loss = 1.7221319675445557, acc = 0.484375\n",
      "Batch 39: loss = 1.6803480386734009, acc = 0.4931640625\n",
      "Batch 40: loss = 1.6717369556427002, acc = 0.49609375\n",
      "Batch 41: loss = 1.6042201519012451, acc = 0.5341796875\n",
      "Batch 42: loss = 1.5589085817337036, acc = 0.51171875\n",
      "Batch 43: loss = 1.627432107925415, acc = 0.4921875\n",
      "Batch 44: loss = 1.6581802368164062, acc = 0.5107421875\n",
      "Batch 45: loss = 1.5420184135437012, acc = 0.54296875\n",
      "Batch 46: loss = 1.6334123611450195, acc = 0.5048828125\n",
      "Batch 47: loss = 1.6081328392028809, acc = 0.529296875\n",
      "Batch 48: loss = 1.524245023727417, acc = 0.5322265625\n",
      "Batch 49: loss = 1.5411038398742676, acc = 0.5390625\n",
      "Batch 50: loss = 1.537891149520874, acc = 0.5390625\n",
      "Batch 51: loss = 1.6185297966003418, acc = 0.5146484375\n",
      "Batch 52: loss = 1.7047035694122314, acc = 0.5\n",
      "Batch 53: loss = 1.700669765472412, acc = 0.4814453125\n",
      "Batch 54: loss = 1.6164953708648682, acc = 0.5478515625\n",
      "Batch 55: loss = 1.675337553024292, acc = 0.5068359375\n",
      "Batch 56: loss = 1.5480685234069824, acc = 0.5263671875\n",
      "Batch 57: loss = 1.634671688079834, acc = 0.4833984375\n",
      "Batch 58: loss = 1.65183424949646, acc = 0.5185546875\n",
      "Batch 59: loss = 1.5006159543991089, acc = 0.5576171875\n",
      "Batch 60: loss = 1.5816259384155273, acc = 0.52734375\n",
      "Batch 61: loss = 1.7372961044311523, acc = 0.5048828125\n",
      "Batch 62: loss = 1.761306881904602, acc = 0.4453125\n",
      "Batch 63: loss = 1.7737809419631958, acc = 0.4931640625\n",
      "Batch 64: loss = 1.4090631008148193, acc = 0.587890625\n",
      "Batch 65: loss = 1.5753579139709473, acc = 0.5341796875\n",
      "Batch 66: loss = 1.5629386901855469, acc = 0.5283203125\n",
      "Batch 67: loss = 1.5697002410888672, acc = 0.548828125\n",
      "Batch 68: loss = 1.5521680116653442, acc = 0.5439453125\n",
      "Batch 69: loss = 1.481494426727295, acc = 0.54296875\n",
      "Batch 70: loss = 1.654761552810669, acc = 0.4970703125\n",
      "Batch 71: loss = 1.561037302017212, acc = 0.5380859375\n",
      "Batch 72: loss = 1.5159876346588135, acc = 0.5546875\n",
      "Batch 73: loss = 1.599561095237732, acc = 0.521484375\n",
      "Batch 74: loss = 1.5554349422454834, acc = 0.515625\n",
      "Batch 75: loss = 1.62992262840271, acc = 0.498046875\n",
      "Batch 76: loss = 1.6220647096633911, acc = 0.5029296875\n",
      "Batch 77: loss = 1.4460666179656982, acc = 0.5771484375\n",
      "Batch 78: loss = 1.4352755546569824, acc = 0.5546875\n",
      "Batch 79: loss = 1.3772027492523193, acc = 0.576171875\n",
      "Batch 80: loss = 1.3899955749511719, acc = 0.560546875\n",
      "Batch 81: loss = 1.4581208229064941, acc = 0.5673828125\n",
      "Batch 82: loss = 1.4371328353881836, acc = 0.5615234375\n",
      "Batch 83: loss = 1.4837496280670166, acc = 0.55078125\n",
      "Batch 84: loss = 1.4918447732925415, acc = 0.55859375\n",
      "Batch 85: loss = 1.5216413736343384, acc = 0.51953125\n",
      "Batch 86: loss = 1.5410146713256836, acc = 0.548828125\n",
      "Batch 87: loss = 1.5085393190383911, acc = 0.5791015625\n",
      "Batch 88: loss = 1.6810857057571411, acc = 0.5009765625\n",
      "Batch 89: loss = 1.6038811206817627, acc = 0.5546875\n",
      "Batch 90: loss = 1.7074267864227295, acc = 0.5107421875\n",
      "Batch 91: loss = 1.593653678894043, acc = 0.515625\n",
      "Batch 92: loss = 1.4529742002487183, acc = 0.5625\n",
      "Batch 93: loss = 1.4643592834472656, acc = 0.5732421875\n",
      "Batch 94: loss = 1.4485979080200195, acc = 0.57421875\n",
      "Batch 95: loss = 1.4908802509307861, acc = 0.51953125\n",
      "Batch 96: loss = 1.5348912477493286, acc = 0.5244140625\n",
      "Batch 97: loss = 1.543674349784851, acc = 0.5400390625\n",
      "Batch 98: loss = 1.5349961519241333, acc = 0.5517578125\n",
      "Batch 99: loss = 1.473139762878418, acc = 0.525390625\n",
      "Batch 100: loss = 1.4497580528259277, acc = 0.5322265625\n",
      "Batch 101: loss = 1.5822805166244507, acc = 0.5263671875\n",
      "Batch 102: loss = 1.6633577346801758, acc = 0.5126953125\n",
      "Batch 103: loss = 1.6461374759674072, acc = 0.5224609375\n",
      "Batch 104: loss = 1.4868353605270386, acc = 0.552734375\n",
      "Batch 105: loss = 1.5569818019866943, acc = 0.5234375\n",
      "Batch 106: loss = 1.5608019828796387, acc = 0.5234375\n",
      "Batch 107: loss = 1.4793729782104492, acc = 0.5439453125\n",
      "Batch 108: loss = 1.5035123825073242, acc = 0.5419921875\n",
      "Batch 109: loss = 1.4744871854782104, acc = 0.5263671875\n",
      "Batch 110: loss = 1.4871368408203125, acc = 0.548828125\n",
      "Batch 111: loss = 1.6514323949813843, acc = 0.5009765625\n",
      "Batch 112: loss = 1.5089555978775024, acc = 0.5439453125\n",
      "Batch 113: loss = 1.4824018478393555, acc = 0.56640625\n",
      "Batch 114: loss = 1.6065974235534668, acc = 0.5341796875\n",
      "Batch 115: loss = 1.6363680362701416, acc = 0.5048828125\n",
      "Batch 116: loss = 1.639768362045288, acc = 0.513671875\n",
      "Batch 117: loss = 1.5394322872161865, acc = 0.556640625\n",
      "Batch 118: loss = 1.5290724039077759, acc = 0.5341796875\n",
      "Batch 119: loss = 1.5673387050628662, acc = 0.513671875\n",
      "Batch 120: loss = 1.6566839218139648, acc = 0.490234375\n",
      "Batch 121: loss = 1.4662108421325684, acc = 0.5546875\n",
      "Batch 122: loss = 1.526615858078003, acc = 0.5361328125\n",
      "Batch 123: loss = 1.5146174430847168, acc = 0.546875\n",
      "Batch 124: loss = 1.5551395416259766, acc = 0.5068359375\n",
      "Batch 125: loss = 1.5526633262634277, acc = 0.51953125\n",
      "Batch 126: loss = 1.6299084424972534, acc = 0.5107421875\n",
      "\n",
      "Epoch 5/100\n",
      "Batch 1: loss = 1.903004765510559, acc = 0.47265625\n",
      "Batch 2: loss = 1.5745718479156494, acc = 0.5185546875\n",
      "Batch 3: loss = 1.6302441358566284, acc = 0.5068359375\n",
      "Batch 4: loss = 1.4866058826446533, acc = 0.53515625\n",
      "Batch 5: loss = 1.7124401330947876, acc = 0.4853515625\n",
      "Batch 6: loss = 1.734649896621704, acc = 0.498046875\n",
      "Batch 7: loss = 1.687245488166809, acc = 0.5009765625\n",
      "Batch 8: loss = 1.4837895631790161, acc = 0.552734375\n",
      "Batch 9: loss = 1.5127849578857422, acc = 0.55078125\n",
      "Batch 10: loss = 1.4093894958496094, acc = 0.572265625\n",
      "Batch 11: loss = 1.5618963241577148, acc = 0.5302734375\n",
      "Batch 12: loss = 1.7228803634643555, acc = 0.5\n",
      "Batch 13: loss = 1.5836760997772217, acc = 0.5361328125\n",
      "Batch 14: loss = 1.4569015502929688, acc = 0.548828125\n",
      "Batch 15: loss = 1.5362576246261597, acc = 0.5546875\n",
      "Batch 16: loss = 1.6140015125274658, acc = 0.5029296875\n",
      "Batch 17: loss = 1.5818955898284912, acc = 0.5302734375\n",
      "Batch 18: loss = 1.6445735692977905, acc = 0.4990234375\n",
      "Batch 19: loss = 1.6534347534179688, acc = 0.5166015625\n",
      "Batch 20: loss = 1.472027063369751, acc = 0.546875\n",
      "Batch 21: loss = 1.6709773540496826, acc = 0.4990234375\n",
      "Batch 22: loss = 1.491065502166748, acc = 0.5390625\n",
      "Batch 23: loss = 1.4971719980239868, acc = 0.5263671875\n",
      "Batch 24: loss = 1.5845247507095337, acc = 0.513671875\n",
      "Batch 25: loss = 1.4590001106262207, acc = 0.5625\n",
      "Batch 26: loss = 1.470750331878662, acc = 0.560546875\n",
      "Batch 27: loss = 1.513393759727478, acc = 0.533203125\n",
      "Batch 28: loss = 1.465193510055542, acc = 0.5224609375\n",
      "Batch 29: loss = 1.4545897245407104, acc = 0.578125\n",
      "Batch 30: loss = 1.4888997077941895, acc = 0.56640625\n",
      "Batch 31: loss = 1.5856107473373413, acc = 0.5263671875\n",
      "Batch 32: loss = 1.7735768556594849, acc = 0.4775390625\n",
      "Batch 33: loss = 1.5730221271514893, acc = 0.5224609375\n",
      "Batch 34: loss = 1.5268319845199585, acc = 0.5185546875\n",
      "Batch 35: loss = 1.5558485984802246, acc = 0.529296875\n",
      "Batch 36: loss = 1.614966869354248, acc = 0.5107421875\n",
      "Batch 37: loss = 1.594721794128418, acc = 0.5419921875\n",
      "Batch 38: loss = 1.579352617263794, acc = 0.5205078125\n",
      "Batch 39: loss = 1.542803406715393, acc = 0.533203125\n",
      "Batch 40: loss = 1.526161551475525, acc = 0.5244140625\n",
      "Batch 41: loss = 1.451358437538147, acc = 0.5634765625\n",
      "Batch 42: loss = 1.4261000156402588, acc = 0.537109375\n",
      "Batch 43: loss = 1.4770203828811646, acc = 0.5185546875\n",
      "Batch 44: loss = 1.479264259338379, acc = 0.546875\n",
      "Batch 45: loss = 1.361295461654663, acc = 0.5849609375\n",
      "Batch 46: loss = 1.4819645881652832, acc = 0.546875\n",
      "Batch 47: loss = 1.453513741493225, acc = 0.548828125\n",
      "Batch 48: loss = 1.3689645528793335, acc = 0.5546875\n",
      "Batch 49: loss = 1.3668540716171265, acc = 0.572265625\n",
      "Batch 50: loss = 1.386594533920288, acc = 0.5810546875\n",
      "Batch 51: loss = 1.4491515159606934, acc = 0.5419921875\n",
      "Batch 52: loss = 1.57895028591156, acc = 0.5146484375\n",
      "Batch 53: loss = 1.5386390686035156, acc = 0.5322265625\n",
      "Batch 54: loss = 1.472902536392212, acc = 0.5634765625\n",
      "Batch 55: loss = 1.5093896389007568, acc = 0.55078125\n",
      "Batch 56: loss = 1.4100353717803955, acc = 0.5439453125\n",
      "Batch 57: loss = 1.5095590353012085, acc = 0.5078125\n",
      "Batch 58: loss = 1.484855055809021, acc = 0.5419921875\n",
      "Batch 59: loss = 1.3158855438232422, acc = 0.603515625\n",
      "Batch 60: loss = 1.4300520420074463, acc = 0.556640625\n",
      "Batch 61: loss = 1.5670809745788574, acc = 0.529296875\n",
      "Batch 62: loss = 1.6176316738128662, acc = 0.4765625\n",
      "Batch 63: loss = 1.6212608814239502, acc = 0.513671875\n",
      "Batch 64: loss = 1.2559864521026611, acc = 0.6123046875\n",
      "Batch 65: loss = 1.4287135601043701, acc = 0.5712890625\n",
      "Batch 66: loss = 1.418191909790039, acc = 0.55078125\n",
      "Batch 67: loss = 1.4049878120422363, acc = 0.5791015625\n",
      "Batch 68: loss = 1.4120190143585205, acc = 0.5830078125\n",
      "Batch 69: loss = 1.367133617401123, acc = 0.576171875\n",
      "Batch 70: loss = 1.5013930797576904, acc = 0.5234375\n",
      "Batch 71: loss = 1.4001338481903076, acc = 0.572265625\n",
      "Batch 72: loss = 1.3784761428833008, acc = 0.572265625\n",
      "Batch 73: loss = 1.4607337713241577, acc = 0.5546875\n",
      "Batch 74: loss = 1.4133882522583008, acc = 0.54296875\n",
      "Batch 75: loss = 1.494053602218628, acc = 0.515625\n",
      "Batch 76: loss = 1.5144145488739014, acc = 0.5302734375\n",
      "Batch 77: loss = 1.3134856224060059, acc = 0.599609375\n",
      "Batch 78: loss = 1.3099455833435059, acc = 0.576171875\n",
      "Batch 79: loss = 1.2271904945373535, acc = 0.6103515625\n",
      "Batch 80: loss = 1.3117797374725342, acc = 0.568359375\n",
      "Batch 81: loss = 1.336571455001831, acc = 0.5791015625\n",
      "Batch 82: loss = 1.2794495820999146, acc = 0.599609375\n",
      "Batch 83: loss = 1.3602910041809082, acc = 0.5673828125\n",
      "Batch 84: loss = 1.3752985000610352, acc = 0.5791015625\n",
      "Batch 85: loss = 1.4340764284133911, acc = 0.54296875\n",
      "Batch 86: loss = 1.419626235961914, acc = 0.57421875\n",
      "Batch 87: loss = 1.3645031452178955, acc = 0.587890625\n",
      "Batch 88: loss = 1.552638292312622, acc = 0.515625\n",
      "Batch 89: loss = 1.4417409896850586, acc = 0.5537109375\n",
      "Batch 90: loss = 1.5397814512252808, acc = 0.5322265625\n",
      "Batch 91: loss = 1.460626244544983, acc = 0.5478515625\n",
      "Batch 92: loss = 1.318158507347107, acc = 0.58203125\n",
      "Batch 93: loss = 1.3305377960205078, acc = 0.6015625\n",
      "Batch 94: loss = 1.3378560543060303, acc = 0.5791015625\n",
      "Batch 95: loss = 1.3911175727844238, acc = 0.529296875\n",
      "Batch 96: loss = 1.414322853088379, acc = 0.556640625\n",
      "Batch 97: loss = 1.414994716644287, acc = 0.5751953125\n",
      "Batch 98: loss = 1.3962945938110352, acc = 0.5849609375\n",
      "Batch 99: loss = 1.3903117179870605, acc = 0.5556640625\n",
      "Batch 100: loss = 1.3503329753875732, acc = 0.556640625\n",
      "Batch 101: loss = 1.4544693231582642, acc = 0.5498046875\n",
      "Batch 102: loss = 1.5474846363067627, acc = 0.5322265625\n",
      "Batch 103: loss = 1.5210061073303223, acc = 0.5380859375\n",
      "Batch 104: loss = 1.3437904119491577, acc = 0.5908203125\n",
      "Batch 105: loss = 1.4148503541946411, acc = 0.5517578125\n",
      "Batch 106: loss = 1.46040940284729, acc = 0.5439453125\n",
      "Batch 107: loss = 1.3750529289245605, acc = 0.572265625\n",
      "Batch 108: loss = 1.3828374147415161, acc = 0.5517578125\n",
      "Batch 109: loss = 1.3790251016616821, acc = 0.5517578125\n",
      "Batch 110: loss = 1.3297926187515259, acc = 0.583984375\n",
      "Batch 111: loss = 1.5503915548324585, acc = 0.51953125\n",
      "Batch 112: loss = 1.382932424545288, acc = 0.5712890625\n",
      "Batch 113: loss = 1.4013183116912842, acc = 0.5654296875\n",
      "Batch 114: loss = 1.4857895374298096, acc = 0.5751953125\n",
      "Batch 115: loss = 1.5320510864257812, acc = 0.53515625\n",
      "Batch 116: loss = 1.5179286003112793, acc = 0.5361328125\n",
      "Batch 117: loss = 1.4152112007141113, acc = 0.576171875\n",
      "Batch 118: loss = 1.3851618766784668, acc = 0.546875\n",
      "Batch 119: loss = 1.4696437120437622, acc = 0.521484375\n",
      "Batch 120: loss = 1.5312118530273438, acc = 0.5126953125\n",
      "Batch 121: loss = 1.3434710502624512, acc = 0.55859375\n",
      "Batch 122: loss = 1.4005944728851318, acc = 0.5634765625\n",
      "Batch 123: loss = 1.4001892805099487, acc = 0.5712890625\n",
      "Batch 124: loss = 1.4270795583724976, acc = 0.529296875\n",
      "Batch 125: loss = 1.431129813194275, acc = 0.5419921875\n",
      "Batch 126: loss = 1.5418343544006348, acc = 0.5390625\n",
      "\n",
      "Epoch 6/100\n",
      "Batch 1: loss = 1.8303533792495728, acc = 0.48046875\n",
      "Batch 2: loss = 1.4809342622756958, acc = 0.53515625\n",
      "Batch 3: loss = 1.5151543617248535, acc = 0.5439453125\n",
      "Batch 4: loss = 1.4163563251495361, acc = 0.5517578125\n",
      "Batch 5: loss = 1.5977028608322144, acc = 0.521484375\n",
      "Batch 6: loss = 1.6153533458709717, acc = 0.51171875\n",
      "Batch 7: loss = 1.5862410068511963, acc = 0.51171875\n",
      "Batch 8: loss = 1.4011106491088867, acc = 0.5703125\n",
      "Batch 9: loss = 1.4089446067810059, acc = 0.552734375\n",
      "Batch 10: loss = 1.2953670024871826, acc = 0.5908203125\n",
      "Batch 11: loss = 1.4584310054779053, acc = 0.541015625\n",
      "Batch 12: loss = 1.6215940713882446, acc = 0.5107421875\n",
      "Batch 13: loss = 1.5034878253936768, acc = 0.5390625\n",
      "Batch 14: loss = 1.3658692836761475, acc = 0.55859375\n",
      "Batch 15: loss = 1.411611557006836, acc = 0.5615234375\n",
      "Batch 16: loss = 1.5400595664978027, acc = 0.51953125\n",
      "Batch 17: loss = 1.4662747383117676, acc = 0.5400390625\n",
      "Batch 18: loss = 1.537323236465454, acc = 0.52734375\n",
      "Batch 19: loss = 1.5317103862762451, acc = 0.5322265625\n",
      "Batch 20: loss = 1.3887946605682373, acc = 0.5654296875\n",
      "Batch 21: loss = 1.5996079444885254, acc = 0.509765625\n",
      "Batch 22: loss = 1.3847248554229736, acc = 0.5556640625\n",
      "Batch 23: loss = 1.4132754802703857, acc = 0.5341796875\n",
      "Batch 24: loss = 1.4716243743896484, acc = 0.5498046875\n",
      "Batch 25: loss = 1.3545827865600586, acc = 0.5712890625\n",
      "Batch 26: loss = 1.397904872894287, acc = 0.5810546875\n",
      "Batch 27: loss = 1.4435386657714844, acc = 0.546875\n",
      "Batch 28: loss = 1.4164361953735352, acc = 0.55078125\n",
      "Batch 29: loss = 1.3914769887924194, acc = 0.5771484375\n",
      "Batch 30: loss = 1.3953043222427368, acc = 0.5703125\n",
      "Batch 31: loss = 1.5194039344787598, acc = 0.5478515625\n",
      "Batch 32: loss = 1.6561359167099, acc = 0.490234375\n",
      "Batch 33: loss = 1.4529098272323608, acc = 0.5517578125\n",
      "Batch 34: loss = 1.4396624565124512, acc = 0.5361328125\n",
      "Batch 35: loss = 1.4750680923461914, acc = 0.55078125\n",
      "Batch 36: loss = 1.5315501689910889, acc = 0.53515625\n",
      "Batch 37: loss = 1.4860618114471436, acc = 0.5673828125\n",
      "Batch 38: loss = 1.470165729522705, acc = 0.5400390625\n",
      "Batch 39: loss = 1.468929409980774, acc = 0.5400390625\n",
      "Batch 40: loss = 1.4250671863555908, acc = 0.5478515625\n",
      "Batch 41: loss = 1.346898078918457, acc = 0.5908203125\n",
      "Batch 42: loss = 1.3462672233581543, acc = 0.568359375\n",
      "Batch 43: loss = 1.3977203369140625, acc = 0.5390625\n",
      "Batch 44: loss = 1.4015319347381592, acc = 0.556640625\n",
      "Batch 45: loss = 1.2711968421936035, acc = 0.5927734375\n",
      "Batch 46: loss = 1.383732795715332, acc = 0.55859375\n",
      "Batch 47: loss = 1.3570897579193115, acc = 0.5625\n",
      "Batch 48: loss = 1.2778358459472656, acc = 0.58203125\n",
      "Batch 49: loss = 1.2632086277008057, acc = 0.6064453125\n",
      "Batch 50: loss = 1.301475167274475, acc = 0.603515625\n",
      "Batch 51: loss = 1.36646568775177, acc = 0.5517578125\n",
      "Batch 52: loss = 1.483879804611206, acc = 0.5166015625\n",
      "Batch 53: loss = 1.4417846202850342, acc = 0.5390625\n",
      "Batch 54: loss = 1.376875400543213, acc = 0.58984375\n",
      "Batch 55: loss = 1.393431544303894, acc = 0.57421875\n",
      "Batch 56: loss = 1.3460944890975952, acc = 0.5517578125\n",
      "Batch 57: loss = 1.4287586212158203, acc = 0.5244140625\n",
      "Batch 58: loss = 1.424943208694458, acc = 0.546875\n",
      "Batch 59: loss = 1.2223460674285889, acc = 0.6201171875\n",
      "Batch 60: loss = 1.3484594821929932, acc = 0.5546875\n",
      "Batch 61: loss = 1.4829368591308594, acc = 0.5263671875\n",
      "Batch 62: loss = 1.555112361907959, acc = 0.48046875\n",
      "Batch 63: loss = 1.53959321975708, acc = 0.51953125\n",
      "Batch 64: loss = 1.1304516792297363, acc = 0.6396484375\n",
      "Batch 65: loss = 1.3759933710098267, acc = 0.55859375\n",
      "Batch 66: loss = 1.3358672857284546, acc = 0.564453125\n",
      "Batch 67: loss = 1.3293185234069824, acc = 0.5986328125\n",
      "Batch 68: loss = 1.3629612922668457, acc = 0.5791015625\n",
      "Batch 69: loss = 1.2995936870574951, acc = 0.58984375\n",
      "Batch 70: loss = 1.4265062808990479, acc = 0.5390625\n",
      "Batch 71: loss = 1.3219870328903198, acc = 0.576171875\n",
      "Batch 72: loss = 1.2891615629196167, acc = 0.595703125\n",
      "Batch 73: loss = 1.417945146560669, acc = 0.548828125\n",
      "Batch 74: loss = 1.3776887655258179, acc = 0.5419921875\n",
      "Batch 75: loss = 1.4494664669036865, acc = 0.5341796875\n",
      "Batch 76: loss = 1.4317278861999512, acc = 0.556640625\n",
      "Batch 77: loss = 1.2502890825271606, acc = 0.6064453125\n",
      "Batch 78: loss = 1.2571027278900146, acc = 0.5888671875\n",
      "Batch 79: loss = 1.1464920043945312, acc = 0.626953125\n",
      "Batch 80: loss = 1.2322593927383423, acc = 0.5712890625\n",
      "Batch 81: loss = 1.2494351863861084, acc = 0.60546875\n",
      "Batch 82: loss = 1.2111263275146484, acc = 0.615234375\n",
      "Batch 83: loss = 1.3085904121398926, acc = 0.5849609375\n",
      "Batch 84: loss = 1.3080414533615112, acc = 0.583984375\n",
      "Batch 85: loss = 1.3880010843276978, acc = 0.5517578125\n",
      "Batch 86: loss = 1.339318871498108, acc = 0.578125\n",
      "Batch 87: loss = 1.2866476774215698, acc = 0.611328125\n",
      "Batch 88: loss = 1.4836468696594238, acc = 0.5263671875\n",
      "Batch 89: loss = 1.374693512916565, acc = 0.5693359375\n",
      "Batch 90: loss = 1.4713108539581299, acc = 0.5478515625\n",
      "Batch 91: loss = 1.4203846454620361, acc = 0.544921875\n",
      "Batch 92: loss = 1.2510418891906738, acc = 0.5927734375\n",
      "Batch 93: loss = 1.2360212802886963, acc = 0.6142578125\n",
      "Batch 94: loss = 1.285381555557251, acc = 0.6044921875\n",
      "Batch 95: loss = 1.3289222717285156, acc = 0.5419921875\n",
      "Batch 96: loss = 1.3562331199645996, acc = 0.5498046875\n",
      "Batch 97: loss = 1.3444764614105225, acc = 0.5849609375\n",
      "Batch 98: loss = 1.3627560138702393, acc = 0.5947265625\n",
      "Batch 99: loss = 1.350306510925293, acc = 0.5634765625\n",
      "Batch 100: loss = 1.2951644659042358, acc = 0.5771484375\n",
      "Batch 101: loss = 1.3812110424041748, acc = 0.5703125\n",
      "Batch 102: loss = 1.4598793983459473, acc = 0.55078125\n",
      "Batch 103: loss = 1.4532077312469482, acc = 0.5458984375\n",
      "Batch 104: loss = 1.2925148010253906, acc = 0.5869140625\n",
      "Batch 105: loss = 1.359602928161621, acc = 0.5693359375\n",
      "Batch 106: loss = 1.4023473262786865, acc = 0.5595703125\n",
      "Batch 107: loss = 1.3000357151031494, acc = 0.5810546875\n",
      "Batch 108: loss = 1.315016269683838, acc = 0.5732421875\n",
      "Batch 109: loss = 1.3343937397003174, acc = 0.5517578125\n",
      "Batch 110: loss = 1.2748546600341797, acc = 0.5849609375\n",
      "Batch 111: loss = 1.4790489673614502, acc = 0.5234375\n",
      "Batch 112: loss = 1.3115202188491821, acc = 0.572265625\n",
      "Batch 113: loss = 1.3249622583389282, acc = 0.5732421875\n",
      "Batch 114: loss = 1.4248344898223877, acc = 0.5673828125\n",
      "Batch 115: loss = 1.4741226434707642, acc = 0.537109375\n",
      "Batch 116: loss = 1.47519850730896, acc = 0.5341796875\n",
      "Batch 117: loss = 1.3135391473770142, acc = 0.5927734375\n",
      "Batch 118: loss = 1.3138104677200317, acc = 0.580078125\n",
      "Batch 119: loss = 1.4019895792007446, acc = 0.5458984375\n",
      "Batch 120: loss = 1.4705157279968262, acc = 0.533203125\n",
      "Batch 121: loss = 1.2776463031768799, acc = 0.5869140625\n",
      "Batch 122: loss = 1.3221261501312256, acc = 0.58984375\n",
      "Batch 123: loss = 1.3447389602661133, acc = 0.5771484375\n",
      "Batch 124: loss = 1.371325135231018, acc = 0.5498046875\n",
      "Batch 125: loss = 1.3629868030548096, acc = 0.55859375\n",
      "Batch 126: loss = 1.493013858795166, acc = 0.564453125\n",
      "\n",
      "Epoch 7/100\n",
      "Batch 1: loss = 1.7343401908874512, acc = 0.4912109375\n",
      "Batch 2: loss = 1.4493314027786255, acc = 0.5380859375\n",
      "Batch 3: loss = 1.4425978660583496, acc = 0.5546875\n",
      "Batch 4: loss = 1.3505984544754028, acc = 0.55859375\n",
      "Batch 5: loss = 1.5315214395523071, acc = 0.5224609375\n",
      "Batch 6: loss = 1.5514519214630127, acc = 0.5166015625\n",
      "Batch 7: loss = 1.5264642238616943, acc = 0.52734375\n",
      "Batch 8: loss = 1.3397865295410156, acc = 0.5732421875\n",
      "Batch 9: loss = 1.353626012802124, acc = 0.5615234375\n",
      "Batch 10: loss = 1.2563769817352295, acc = 0.599609375\n",
      "Batch 11: loss = 1.4146459102630615, acc = 0.560546875\n",
      "Batch 12: loss = 1.5606735944747925, acc = 0.5302734375\n",
      "Batch 13: loss = 1.4369394779205322, acc = 0.548828125\n",
      "Batch 14: loss = 1.3099828958511353, acc = 0.5771484375\n",
      "Batch 15: loss = 1.3374686241149902, acc = 0.595703125\n",
      "Batch 16: loss = 1.4843683242797852, acc = 0.53125\n",
      "Batch 17: loss = 1.404581069946289, acc = 0.5595703125\n",
      "Batch 18: loss = 1.4873756170272827, acc = 0.51953125\n",
      "Batch 19: loss = 1.452573299407959, acc = 0.55078125\n",
      "Batch 20: loss = 1.3122167587280273, acc = 0.5810546875\n",
      "Batch 21: loss = 1.5230679512023926, acc = 0.525390625\n",
      "Batch 22: loss = 1.3228412866592407, acc = 0.5732421875\n",
      "Batch 23: loss = 1.3510754108428955, acc = 0.55078125\n",
      "Batch 24: loss = 1.4120538234710693, acc = 0.5654296875\n",
      "Batch 25: loss = 1.2743024826049805, acc = 0.5869140625\n",
      "Batch 26: loss = 1.3227014541625977, acc = 0.5927734375\n",
      "Batch 27: loss = 1.3754150867462158, acc = 0.5517578125\n",
      "Batch 28: loss = 1.3702294826507568, acc = 0.5546875\n",
      "Batch 29: loss = 1.3307727575302124, acc = 0.587890625\n",
      "Batch 30: loss = 1.320562481880188, acc = 0.5791015625\n",
      "Batch 31: loss = 1.4596166610717773, acc = 0.5625\n",
      "Batch 32: loss = 1.6196038722991943, acc = 0.4931640625\n",
      "Batch 33: loss = 1.3884356021881104, acc = 0.560546875\n",
      "Batch 34: loss = 1.415445327758789, acc = 0.546875\n",
      "Batch 35: loss = 1.407525897026062, acc = 0.5556640625\n",
      "Batch 36: loss = 1.4275081157684326, acc = 0.5634765625\n",
      "Batch 37: loss = 1.4374011754989624, acc = 0.5654296875\n",
      "Batch 38: loss = 1.4504523277282715, acc = 0.5546875\n",
      "Batch 39: loss = 1.3947224617004395, acc = 0.546875\n",
      "Batch 40: loss = 1.357170581817627, acc = 0.5634765625\n",
      "Batch 41: loss = 1.3066964149475098, acc = 0.580078125\n",
      "Batch 42: loss = 1.3089306354522705, acc = 0.5703125\n",
      "Batch 43: loss = 1.3730400800704956, acc = 0.546875\n",
      "Batch 44: loss = 1.352149486541748, acc = 0.568359375\n",
      "Batch 45: loss = 1.222416639328003, acc = 0.6162109375\n",
      "Batch 46: loss = 1.3295021057128906, acc = 0.5712890625\n",
      "Batch 47: loss = 1.3011393547058105, acc = 0.5791015625\n",
      "Batch 48: loss = 1.2442524433135986, acc = 0.5849609375\n",
      "Batch 49: loss = 1.1872543096542358, acc = 0.6298828125\n",
      "Batch 50: loss = 1.2467632293701172, acc = 0.6162109375\n",
      "Batch 51: loss = 1.2907240390777588, acc = 0.5703125\n",
      "Batch 52: loss = 1.4396464824676514, acc = 0.5400390625\n",
      "Batch 53: loss = 1.4129223823547363, acc = 0.541015625\n",
      "Batch 54: loss = 1.3207666873931885, acc = 0.5849609375\n",
      "Batch 55: loss = 1.3615009784698486, acc = 0.5810546875\n",
      "Batch 56: loss = 1.2843714952468872, acc = 0.56640625\n",
      "Batch 57: loss = 1.3998209238052368, acc = 0.5234375\n",
      "Batch 58: loss = 1.3463034629821777, acc = 0.568359375\n",
      "Batch 59: loss = 1.1539814472198486, acc = 0.6279296875\n",
      "Batch 60: loss = 1.3106284141540527, acc = 0.568359375\n",
      "Batch 61: loss = 1.410866379737854, acc = 0.541015625\n",
      "Batch 62: loss = 1.5093252658843994, acc = 0.4853515625\n",
      "Batch 63: loss = 1.4716947078704834, acc = 0.5361328125\n",
      "Batch 64: loss = 1.0948542356491089, acc = 0.6318359375\n",
      "Batch 65: loss = 1.324258804321289, acc = 0.576171875\n",
      "Batch 66: loss = 1.2845005989074707, acc = 0.5810546875\n",
      "Batch 67: loss = 1.2598323822021484, acc = 0.615234375\n",
      "Batch 68: loss = 1.302028775215149, acc = 0.583984375\n",
      "Batch 69: loss = 1.261216163635254, acc = 0.5986328125\n",
      "Batch 70: loss = 1.3712975978851318, acc = 0.5595703125\n",
      "Batch 71: loss = 1.2468760013580322, acc = 0.6044921875\n",
      "Batch 72: loss = 1.2307194471359253, acc = 0.5947265625\n",
      "Batch 73: loss = 1.3632495403289795, acc = 0.5693359375\n",
      "Batch 74: loss = 1.3129141330718994, acc = 0.5556640625\n",
      "Batch 75: loss = 1.4126688241958618, acc = 0.5341796875\n",
      "Batch 76: loss = 1.3964207172393799, acc = 0.560546875\n",
      "Batch 77: loss = 1.2092230319976807, acc = 0.6103515625\n",
      "Batch 78: loss = 1.2093976736068726, acc = 0.619140625\n",
      "Batch 79: loss = 1.1114952564239502, acc = 0.64453125\n",
      "Batch 80: loss = 1.1842310428619385, acc = 0.5908203125\n",
      "Batch 81: loss = 1.2066954374313354, acc = 0.6123046875\n",
      "Batch 82: loss = 1.15517258644104, acc = 0.630859375\n",
      "Batch 83: loss = 1.246274709701538, acc = 0.5966796875\n",
      "Batch 84: loss = 1.2684673070907593, acc = 0.5927734375\n",
      "Batch 85: loss = 1.3711392879486084, acc = 0.56640625\n",
      "Batch 86: loss = 1.309448003768921, acc = 0.58984375\n",
      "Batch 87: loss = 1.2238643169403076, acc = 0.619140625\n",
      "Batch 88: loss = 1.444368839263916, acc = 0.5400390625\n",
      "Batch 89: loss = 1.3279352188110352, acc = 0.580078125\n",
      "Batch 90: loss = 1.4287960529327393, acc = 0.556640625\n",
      "Batch 91: loss = 1.3686597347259521, acc = 0.5693359375\n",
      "Batch 92: loss = 1.2231204509735107, acc = 0.6083984375\n",
      "Batch 93: loss = 1.2062417268753052, acc = 0.6376953125\n",
      "Batch 94: loss = 1.2322888374328613, acc = 0.603515625\n",
      "Batch 95: loss = 1.2995661497116089, acc = 0.5537109375\n",
      "Batch 96: loss = 1.3087401390075684, acc = 0.5615234375\n",
      "Batch 97: loss = 1.3176393508911133, acc = 0.5859375\n",
      "Batch 98: loss = 1.3235299587249756, acc = 0.58984375\n",
      "Batch 99: loss = 1.3117120265960693, acc = 0.5703125\n",
      "Batch 100: loss = 1.2690547704696655, acc = 0.5888671875\n",
      "Batch 101: loss = 1.342137098312378, acc = 0.57421875\n",
      "Batch 102: loss = 1.4252922534942627, acc = 0.55859375\n",
      "Batch 103: loss = 1.3838677406311035, acc = 0.5625\n",
      "Batch 104: loss = 1.2275714874267578, acc = 0.609375\n",
      "Batch 105: loss = 1.291560411453247, acc = 0.6015625\n",
      "Batch 106: loss = 1.3548954725265503, acc = 0.5771484375\n",
      "Batch 107: loss = 1.2749903202056885, acc = 0.5830078125\n",
      "Batch 108: loss = 1.2819567918777466, acc = 0.5732421875\n",
      "Batch 109: loss = 1.2806627750396729, acc = 0.578125\n",
      "Batch 110: loss = 1.2327698469161987, acc = 0.6005859375\n",
      "Batch 111: loss = 1.4349101781845093, acc = 0.5322265625\n",
      "Batch 112: loss = 1.267665147781372, acc = 0.5673828125\n",
      "Batch 113: loss = 1.2820348739624023, acc = 0.58984375\n",
      "Batch 114: loss = 1.3569300174713135, acc = 0.5859375\n",
      "Batch 115: loss = 1.4381699562072754, acc = 0.544921875\n",
      "Batch 116: loss = 1.444459319114685, acc = 0.5458984375\n",
      "Batch 117: loss = 1.267814040184021, acc = 0.6005859375\n",
      "Batch 118: loss = 1.2829139232635498, acc = 0.578125\n",
      "Batch 119: loss = 1.3375890254974365, acc = 0.5478515625\n",
      "Batch 120: loss = 1.4287834167480469, acc = 0.5498046875\n",
      "Batch 121: loss = 1.2439556121826172, acc = 0.5869140625\n",
      "Batch 122: loss = 1.2826929092407227, acc = 0.5908203125\n",
      "Batch 123: loss = 1.296226978302002, acc = 0.5927734375\n",
      "Batch 124: loss = 1.3511487245559692, acc = 0.5556640625\n",
      "Batch 125: loss = 1.3237836360931396, acc = 0.5673828125\n",
      "Batch 126: loss = 1.453554630279541, acc = 0.55859375\n",
      "\n",
      "Epoch 8/100\n",
      "Batch 1: loss = 1.6597927808761597, acc = 0.515625\n",
      "Batch 2: loss = 1.4059487581253052, acc = 0.5546875\n",
      "Batch 3: loss = 1.3998743295669556, acc = 0.572265625\n",
      "Batch 4: loss = 1.3355319499969482, acc = 0.5712890625\n",
      "Batch 5: loss = 1.4765639305114746, acc = 0.5439453125\n",
      "Batch 6: loss = 1.510926604270935, acc = 0.53125\n",
      "Batch 7: loss = 1.4797122478485107, acc = 0.5244140625\n",
      "Batch 8: loss = 1.2844802141189575, acc = 0.5888671875\n",
      "Batch 9: loss = 1.3039557933807373, acc = 0.5908203125\n",
      "Batch 10: loss = 1.2221016883850098, acc = 0.6044921875\n",
      "Batch 11: loss = 1.3826484680175781, acc = 0.55859375\n",
      "Batch 12: loss = 1.4817246198654175, acc = 0.5283203125\n",
      "Batch 13: loss = 1.3882570266723633, acc = 0.546875\n",
      "Batch 14: loss = 1.2834738492965698, acc = 0.58203125\n",
      "Batch 15: loss = 1.3155031204223633, acc = 0.57421875\n",
      "Batch 16: loss = 1.4317189455032349, acc = 0.5419921875\n",
      "Batch 17: loss = 1.3613332509994507, acc = 0.572265625\n",
      "Batch 18: loss = 1.4452993869781494, acc = 0.5380859375\n",
      "Batch 19: loss = 1.3958203792572021, acc = 0.556640625\n",
      "Batch 20: loss = 1.2770658731460571, acc = 0.5888671875\n",
      "Batch 21: loss = 1.4832251071929932, acc = 0.5380859375\n",
      "Batch 22: loss = 1.2685232162475586, acc = 0.5771484375\n",
      "Batch 23: loss = 1.3055113554000854, acc = 0.5615234375\n",
      "Batch 24: loss = 1.3571776151657104, acc = 0.556640625\n",
      "Batch 25: loss = 1.2192200422286987, acc = 0.61328125\n",
      "Batch 26: loss = 1.2657928466796875, acc = 0.6015625\n",
      "Batch 27: loss = 1.3582093715667725, acc = 0.568359375\n",
      "Batch 28: loss = 1.3191454410552979, acc = 0.5791015625\n",
      "Batch 29: loss = 1.2975788116455078, acc = 0.5849609375\n",
      "Batch 30: loss = 1.2601938247680664, acc = 0.607421875\n",
      "Batch 31: loss = 1.3978662490844727, acc = 0.55859375\n",
      "Batch 32: loss = 1.555009126663208, acc = 0.5009765625\n",
      "Batch 33: loss = 1.3529067039489746, acc = 0.5498046875\n",
      "Batch 34: loss = 1.358696460723877, acc = 0.560546875\n",
      "Batch 35: loss = 1.3532859086990356, acc = 0.56640625\n",
      "Batch 36: loss = 1.3677051067352295, acc = 0.5703125\n",
      "Batch 37: loss = 1.3635854721069336, acc = 0.5810546875\n",
      "Batch 38: loss = 1.4017163515090942, acc = 0.56640625\n",
      "Batch 39: loss = 1.3345062732696533, acc = 0.5703125\n",
      "Batch 40: loss = 1.3114997148513794, acc = 0.5751953125\n",
      "Batch 41: loss = 1.2650291919708252, acc = 0.5966796875\n",
      "Batch 42: loss = 1.2825990915298462, acc = 0.57421875\n",
      "Batch 43: loss = 1.3326232433319092, acc = 0.55078125\n",
      "Batch 44: loss = 1.3009599447250366, acc = 0.5771484375\n",
      "Batch 45: loss = 1.1797497272491455, acc = 0.609375\n",
      "Batch 46: loss = 1.288851261138916, acc = 0.58203125\n",
      "Batch 47: loss = 1.2699170112609863, acc = 0.591796875\n",
      "Batch 48: loss = 1.1887505054473877, acc = 0.5966796875\n",
      "Batch 49: loss = 1.140273928642273, acc = 0.626953125\n",
      "Batch 50: loss = 1.2028063535690308, acc = 0.609375\n",
      "Batch 51: loss = 1.2376219034194946, acc = 0.5908203125\n",
      "Batch 52: loss = 1.390642762184143, acc = 0.5400390625\n",
      "Batch 53: loss = 1.3459014892578125, acc = 0.55859375\n",
      "Batch 54: loss = 1.264310598373413, acc = 0.6171875\n",
      "Batch 55: loss = 1.2900316715240479, acc = 0.583984375\n",
      "Batch 56: loss = 1.253305435180664, acc = 0.5771484375\n",
      "Batch 57: loss = 1.3416706323623657, acc = 0.5498046875\n",
      "Batch 58: loss = 1.313018798828125, acc = 0.576171875\n",
      "Batch 59: loss = 1.1172136068344116, acc = 0.6357421875\n",
      "Batch 60: loss = 1.259250521659851, acc = 0.58203125\n",
      "Batch 61: loss = 1.3498616218566895, acc = 0.572265625\n",
      "Batch 62: loss = 1.4714691638946533, acc = 0.4912109375\n",
      "Batch 63: loss = 1.4245325326919556, acc = 0.5498046875\n",
      "Batch 64: loss = 1.0514323711395264, acc = 0.6640625\n",
      "Batch 65: loss = 1.2892799377441406, acc = 0.583984375\n",
      "Batch 66: loss = 1.243470549583435, acc = 0.5908203125\n",
      "Batch 67: loss = 1.2168092727661133, acc = 0.62109375\n",
      "Batch 68: loss = 1.2597310543060303, acc = 0.61328125\n",
      "Batch 69: loss = 1.232548713684082, acc = 0.6103515625\n",
      "Batch 70: loss = 1.3311618566513062, acc = 0.576171875\n",
      "Batch 71: loss = 1.2089178562164307, acc = 0.609375\n",
      "Batch 72: loss = 1.1856204271316528, acc = 0.62109375\n",
      "Batch 73: loss = 1.3250691890716553, acc = 0.5693359375\n",
      "Batch 74: loss = 1.2787892818450928, acc = 0.5791015625\n",
      "Batch 75: loss = 1.3812776803970337, acc = 0.52734375\n",
      "Batch 76: loss = 1.3583738803863525, acc = 0.578125\n",
      "Batch 77: loss = 1.1812236309051514, acc = 0.6240234375\n",
      "Batch 78: loss = 1.1856948137283325, acc = 0.607421875\n",
      "Batch 79: loss = 1.059051752090454, acc = 0.669921875\n",
      "Batch 80: loss = 1.1563310623168945, acc = 0.587890625\n",
      "Batch 81: loss = 1.1874942779541016, acc = 0.615234375\n",
      "Batch 82: loss = 1.1238043308258057, acc = 0.63671875\n",
      "Batch 83: loss = 1.2202693223953247, acc = 0.603515625\n",
      "Batch 84: loss = 1.2090961933135986, acc = 0.6171875\n",
      "Batch 85: loss = 1.3288850784301758, acc = 0.556640625\n",
      "Batch 86: loss = 1.263552188873291, acc = 0.583984375\n",
      "Batch 87: loss = 1.2036257982254028, acc = 0.623046875\n",
      "Batch 88: loss = 1.4008269309997559, acc = 0.556640625\n",
      "Batch 89: loss = 1.2809548377990723, acc = 0.595703125\n",
      "Batch 90: loss = 1.3888221979141235, acc = 0.564453125\n",
      "Batch 91: loss = 1.3335442543029785, acc = 0.5654296875\n",
      "Batch 92: loss = 1.1861751079559326, acc = 0.6162109375\n",
      "Batch 93: loss = 1.1443581581115723, acc = 0.63671875\n",
      "Batch 94: loss = 1.1970584392547607, acc = 0.6083984375\n",
      "Batch 95: loss = 1.2606827020645142, acc = 0.552734375\n",
      "Batch 96: loss = 1.2760705947875977, acc = 0.56640625\n",
      "Batch 97: loss = 1.2733561992645264, acc = 0.59765625\n",
      "Batch 98: loss = 1.2634975910186768, acc = 0.615234375\n",
      "Batch 99: loss = 1.2740226984024048, acc = 0.5859375\n",
      "Batch 100: loss = 1.2312419414520264, acc = 0.6025390625\n",
      "Batch 101: loss = 1.295137643814087, acc = 0.5927734375\n",
      "Batch 102: loss = 1.3715081214904785, acc = 0.5693359375\n",
      "Batch 103: loss = 1.3530991077423096, acc = 0.5673828125\n",
      "Batch 104: loss = 1.186345100402832, acc = 0.62109375\n",
      "Batch 105: loss = 1.247178316116333, acc = 0.60546875\n",
      "Batch 106: loss = 1.3307626247406006, acc = 0.5771484375\n",
      "Batch 107: loss = 1.2287462949752808, acc = 0.599609375\n",
      "Batch 108: loss = 1.2568018436431885, acc = 0.5888671875\n",
      "Batch 109: loss = 1.2314945459365845, acc = 0.59375\n",
      "Batch 110: loss = 1.1753010749816895, acc = 0.6240234375\n",
      "Batch 111: loss = 1.3934928178787231, acc = 0.55078125\n",
      "Batch 112: loss = 1.2163989543914795, acc = 0.6064453125\n",
      "Batch 113: loss = 1.2566369771957397, acc = 0.6025390625\n",
      "Batch 114: loss = 1.321523904800415, acc = 0.6103515625\n",
      "Batch 115: loss = 1.3652570247650146, acc = 0.5712890625\n",
      "Batch 116: loss = 1.3833675384521484, acc = 0.5712890625\n",
      "Batch 117: loss = 1.229066014289856, acc = 0.6142578125\n",
      "Batch 118: loss = 1.2173148393630981, acc = 0.6103515625\n",
      "Batch 119: loss = 1.2939567565917969, acc = 0.5849609375\n",
      "Batch 120: loss = 1.3717042207717896, acc = 0.568359375\n",
      "Batch 121: loss = 1.1993056535720825, acc = 0.6083984375\n",
      "Batch 122: loss = 1.2578952312469482, acc = 0.599609375\n",
      "Batch 123: loss = 1.2686717510223389, acc = 0.587890625\n",
      "Batch 124: loss = 1.30060875415802, acc = 0.560546875\n",
      "Batch 125: loss = 1.2883131504058838, acc = 0.5830078125\n",
      "Batch 126: loss = 1.397261619567871, acc = 0.578125\n",
      "\n",
      "Epoch 9/100\n",
      "Batch 1: loss = 1.631584644317627, acc = 0.541015625\n",
      "Batch 2: loss = 1.3823950290679932, acc = 0.5673828125\n",
      "Batch 3: loss = 1.3512874841690063, acc = 0.5810546875\n",
      "Batch 4: loss = 1.2864280939102173, acc = 0.5947265625\n",
      "Batch 5: loss = 1.4324772357940674, acc = 0.5546875\n",
      "Batch 6: loss = 1.43015456199646, acc = 0.55859375\n",
      "Batch 7: loss = 1.4333484172821045, acc = 0.5400390625\n",
      "Batch 8: loss = 1.248292326927185, acc = 0.591796875\n",
      "Batch 9: loss = 1.2587475776672363, acc = 0.5966796875\n",
      "Batch 10: loss = 1.1721903085708618, acc = 0.625\n",
      "Batch 11: loss = 1.3391194343566895, acc = 0.58203125\n",
      "Batch 12: loss = 1.428666114807129, acc = 0.5458984375\n",
      "Batch 13: loss = 1.3145992755889893, acc = 0.5732421875\n",
      "Batch 14: loss = 1.2268345355987549, acc = 0.5947265625\n",
      "Batch 15: loss = 1.2482249736785889, acc = 0.5986328125\n",
      "Batch 16: loss = 1.374279499053955, acc = 0.5498046875\n",
      "Batch 17: loss = 1.2897642850875854, acc = 0.591796875\n",
      "Batch 18: loss = 1.3714452981948853, acc = 0.5458984375\n",
      "Batch 19: loss = 1.363853931427002, acc = 0.572265625\n",
      "Batch 20: loss = 1.2349172830581665, acc = 0.603515625\n",
      "Batch 21: loss = 1.4122929573059082, acc = 0.5576171875\n",
      "Batch 22: loss = 1.2485936880111694, acc = 0.59375\n",
      "Batch 23: loss = 1.2506954669952393, acc = 0.5869140625\n",
      "Batch 24: loss = 1.3062491416931152, acc = 0.5771484375\n",
      "Batch 25: loss = 1.161280632019043, acc = 0.626953125\n",
      "Batch 26: loss = 1.2319109439849854, acc = 0.611328125\n",
      "Batch 27: loss = 1.305985450744629, acc = 0.572265625\n",
      "Batch 28: loss = 1.2856312990188599, acc = 0.58203125\n",
      "Batch 29: loss = 1.2413969039916992, acc = 0.6259765625\n",
      "Batch 30: loss = 1.208804965019226, acc = 0.609375\n",
      "Batch 31: loss = 1.366018533706665, acc = 0.5693359375\n",
      "Batch 32: loss = 1.5044300556182861, acc = 0.5322265625\n",
      "Batch 33: loss = 1.2964211702346802, acc = 0.5791015625\n",
      "Batch 34: loss = 1.2920567989349365, acc = 0.5859375\n",
      "Batch 35: loss = 1.2860212326049805, acc = 0.580078125\n",
      "Batch 36: loss = 1.325507640838623, acc = 0.5849609375\n",
      "Batch 37: loss = 1.3230466842651367, acc = 0.6025390625\n",
      "Batch 38: loss = 1.3442325592041016, acc = 0.5859375\n",
      "Batch 39: loss = 1.2907741069793701, acc = 0.5771484375\n",
      "Batch 40: loss = 1.2825520038604736, acc = 0.5830078125\n",
      "Batch 41: loss = 1.2198776006698608, acc = 0.60546875\n",
      "Batch 42: loss = 1.2211897373199463, acc = 0.6044921875\n",
      "Batch 43: loss = 1.2764637470245361, acc = 0.56640625\n",
      "Batch 44: loss = 1.2508894205093384, acc = 0.59765625\n",
      "Batch 45: loss = 1.1307580471038818, acc = 0.6318359375\n",
      "Batch 46: loss = 1.2581443786621094, acc = 0.6044921875\n",
      "Batch 47: loss = 1.1914620399475098, acc = 0.6220703125\n",
      "Batch 48: loss = 1.1485673189163208, acc = 0.6181640625\n",
      "Batch 49: loss = 1.0937204360961914, acc = 0.6494140625\n",
      "Batch 50: loss = 1.165737509727478, acc = 0.64453125\n",
      "Batch 51: loss = 1.1933181285858154, acc = 0.6015625\n",
      "Batch 52: loss = 1.3320151567459106, acc = 0.5673828125\n",
      "Batch 53: loss = 1.296142578125, acc = 0.5703125\n",
      "Batch 54: loss = 1.213341474533081, acc = 0.6201171875\n",
      "Batch 55: loss = 1.2221821546554565, acc = 0.5986328125\n",
      "Batch 56: loss = 1.2169008255004883, acc = 0.5966796875\n",
      "Batch 57: loss = 1.3095837831497192, acc = 0.5556640625\n",
      "Batch 58: loss = 1.279282808303833, acc = 0.58984375\n",
      "Batch 59: loss = 1.0685701370239258, acc = 0.654296875\n",
      "Batch 60: loss = 1.211998701095581, acc = 0.6015625\n",
      "Batch 61: loss = 1.3039028644561768, acc = 0.591796875\n",
      "Batch 62: loss = 1.44002366065979, acc = 0.5283203125\n",
      "Batch 63: loss = 1.3975765705108643, acc = 0.5576171875\n",
      "Batch 64: loss = 1.0284197330474854, acc = 0.67578125\n",
      "Batch 65: loss = 1.2359378337860107, acc = 0.599609375\n",
      "Batch 66: loss = 1.212010145187378, acc = 0.60546875\n",
      "Batch 67: loss = 1.1715238094329834, acc = 0.6318359375\n",
      "Batch 68: loss = 1.2086732387542725, acc = 0.6240234375\n",
      "Batch 69: loss = 1.1810541152954102, acc = 0.6279296875\n",
      "Batch 70: loss = 1.2820640802383423, acc = 0.5791015625\n",
      "Batch 71: loss = 1.1773552894592285, acc = 0.626953125\n",
      "Batch 72: loss = 1.1334271430969238, acc = 0.6298828125\n",
      "Batch 73: loss = 1.26399827003479, acc = 0.5908203125\n",
      "Batch 74: loss = 1.2423325777053833, acc = 0.5791015625\n",
      "Batch 75: loss = 1.3078006505966187, acc = 0.560546875\n",
      "Batch 76: loss = 1.3109489679336548, acc = 0.576171875\n",
      "Batch 77: loss = 1.122197151184082, acc = 0.634765625\n",
      "Batch 78: loss = 1.1441818475723267, acc = 0.62109375\n",
      "Batch 79: loss = 1.0224347114562988, acc = 0.6630859375\n",
      "Batch 80: loss = 1.103867769241333, acc = 0.62109375\n",
      "Batch 81: loss = 1.1352607011795044, acc = 0.63671875\n",
      "Batch 82: loss = 1.0735974311828613, acc = 0.6513671875\n",
      "Batch 83: loss = 1.1893417835235596, acc = 0.615234375\n",
      "Batch 84: loss = 1.1921710968017578, acc = 0.63671875\n",
      "Batch 85: loss = 1.2722452878952026, acc = 0.583984375\n",
      "Batch 86: loss = 1.2009363174438477, acc = 0.6083984375\n",
      "Batch 87: loss = 1.1666483879089355, acc = 0.619140625\n",
      "Batch 88: loss = 1.3473057746887207, acc = 0.5712890625\n",
      "Batch 89: loss = 1.2316186428070068, acc = 0.6044921875\n",
      "Batch 90: loss = 1.3438456058502197, acc = 0.591796875\n",
      "Batch 91: loss = 1.2847614288330078, acc = 0.5859375\n",
      "Batch 92: loss = 1.139777660369873, acc = 0.63671875\n",
      "Batch 93: loss = 1.105278730392456, acc = 0.6533203125\n",
      "Batch 94: loss = 1.143876075744629, acc = 0.6279296875\n",
      "Batch 95: loss = 1.2269530296325684, acc = 0.5751953125\n",
      "Batch 96: loss = 1.2171247005462646, acc = 0.5888671875\n",
      "Batch 97: loss = 1.23635995388031, acc = 0.6005859375\n",
      "Batch 98: loss = 1.247568130493164, acc = 0.6279296875\n",
      "Batch 99: loss = 1.2318594455718994, acc = 0.603515625\n",
      "Batch 100: loss = 1.1863480806350708, acc = 0.5966796875\n",
      "Batch 101: loss = 1.23982834815979, acc = 0.6015625\n",
      "Batch 102: loss = 1.3268811702728271, acc = 0.580078125\n",
      "Batch 103: loss = 1.2803902626037598, acc = 0.5869140625\n",
      "Batch 104: loss = 1.1580631732940674, acc = 0.6162109375\n",
      "Batch 105: loss = 1.1894865036010742, acc = 0.6298828125\n",
      "Batch 106: loss = 1.26682710647583, acc = 0.607421875\n",
      "Batch 107: loss = 1.1983027458190918, acc = 0.609375\n",
      "Batch 108: loss = 1.2034839391708374, acc = 0.6025390625\n",
      "Batch 109: loss = 1.1921963691711426, acc = 0.6005859375\n",
      "Batch 110: loss = 1.1358959674835205, acc = 0.6484375\n",
      "Batch 111: loss = 1.3254053592681885, acc = 0.5771484375\n",
      "Batch 112: loss = 1.1663525104522705, acc = 0.626953125\n",
      "Batch 113: loss = 1.2002742290496826, acc = 0.623046875\n",
      "Batch 114: loss = 1.2764785289764404, acc = 0.6201171875\n",
      "Batch 115: loss = 1.330691933631897, acc = 0.5810546875\n",
      "Batch 116: loss = 1.3237295150756836, acc = 0.5888671875\n",
      "Batch 117: loss = 1.1740319728851318, acc = 0.625\n",
      "Batch 118: loss = 1.1512359380722046, acc = 0.6142578125\n",
      "Batch 119: loss = 1.2641435861587524, acc = 0.58984375\n",
      "Batch 120: loss = 1.3333187103271484, acc = 0.5703125\n",
      "Batch 121: loss = 1.162262201309204, acc = 0.619140625\n",
      "Batch 122: loss = 1.1831731796264648, acc = 0.6181640625\n",
      "Batch 123: loss = 1.2066625356674194, acc = 0.615234375\n",
      "Batch 124: loss = 1.2567944526672363, acc = 0.572265625\n",
      "Batch 125: loss = 1.239695429801941, acc = 0.58203125\n",
      "Batch 126: loss = 1.3520673513412476, acc = 0.58203125\n",
      "\n",
      "Epoch 10/100\n",
      "Batch 1: loss = 1.5758752822875977, acc = 0.546875\n",
      "Batch 2: loss = 1.3425123691558838, acc = 0.5693359375\n",
      "Batch 3: loss = 1.2969861030578613, acc = 0.60546875\n",
      "Batch 4: loss = 1.2508554458618164, acc = 0.6015625\n",
      "Batch 5: loss = 1.4087433815002441, acc = 0.556640625\n",
      "Batch 6: loss = 1.4013246297836304, acc = 0.5634765625\n",
      "Batch 7: loss = 1.3906491994857788, acc = 0.560546875\n",
      "Batch 8: loss = 1.2057679891586304, acc = 0.61328125\n",
      "Batch 9: loss = 1.209824562072754, acc = 0.611328125\n",
      "Batch 10: loss = 1.1361582279205322, acc = 0.6240234375\n",
      "Batch 11: loss = 1.3014634847640991, acc = 0.57421875\n",
      "Batch 12: loss = 1.381690263748169, acc = 0.54296875\n",
      "Batch 13: loss = 1.2722983360290527, acc = 0.5947265625\n",
      "Batch 14: loss = 1.188995361328125, acc = 0.599609375\n",
      "Batch 15: loss = 1.2212822437286377, acc = 0.6083984375\n",
      "Batch 16: loss = 1.3099042177200317, acc = 0.5595703125\n",
      "Batch 17: loss = 1.267317533493042, acc = 0.5888671875\n",
      "Batch 18: loss = 1.3226900100708008, acc = 0.564453125\n",
      "Batch 19: loss = 1.2902469635009766, acc = 0.5869140625\n",
      "Batch 20: loss = 1.17692232131958, acc = 0.6171875\n",
      "Batch 21: loss = 1.3684285879135132, acc = 0.5712890625\n",
      "Batch 22: loss = 1.1852335929870605, acc = 0.611328125\n",
      "Batch 23: loss = 1.187653660774231, acc = 0.599609375\n",
      "Batch 24: loss = 1.244042158126831, acc = 0.5888671875\n",
      "Batch 25: loss = 1.1333379745483398, acc = 0.6376953125\n",
      "Batch 26: loss = 1.1673884391784668, acc = 0.6318359375\n",
      "Batch 27: loss = 1.2748632431030273, acc = 0.6025390625\n",
      "Batch 28: loss = 1.2316713333129883, acc = 0.5908203125\n",
      "Batch 29: loss = 1.195317268371582, acc = 0.6396484375\n",
      "Batch 30: loss = 1.1666569709777832, acc = 0.626953125\n",
      "Batch 31: loss = 1.295475721359253, acc = 0.5986328125\n",
      "Batch 32: loss = 1.4338327646255493, acc = 0.5546875\n",
      "Batch 33: loss = 1.2485570907592773, acc = 0.607421875\n",
      "Batch 34: loss = 1.249049425125122, acc = 0.60546875\n",
      "Batch 35: loss = 1.259730577468872, acc = 0.58984375\n",
      "Batch 36: loss = 1.279484510421753, acc = 0.599609375\n",
      "Batch 37: loss = 1.2493183612823486, acc = 0.6142578125\n",
      "Batch 38: loss = 1.2901276350021362, acc = 0.62109375\n",
      "Batch 39: loss = 1.2438093423843384, acc = 0.5927734375\n",
      "Batch 40: loss = 1.240020990371704, acc = 0.5986328125\n",
      "Batch 41: loss = 1.1766784191131592, acc = 0.619140625\n",
      "Batch 42: loss = 1.1717720031738281, acc = 0.6220703125\n",
      "Batch 43: loss = 1.2384395599365234, acc = 0.5927734375\n",
      "Batch 44: loss = 1.1950232982635498, acc = 0.6142578125\n",
      "Batch 45: loss = 1.1008851528167725, acc = 0.640625\n",
      "Batch 46: loss = 1.2067468166351318, acc = 0.6220703125\n",
      "Batch 47: loss = 1.1481395959854126, acc = 0.6279296875\n",
      "Batch 48: loss = 1.1068012714385986, acc = 0.6279296875\n",
      "Batch 49: loss = 1.0662312507629395, acc = 0.6572265625\n",
      "Batch 50: loss = 1.1164872646331787, acc = 0.6513671875\n",
      "Batch 51: loss = 1.1298840045928955, acc = 0.6201171875\n",
      "Batch 52: loss = 1.2645996809005737, acc = 0.59375\n",
      "Batch 53: loss = 1.2506253719329834, acc = 0.595703125\n",
      "Batch 54: loss = 1.1842658519744873, acc = 0.6357421875\n",
      "Batch 55: loss = 1.1685559749603271, acc = 0.6328125\n",
      "Batch 56: loss = 1.180098295211792, acc = 0.5947265625\n",
      "Batch 57: loss = 1.28020179271698, acc = 0.5576171875\n",
      "Batch 58: loss = 1.2325031757354736, acc = 0.609375\n",
      "Batch 59: loss = 1.0275113582611084, acc = 0.6748046875\n",
      "Batch 60: loss = 1.1775206327438354, acc = 0.6044921875\n",
      "Batch 61: loss = 1.2460170984268188, acc = 0.609375\n",
      "Batch 62: loss = 1.3869171142578125, acc = 0.544921875\n",
      "Batch 63: loss = 1.3477520942687988, acc = 0.572265625\n",
      "Batch 64: loss = 0.9906441569328308, acc = 0.673828125\n",
      "Batch 65: loss = 1.1776723861694336, acc = 0.6337890625\n",
      "Batch 66: loss = 1.1769742965698242, acc = 0.61328125\n",
      "Batch 67: loss = 1.1137290000915527, acc = 0.662109375\n",
      "Batch 68: loss = 1.1875405311584473, acc = 0.6240234375\n",
      "Batch 69: loss = 1.1426607370376587, acc = 0.64453125\n",
      "Batch 70: loss = 1.2343730926513672, acc = 0.599609375\n",
      "Batch 71: loss = 1.1182787418365479, acc = 0.638671875\n",
      "Batch 72: loss = 1.1070597171783447, acc = 0.6357421875\n",
      "Batch 73: loss = 1.223931908607483, acc = 0.595703125\n",
      "Batch 74: loss = 1.2075409889221191, acc = 0.5908203125\n",
      "Batch 75: loss = 1.2836066484451294, acc = 0.583984375\n",
      "Batch 76: loss = 1.2706843614578247, acc = 0.5927734375\n",
      "Batch 77: loss = 1.0928038358688354, acc = 0.6513671875\n",
      "Batch 78: loss = 1.118032693862915, acc = 0.63671875\n",
      "Batch 79: loss = 0.9801287055015564, acc = 0.677734375\n",
      "Batch 80: loss = 1.0680994987487793, acc = 0.630859375\n",
      "Batch 81: loss = 1.095231056213379, acc = 0.64453125\n",
      "Batch 82: loss = 1.0309717655181885, acc = 0.662109375\n",
      "Batch 83: loss = 1.1655908823013306, acc = 0.619140625\n",
      "Batch 84: loss = 1.1427513360977173, acc = 0.6337890625\n",
      "Batch 85: loss = 1.2534101009368896, acc = 0.6005859375\n",
      "Batch 86: loss = 1.1839690208435059, acc = 0.6005859375\n",
      "Batch 87: loss = 1.109727144241333, acc = 0.6328125\n",
      "Batch 88: loss = 1.2859821319580078, acc = 0.572265625\n",
      "Batch 89: loss = 1.18892240524292, acc = 0.6142578125\n",
      "Batch 90: loss = 1.3160145282745361, acc = 0.5927734375\n",
      "Batch 91: loss = 1.25320303440094, acc = 0.5927734375\n",
      "Batch 92: loss = 1.116652011871338, acc = 0.640625\n",
      "Batch 93: loss = 1.0469170808792114, acc = 0.6787109375\n",
      "Batch 94: loss = 1.106873869895935, acc = 0.63671875\n",
      "Batch 95: loss = 1.1876190900802612, acc = 0.58984375\n",
      "Batch 96: loss = 1.193526029586792, acc = 0.60546875\n",
      "Batch 97: loss = 1.1881399154663086, acc = 0.6181640625\n",
      "Batch 98: loss = 1.1820828914642334, acc = 0.6396484375\n",
      "Batch 99: loss = 1.1849676370620728, acc = 0.6103515625\n",
      "Batch 100: loss = 1.1617274284362793, acc = 0.6201171875\n",
      "Batch 101: loss = 1.1966602802276611, acc = 0.6142578125\n",
      "Batch 102: loss = 1.2681965827941895, acc = 0.611328125\n",
      "Batch 103: loss = 1.2165839672088623, acc = 0.609375\n",
      "Batch 104: loss = 1.1006873846054077, acc = 0.6357421875\n",
      "Batch 105: loss = 1.1553537845611572, acc = 0.6318359375\n",
      "Batch 106: loss = 1.2321923971176147, acc = 0.6171875\n",
      "Batch 107: loss = 1.131459355354309, acc = 0.650390625\n",
      "Batch 108: loss = 1.1723620891571045, acc = 0.6142578125\n",
      "Batch 109: loss = 1.1368539333343506, acc = 0.62890625\n",
      "Batch 110: loss = 1.0851671695709229, acc = 0.658203125\n",
      "Batch 111: loss = 1.2762757539749146, acc = 0.5869140625\n",
      "Batch 112: loss = 1.1228325366973877, acc = 0.62890625\n",
      "Batch 113: loss = 1.157702088356018, acc = 0.6328125\n",
      "Batch 114: loss = 1.2114250659942627, acc = 0.6328125\n",
      "Batch 115: loss = 1.2811895608901978, acc = 0.583984375\n",
      "Batch 116: loss = 1.3036367893218994, acc = 0.5966796875\n",
      "Batch 117: loss = 1.1600723266601562, acc = 0.626953125\n",
      "Batch 118: loss = 1.1129720211029053, acc = 0.6376953125\n",
      "Batch 119: loss = 1.2075653076171875, acc = 0.6015625\n",
      "Batch 120: loss = 1.266350507736206, acc = 0.580078125\n",
      "Batch 121: loss = 1.11201810836792, acc = 0.642578125\n",
      "Batch 122: loss = 1.145810604095459, acc = 0.6396484375\n",
      "Batch 123: loss = 1.199703335762024, acc = 0.6171875\n",
      "Batch 124: loss = 1.2267307043075562, acc = 0.5810546875\n",
      "Batch 125: loss = 1.191122055053711, acc = 0.607421875\n",
      "Batch 126: loss = 1.3175625801086426, acc = 0.587890625\n",
      "\n",
      "Epoch 11/100\n",
      "Batch 1: loss = 1.5088447332382202, acc = 0.560546875\n",
      "Batch 2: loss = 1.3272936344146729, acc = 0.5869140625\n",
      "Batch 3: loss = 1.2534102201461792, acc = 0.62109375\n",
      "Batch 4: loss = 1.1979212760925293, acc = 0.625\n",
      "Batch 5: loss = 1.3558533191680908, acc = 0.5732421875\n",
      "Batch 6: loss = 1.3608629703521729, acc = 0.5712890625\n",
      "Batch 7: loss = 1.3284213542938232, acc = 0.5771484375\n",
      "Batch 8: loss = 1.1741183996200562, acc = 0.6123046875\n",
      "Batch 9: loss = 1.1625843048095703, acc = 0.6318359375\n",
      "Batch 10: loss = 1.0987064838409424, acc = 0.6396484375\n",
      "Batch 11: loss = 1.2473161220550537, acc = 0.6025390625\n",
      "Batch 12: loss = 1.3144023418426514, acc = 0.564453125\n",
      "Batch 13: loss = 1.2140462398529053, acc = 0.5966796875\n",
      "Batch 14: loss = 1.1515032052993774, acc = 0.6064453125\n",
      "Batch 15: loss = 1.1664884090423584, acc = 0.611328125\n",
      "Batch 16: loss = 1.2742042541503906, acc = 0.568359375\n",
      "Batch 17: loss = 1.1994366645812988, acc = 0.6142578125\n",
      "Batch 18: loss = 1.3081247806549072, acc = 0.5634765625\n",
      "Batch 19: loss = 1.2518177032470703, acc = 0.6015625\n",
      "Batch 20: loss = 1.1390597820281982, acc = 0.6181640625\n",
      "Batch 21: loss = 1.3337348699569702, acc = 0.5703125\n",
      "Batch 22: loss = 1.1564078330993652, acc = 0.6181640625\n",
      "Batch 23: loss = 1.161260724067688, acc = 0.6103515625\n",
      "Batch 24: loss = 1.1886780261993408, acc = 0.6181640625\n",
      "Batch 25: loss = 1.0829322338104248, acc = 0.6494140625\n",
      "Batch 26: loss = 1.1217257976531982, acc = 0.6484375\n",
      "Batch 27: loss = 1.221135139465332, acc = 0.62890625\n",
      "Batch 28: loss = 1.1816201210021973, acc = 0.6181640625\n",
      "Batch 29: loss = 1.1579080820083618, acc = 0.64453125\n",
      "Batch 30: loss = 1.1374566555023193, acc = 0.6259765625\n",
      "Batch 31: loss = 1.2522084712982178, acc = 0.607421875\n",
      "Batch 32: loss = 1.3947404623031616, acc = 0.564453125\n",
      "Batch 33: loss = 1.199486255645752, acc = 0.6201171875\n",
      "Batch 34: loss = 1.203301191329956, acc = 0.603515625\n",
      "Batch 35: loss = 1.2053337097167969, acc = 0.6220703125\n",
      "Batch 36: loss = 1.2280378341674805, acc = 0.6142578125\n",
      "Batch 37: loss = 1.2155804634094238, acc = 0.619140625\n",
      "Batch 38: loss = 1.2659506797790527, acc = 0.607421875\n",
      "Batch 39: loss = 1.2099864482879639, acc = 0.6005859375\n",
      "Batch 40: loss = 1.1649808883666992, acc = 0.630859375\n",
      "Batch 41: loss = 1.1160093545913696, acc = 0.6318359375\n",
      "Batch 42: loss = 1.133479356765747, acc = 0.62890625\n",
      "Batch 43: loss = 1.1940118074417114, acc = 0.6005859375\n",
      "Batch 44: loss = 1.1491787433624268, acc = 0.6357421875\n",
      "Batch 45: loss = 1.0421321392059326, acc = 0.66015625\n",
      "Batch 46: loss = 1.1493704319000244, acc = 0.640625\n",
      "Batch 47: loss = 1.106436014175415, acc = 0.6572265625\n",
      "Batch 48: loss = 1.0496317148208618, acc = 0.6435546875\n",
      "Batch 49: loss = 1.0053657293319702, acc = 0.6796875\n",
      "Batch 50: loss = 1.0689129829406738, acc = 0.673828125\n",
      "Batch 51: loss = 1.1000187397003174, acc = 0.6279296875\n",
      "Batch 52: loss = 1.231693983078003, acc = 0.587890625\n",
      "Batch 53: loss = 1.2225667238235474, acc = 0.6142578125\n",
      "Batch 54: loss = 1.1184805631637573, acc = 0.65234375\n",
      "Batch 55: loss = 1.1305387020111084, acc = 0.634765625\n",
      "Batch 56: loss = 1.1200296878814697, acc = 0.623046875\n",
      "Batch 57: loss = 1.2378729581832886, acc = 0.5712890625\n",
      "Batch 58: loss = 1.1957380771636963, acc = 0.615234375\n",
      "Batch 59: loss = 0.9879094362258911, acc = 0.6962890625\n",
      "Batch 60: loss = 1.1599295139312744, acc = 0.6162109375\n",
      "Batch 61: loss = 1.212770938873291, acc = 0.626953125\n",
      "Batch 62: loss = 1.3673150539398193, acc = 0.5390625\n",
      "Batch 63: loss = 1.3103439807891846, acc = 0.5908203125\n",
      "Batch 64: loss = 0.9505853652954102, acc = 0.685546875\n",
      "Batch 65: loss = 1.1574866771697998, acc = 0.619140625\n",
      "Batch 66: loss = 1.1083441972732544, acc = 0.6396484375\n",
      "Batch 67: loss = 1.085085153579712, acc = 0.6650390625\n",
      "Batch 68: loss = 1.1420515775680542, acc = 0.64453125\n",
      "Batch 69: loss = 1.1152375936508179, acc = 0.64453125\n",
      "Batch 70: loss = 1.1918118000030518, acc = 0.6142578125\n",
      "Batch 71: loss = 1.0921778678894043, acc = 0.650390625\n",
      "Batch 72: loss = 1.0697160959243774, acc = 0.6484375\n",
      "Batch 73: loss = 1.2023563385009766, acc = 0.6171875\n",
      "Batch 74: loss = 1.1644582748413086, acc = 0.6201171875\n",
      "Batch 75: loss = 1.2624304294586182, acc = 0.576171875\n",
      "Batch 76: loss = 1.2347450256347656, acc = 0.59765625\n",
      "Batch 77: loss = 1.0540138483047485, acc = 0.650390625\n",
      "Batch 78: loss = 1.0932819843292236, acc = 0.6337890625\n",
      "Batch 79: loss = 0.9563987255096436, acc = 0.6875\n",
      "Batch 80: loss = 1.0043818950653076, acc = 0.63671875\n",
      "Batch 81: loss = 1.0694537162780762, acc = 0.6513671875\n",
      "Batch 82: loss = 0.9905068278312683, acc = 0.681640625\n",
      "Batch 83: loss = 1.1222147941589355, acc = 0.6240234375\n",
      "Batch 84: loss = 1.100106120109558, acc = 0.6376953125\n",
      "Batch 85: loss = 1.1965365409851074, acc = 0.6103515625\n",
      "Batch 86: loss = 1.147756814956665, acc = 0.626953125\n",
      "Batch 87: loss = 1.073959231376648, acc = 0.64453125\n",
      "Batch 88: loss = 1.245994210243225, acc = 0.587890625\n",
      "Batch 89: loss = 1.1511495113372803, acc = 0.6337890625\n",
      "Batch 90: loss = 1.2499520778656006, acc = 0.609375\n",
      "Batch 91: loss = 1.2087841033935547, acc = 0.6005859375\n",
      "Batch 92: loss = 1.081352949142456, acc = 0.650390625\n",
      "Batch 93: loss = 1.014400601387024, acc = 0.6748046875\n",
      "Batch 94: loss = 1.078505277633667, acc = 0.642578125\n",
      "Batch 95: loss = 1.1369385719299316, acc = 0.6142578125\n",
      "Batch 96: loss = 1.1708216667175293, acc = 0.609375\n",
      "Batch 97: loss = 1.1436381340026855, acc = 0.623046875\n",
      "Batch 98: loss = 1.1426074504852295, acc = 0.6474609375\n",
      "Batch 99: loss = 1.155844807624817, acc = 0.60546875\n",
      "Batch 100: loss = 1.1067397594451904, acc = 0.625\n",
      "Batch 101: loss = 1.146228313446045, acc = 0.6318359375\n",
      "Batch 102: loss = 1.2366807460784912, acc = 0.599609375\n",
      "Batch 103: loss = 1.1901724338531494, acc = 0.62109375\n",
      "Batch 104: loss = 1.0772156715393066, acc = 0.640625\n",
      "Batch 105: loss = 1.123112440109253, acc = 0.64453125\n",
      "Batch 106: loss = 1.2107315063476562, acc = 0.619140625\n",
      "Batch 107: loss = 1.1103179454803467, acc = 0.646484375\n",
      "Batch 108: loss = 1.141568660736084, acc = 0.625\n",
      "Batch 109: loss = 1.1115195751190186, acc = 0.625\n",
      "Batch 110: loss = 1.050865650177002, acc = 0.658203125\n",
      "Batch 111: loss = 1.2358989715576172, acc = 0.587890625\n",
      "Batch 112: loss = 1.093421459197998, acc = 0.6240234375\n",
      "Batch 113: loss = 1.1443781852722168, acc = 0.642578125\n",
      "Batch 114: loss = 1.1962337493896484, acc = 0.6357421875\n",
      "Batch 115: loss = 1.2226473093032837, acc = 0.5947265625\n",
      "Batch 116: loss = 1.2771921157836914, acc = 0.6025390625\n",
      "Batch 117: loss = 1.0947014093399048, acc = 0.6494140625\n",
      "Batch 118: loss = 1.0737619400024414, acc = 0.6435546875\n",
      "Batch 119: loss = 1.1521308422088623, acc = 0.625\n",
      "Batch 120: loss = 1.222078800201416, acc = 0.5966796875\n",
      "Batch 121: loss = 1.094374179840088, acc = 0.6416015625\n",
      "Batch 122: loss = 1.1236546039581299, acc = 0.63671875\n",
      "Batch 123: loss = 1.152957558631897, acc = 0.6298828125\n",
      "Batch 124: loss = 1.1857644319534302, acc = 0.5927734375\n",
      "Batch 125: loss = 1.1619043350219727, acc = 0.6162109375\n",
      "Batch 126: loss = 1.2826663255691528, acc = 0.6015625\n",
      "\n",
      "Epoch 12/100\n",
      "Batch 1: loss = 1.4581881761550903, acc = 0.5771484375\n",
      "Batch 2: loss = 1.284073829650879, acc = 0.5791015625\n",
      "Batch 3: loss = 1.2034194469451904, acc = 0.625\n",
      "Batch 4: loss = 1.162123680114746, acc = 0.6201171875\n",
      "Batch 5: loss = 1.2937226295471191, acc = 0.580078125\n",
      "Batch 6: loss = 1.3067162036895752, acc = 0.58203125\n",
      "Batch 7: loss = 1.2833586931228638, acc = 0.5859375\n",
      "Batch 8: loss = 1.1422357559204102, acc = 0.623046875\n",
      "Batch 9: loss = 1.1216647624969482, acc = 0.6455078125\n",
      "Batch 10: loss = 1.0540204048156738, acc = 0.66015625\n",
      "Batch 11: loss = 1.2183513641357422, acc = 0.591796875\n",
      "Batch 12: loss = 1.282039761543274, acc = 0.58984375\n",
      "Batch 13: loss = 1.1625888347625732, acc = 0.6083984375\n",
      "Batch 14: loss = 1.1164672374725342, acc = 0.6376953125\n",
      "Batch 15: loss = 1.123017430305481, acc = 0.6318359375\n",
      "Batch 16: loss = 1.22420072555542, acc = 0.59375\n",
      "Batch 17: loss = 1.1896281242370605, acc = 0.61328125\n",
      "Batch 18: loss = 1.234855055809021, acc = 0.587890625\n",
      "Batch 19: loss = 1.204439401626587, acc = 0.6171875\n",
      "Batch 20: loss = 1.1100454330444336, acc = 0.6279296875\n",
      "Batch 21: loss = 1.279769778251648, acc = 0.568359375\n",
      "Batch 22: loss = 1.1015524864196777, acc = 0.625\n",
      "Batch 23: loss = 1.104343295097351, acc = 0.6240234375\n",
      "Batch 24: loss = 1.1527749300003052, acc = 0.6220703125\n",
      "Batch 25: loss = 1.048805594444275, acc = 0.6455078125\n",
      "Batch 26: loss = 1.0647286176681519, acc = 0.6669921875\n",
      "Batch 27: loss = 1.2102082967758179, acc = 0.609375\n",
      "Batch 28: loss = 1.148539423942566, acc = 0.6220703125\n",
      "Batch 29: loss = 1.1194746494293213, acc = 0.6484375\n",
      "Batch 30: loss = 1.080174207687378, acc = 0.6572265625\n",
      "Batch 31: loss = 1.217048168182373, acc = 0.60546875\n",
      "Batch 32: loss = 1.3426518440246582, acc = 0.5673828125\n",
      "Batch 33: loss = 1.1613280773162842, acc = 0.6201171875\n",
      "Batch 34: loss = 1.1667494773864746, acc = 0.607421875\n",
      "Batch 35: loss = 1.1830146312713623, acc = 0.6064453125\n",
      "Batch 36: loss = 1.1690020561218262, acc = 0.6337890625\n",
      "Batch 37: loss = 1.1973481178283691, acc = 0.625\n",
      "Batch 38: loss = 1.2308827638626099, acc = 0.6298828125\n",
      "Batch 39: loss = 1.1684207916259766, acc = 0.623046875\n",
      "Batch 40: loss = 1.1534262895584106, acc = 0.625\n",
      "Batch 41: loss = 1.0861859321594238, acc = 0.6455078125\n",
      "Batch 42: loss = 1.1024870872497559, acc = 0.646484375\n",
      "Batch 43: loss = 1.157780408859253, acc = 0.60546875\n",
      "Batch 44: loss = 1.1121034622192383, acc = 0.634765625\n",
      "Batch 45: loss = 1.0120681524276733, acc = 0.6572265625\n",
      "Batch 46: loss = 1.1177120208740234, acc = 0.6259765625\n",
      "Batch 47: loss = 1.0564172267913818, acc = 0.6611328125\n",
      "Batch 48: loss = 1.0243415832519531, acc = 0.650390625\n",
      "Batch 49: loss = 0.9806819558143616, acc = 0.68359375\n",
      "Batch 50: loss = 1.0532901287078857, acc = 0.666015625\n",
      "Batch 51: loss = 1.060718297958374, acc = 0.6357421875\n",
      "Batch 52: loss = 1.1847227811813354, acc = 0.6181640625\n",
      "Batch 53: loss = 1.166003942489624, acc = 0.630859375\n",
      "Batch 54: loss = 1.097752332687378, acc = 0.6396484375\n",
      "Batch 55: loss = 1.0901403427124023, acc = 0.6435546875\n",
      "Batch 56: loss = 1.098259687423706, acc = 0.6201171875\n",
      "Batch 57: loss = 1.198591709136963, acc = 0.58203125\n",
      "Batch 58: loss = 1.1786749362945557, acc = 0.6181640625\n",
      "Batch 59: loss = 0.944711446762085, acc = 0.7041015625\n",
      "Batch 60: loss = 1.1102327108383179, acc = 0.6240234375\n",
      "Batch 61: loss = 1.1904590129852295, acc = 0.6357421875\n",
      "Batch 62: loss = 1.325483798980713, acc = 0.556640625\n",
      "Batch 63: loss = 1.283553123474121, acc = 0.583984375\n",
      "Batch 64: loss = 0.9225249886512756, acc = 0.7041015625\n",
      "Batch 65: loss = 1.1269686222076416, acc = 0.634765625\n",
      "Batch 66: loss = 1.1049449443817139, acc = 0.638671875\n",
      "Batch 67: loss = 1.0419634580612183, acc = 0.6708984375\n",
      "Batch 68: loss = 1.1062240600585938, acc = 0.6513671875\n",
      "Batch 69: loss = 1.091604232788086, acc = 0.654296875\n",
      "Batch 70: loss = 1.1792727708816528, acc = 0.626953125\n",
      "Batch 71: loss = 1.0612833499908447, acc = 0.65234375\n",
      "Batch 72: loss = 1.0211138725280762, acc = 0.658203125\n",
      "Batch 73: loss = 1.169691562652588, acc = 0.61328125\n",
      "Batch 74: loss = 1.150836706161499, acc = 0.6123046875\n",
      "Batch 75: loss = 1.2035713195800781, acc = 0.5908203125\n",
      "Batch 76: loss = 1.191088080406189, acc = 0.607421875\n",
      "Batch 77: loss = 1.0366861820220947, acc = 0.6640625\n",
      "Batch 78: loss = 1.0534472465515137, acc = 0.65234375\n",
      "Batch 79: loss = 0.9160937070846558, acc = 0.7001953125\n",
      "Batch 80: loss = 0.9927664399147034, acc = 0.6416015625\n",
      "Batch 81: loss = 1.0449397563934326, acc = 0.6669921875\n",
      "Batch 82: loss = 0.9592044949531555, acc = 0.69921875\n",
      "Batch 83: loss = 1.0885107517242432, acc = 0.63671875\n",
      "Batch 84: loss = 1.0651798248291016, acc = 0.6572265625\n",
      "Batch 85: loss = 1.1880786418914795, acc = 0.6025390625\n",
      "Batch 86: loss = 1.0966241359710693, acc = 0.64453125\n",
      "Batch 87: loss = 1.0629420280456543, acc = 0.654296875\n",
      "Batch 88: loss = 1.215714693069458, acc = 0.609375\n",
      "Batch 89: loss = 1.1146724224090576, acc = 0.64453125\n",
      "Batch 90: loss = 1.2150989770889282, acc = 0.6201171875\n",
      "Batch 91: loss = 1.1681028604507446, acc = 0.607421875\n",
      "Batch 92: loss = 1.0558795928955078, acc = 0.6484375\n",
      "Batch 93: loss = 1.0018081665039062, acc = 0.6845703125\n",
      "Batch 94: loss = 1.0372555255889893, acc = 0.66796875\n",
      "Batch 95: loss = 1.0970301628112793, acc = 0.6220703125\n",
      "Batch 96: loss = 1.105698823928833, acc = 0.6318359375\n",
      "Batch 97: loss = 1.1005489826202393, acc = 0.646484375\n",
      "Batch 98: loss = 1.1050317287445068, acc = 0.65234375\n",
      "Batch 99: loss = 1.1206305027008057, acc = 0.6220703125\n",
      "Batch 100: loss = 1.080762505531311, acc = 0.6318359375\n",
      "Batch 101: loss = 1.1073129177093506, acc = 0.6396484375\n",
      "Batch 102: loss = 1.2040067911148071, acc = 0.619140625\n",
      "Batch 103: loss = 1.156728744506836, acc = 0.626953125\n",
      "Batch 104: loss = 1.0595180988311768, acc = 0.6455078125\n",
      "Batch 105: loss = 1.0968031883239746, acc = 0.654296875\n",
      "Batch 106: loss = 1.1603325605392456, acc = 0.6259765625\n",
      "Batch 107: loss = 1.08713698387146, acc = 0.646484375\n",
      "Batch 108: loss = 1.0918978452682495, acc = 0.6328125\n",
      "Batch 109: loss = 1.073875904083252, acc = 0.638671875\n",
      "Batch 110: loss = 1.0017542839050293, acc = 0.6865234375\n",
      "Batch 111: loss = 1.2202039957046509, acc = 0.6044921875\n",
      "Batch 112: loss = 1.0602858066558838, acc = 0.64453125\n",
      "Batch 113: loss = 1.1238774061203003, acc = 0.6572265625\n",
      "Batch 114: loss = 1.1590547561645508, acc = 0.65234375\n",
      "Batch 115: loss = 1.189279556274414, acc = 0.61328125\n",
      "Batch 116: loss = 1.229909896850586, acc = 0.6162109375\n",
      "Batch 117: loss = 1.0604740381240845, acc = 0.6552734375\n",
      "Batch 118: loss = 1.0256426334381104, acc = 0.666015625\n",
      "Batch 119: loss = 1.1151680946350098, acc = 0.6259765625\n",
      "Batch 120: loss = 1.1863782405853271, acc = 0.6015625\n",
      "Batch 121: loss = 1.059117317199707, acc = 0.6611328125\n",
      "Batch 122: loss = 1.0738214254379272, acc = 0.65625\n",
      "Batch 123: loss = 1.1071269512176514, acc = 0.6533203125\n",
      "Batch 124: loss = 1.1378505229949951, acc = 0.615234375\n",
      "Batch 125: loss = 1.157364845275879, acc = 0.626953125\n",
      "Batch 126: loss = 1.2370789051055908, acc = 0.625\n",
      "\n",
      "Epoch 13/100\n",
      "Batch 1: loss = 1.431519627571106, acc = 0.5732421875\n",
      "Batch 2: loss = 1.2570631504058838, acc = 0.603515625\n",
      "Batch 3: loss = 1.1797058582305908, acc = 0.630859375\n",
      "Batch 4: loss = 1.1470779180526733, acc = 0.6328125\n",
      "Batch 5: loss = 1.2817704677581787, acc = 0.5830078125\n",
      "Batch 6: loss = 1.2542650699615479, acc = 0.607421875\n",
      "Batch 7: loss = 1.2345209121704102, acc = 0.5947265625\n",
      "Batch 8: loss = 1.1061395406723022, acc = 0.6484375\n",
      "Batch 9: loss = 1.0749099254608154, acc = 0.65234375\n",
      "Batch 10: loss = 1.0490472316741943, acc = 0.6689453125\n",
      "Batch 11: loss = 1.187934160232544, acc = 0.6142578125\n",
      "Batch 12: loss = 1.2477028369903564, acc = 0.5888671875\n",
      "Batch 13: loss = 1.150884747505188, acc = 0.6201171875\n",
      "Batch 14: loss = 1.0850799083709717, acc = 0.64453125\n",
      "Batch 15: loss = 1.0819134712219238, acc = 0.66015625\n",
      "Batch 16: loss = 1.1882116794586182, acc = 0.611328125\n",
      "Batch 17: loss = 1.1387884616851807, acc = 0.6357421875\n",
      "Batch 18: loss = 1.195826768875122, acc = 0.59765625\n",
      "Batch 19: loss = 1.163648247718811, acc = 0.630859375\n",
      "Batch 20: loss = 1.074033498764038, acc = 0.654296875\n",
      "Batch 21: loss = 1.2554311752319336, acc = 0.5888671875\n",
      "Batch 22: loss = 1.092718482017517, acc = 0.6513671875\n",
      "Batch 23: loss = 1.091341495513916, acc = 0.63671875\n",
      "Batch 24: loss = 1.1085339784622192, acc = 0.6416015625\n",
      "Batch 25: loss = 1.0162696838378906, acc = 0.66015625\n",
      "Batch 26: loss = 1.062697410583496, acc = 0.6630859375\n",
      "Batch 27: loss = 1.1530232429504395, acc = 0.6337890625\n",
      "Batch 28: loss = 1.101737380027771, acc = 0.62890625\n",
      "Batch 29: loss = 1.0910768508911133, acc = 0.6455078125\n",
      "Batch 30: loss = 1.0420640707015991, acc = 0.66796875\n",
      "Batch 31: loss = 1.1970349550247192, acc = 0.6220703125\n",
      "Batch 32: loss = 1.326845645904541, acc = 0.56640625\n",
      "Batch 33: loss = 1.1205236911773682, acc = 0.6318359375\n",
      "Batch 34: loss = 1.1601632833480835, acc = 0.603515625\n",
      "Batch 35: loss = 1.1475087404251099, acc = 0.625\n",
      "Batch 36: loss = 1.146823763847351, acc = 0.6396484375\n",
      "Batch 37: loss = 1.1432117223739624, acc = 0.6513671875\n",
      "Batch 38: loss = 1.213217854499817, acc = 0.62890625\n",
      "Batch 39: loss = 1.141047477722168, acc = 0.6337890625\n",
      "Batch 40: loss = 1.1195533275604248, acc = 0.6357421875\n",
      "Batch 41: loss = 1.0414295196533203, acc = 0.642578125\n",
      "Batch 42: loss = 1.047702670097351, acc = 0.6474609375\n",
      "Batch 43: loss = 1.1281120777130127, acc = 0.625\n",
      "Batch 44: loss = 1.0741294622421265, acc = 0.646484375\n",
      "Batch 45: loss = 0.9605375528335571, acc = 0.671875\n",
      "Batch 46: loss = 1.0803909301757812, acc = 0.6474609375\n",
      "Batch 47: loss = 1.046820878982544, acc = 0.6640625\n",
      "Batch 48: loss = 0.9808465242385864, acc = 0.68359375\n",
      "Batch 49: loss = 0.9584491848945618, acc = 0.6826171875\n",
      "Batch 50: loss = 1.0125877857208252, acc = 0.6845703125\n",
      "Batch 51: loss = 1.0248942375183105, acc = 0.65234375\n",
      "Batch 52: loss = 1.1371715068817139, acc = 0.6171875\n",
      "Batch 53: loss = 1.1214851140975952, acc = 0.6435546875\n",
      "Batch 54: loss = 1.0596489906311035, acc = 0.658203125\n",
      "Batch 55: loss = 1.0517902374267578, acc = 0.650390625\n",
      "Batch 56: loss = 1.0787582397460938, acc = 0.63671875\n",
      "Batch 57: loss = 1.143484115600586, acc = 0.6201171875\n",
      "Batch 58: loss = 1.1356618404388428, acc = 0.6318359375\n",
      "Batch 59: loss = 0.9371030330657959, acc = 0.712890625\n",
      "Batch 60: loss = 1.090800166130066, acc = 0.6376953125\n",
      "Batch 61: loss = 1.1398847103118896, acc = 0.64453125\n",
      "Batch 62: loss = 1.3081575632095337, acc = 0.5634765625\n",
      "Batch 63: loss = 1.2612978219985962, acc = 0.591796875\n",
      "Batch 64: loss = 0.9187921285629272, acc = 0.6982421875\n",
      "Batch 65: loss = 1.115290880203247, acc = 0.630859375\n",
      "Batch 66: loss = 1.0695462226867676, acc = 0.66015625\n",
      "Batch 67: loss = 1.025429129600525, acc = 0.6689453125\n",
      "Batch 68: loss = 1.0703234672546387, acc = 0.6640625\n",
      "Batch 69: loss = 1.0593997240066528, acc = 0.6533203125\n",
      "Batch 70: loss = 1.1483757495880127, acc = 0.640625\n",
      "Batch 71: loss = 1.033033013343811, acc = 0.6611328125\n",
      "Batch 72: loss = 1.000065803527832, acc = 0.6611328125\n",
      "Batch 73: loss = 1.1298911571502686, acc = 0.62109375\n",
      "Batch 74: loss = 1.1338365077972412, acc = 0.6220703125\n",
      "Batch 75: loss = 1.1848936080932617, acc = 0.603515625\n",
      "Batch 76: loss = 1.1657207012176514, acc = 0.6240234375\n",
      "Batch 77: loss = 1.0030837059020996, acc = 0.6650390625\n",
      "Batch 78: loss = 1.0275068283081055, acc = 0.6533203125\n",
      "Batch 79: loss = 0.8939854502677917, acc = 0.7021484375\n",
      "Batch 80: loss = 0.9544007778167725, acc = 0.6728515625\n",
      "Batch 81: loss = 1.0177457332611084, acc = 0.6689453125\n",
      "Batch 82: loss = 0.9459595084190369, acc = 0.677734375\n",
      "Batch 83: loss = 1.0568428039550781, acc = 0.6357421875\n",
      "Batch 84: loss = 1.025681734085083, acc = 0.673828125\n",
      "Batch 85: loss = 1.1447186470031738, acc = 0.615234375\n",
      "Batch 86: loss = 1.08341383934021, acc = 0.646484375\n",
      "Batch 87: loss = 1.0456204414367676, acc = 0.654296875\n",
      "Batch 88: loss = 1.198230504989624, acc = 0.6220703125\n",
      "Batch 89: loss = 1.0848950147628784, acc = 0.6494140625\n",
      "Batch 90: loss = 1.1820075511932373, acc = 0.634765625\n",
      "Batch 91: loss = 1.1200988292694092, acc = 0.6279296875\n",
      "Batch 92: loss = 1.0441709756851196, acc = 0.65234375\n",
      "Batch 93: loss = 0.9632257223129272, acc = 0.69140625\n",
      "Batch 94: loss = 1.0163097381591797, acc = 0.6591796875\n",
      "Batch 95: loss = 1.0698251724243164, acc = 0.6318359375\n",
      "Batch 96: loss = 1.1019608974456787, acc = 0.634765625\n",
      "Batch 97: loss = 1.0795519351959229, acc = 0.65234375\n",
      "Batch 98: loss = 1.0763559341430664, acc = 0.669921875\n",
      "Batch 99: loss = 1.0960417985916138, acc = 0.634765625\n",
      "Batch 100: loss = 1.0646083354949951, acc = 0.6435546875\n",
      "Batch 101: loss = 1.09403395652771, acc = 0.6357421875\n",
      "Batch 102: loss = 1.1708006858825684, acc = 0.6220703125\n",
      "Batch 103: loss = 1.1068367958068848, acc = 0.638671875\n",
      "Batch 104: loss = 1.0124516487121582, acc = 0.650390625\n",
      "Batch 105: loss = 1.0673418045043945, acc = 0.673828125\n",
      "Batch 106: loss = 1.1353237628936768, acc = 0.634765625\n",
      "Batch 107: loss = 1.0630205869674683, acc = 0.650390625\n",
      "Batch 108: loss = 1.0721476078033447, acc = 0.662109375\n",
      "Batch 109: loss = 1.0688273906707764, acc = 0.6435546875\n",
      "Batch 110: loss = 0.9843941330909729, acc = 0.6826171875\n",
      "Batch 111: loss = 1.1860616207122803, acc = 0.6103515625\n",
      "Batch 112: loss = 1.0403701066970825, acc = 0.64453125\n",
      "Batch 113: loss = 1.0878793001174927, acc = 0.642578125\n",
      "Batch 114: loss = 1.129874587059021, acc = 0.650390625\n",
      "Batch 115: loss = 1.1595966815948486, acc = 0.609375\n",
      "Batch 116: loss = 1.1691731214523315, acc = 0.6337890625\n",
      "Batch 117: loss = 1.0425608158111572, acc = 0.650390625\n",
      "Batch 118: loss = 1.0091898441314697, acc = 0.669921875\n",
      "Batch 119: loss = 1.081709623336792, acc = 0.638671875\n",
      "Batch 120: loss = 1.1377217769622803, acc = 0.6328125\n",
      "Batch 121: loss = 1.0453317165374756, acc = 0.666015625\n",
      "Batch 122: loss = 1.0450317859649658, acc = 0.66015625\n",
      "Batch 123: loss = 1.0856634378433228, acc = 0.662109375\n",
      "Batch 124: loss = 1.1091090440750122, acc = 0.6279296875\n",
      "Batch 125: loss = 1.1099457740783691, acc = 0.625\n",
      "Batch 126: loss = 1.1871984004974365, acc = 0.62890625\n",
      "\n",
      "Epoch 14/100\n",
      "Batch 1: loss = 1.3727171421051025, acc = 0.595703125\n",
      "Batch 2: loss = 1.2204375267028809, acc = 0.6103515625\n",
      "Batch 3: loss = 1.1598542928695679, acc = 0.6298828125\n",
      "Batch 4: loss = 1.1187708377838135, acc = 0.6328125\n",
      "Batch 5: loss = 1.2557625770568848, acc = 0.6142578125\n",
      "Batch 6: loss = 1.2432148456573486, acc = 0.5947265625\n",
      "Batch 7: loss = 1.2018260955810547, acc = 0.6064453125\n",
      "Batch 8: loss = 1.0921883583068848, acc = 0.638671875\n",
      "Batch 9: loss = 1.060986876487732, acc = 0.662109375\n",
      "Batch 10: loss = 1.0002949237823486, acc = 0.6689453125\n",
      "Batch 11: loss = 1.1734306812286377, acc = 0.615234375\n",
      "Batch 12: loss = 1.2062325477600098, acc = 0.607421875\n",
      "Batch 13: loss = 1.1145689487457275, acc = 0.6123046875\n",
      "Batch 14: loss = 1.0586652755737305, acc = 0.642578125\n",
      "Batch 15: loss = 1.0266377925872803, acc = 0.6640625\n",
      "Batch 16: loss = 1.1614056825637817, acc = 0.6142578125\n",
      "Batch 17: loss = 1.1012318134307861, acc = 0.6474609375\n",
      "Batch 18: loss = 1.1703200340270996, acc = 0.611328125\n",
      "Batch 19: loss = 1.1324435472488403, acc = 0.642578125\n",
      "Batch 20: loss = 1.0576568841934204, acc = 0.64453125\n",
      "Batch 21: loss = 1.2369961738586426, acc = 0.6083984375\n",
      "Batch 22: loss = 1.0565953254699707, acc = 0.6435546875\n",
      "Batch 23: loss = 1.0299172401428223, acc = 0.6630859375\n",
      "Batch 24: loss = 1.064401388168335, acc = 0.646484375\n",
      "Batch 25: loss = 1.0103086233139038, acc = 0.66796875\n",
      "Batch 26: loss = 1.0254517793655396, acc = 0.6669921875\n",
      "Batch 27: loss = 1.1367193460464478, acc = 0.6220703125\n",
      "Batch 28: loss = 1.087784767150879, acc = 0.6435546875\n",
      "Batch 29: loss = 1.064589262008667, acc = 0.6640625\n",
      "Batch 30: loss = 1.0186938047409058, acc = 0.671875\n",
      "Batch 31: loss = 1.1559300422668457, acc = 0.625\n",
      "Batch 32: loss = 1.2969646453857422, acc = 0.5830078125\n",
      "Batch 33: loss = 1.0810320377349854, acc = 0.650390625\n",
      "Batch 34: loss = 1.1139599084854126, acc = 0.6279296875\n",
      "Batch 35: loss = 1.117269515991211, acc = 0.6474609375\n",
      "Batch 36: loss = 1.1000759601593018, acc = 0.650390625\n",
      "Batch 37: loss = 1.0869803428649902, acc = 0.6533203125\n",
      "Batch 38: loss = 1.1898882389068604, acc = 0.6240234375\n",
      "Batch 39: loss = 1.1121861934661865, acc = 0.6279296875\n",
      "Batch 40: loss = 1.0804675817489624, acc = 0.6416015625\n",
      "Batch 41: loss = 1.0175436735153198, acc = 0.6748046875\n",
      "Batch 42: loss = 1.0317755937576294, acc = 0.658203125\n",
      "Batch 43: loss = 1.1045817136764526, acc = 0.623046875\n",
      "Batch 44: loss = 1.03586745262146, acc = 0.6689453125\n",
      "Batch 45: loss = 0.9431909918785095, acc = 0.669921875\n",
      "Batch 46: loss = 1.0430917739868164, acc = 0.6630859375\n",
      "Batch 47: loss = 1.0194610357284546, acc = 0.6796875\n",
      "Batch 48: loss = 0.9687246680259705, acc = 0.6630859375\n",
      "Batch 49: loss = 0.9138532876968384, acc = 0.705078125\n",
      "Batch 50: loss = 0.9744484424591064, acc = 0.7080078125\n",
      "Batch 51: loss = 0.9867401123046875, acc = 0.6669921875\n",
      "Batch 52: loss = 1.1059348583221436, acc = 0.6455078125\n",
      "Batch 53: loss = 1.0912268161773682, acc = 0.6513671875\n",
      "Batch 54: loss = 1.0100136995315552, acc = 0.6708984375\n",
      "Batch 55: loss = 1.0177154541015625, acc = 0.666015625\n",
      "Batch 56: loss = 1.0386356115341187, acc = 0.6328125\n",
      "Batch 57: loss = 1.1320934295654297, acc = 0.619140625\n",
      "Batch 58: loss = 1.12236487865448, acc = 0.6279296875\n",
      "Batch 59: loss = 0.8985442519187927, acc = 0.724609375\n",
      "Batch 60: loss = 1.071134090423584, acc = 0.6484375\n",
      "Batch 61: loss = 1.1439802646636963, acc = 0.654296875\n",
      "Batch 62: loss = 1.2799991369247437, acc = 0.5634765625\n",
      "Batch 63: loss = 1.2235363721847534, acc = 0.6162109375\n",
      "Batch 64: loss = 0.8931183815002441, acc = 0.697265625\n",
      "Batch 65: loss = 1.0546287298202515, acc = 0.654296875\n",
      "Batch 66: loss = 1.0450670719146729, acc = 0.6572265625\n",
      "Batch 67: loss = 0.9576611518859863, acc = 0.6943359375\n",
      "Batch 68: loss = 1.0540173053741455, acc = 0.6748046875\n",
      "Batch 69: loss = 1.0331177711486816, acc = 0.6630859375\n",
      "Batch 70: loss = 1.120018720626831, acc = 0.6337890625\n",
      "Batch 71: loss = 1.023398518562317, acc = 0.6787109375\n",
      "Batch 72: loss = 0.9760868549346924, acc = 0.67578125\n",
      "Batch 73: loss = 1.102426290512085, acc = 0.6279296875\n",
      "Batch 74: loss = 1.1075363159179688, acc = 0.6123046875\n",
      "Batch 75: loss = 1.1680686473846436, acc = 0.60546875\n",
      "Batch 76: loss = 1.1396900415420532, acc = 0.6064453125\n",
      "Batch 77: loss = 0.9856923818588257, acc = 0.673828125\n",
      "Batch 78: loss = 1.0379787683486938, acc = 0.66015625\n",
      "Batch 79: loss = 0.8961788415908813, acc = 0.7109375\n",
      "Batch 80: loss = 0.918633759021759, acc = 0.6796875\n",
      "Batch 81: loss = 0.985000491142273, acc = 0.6689453125\n",
      "Batch 82: loss = 0.9086861610412598, acc = 0.7041015625\n",
      "Batch 83: loss = 1.0382386445999146, acc = 0.650390625\n",
      "Batch 84: loss = 1.0303893089294434, acc = 0.6640625\n",
      "Batch 85: loss = 1.1180968284606934, acc = 0.6318359375\n",
      "Batch 86: loss = 1.0562056303024292, acc = 0.6591796875\n",
      "Batch 87: loss = 1.0008000135421753, acc = 0.662109375\n",
      "Batch 88: loss = 1.169870376586914, acc = 0.6123046875\n",
      "Batch 89: loss = 1.0733911991119385, acc = 0.658203125\n",
      "Batch 90: loss = 1.154364824295044, acc = 0.6240234375\n",
      "Batch 91: loss = 1.1197247505187988, acc = 0.6357421875\n",
      "Batch 92: loss = 1.0229066610336304, acc = 0.6572265625\n",
      "Batch 93: loss = 0.9320409297943115, acc = 0.7060546875\n",
      "Batch 94: loss = 0.9821099042892456, acc = 0.6787109375\n",
      "Batch 95: loss = 1.0583226680755615, acc = 0.6357421875\n",
      "Batch 96: loss = 1.0650289058685303, acc = 0.6416015625\n",
      "Batch 97: loss = 1.0521843433380127, acc = 0.6640625\n",
      "Batch 98: loss = 1.0455520153045654, acc = 0.6748046875\n",
      "Batch 99: loss = 1.0458323955535889, acc = 0.6650390625\n",
      "Batch 100: loss = 1.0323508977890015, acc = 0.6494140625\n",
      "Batch 101: loss = 1.0543460845947266, acc = 0.6533203125\n",
      "Batch 102: loss = 1.1425752639770508, acc = 0.6298828125\n",
      "Batch 103: loss = 1.0988779067993164, acc = 0.646484375\n",
      "Batch 104: loss = 0.991558313369751, acc = 0.66796875\n",
      "Batch 105: loss = 1.0280120372772217, acc = 0.6845703125\n",
      "Batch 106: loss = 1.107316493988037, acc = 0.65625\n",
      "Batch 107: loss = 1.0267432928085327, acc = 0.671875\n",
      "Batch 108: loss = 1.0309776067733765, acc = 0.666015625\n",
      "Batch 109: loss = 1.0156539678573608, acc = 0.6513671875\n",
      "Batch 110: loss = 0.9665576815605164, acc = 0.6962890625\n",
      "Batch 111: loss = 1.1566171646118164, acc = 0.62890625\n",
      "Batch 112: loss = 1.0148615837097168, acc = 0.6484375\n",
      "Batch 113: loss = 1.0778254270553589, acc = 0.6513671875\n",
      "Batch 114: loss = 1.0842194557189941, acc = 0.6796875\n",
      "Batch 115: loss = 1.1028499603271484, acc = 0.63671875\n",
      "Batch 116: loss = 1.144141674041748, acc = 0.642578125\n",
      "Batch 117: loss = 1.0191091299057007, acc = 0.6865234375\n",
      "Batch 118: loss = 0.9695451855659485, acc = 0.67578125\n",
      "Batch 119: loss = 1.053497314453125, acc = 0.658203125\n",
      "Batch 120: loss = 1.1156569719314575, acc = 0.6396484375\n",
      "Batch 121: loss = 1.030045747756958, acc = 0.6494140625\n",
      "Batch 122: loss = 1.0212961435317993, acc = 0.6728515625\n",
      "Batch 123: loss = 1.06154465675354, acc = 0.6669921875\n",
      "Batch 124: loss = 1.1097790002822876, acc = 0.61328125\n",
      "Batch 125: loss = 1.0961861610412598, acc = 0.6337890625\n",
      "Batch 126: loss = 1.1842280626296997, acc = 0.6240234375\n",
      "\n",
      "Epoch 15/100\n",
      "Batch 1: loss = 1.3355271816253662, acc = 0.591796875\n",
      "Batch 2: loss = 1.2047607898712158, acc = 0.6083984375\n",
      "Batch 3: loss = 1.1211159229278564, acc = 0.6494140625\n",
      "Batch 4: loss = 1.0815807580947876, acc = 0.6455078125\n",
      "Batch 5: loss = 1.1866157054901123, acc = 0.615234375\n",
      "Batch 6: loss = 1.1857025623321533, acc = 0.6044921875\n",
      "Batch 7: loss = 1.1756665706634521, acc = 0.619140625\n",
      "Batch 8: loss = 1.0716476440429688, acc = 0.65625\n",
      "Batch 9: loss = 1.05415678024292, acc = 0.6689453125\n",
      "Batch 10: loss = 0.9842486381530762, acc = 0.6865234375\n",
      "Batch 11: loss = 1.1197268962860107, acc = 0.6279296875\n",
      "Batch 12: loss = 1.1694822311401367, acc = 0.6162109375\n",
      "Batch 13: loss = 1.0640332698822021, acc = 0.6455078125\n",
      "Batch 14: loss = 1.0249460935592651, acc = 0.6552734375\n",
      "Batch 15: loss = 1.0076086521148682, acc = 0.669921875\n",
      "Batch 16: loss = 1.133770227432251, acc = 0.626953125\n",
      "Batch 17: loss = 1.0724551677703857, acc = 0.650390625\n",
      "Batch 18: loss = 1.1281943321228027, acc = 0.623046875\n",
      "Batch 19: loss = 1.0939550399780273, acc = 0.6630859375\n",
      "Batch 20: loss = 1.0438311100006104, acc = 0.6455078125\n",
      "Batch 21: loss = 1.1941767930984497, acc = 0.6181640625\n",
      "Batch 22: loss = 1.029059886932373, acc = 0.658203125\n",
      "Batch 23: loss = 1.0258896350860596, acc = 0.6591796875\n",
      "Batch 24: loss = 1.0548608303070068, acc = 0.65234375\n",
      "Batch 25: loss = 0.9510277509689331, acc = 0.693359375\n",
      "Batch 26: loss = 1.0084505081176758, acc = 0.67578125\n",
      "Batch 27: loss = 1.1113698482513428, acc = 0.638671875\n",
      "Batch 28: loss = 1.0375367403030396, acc = 0.65625\n",
      "Batch 29: loss = 1.058880090713501, acc = 0.658203125\n",
      "Batch 30: loss = 0.9827702045440674, acc = 0.6845703125\n",
      "Batch 31: loss = 1.1520397663116455, acc = 0.6328125\n",
      "Batch 32: loss = 1.2449541091918945, acc = 0.5966796875\n",
      "Batch 33: loss = 1.0565423965454102, acc = 0.650390625\n",
      "Batch 34: loss = 1.1230080127716064, acc = 0.6279296875\n",
      "Batch 35: loss = 1.10105299949646, acc = 0.6484375\n",
      "Batch 36: loss = 1.094923734664917, acc = 0.658203125\n",
      "Batch 37: loss = 1.0646216869354248, acc = 0.66015625\n",
      "Batch 38: loss = 1.1495267152786255, acc = 0.64453125\n",
      "Batch 39: loss = 1.0888890027999878, acc = 0.6572265625\n",
      "Batch 40: loss = 1.0488955974578857, acc = 0.6484375\n",
      "Batch 41: loss = 0.990206241607666, acc = 0.677734375\n",
      "Batch 42: loss = 1.0056848526000977, acc = 0.6650390625\n",
      "Batch 43: loss = 1.0760676860809326, acc = 0.634765625\n",
      "Batch 44: loss = 1.0301817655563354, acc = 0.6689453125\n",
      "Batch 45: loss = 0.9036889672279358, acc = 0.6962890625\n",
      "Batch 46: loss = 1.0234489440917969, acc = 0.6669921875\n",
      "Batch 47: loss = 1.0005697011947632, acc = 0.677734375\n",
      "Batch 48: loss = 0.9282658100128174, acc = 0.6845703125\n",
      "Batch 49: loss = 0.8952573537826538, acc = 0.708984375\n",
      "Batch 50: loss = 0.966490626335144, acc = 0.701171875\n",
      "Batch 51: loss = 0.9466784596443176, acc = 0.681640625\n",
      "Batch 52: loss = 1.080805778503418, acc = 0.6376953125\n",
      "Batch 53: loss = 1.0745289325714111, acc = 0.65625\n",
      "Batch 54: loss = 0.9785261154174805, acc = 0.6884765625\n",
      "Batch 55: loss = 0.9849360585212708, acc = 0.677734375\n",
      "Batch 56: loss = 1.0355443954467773, acc = 0.6484375\n",
      "Batch 57: loss = 1.0987684726715088, acc = 0.63671875\n",
      "Batch 58: loss = 1.0904664993286133, acc = 0.6455078125\n",
      "Batch 59: loss = 0.8626487255096436, acc = 0.732421875\n",
      "Batch 60: loss = 1.0450572967529297, acc = 0.6552734375\n",
      "Batch 61: loss = 1.0938408374786377, acc = 0.6572265625\n",
      "Batch 62: loss = 1.2240909337997437, acc = 0.587890625\n",
      "Batch 63: loss = 1.168205738067627, acc = 0.615234375\n",
      "Batch 64: loss = 0.8825829029083252, acc = 0.7177734375\n",
      "Batch 65: loss = 1.0468168258666992, acc = 0.6689453125\n",
      "Batch 66: loss = 1.006511926651001, acc = 0.685546875\n",
      "Batch 67: loss = 0.9559354782104492, acc = 0.6845703125\n",
      "Batch 68: loss = 1.0276894569396973, acc = 0.671875\n",
      "Batch 69: loss = 1.001116156578064, acc = 0.6767578125\n",
      "Batch 70: loss = 1.0930426120758057, acc = 0.6494140625\n",
      "Batch 71: loss = 0.9935746788978577, acc = 0.68359375\n",
      "Batch 72: loss = 0.9643833637237549, acc = 0.669921875\n",
      "Batch 73: loss = 1.0748928785324097, acc = 0.634765625\n",
      "Batch 74: loss = 1.0716700553894043, acc = 0.6533203125\n",
      "Batch 75: loss = 1.1499152183532715, acc = 0.6171875\n",
      "Batch 76: loss = 1.090120792388916, acc = 0.6259765625\n",
      "Batch 77: loss = 0.9595776796340942, acc = 0.6767578125\n",
      "Batch 78: loss = 0.9926713705062866, acc = 0.677734375\n",
      "Batch 79: loss = 0.8620725870132446, acc = 0.7255859375\n",
      "Batch 80: loss = 0.9009877443313599, acc = 0.6904296875\n",
      "Batch 81: loss = 0.9802982211112976, acc = 0.6904296875\n",
      "Batch 82: loss = 0.904253363609314, acc = 0.7041015625\n",
      "Batch 83: loss = 0.9958263635635376, acc = 0.6748046875\n",
      "Batch 84: loss = 1.0023455619812012, acc = 0.6748046875\n",
      "Batch 85: loss = 1.0856472253799438, acc = 0.63671875\n",
      "Batch 86: loss = 1.0280382633209229, acc = 0.6708984375\n",
      "Batch 87: loss = 0.9752460718154907, acc = 0.671875\n",
      "Batch 88: loss = 1.1476554870605469, acc = 0.6279296875\n",
      "Batch 89: loss = 1.0405418872833252, acc = 0.6640625\n",
      "Batch 90: loss = 1.1044394969940186, acc = 0.65234375\n",
      "Batch 91: loss = 1.0982823371887207, acc = 0.6337890625\n",
      "Batch 92: loss = 1.0144312381744385, acc = 0.6669921875\n",
      "Batch 93: loss = 0.9124795198440552, acc = 0.71484375\n",
      "Batch 94: loss = 0.9582967758178711, acc = 0.6875\n",
      "Batch 95: loss = 1.0127910375595093, acc = 0.6513671875\n",
      "Batch 96: loss = 1.0542759895324707, acc = 0.6552734375\n",
      "Batch 97: loss = 1.0345442295074463, acc = 0.6865234375\n",
      "Batch 98: loss = 1.0229144096374512, acc = 0.6630859375\n",
      "Batch 99: loss = 0.9967809915542603, acc = 0.6640625\n",
      "Batch 100: loss = 1.012277364730835, acc = 0.6630859375\n",
      "Batch 101: loss = 1.0394833087921143, acc = 0.6650390625\n",
      "Batch 102: loss = 1.1232810020446777, acc = 0.6298828125\n",
      "Batch 103: loss = 1.0557409524917603, acc = 0.6513671875\n",
      "Batch 104: loss = 0.960624098777771, acc = 0.671875\n",
      "Batch 105: loss = 1.0131020545959473, acc = 0.677734375\n",
      "Batch 106: loss = 1.0692325830459595, acc = 0.669921875\n",
      "Batch 107: loss = 1.0008537769317627, acc = 0.6787109375\n",
      "Batch 108: loss = 1.0347810983657837, acc = 0.669921875\n",
      "Batch 109: loss = 1.0013465881347656, acc = 0.6650390625\n",
      "Batch 110: loss = 0.9402648210525513, acc = 0.693359375\n",
      "Batch 111: loss = 1.1207969188690186, acc = 0.6474609375\n",
      "Batch 112: loss = 0.9851624965667725, acc = 0.6630859375\n",
      "Batch 113: loss = 1.0402624607086182, acc = 0.6572265625\n",
      "Batch 114: loss = 1.055830717086792, acc = 0.681640625\n",
      "Batch 115: loss = 1.0928109884262085, acc = 0.6455078125\n",
      "Batch 116: loss = 1.1263015270233154, acc = 0.64453125\n",
      "Batch 117: loss = 0.9963963627815247, acc = 0.6796875\n",
      "Batch 118: loss = 0.9291449189186096, acc = 0.689453125\n",
      "Batch 119: loss = 1.0357563495635986, acc = 0.6494140625\n",
      "Batch 120: loss = 1.0980534553527832, acc = 0.6455078125\n",
      "Batch 121: loss = 1.006789207458496, acc = 0.6689453125\n",
      "Batch 122: loss = 0.9760445952415466, acc = 0.6787109375\n",
      "Batch 123: loss = 1.0351262092590332, acc = 0.6728515625\n",
      "Batch 124: loss = 1.0808813571929932, acc = 0.63671875\n",
      "Batch 125: loss = 1.0790904760360718, acc = 0.6416015625\n",
      "Batch 126: loss = 1.143979787826538, acc = 0.6416015625\n",
      "\n",
      "Epoch 16/100\n",
      "Batch 1: loss = 1.291805386543274, acc = 0.6044921875\n",
      "Batch 2: loss = 1.1646711826324463, acc = 0.6357421875\n",
      "Batch 3: loss = 1.089357852935791, acc = 0.658203125\n",
      "Batch 4: loss = 1.0807836055755615, acc = 0.6552734375\n",
      "Batch 5: loss = 1.1756527423858643, acc = 0.630859375\n",
      "Batch 6: loss = 1.1826450824737549, acc = 0.6240234375\n",
      "Batch 7: loss = 1.144317388534546, acc = 0.63671875\n",
      "Batch 8: loss = 1.0243840217590332, acc = 0.669921875\n",
      "Batch 9: loss = 1.0141313076019287, acc = 0.67578125\n",
      "Batch 10: loss = 0.9447604417800903, acc = 0.6826171875\n",
      "Batch 11: loss = 1.1148923635482788, acc = 0.6376953125\n",
      "Batch 12: loss = 1.1352380514144897, acc = 0.6298828125\n",
      "Batch 13: loss = 1.0458403825759888, acc = 0.6552734375\n",
      "Batch 14: loss = 1.012159824371338, acc = 0.6708984375\n",
      "Batch 15: loss = 0.9665336608886719, acc = 0.6767578125\n",
      "Batch 16: loss = 1.107508659362793, acc = 0.6279296875\n",
      "Batch 17: loss = 1.0446172952651978, acc = 0.6650390625\n",
      "Batch 18: loss = 1.0965126752853394, acc = 0.63671875\n",
      "Batch 19: loss = 1.0384280681610107, acc = 0.666015625\n",
      "Batch 20: loss = 1.0099358558654785, acc = 0.6689453125\n",
      "Batch 21: loss = 1.1664786338806152, acc = 0.6259765625\n",
      "Batch 22: loss = 1.0182307958602905, acc = 0.662109375\n",
      "Batch 23: loss = 1.0028021335601807, acc = 0.6748046875\n",
      "Batch 24: loss = 1.0225939750671387, acc = 0.669921875\n",
      "Batch 25: loss = 0.9374141097068787, acc = 0.6904296875\n",
      "Batch 26: loss = 0.9710246324539185, acc = 0.6884765625\n",
      "Batch 27: loss = 1.112069010734558, acc = 0.6279296875\n",
      "Batch 28: loss = 1.0271843671798706, acc = 0.6552734375\n",
      "Batch 29: loss = 1.0255857706069946, acc = 0.6865234375\n",
      "Batch 30: loss = 0.9531745910644531, acc = 0.69921875\n",
      "Batch 31: loss = 1.1135947704315186, acc = 0.640625\n",
      "Batch 32: loss = 1.2001309394836426, acc = 0.6044921875\n",
      "Batch 33: loss = 1.0299005508422852, acc = 0.658203125\n",
      "Batch 34: loss = 1.0658462047576904, acc = 0.654296875\n",
      "Batch 35: loss = 1.0650256872177124, acc = 0.64453125\n",
      "Batch 36: loss = 1.0667487382888794, acc = 0.66796875\n",
      "Batch 37: loss = 1.0325562953948975, acc = 0.6787109375\n",
      "Batch 38: loss = 1.1123690605163574, acc = 0.6484375\n",
      "Batch 39: loss = 1.0683200359344482, acc = 0.6513671875\n",
      "Batch 40: loss = 1.0237663984298706, acc = 0.666015625\n",
      "Batch 41: loss = 0.9564507007598877, acc = 0.7041015625\n",
      "Batch 42: loss = 0.9868756532669067, acc = 0.6640625\n",
      "Batch 43: loss = 1.0656274557113647, acc = 0.6396484375\n",
      "Batch 44: loss = 1.0029206275939941, acc = 0.6796875\n",
      "Batch 45: loss = 0.8783884048461914, acc = 0.701171875\n",
      "Batch 46: loss = 1.0043506622314453, acc = 0.6826171875\n",
      "Batch 47: loss = 0.9680874347686768, acc = 0.6865234375\n",
      "Batch 48: loss = 0.9187960028648376, acc = 0.6953125\n",
      "Batch 49: loss = 0.8800797462463379, acc = 0.7119140625\n",
      "Batch 50: loss = 0.9436425566673279, acc = 0.7216796875\n",
      "Batch 51: loss = 0.9501082897186279, acc = 0.6845703125\n",
      "Batch 52: loss = 1.04270339012146, acc = 0.6572265625\n",
      "Batch 53: loss = 1.0415830612182617, acc = 0.6640625\n",
      "Batch 54: loss = 0.9564090967178345, acc = 0.6875\n",
      "Batch 55: loss = 0.954932451248169, acc = 0.6962890625\n",
      "Batch 56: loss = 1.0010247230529785, acc = 0.65234375\n",
      "Batch 57: loss = 1.0987370014190674, acc = 0.6357421875\n",
      "Batch 58: loss = 1.0655486583709717, acc = 0.65625\n",
      "Batch 59: loss = 0.8630140423774719, acc = 0.728515625\n",
      "Batch 60: loss = 1.0141031742095947, acc = 0.658203125\n",
      "Batch 61: loss = 1.0824131965637207, acc = 0.6513671875\n",
      "Batch 62: loss = 1.2282390594482422, acc = 0.572265625\n",
      "Batch 63: loss = 1.1702176332473755, acc = 0.62109375\n",
      "Batch 64: loss = 0.8493039608001709, acc = 0.7265625\n",
      "Batch 65: loss = 1.0373951196670532, acc = 0.6533203125\n",
      "Batch 66: loss = 1.0138483047485352, acc = 0.66796875\n",
      "Batch 67: loss = 0.9347826838493347, acc = 0.6884765625\n",
      "Batch 68: loss = 1.0162262916564941, acc = 0.671875\n",
      "Batch 69: loss = 0.991357147693634, acc = 0.673828125\n",
      "Batch 70: loss = 1.0616552829742432, acc = 0.650390625\n",
      "Batch 71: loss = 0.980487585067749, acc = 0.6748046875\n",
      "Batch 72: loss = 0.9674293398857117, acc = 0.67578125\n",
      "Batch 73: loss = 1.0781974792480469, acc = 0.640625\n",
      "Batch 74: loss = 1.0439324378967285, acc = 0.654296875\n",
      "Batch 75: loss = 1.1407699584960938, acc = 0.623046875\n",
      "Batch 76: loss = 1.0802041292190552, acc = 0.6328125\n",
      "Batch 77: loss = 0.9397648572921753, acc = 0.6943359375\n",
      "Batch 78: loss = 0.9836167693138123, acc = 0.6787109375\n",
      "Batch 79: loss = 0.8497906923294067, acc = 0.7177734375\n",
      "Batch 80: loss = 0.8869843482971191, acc = 0.6943359375\n",
      "Batch 81: loss = 0.9627252221107483, acc = 0.69921875\n",
      "Batch 82: loss = 0.8660772442817688, acc = 0.7138671875\n",
      "Batch 83: loss = 0.9838014841079712, acc = 0.6708984375\n",
      "Batch 84: loss = 0.9690419435501099, acc = 0.6943359375\n",
      "Batch 85: loss = 1.0612999200820923, acc = 0.6513671875\n",
      "Batch 86: loss = 1.031713843345642, acc = 0.6591796875\n",
      "Batch 87: loss = 0.9546945095062256, acc = 0.6884765625\n",
      "Batch 88: loss = 1.1276192665100098, acc = 0.6318359375\n",
      "Batch 89: loss = 1.0167689323425293, acc = 0.6767578125\n",
      "Batch 90: loss = 1.093238115310669, acc = 0.658203125\n",
      "Batch 91: loss = 1.0625983476638794, acc = 0.6435546875\n",
      "Batch 92: loss = 0.979444682598114, acc = 0.6728515625\n",
      "Batch 93: loss = 0.9004497528076172, acc = 0.720703125\n",
      "Batch 94: loss = 0.9373441338539124, acc = 0.6845703125\n",
      "Batch 95: loss = 0.975241482257843, acc = 0.6591796875\n",
      "Batch 96: loss = 1.0182431936264038, acc = 0.673828125\n",
      "Batch 97: loss = 0.9996699094772339, acc = 0.6875\n",
      "Batch 98: loss = 0.9816936254501343, acc = 0.703125\n",
      "Batch 99: loss = 1.016655683517456, acc = 0.677734375\n",
      "Batch 100: loss = 0.9865341186523438, acc = 0.65625\n",
      "Batch 101: loss = 0.9886813163757324, acc = 0.6806640625\n",
      "Batch 102: loss = 1.093200445175171, acc = 0.6455078125\n",
      "Batch 103: loss = 1.0227010250091553, acc = 0.658203125\n",
      "Batch 104: loss = 0.9430255889892578, acc = 0.677734375\n",
      "Batch 105: loss = 0.9480445384979248, acc = 0.703125\n",
      "Batch 106: loss = 1.0524256229400635, acc = 0.66015625\n",
      "Batch 107: loss = 0.985058605670929, acc = 0.6826171875\n",
      "Batch 108: loss = 0.994106113910675, acc = 0.67578125\n",
      "Batch 109: loss = 0.9844697117805481, acc = 0.66796875\n",
      "Batch 110: loss = 0.8901480436325073, acc = 0.7099609375\n",
      "Batch 111: loss = 1.1006245613098145, acc = 0.6474609375\n",
      "Batch 112: loss = 0.9729580283164978, acc = 0.6806640625\n",
      "Batch 113: loss = 1.0296895503997803, acc = 0.669921875\n",
      "Batch 114: loss = 1.0393555164337158, acc = 0.6787109375\n",
      "Batch 115: loss = 1.078901767730713, acc = 0.6513671875\n",
      "Batch 116: loss = 1.1171813011169434, acc = 0.650390625\n",
      "Batch 117: loss = 0.9736133813858032, acc = 0.677734375\n",
      "Batch 118: loss = 0.9230022430419922, acc = 0.6875\n",
      "Batch 119: loss = 1.035465955734253, acc = 0.6474609375\n",
      "Batch 120: loss = 1.0647904872894287, acc = 0.658203125\n",
      "Batch 121: loss = 0.9869301319122314, acc = 0.6845703125\n",
      "Batch 122: loss = 0.9631341695785522, acc = 0.6943359375\n",
      "Batch 123: loss = 1.0208077430725098, acc = 0.6669921875\n",
      "Batch 124: loss = 1.0624301433563232, acc = 0.642578125\n",
      "Batch 125: loss = 1.0388593673706055, acc = 0.6494140625\n",
      "Batch 126: loss = 1.1188750267028809, acc = 0.64453125\n",
      "\n",
      "Epoch 17/100\n",
      "Batch 1: loss = 1.2733781337738037, acc = 0.607421875\n",
      "Batch 2: loss = 1.134711742401123, acc = 0.638671875\n",
      "Batch 3: loss = 1.0760564804077148, acc = 0.666015625\n",
      "Batch 4: loss = 1.041823148727417, acc = 0.6650390625\n",
      "Batch 5: loss = 1.1431794166564941, acc = 0.6357421875\n",
      "Batch 6: loss = 1.136657476425171, acc = 0.634765625\n",
      "Batch 7: loss = 1.0854779481887817, acc = 0.6494140625\n",
      "Batch 8: loss = 1.0021920204162598, acc = 0.6708984375\n",
      "Batch 9: loss = 0.9638733267784119, acc = 0.681640625\n",
      "Batch 10: loss = 0.9305579662322998, acc = 0.6875\n",
      "Batch 11: loss = 1.0504682064056396, acc = 0.6474609375\n",
      "Batch 12: loss = 1.0919792652130127, acc = 0.640625\n",
      "Batch 13: loss = 1.019690752029419, acc = 0.654296875\n",
      "Batch 14: loss = 0.9718373417854309, acc = 0.6748046875\n",
      "Batch 15: loss = 0.9490357637405396, acc = 0.69140625\n",
      "Batch 16: loss = 1.0829347372055054, acc = 0.646484375\n",
      "Batch 17: loss = 1.0298829078674316, acc = 0.6728515625\n",
      "Batch 18: loss = 1.0691988468170166, acc = 0.646484375\n",
      "Batch 19: loss = 1.0293233394622803, acc = 0.6591796875\n",
      "Batch 20: loss = 0.9895564317703247, acc = 0.6708984375\n",
      "Batch 21: loss = 1.1379538774490356, acc = 0.6279296875\n",
      "Batch 22: loss = 0.9800443649291992, acc = 0.673828125\n",
      "Batch 23: loss = 0.9626330733299255, acc = 0.6796875\n",
      "Batch 24: loss = 0.985257625579834, acc = 0.666015625\n",
      "Batch 25: loss = 0.9245705604553223, acc = 0.6962890625\n",
      "Batch 26: loss = 0.9465852975845337, acc = 0.69921875\n",
      "Batch 27: loss = 1.0695303678512573, acc = 0.65234375\n",
      "Batch 28: loss = 1.008854866027832, acc = 0.6748046875\n",
      "Batch 29: loss = 0.9840229153633118, acc = 0.69140625\n",
      "Batch 30: loss = 0.9315253496170044, acc = 0.703125\n",
      "Batch 31: loss = 1.0824857950210571, acc = 0.658203125\n",
      "Batch 32: loss = 1.2033168077468872, acc = 0.60546875\n",
      "Batch 33: loss = 0.9925072193145752, acc = 0.6650390625\n",
      "Batch 34: loss = 1.043879508972168, acc = 0.66015625\n",
      "Batch 35: loss = 1.048513650894165, acc = 0.6630859375\n",
      "Batch 36: loss = 1.024867296218872, acc = 0.666015625\n",
      "Batch 37: loss = 1.0086860656738281, acc = 0.67578125\n",
      "Batch 38: loss = 1.09578537940979, acc = 0.6484375\n",
      "Batch 39: loss = 1.0192301273345947, acc = 0.6689453125\n",
      "Batch 40: loss = 1.0051562786102295, acc = 0.66796875\n",
      "Batch 41: loss = 0.9285643100738525, acc = 0.6884765625\n",
      "Batch 42: loss = 0.9644628763198853, acc = 0.67578125\n",
      "Batch 43: loss = 1.0263128280639648, acc = 0.6591796875\n",
      "Batch 44: loss = 0.9764688014984131, acc = 0.689453125\n",
      "Batch 45: loss = 0.8653199672698975, acc = 0.701171875\n",
      "Batch 46: loss = 0.9886525869369507, acc = 0.6806640625\n",
      "Batch 47: loss = 0.9473919868469238, acc = 0.69921875\n",
      "Batch 48: loss = 0.8998094797134399, acc = 0.6767578125\n",
      "Batch 49: loss = 0.8531680107116699, acc = 0.7177734375\n",
      "Batch 50: loss = 0.9093658924102783, acc = 0.7099609375\n",
      "Batch 51: loss = 0.9256863594055176, acc = 0.6875\n",
      "Batch 52: loss = 1.0236340761184692, acc = 0.6728515625\n",
      "Batch 53: loss = 1.0126394033432007, acc = 0.6767578125\n",
      "Batch 54: loss = 0.9257553815841675, acc = 0.69140625\n",
      "Batch 55: loss = 0.9238148927688599, acc = 0.697265625\n",
      "Batch 56: loss = 0.972113847732544, acc = 0.671875\n",
      "Batch 57: loss = 1.0595943927764893, acc = 0.6650390625\n",
      "Batch 58: loss = 1.0421693325042725, acc = 0.6630859375\n",
      "Batch 59: loss = 0.8472949862480164, acc = 0.7412109375\n",
      "Batch 60: loss = 0.9849523305892944, acc = 0.673828125\n",
      "Batch 61: loss = 1.0246978998184204, acc = 0.6748046875\n",
      "Batch 62: loss = 1.189932107925415, acc = 0.6044921875\n",
      "Batch 63: loss = 1.1331672668457031, acc = 0.6357421875\n",
      "Batch 64: loss = 0.8439311385154724, acc = 0.7265625\n",
      "Batch 65: loss = 1.0042684078216553, acc = 0.6826171875\n",
      "Batch 66: loss = 0.9805774092674255, acc = 0.6826171875\n",
      "Batch 67: loss = 0.9144589900970459, acc = 0.697265625\n",
      "Batch 68: loss = 1.0168898105621338, acc = 0.6806640625\n",
      "Batch 69: loss = 0.964472770690918, acc = 0.70703125\n",
      "Batch 70: loss = 1.0320830345153809, acc = 0.6494140625\n",
      "Batch 71: loss = 0.9546194672584534, acc = 0.6845703125\n",
      "Batch 72: loss = 0.9258255362510681, acc = 0.6884765625\n",
      "Batch 73: loss = 1.0360926389694214, acc = 0.6572265625\n",
      "Batch 74: loss = 1.0174832344055176, acc = 0.6669921875\n",
      "Batch 75: loss = 1.0939136743545532, acc = 0.6435546875\n",
      "Batch 76: loss = 1.0356470346450806, acc = 0.6552734375\n",
      "Batch 77: loss = 0.926068902015686, acc = 0.7041015625\n",
      "Batch 78: loss = 0.9629884958267212, acc = 0.6787109375\n",
      "Batch 79: loss = 0.8367272019386292, acc = 0.7158203125\n",
      "Batch 80: loss = 0.8669036626815796, acc = 0.6884765625\n",
      "Batch 81: loss = 0.9480804204940796, acc = 0.6796875\n",
      "Batch 82: loss = 0.8560827970504761, acc = 0.728515625\n",
      "Batch 83: loss = 0.9530078768730164, acc = 0.6796875\n",
      "Batch 84: loss = 0.9368605613708496, acc = 0.6982421875\n",
      "Batch 85: loss = 1.0163767337799072, acc = 0.6669921875\n",
      "Batch 86: loss = 0.9861208200454712, acc = 0.681640625\n",
      "Batch 87: loss = 0.9383000731468201, acc = 0.6982421875\n",
      "Batch 88: loss = 1.1063320636749268, acc = 0.64453125\n",
      "Batch 89: loss = 0.9903900027275085, acc = 0.6953125\n",
      "Batch 90: loss = 1.0396075248718262, acc = 0.6591796875\n",
      "Batch 91: loss = 1.0540556907653809, acc = 0.6640625\n",
      "Batch 92: loss = 0.9543987512588501, acc = 0.6845703125\n",
      "Batch 93: loss = 0.8849194645881653, acc = 0.7275390625\n",
      "Batch 94: loss = 0.896188497543335, acc = 0.69921875\n",
      "Batch 95: loss = 0.9530624151229858, acc = 0.6689453125\n",
      "Batch 96: loss = 1.0073236227035522, acc = 0.658203125\n",
      "Batch 97: loss = 0.9852782487869263, acc = 0.69140625\n",
      "Batch 98: loss = 0.9614049196243286, acc = 0.681640625\n",
      "Batch 99: loss = 0.9699500799179077, acc = 0.6865234375\n",
      "Batch 100: loss = 0.969336748123169, acc = 0.666015625\n",
      "Batch 101: loss = 1.004530906677246, acc = 0.6650390625\n",
      "Batch 102: loss = 1.073826551437378, acc = 0.650390625\n",
      "Batch 103: loss = 0.9994710087776184, acc = 0.6728515625\n",
      "Batch 104: loss = 0.9003162384033203, acc = 0.6826171875\n",
      "Batch 105: loss = 0.9545539617538452, acc = 0.6953125\n",
      "Batch 106: loss = 1.0310392379760742, acc = 0.677734375\n",
      "Batch 107: loss = 0.9525331258773804, acc = 0.69140625\n",
      "Batch 108: loss = 0.9572798013687134, acc = 0.6943359375\n",
      "Batch 109: loss = 0.9659839272499084, acc = 0.6884765625\n",
      "Batch 110: loss = 0.8813790678977966, acc = 0.71484375\n",
      "Batch 111: loss = 1.075655460357666, acc = 0.658203125\n",
      "Batch 112: loss = 0.936018705368042, acc = 0.6875\n",
      "Batch 113: loss = 1.0074530839920044, acc = 0.66796875\n",
      "Batch 114: loss = 1.0065104961395264, acc = 0.697265625\n",
      "Batch 115: loss = 1.0513179302215576, acc = 0.6591796875\n",
      "Batch 116: loss = 1.0923209190368652, acc = 0.654296875\n",
      "Batch 117: loss = 0.9505954384803772, acc = 0.685546875\n",
      "Batch 118: loss = 0.9151561260223389, acc = 0.697265625\n",
      "Batch 119: loss = 1.0048261880874634, acc = 0.6689453125\n",
      "Batch 120: loss = 1.0479161739349365, acc = 0.6533203125\n",
      "Batch 121: loss = 0.977251410484314, acc = 0.6787109375\n",
      "Batch 122: loss = 0.9556418657302856, acc = 0.6884765625\n",
      "Batch 123: loss = 0.9890239238739014, acc = 0.6767578125\n",
      "Batch 124: loss = 1.0463591814041138, acc = 0.6416015625\n",
      "Batch 125: loss = 1.0269488096237183, acc = 0.669921875\n",
      "Batch 126: loss = 1.0934903621673584, acc = 0.6533203125\n",
      "\n",
      "Epoch 18/100\n",
      "Batch 1: loss = 1.2534043788909912, acc = 0.6171875\n",
      "Batch 2: loss = 1.1272058486938477, acc = 0.6357421875\n",
      "Batch 3: loss = 1.0476584434509277, acc = 0.6708984375\n",
      "Batch 4: loss = 1.0262986421585083, acc = 0.6748046875\n",
      "Batch 5: loss = 1.1289182901382446, acc = 0.6318359375\n",
      "Batch 6: loss = 1.1261870861053467, acc = 0.630859375\n",
      "Batch 7: loss = 1.0770727396011353, acc = 0.6513671875\n",
      "Batch 8: loss = 0.9988051056861877, acc = 0.67578125\n",
      "Batch 9: loss = 0.9525076150894165, acc = 0.6923828125\n",
      "Batch 10: loss = 0.8954650163650513, acc = 0.7080078125\n",
      "Batch 11: loss = 1.0343151092529297, acc = 0.6630859375\n",
      "Batch 12: loss = 1.0498296022415161, acc = 0.646484375\n",
      "Batch 13: loss = 0.9823582768440247, acc = 0.6806640625\n",
      "Batch 14: loss = 0.9726253151893616, acc = 0.6796875\n",
      "Batch 15: loss = 0.9362571239471436, acc = 0.6982421875\n",
      "Batch 16: loss = 1.0430047512054443, acc = 0.6591796875\n",
      "Batch 17: loss = 1.0234050750732422, acc = 0.671875\n",
      "Batch 18: loss = 1.0204217433929443, acc = 0.6650390625\n",
      "Batch 19: loss = 0.9982262849807739, acc = 0.6875\n",
      "Batch 20: loss = 0.9638737440109253, acc = 0.6796875\n",
      "Batch 21: loss = 1.1168268918991089, acc = 0.634765625\n",
      "Batch 22: loss = 0.9639112949371338, acc = 0.6884765625\n",
      "Batch 23: loss = 0.957543134689331, acc = 0.6943359375\n",
      "Batch 24: loss = 0.9637272357940674, acc = 0.6748046875\n",
      "Batch 25: loss = 0.9076496958732605, acc = 0.6875\n",
      "Batch 26: loss = 0.9294091463088989, acc = 0.701171875\n",
      "Batch 27: loss = 1.0595908164978027, acc = 0.6513671875\n",
      "Batch 28: loss = 0.9957404136657715, acc = 0.650390625\n",
      "Batch 29: loss = 0.9728347659111023, acc = 0.6845703125\n",
      "Batch 30: loss = 0.9081618785858154, acc = 0.703125\n",
      "Batch 31: loss = 1.081993579864502, acc = 0.654296875\n",
      "Batch 32: loss = 1.1751679182052612, acc = 0.6123046875\n",
      "Batch 33: loss = 0.9639761447906494, acc = 0.6796875\n",
      "Batch 34: loss = 1.0277841091156006, acc = 0.65625\n",
      "Batch 35: loss = 1.015175700187683, acc = 0.68359375\n",
      "Batch 36: loss = 1.0161025524139404, acc = 0.6865234375\n",
      "Batch 37: loss = 1.0032192468643188, acc = 0.6845703125\n",
      "Batch 38: loss = 1.0846288204193115, acc = 0.65625\n",
      "Batch 39: loss = 1.023054599761963, acc = 0.6669921875\n",
      "Batch 40: loss = 0.9834966063499451, acc = 0.669921875\n",
      "Batch 41: loss = 0.8944355249404907, acc = 0.7041015625\n",
      "Batch 42: loss = 0.9159061908721924, acc = 0.69140625\n",
      "Batch 43: loss = 0.9944505095481873, acc = 0.6640625\n",
      "Batch 44: loss = 0.9402408599853516, acc = 0.6875\n",
      "Batch 45: loss = 0.8476295471191406, acc = 0.716796875\n",
      "Batch 46: loss = 0.9491223692893982, acc = 0.6904296875\n",
      "Batch 47: loss = 0.9334182739257812, acc = 0.693359375\n",
      "Batch 48: loss = 0.8881075978279114, acc = 0.6923828125\n",
      "Batch 49: loss = 0.8330168724060059, acc = 0.7373046875\n",
      "Batch 50: loss = 0.8763037919998169, acc = 0.7177734375\n",
      "Batch 51: loss = 0.901003897190094, acc = 0.7021484375\n",
      "Batch 52: loss = 0.98655104637146, acc = 0.6728515625\n",
      "Batch 53: loss = 0.9785606265068054, acc = 0.681640625\n",
      "Batch 54: loss = 0.8881563544273376, acc = 0.712890625\n",
      "Batch 55: loss = 0.8821585178375244, acc = 0.7109375\n",
      "Batch 56: loss = 0.9493929147720337, acc = 0.6806640625\n",
      "Batch 57: loss = 1.0534121990203857, acc = 0.650390625\n",
      "Batch 58: loss = 1.0239166021347046, acc = 0.6630859375\n",
      "Batch 59: loss = 0.8273909091949463, acc = 0.7470703125\n",
      "Batch 60: loss = 0.9545589685440063, acc = 0.6806640625\n",
      "Batch 61: loss = 1.020673155784607, acc = 0.67578125\n",
      "Batch 62: loss = 1.1475509405136108, acc = 0.615234375\n",
      "Batch 63: loss = 1.1169302463531494, acc = 0.6376953125\n",
      "Batch 64: loss = 0.8252424001693726, acc = 0.7236328125\n",
      "Batch 65: loss = 0.9621995091438293, acc = 0.677734375\n",
      "Batch 66: loss = 0.962752103805542, acc = 0.6865234375\n",
      "Batch 67: loss = 0.8841979503631592, acc = 0.712890625\n",
      "Batch 68: loss = 0.9937850832939148, acc = 0.6796875\n",
      "Batch 69: loss = 0.9454163312911987, acc = 0.7001953125\n",
      "Batch 70: loss = 1.0212631225585938, acc = 0.6591796875\n",
      "Batch 71: loss = 0.9477493166923523, acc = 0.6884765625\n",
      "Batch 72: loss = 0.8994849920272827, acc = 0.7001953125\n",
      "Batch 73: loss = 1.0243945121765137, acc = 0.66015625\n",
      "Batch 74: loss = 1.0069684982299805, acc = 0.6650390625\n",
      "Batch 75: loss = 1.098734736442566, acc = 0.634765625\n",
      "Batch 76: loss = 1.0146859884262085, acc = 0.650390625\n",
      "Batch 77: loss = 0.9272229671478271, acc = 0.6904296875\n",
      "Batch 78: loss = 0.952082633972168, acc = 0.673828125\n",
      "Batch 79: loss = 0.8005636930465698, acc = 0.744140625\n",
      "Batch 80: loss = 0.8570641875267029, acc = 0.6923828125\n",
      "Batch 81: loss = 0.9228746891021729, acc = 0.7099609375\n",
      "Batch 82: loss = 0.8381412029266357, acc = 0.72265625\n",
      "Batch 83: loss = 0.9505696296691895, acc = 0.681640625\n",
      "Batch 84: loss = 0.9005253314971924, acc = 0.712890625\n",
      "Batch 85: loss = 1.0247200727462769, acc = 0.6611328125\n",
      "Batch 86: loss = 0.9645516872406006, acc = 0.6884765625\n",
      "Batch 87: loss = 0.9433543682098389, acc = 0.6826171875\n",
      "Batch 88: loss = 1.092484474182129, acc = 0.6494140625\n",
      "Batch 89: loss = 0.9776625633239746, acc = 0.689453125\n",
      "Batch 90: loss = 1.015636920928955, acc = 0.6689453125\n",
      "Batch 91: loss = 1.008987307548523, acc = 0.6591796875\n",
      "Batch 92: loss = 0.9524247646331787, acc = 0.69140625\n",
      "Batch 93: loss = 0.8532594442367554, acc = 0.7255859375\n",
      "Batch 94: loss = 0.8920064568519592, acc = 0.7119140625\n",
      "Batch 95: loss = 0.9370136260986328, acc = 0.671875\n",
      "Batch 96: loss = 0.9836684465408325, acc = 0.6708984375\n",
      "Batch 97: loss = 0.9722856283187866, acc = 0.705078125\n",
      "Batch 98: loss = 0.9524440765380859, acc = 0.7001953125\n",
      "Batch 99: loss = 0.9640767574310303, acc = 0.673828125\n",
      "Batch 100: loss = 0.9439297914505005, acc = 0.67578125\n",
      "Batch 101: loss = 0.9773261547088623, acc = 0.685546875\n",
      "Batch 102: loss = 1.0548222064971924, acc = 0.65625\n",
      "Batch 103: loss = 0.9826494455337524, acc = 0.68359375\n",
      "Batch 104: loss = 0.8846768140792847, acc = 0.6875\n",
      "Batch 105: loss = 0.9449992775917053, acc = 0.6923828125\n",
      "Batch 106: loss = 1.0017962455749512, acc = 0.69140625\n",
      "Batch 107: loss = 0.9254351854324341, acc = 0.69921875\n",
      "Batch 108: loss = 0.9416316151618958, acc = 0.6962890625\n",
      "Batch 109: loss = 0.9229487180709839, acc = 0.69140625\n",
      "Batch 110: loss = 0.8782068490982056, acc = 0.7041015625\n",
      "Batch 111: loss = 1.054997205734253, acc = 0.65234375\n",
      "Batch 112: loss = 0.9141190052032471, acc = 0.6953125\n",
      "Batch 113: loss = 0.9788872003555298, acc = 0.6796875\n",
      "Batch 114: loss = 0.9997515678405762, acc = 0.685546875\n",
      "Batch 115: loss = 1.0444949865341187, acc = 0.6572265625\n",
      "Batch 116: loss = 1.056811809539795, acc = 0.6640625\n",
      "Batch 117: loss = 0.9366517066955566, acc = 0.6884765625\n",
      "Batch 118: loss = 0.8740469217300415, acc = 0.7060546875\n",
      "Batch 119: loss = 0.9886358976364136, acc = 0.669921875\n",
      "Batch 120: loss = 1.0127769708633423, acc = 0.666015625\n",
      "Batch 121: loss = 0.9448556900024414, acc = 0.6875\n",
      "Batch 122: loss = 0.9298216104507446, acc = 0.6943359375\n",
      "Batch 123: loss = 0.9769063591957092, acc = 0.6748046875\n",
      "Batch 124: loss = 1.0132001638412476, acc = 0.65625\n",
      "Batch 125: loss = 1.0037370920181274, acc = 0.669921875\n",
      "Batch 126: loss = 1.0729014873504639, acc = 0.6494140625\n",
      "\n",
      "Epoch 19/100\n",
      "Batch 1: loss = 1.2147891521453857, acc = 0.625\n",
      "Batch 2: loss = 1.1258320808410645, acc = 0.6474609375\n",
      "Batch 3: loss = 1.0098220109939575, acc = 0.6845703125\n",
      "Batch 4: loss = 0.9931954145431519, acc = 0.69140625\n",
      "Batch 5: loss = 1.084946632385254, acc = 0.642578125\n",
      "Batch 6: loss = 1.1019301414489746, acc = 0.634765625\n",
      "Batch 7: loss = 1.0386912822723389, acc = 0.6494140625\n",
      "Batch 8: loss = 0.988776683807373, acc = 0.6767578125\n",
      "Batch 9: loss = 0.9344012141227722, acc = 0.6953125\n",
      "Batch 10: loss = 0.8827880024909973, acc = 0.70703125\n",
      "Batch 11: loss = 1.0035325288772583, acc = 0.6591796875\n",
      "Batch 12: loss = 1.0386061668395996, acc = 0.6630859375\n",
      "Batch 13: loss = 0.9752697944641113, acc = 0.6875\n",
      "Batch 14: loss = 0.9369027614593506, acc = 0.685546875\n",
      "Batch 15: loss = 0.9095048904418945, acc = 0.701171875\n",
      "Batch 16: loss = 1.0140633583068848, acc = 0.6650390625\n",
      "Batch 17: loss = 0.997941792011261, acc = 0.6845703125\n",
      "Batch 18: loss = 1.0005824565887451, acc = 0.66796875\n",
      "Batch 19: loss = 0.9579057097434998, acc = 0.6923828125\n",
      "Batch 20: loss = 0.9552274942398071, acc = 0.6806640625\n",
      "Batch 21: loss = 1.0850653648376465, acc = 0.6455078125\n",
      "Batch 22: loss = 0.9227680563926697, acc = 0.697265625\n",
      "Batch 23: loss = 0.924248456954956, acc = 0.6953125\n",
      "Batch 24: loss = 0.9506285786628723, acc = 0.6875\n",
      "Batch 25: loss = 0.8873032927513123, acc = 0.70703125\n",
      "Batch 26: loss = 0.9027215242385864, acc = 0.7138671875\n",
      "Batch 27: loss = 1.0232439041137695, acc = 0.6630859375\n",
      "Batch 28: loss = 0.9649295806884766, acc = 0.673828125\n",
      "Batch 29: loss = 0.9522311091423035, acc = 0.7021484375\n",
      "Batch 30: loss = 0.9077905416488647, acc = 0.6982421875\n",
      "Batch 31: loss = 1.0526913404464722, acc = 0.650390625\n",
      "Batch 32: loss = 1.1444568634033203, acc = 0.634765625\n",
      "Batch 33: loss = 0.9358510971069336, acc = 0.6904296875\n",
      "Batch 34: loss = 0.9996227025985718, acc = 0.6728515625\n",
      "Batch 35: loss = 0.9868130087852478, acc = 0.6865234375\n",
      "Batch 36: loss = 0.9628292322158813, acc = 0.6962890625\n",
      "Batch 37: loss = 0.9716170430183411, acc = 0.697265625\n",
      "Batch 38: loss = 1.0635902881622314, acc = 0.6650390625\n",
      "Batch 39: loss = 0.9865404367446899, acc = 0.677734375\n",
      "Batch 40: loss = 0.9503501653671265, acc = 0.6884765625\n",
      "Batch 41: loss = 0.868755578994751, acc = 0.7041015625\n",
      "Batch 42: loss = 0.9161182641983032, acc = 0.6884765625\n",
      "Batch 43: loss = 0.9904308319091797, acc = 0.6630859375\n",
      "Batch 44: loss = 0.9223549962043762, acc = 0.6943359375\n",
      "Batch 45: loss = 0.8133816719055176, acc = 0.7236328125\n",
      "Batch 46: loss = 0.9426694512367249, acc = 0.689453125\n",
      "Batch 47: loss = 0.9092843532562256, acc = 0.7158203125\n",
      "Batch 48: loss = 0.8538962006568909, acc = 0.7041015625\n",
      "Batch 49: loss = 0.8172125816345215, acc = 0.7314453125\n",
      "Batch 50: loss = 0.8707841038703918, acc = 0.732421875\n",
      "Batch 51: loss = 0.8829432725906372, acc = 0.70703125\n",
      "Batch 52: loss = 0.9548859596252441, acc = 0.6875\n",
      "Batch 53: loss = 0.9724467992782593, acc = 0.6884765625\n",
      "Batch 54: loss = 0.8668923377990723, acc = 0.716796875\n",
      "Batch 55: loss = 0.8736704587936401, acc = 0.7177734375\n",
      "Batch 56: loss = 0.93849778175354, acc = 0.6826171875\n",
      "Batch 57: loss = 1.0250942707061768, acc = 0.6591796875\n",
      "Batch 58: loss = 1.0038996934890747, acc = 0.6728515625\n",
      "Batch 59: loss = 0.8235294818878174, acc = 0.7353515625\n",
      "Batch 60: loss = 0.947431206703186, acc = 0.689453125\n",
      "Batch 61: loss = 0.9816095232963562, acc = 0.685546875\n",
      "Batch 62: loss = 1.1215375661849976, acc = 0.619140625\n",
      "Batch 63: loss = 1.0922472476959229, acc = 0.64453125\n",
      "Batch 64: loss = 0.8128751516342163, acc = 0.724609375\n",
      "Batch 65: loss = 0.9587754011154175, acc = 0.701171875\n",
      "Batch 66: loss = 0.9214435815811157, acc = 0.703125\n",
      "Batch 67: loss = 0.8496806621551514, acc = 0.728515625\n",
      "Batch 68: loss = 0.9717427492141724, acc = 0.6865234375\n",
      "Batch 69: loss = 0.947955846786499, acc = 0.7099609375\n",
      "Batch 70: loss = 1.0007110834121704, acc = 0.6787109375\n",
      "Batch 71: loss = 0.9387029409408569, acc = 0.6884765625\n",
      "Batch 72: loss = 0.876251220703125, acc = 0.708984375\n",
      "Batch 73: loss = 0.9971758127212524, acc = 0.671875\n",
      "Batch 74: loss = 0.993263840675354, acc = 0.669921875\n",
      "Batch 75: loss = 1.0533113479614258, acc = 0.6435546875\n",
      "Batch 76: loss = 0.9717334508895874, acc = 0.689453125\n",
      "Batch 77: loss = 0.8711340427398682, acc = 0.716796875\n",
      "Batch 78: loss = 0.9122650623321533, acc = 0.693359375\n",
      "Batch 79: loss = 0.8012762069702148, acc = 0.732421875\n",
      "Batch 80: loss = 0.8569574356079102, acc = 0.69140625\n",
      "Batch 81: loss = 0.9190247654914856, acc = 0.701171875\n",
      "Batch 82: loss = 0.813307523727417, acc = 0.7373046875\n",
      "Batch 83: loss = 0.9178932905197144, acc = 0.69140625\n",
      "Batch 84: loss = 0.8886659741401672, acc = 0.7177734375\n",
      "Batch 85: loss = 1.0031893253326416, acc = 0.6767578125\n",
      "Batch 86: loss = 0.959040641784668, acc = 0.6953125\n",
      "Batch 87: loss = 0.9151627421379089, acc = 0.6943359375\n",
      "Batch 88: loss = 1.0891339778900146, acc = 0.6494140625\n",
      "Batch 89: loss = 0.9805474281311035, acc = 0.685546875\n",
      "Batch 90: loss = 0.9877039194107056, acc = 0.6787109375\n",
      "Batch 91: loss = 0.9856768250465393, acc = 0.677734375\n",
      "Batch 92: loss = 0.9210172891616821, acc = 0.7021484375\n",
      "Batch 93: loss = 0.8328096866607666, acc = 0.734375\n",
      "Batch 94: loss = 0.8763703107833862, acc = 0.720703125\n",
      "Batch 95: loss = 0.9334326982498169, acc = 0.6865234375\n",
      "Batch 96: loss = 0.9651203751564026, acc = 0.677734375\n",
      "Batch 97: loss = 0.9411134123802185, acc = 0.6923828125\n",
      "Batch 98: loss = 0.9231430292129517, acc = 0.7138671875\n",
      "Batch 99: loss = 0.9442797899246216, acc = 0.6865234375\n",
      "Batch 100: loss = 0.9331134557723999, acc = 0.669921875\n",
      "Batch 101: loss = 0.9362297058105469, acc = 0.68359375\n",
      "Batch 102: loss = 1.0158040523529053, acc = 0.6640625\n",
      "Batch 103: loss = 0.9637922048568726, acc = 0.6708984375\n",
      "Batch 104: loss = 0.8540619015693665, acc = 0.7119140625\n",
      "Batch 105: loss = 0.8866442441940308, acc = 0.7158203125\n",
      "Batch 106: loss = 0.9557738900184631, acc = 0.6962890625\n",
      "Batch 107: loss = 0.9312096238136292, acc = 0.70703125\n",
      "Batch 108: loss = 0.924461305141449, acc = 0.693359375\n",
      "Batch 109: loss = 0.8998609781265259, acc = 0.693359375\n",
      "Batch 110: loss = 0.8386660218238831, acc = 0.7353515625\n",
      "Batch 111: loss = 1.033216118812561, acc = 0.6591796875\n",
      "Batch 112: loss = 0.9118464589118958, acc = 0.7177734375\n",
      "Batch 113: loss = 0.9597005844116211, acc = 0.677734375\n",
      "Batch 114: loss = 0.97788006067276, acc = 0.69140625\n",
      "Batch 115: loss = 1.0103349685668945, acc = 0.67578125\n",
      "Batch 116: loss = 1.0357041358947754, acc = 0.671875\n",
      "Batch 117: loss = 0.8924440145492554, acc = 0.703125\n",
      "Batch 118: loss = 0.8718283176422119, acc = 0.6982421875\n",
      "Batch 119: loss = 0.950913667678833, acc = 0.6806640625\n",
      "Batch 120: loss = 0.9815679788589478, acc = 0.6728515625\n",
      "Batch 121: loss = 0.9354867339134216, acc = 0.685546875\n",
      "Batch 122: loss = 0.9016988277435303, acc = 0.6962890625\n",
      "Batch 123: loss = 0.9482050538063049, acc = 0.6904296875\n",
      "Batch 124: loss = 0.986636757850647, acc = 0.66796875\n",
      "Batch 125: loss = 0.9861693978309631, acc = 0.67578125\n",
      "Batch 126: loss = 1.0444471836090088, acc = 0.6572265625\n",
      "\n",
      "Epoch 20/100\n",
      "Batch 1: loss = 1.1982831954956055, acc = 0.625\n",
      "Batch 2: loss = 1.0845069885253906, acc = 0.6611328125\n",
      "Batch 3: loss = 0.978293240070343, acc = 0.685546875\n",
      "Batch 4: loss = 0.9639201164245605, acc = 0.7060546875\n",
      "Batch 5: loss = 1.0515238046646118, acc = 0.669921875\n",
      "Batch 6: loss = 1.0595676898956299, acc = 0.65234375\n",
      "Batch 7: loss = 1.0216888189315796, acc = 0.66796875\n",
      "Batch 8: loss = 0.9592220783233643, acc = 0.6904296875\n",
      "Batch 9: loss = 0.9143311381340027, acc = 0.7060546875\n",
      "Batch 10: loss = 0.8696302175521851, acc = 0.71875\n",
      "Batch 11: loss = 0.9944286346435547, acc = 0.669921875\n",
      "Batch 12: loss = 1.0065853595733643, acc = 0.6689453125\n",
      "Batch 13: loss = 0.9704996943473816, acc = 0.66015625\n",
      "Batch 14: loss = 0.9212221503257751, acc = 0.693359375\n",
      "Batch 15: loss = 0.9005918502807617, acc = 0.7080078125\n",
      "Batch 16: loss = 1.0003160238265991, acc = 0.6669921875\n",
      "Batch 17: loss = 0.9842122197151184, acc = 0.693359375\n",
      "Batch 18: loss = 0.9817704558372498, acc = 0.689453125\n",
      "Batch 19: loss = 0.9440057277679443, acc = 0.703125\n",
      "Batch 20: loss = 0.9375585317611694, acc = 0.69140625\n",
      "Batch 21: loss = 1.0696525573730469, acc = 0.6513671875\n",
      "Batch 22: loss = 0.9065156579017639, acc = 0.7119140625\n",
      "Batch 23: loss = 0.9038456678390503, acc = 0.7041015625\n",
      "Batch 24: loss = 0.9039376974105835, acc = 0.693359375\n",
      "Batch 25: loss = 0.8659364581108093, acc = 0.712890625\n",
      "Batch 26: loss = 0.8747494220733643, acc = 0.724609375\n",
      "Batch 27: loss = 1.0041530132293701, acc = 0.67578125\n",
      "Batch 28: loss = 0.9383513927459717, acc = 0.693359375\n",
      "Batch 29: loss = 0.9263001084327698, acc = 0.70703125\n",
      "Batch 30: loss = 0.8813721537590027, acc = 0.7265625\n",
      "Batch 31: loss = 1.0375869274139404, acc = 0.66796875\n",
      "Batch 32: loss = 1.1136672496795654, acc = 0.6484375\n",
      "Batch 33: loss = 0.9301441311836243, acc = 0.693359375\n",
      "Batch 34: loss = 0.9862883687019348, acc = 0.6845703125\n",
      "Batch 35: loss = 0.9766138792037964, acc = 0.6923828125\n",
      "Batch 36: loss = 0.9430303573608398, acc = 0.7041015625\n",
      "Batch 37: loss = 0.9614018797874451, acc = 0.69921875\n",
      "Batch 38: loss = 1.0245641469955444, acc = 0.671875\n",
      "Batch 39: loss = 0.9611738920211792, acc = 0.6748046875\n",
      "Batch 40: loss = 0.9131976366043091, acc = 0.6884765625\n",
      "Batch 41: loss = 0.8759030699729919, acc = 0.70703125\n",
      "Batch 42: loss = 0.8934419751167297, acc = 0.69140625\n",
      "Batch 43: loss = 0.9471485614776611, acc = 0.6806640625\n",
      "Batch 44: loss = 0.9358572363853455, acc = 0.7041015625\n",
      "Batch 45: loss = 0.7861202955245972, acc = 0.7333984375\n",
      "Batch 46: loss = 0.9063201546669006, acc = 0.70703125\n",
      "Batch 47: loss = 0.8898440599441528, acc = 0.7138671875\n",
      "Batch 48: loss = 0.8520190715789795, acc = 0.716796875\n",
      "Batch 49: loss = 0.8052603602409363, acc = 0.7451171875\n",
      "Batch 50: loss = 0.8467358946800232, acc = 0.7353515625\n",
      "Batch 51: loss = 0.8683335185050964, acc = 0.7021484375\n",
      "Batch 52: loss = 0.9515678882598877, acc = 0.6796875\n",
      "Batch 53: loss = 0.9578266143798828, acc = 0.6845703125\n",
      "Batch 54: loss = 0.8204054832458496, acc = 0.73046875\n",
      "Batch 55: loss = 0.8617138862609863, acc = 0.7294921875\n",
      "Batch 56: loss = 0.8873538970947266, acc = 0.6962890625\n",
      "Batch 57: loss = 0.9964375495910645, acc = 0.6728515625\n",
      "Batch 58: loss = 0.9788838624954224, acc = 0.68359375\n",
      "Batch 59: loss = 0.7882527112960815, acc = 0.740234375\n",
      "Batch 60: loss = 0.9199347496032715, acc = 0.6953125\n",
      "Batch 61: loss = 0.9761724472045898, acc = 0.6689453125\n",
      "Batch 62: loss = 1.1013165712356567, acc = 0.6201171875\n",
      "Batch 63: loss = 1.0652143955230713, acc = 0.6474609375\n",
      "Batch 64: loss = 0.7912479639053345, acc = 0.736328125\n",
      "Batch 65: loss = 0.9518353939056396, acc = 0.69140625\n",
      "Batch 66: loss = 0.9186495542526245, acc = 0.7041015625\n",
      "Batch 67: loss = 0.8587155342102051, acc = 0.7109375\n",
      "Batch 68: loss = 0.9339261651039124, acc = 0.7041015625\n",
      "Batch 69: loss = 0.9198778867721558, acc = 0.7080078125\n",
      "Batch 70: loss = 0.9973157048225403, acc = 0.66015625\n",
      "Batch 71: loss = 0.9327220916748047, acc = 0.6943359375\n",
      "Batch 72: loss = 0.8650173544883728, acc = 0.716796875\n",
      "Batch 73: loss = 0.9913264513015747, acc = 0.681640625\n",
      "Batch 74: loss = 0.9410767555236816, acc = 0.6865234375\n",
      "Batch 75: loss = 1.0326714515686035, acc = 0.65234375\n",
      "Batch 76: loss = 0.9662405252456665, acc = 0.6748046875\n",
      "Batch 77: loss = 0.8463214039802551, acc = 0.7294921875\n",
      "Batch 78: loss = 0.9091084003448486, acc = 0.6962890625\n",
      "Batch 79: loss = 0.8024910688400269, acc = 0.7216796875\n",
      "Batch 80: loss = 0.8436248302459717, acc = 0.7060546875\n",
      "Batch 81: loss = 0.8983865976333618, acc = 0.71484375\n",
      "Batch 82: loss = 0.7923827171325684, acc = 0.736328125\n",
      "Batch 83: loss = 0.9210185408592224, acc = 0.6865234375\n",
      "Batch 84: loss = 0.8855960369110107, acc = 0.7109375\n",
      "Batch 85: loss = 0.9835755228996277, acc = 0.6640625\n",
      "Batch 86: loss = 0.9341819286346436, acc = 0.6875\n",
      "Batch 87: loss = 0.8700014352798462, acc = 0.7109375\n",
      "Batch 88: loss = 1.0405709743499756, acc = 0.6689453125\n",
      "Batch 89: loss = 0.9296363592147827, acc = 0.693359375\n",
      "Batch 90: loss = 0.9961907267570496, acc = 0.6845703125\n",
      "Batch 91: loss = 0.9837316274642944, acc = 0.673828125\n",
      "Batch 92: loss = 0.8979789018630981, acc = 0.708984375\n",
      "Batch 93: loss = 0.8259243965148926, acc = 0.7373046875\n",
      "Batch 94: loss = 0.863331139087677, acc = 0.7138671875\n",
      "Batch 95: loss = 0.8829047679901123, acc = 0.7001953125\n",
      "Batch 96: loss = 0.9399742484092712, acc = 0.685546875\n",
      "Batch 97: loss = 0.927715003490448, acc = 0.71484375\n",
      "Batch 98: loss = 0.9160121083259583, acc = 0.7197265625\n",
      "Batch 99: loss = 0.9150874018669128, acc = 0.6943359375\n",
      "Batch 100: loss = 0.9188581705093384, acc = 0.6708984375\n",
      "Batch 101: loss = 0.91950523853302, acc = 0.693359375\n",
      "Batch 102: loss = 0.9910244345664978, acc = 0.69140625\n",
      "Batch 103: loss = 0.9482352137565613, acc = 0.689453125\n",
      "Batch 104: loss = 0.8651757836341858, acc = 0.7099609375\n",
      "Batch 105: loss = 0.8815191388130188, acc = 0.71484375\n",
      "Batch 106: loss = 0.9688780307769775, acc = 0.6962890625\n",
      "Batch 107: loss = 0.902840256690979, acc = 0.708984375\n",
      "Batch 108: loss = 0.9138729572296143, acc = 0.6943359375\n",
      "Batch 109: loss = 0.8948099613189697, acc = 0.71484375\n",
      "Batch 110: loss = 0.8166511058807373, acc = 0.7255859375\n",
      "Batch 111: loss = 1.0324347019195557, acc = 0.677734375\n",
      "Batch 112: loss = 0.8708556294441223, acc = 0.6943359375\n",
      "Batch 113: loss = 0.9459218978881836, acc = 0.6884765625\n",
      "Batch 114: loss = 0.9681972861289978, acc = 0.69921875\n",
      "Batch 115: loss = 0.9832265973091125, acc = 0.67578125\n",
      "Batch 116: loss = 1.035616159439087, acc = 0.669921875\n",
      "Batch 117: loss = 0.8820730447769165, acc = 0.70703125\n",
      "Batch 118: loss = 0.8450523614883423, acc = 0.7216796875\n",
      "Batch 119: loss = 0.9315376281738281, acc = 0.6884765625\n",
      "Batch 120: loss = 0.9704803824424744, acc = 0.681640625\n",
      "Batch 121: loss = 0.8881740570068359, acc = 0.7158203125\n",
      "Batch 122: loss = 0.8866314888000488, acc = 0.708984375\n",
      "Batch 123: loss = 0.9418952465057373, acc = 0.7001953125\n",
      "Batch 124: loss = 0.9531040191650391, acc = 0.67578125\n",
      "Batch 125: loss = 0.9708585739135742, acc = 0.6875\n",
      "Batch 126: loss = 1.0148296356201172, acc = 0.673828125\n",
      "Saved checkpoint to weights.20.h5\n",
      "\n",
      "Epoch 21/100\n",
      "Batch 1: loss = 1.1689889430999756, acc = 0.6298828125\n",
      "Batch 2: loss = 1.0712047815322876, acc = 0.65625\n",
      "Batch 3: loss = 0.9937795400619507, acc = 0.6875\n",
      "Batch 4: loss = 0.9422109127044678, acc = 0.7001953125\n",
      "Batch 5: loss = 1.0446797609329224, acc = 0.671875\n",
      "Batch 6: loss = 1.0419001579284668, acc = 0.658203125\n",
      "Batch 7: loss = 1.0198947191238403, acc = 0.681640625\n",
      "Batch 8: loss = 0.9313270449638367, acc = 0.6875\n",
      "Batch 9: loss = 0.8682621717453003, acc = 0.7275390625\n",
      "Batch 10: loss = 0.8483265042304993, acc = 0.7236328125\n",
      "Batch 11: loss = 0.9869707822799683, acc = 0.6767578125\n",
      "Batch 12: loss = 0.9869905114173889, acc = 0.66796875\n",
      "Batch 13: loss = 0.9193150997161865, acc = 0.6943359375\n",
      "Batch 14: loss = 0.8909217119216919, acc = 0.7158203125\n",
      "Batch 15: loss = 0.8720601797103882, acc = 0.716796875\n",
      "Batch 16: loss = 0.9739137887954712, acc = 0.6650390625\n",
      "Batch 17: loss = 0.9556494355201721, acc = 0.6904296875\n",
      "Batch 18: loss = 0.9654402732849121, acc = 0.6787109375\n",
      "Batch 19: loss = 0.895531415939331, acc = 0.7197265625\n",
      "Batch 20: loss = 0.916309654712677, acc = 0.703125\n",
      "Batch 21: loss = 1.041413426399231, acc = 0.6552734375\n",
      "Batch 22: loss = 0.8973211646080017, acc = 0.703125\n",
      "Batch 23: loss = 0.8804054260253906, acc = 0.697265625\n",
      "Batch 24: loss = 0.8733205199241638, acc = 0.7060546875\n",
      "Batch 25: loss = 0.8201428651809692, acc = 0.720703125\n",
      "Batch 26: loss = 0.8528921008110046, acc = 0.7216796875\n",
      "Batch 27: loss = 0.9912685751914978, acc = 0.6806640625\n",
      "Batch 28: loss = 0.922288179397583, acc = 0.7001953125\n",
      "Batch 29: loss = 0.9141823053359985, acc = 0.7080078125\n",
      "Batch 30: loss = 0.8276481628417969, acc = 0.724609375\n",
      "Batch 31: loss = 0.9859386086463928, acc = 0.6884765625\n",
      "Batch 32: loss = 1.091529130935669, acc = 0.6474609375\n",
      "Batch 33: loss = 0.9084551334381104, acc = 0.7001953125\n",
      "Batch 34: loss = 0.9964863061904907, acc = 0.671875\n",
      "Batch 35: loss = 0.9589029550552368, acc = 0.6953125\n",
      "Batch 36: loss = 0.9358373880386353, acc = 0.703125\n",
      "Batch 37: loss = 0.9156491756439209, acc = 0.7001953125\n",
      "Batch 38: loss = 0.9887534379959106, acc = 0.693359375\n",
      "Batch 39: loss = 0.9709463119506836, acc = 0.685546875\n",
      "Batch 40: loss = 0.8973528146743774, acc = 0.708984375\n",
      "Batch 41: loss = 0.8475958108901978, acc = 0.7265625\n",
      "Batch 42: loss = 0.9098984003067017, acc = 0.6982421875\n",
      "Batch 43: loss = 0.9270824790000916, acc = 0.685546875\n",
      "Batch 44: loss = 0.8658919334411621, acc = 0.7265625\n",
      "Batch 45: loss = 0.769885241985321, acc = 0.7431640625\n",
      "Batch 46: loss = 0.8781592845916748, acc = 0.7177734375\n",
      "Batch 47: loss = 0.8690391778945923, acc = 0.705078125\n",
      "Batch 48: loss = 0.8296844959259033, acc = 0.7197265625\n",
      "Batch 49: loss = 0.7960496544837952, acc = 0.7451171875\n",
      "Batch 50: loss = 0.8385961651802063, acc = 0.728515625\n",
      "Batch 51: loss = 0.8643819093704224, acc = 0.70703125\n",
      "Batch 52: loss = 0.9309499263763428, acc = 0.703125\n",
      "Batch 53: loss = 0.9268450140953064, acc = 0.6982421875\n",
      "Batch 54: loss = 0.8297823071479797, acc = 0.72265625\n",
      "Batch 55: loss = 0.8313016295433044, acc = 0.7216796875\n",
      "Batch 56: loss = 0.8647129535675049, acc = 0.7021484375\n",
      "Batch 57: loss = 0.9902421236038208, acc = 0.6640625\n",
      "Batch 58: loss = 0.9610596895217896, acc = 0.6865234375\n",
      "Batch 59: loss = 0.7433524131774902, acc = 0.763671875\n",
      "Batch 60: loss = 0.8922394514083862, acc = 0.7080078125\n",
      "Batch 61: loss = 0.9285913109779358, acc = 0.703125\n",
      "Batch 62: loss = 1.0831427574157715, acc = 0.64453125\n",
      "Batch 63: loss = 1.052193284034729, acc = 0.65625\n",
      "Batch 64: loss = 0.7772895097732544, acc = 0.7451171875\n",
      "Batch 65: loss = 0.920012354850769, acc = 0.6923828125\n",
      "Batch 66: loss = 0.884648323059082, acc = 0.7197265625\n",
      "Batch 67: loss = 0.8300255537033081, acc = 0.7255859375\n",
      "Batch 68: loss = 0.9237042665481567, acc = 0.703125\n",
      "Batch 69: loss = 0.8913223743438721, acc = 0.712890625\n",
      "Batch 70: loss = 0.9638993740081787, acc = 0.6875\n",
      "Batch 71: loss = 0.9140435457229614, acc = 0.6982421875\n",
      "Batch 72: loss = 0.8474289178848267, acc = 0.7109375\n",
      "Batch 73: loss = 0.9585946798324585, acc = 0.6787109375\n",
      "Batch 74: loss = 0.9269310235977173, acc = 0.6826171875\n",
      "Batch 75: loss = 1.0147831439971924, acc = 0.669921875\n",
      "Batch 76: loss = 0.945583164691925, acc = 0.68359375\n",
      "Batch 77: loss = 0.8338854908943176, acc = 0.7314453125\n",
      "Batch 78: loss = 0.8702913522720337, acc = 0.7109375\n",
      "Batch 79: loss = 0.7726675271987915, acc = 0.74609375\n",
      "Batch 80: loss = 0.8236914873123169, acc = 0.7080078125\n",
      "Batch 81: loss = 0.8761612176895142, acc = 0.716796875\n",
      "Batch 82: loss = 0.789298415184021, acc = 0.75\n",
      "Batch 83: loss = 0.8769066333770752, acc = 0.70703125\n",
      "Batch 84: loss = 0.8557325601577759, acc = 0.7255859375\n",
      "Batch 85: loss = 0.9625470638275146, acc = 0.6923828125\n",
      "Batch 86: loss = 0.9119939804077148, acc = 0.7021484375\n",
      "Batch 87: loss = 0.8517858982086182, acc = 0.7216796875\n",
      "Batch 88: loss = 1.0176281929016113, acc = 0.671875\n",
      "Batch 89: loss = 0.9396591186523438, acc = 0.6875\n",
      "Batch 90: loss = 0.9583189487457275, acc = 0.701171875\n",
      "Batch 91: loss = 0.9422956705093384, acc = 0.693359375\n",
      "Batch 92: loss = 0.9168250560760498, acc = 0.6962890625\n",
      "Batch 93: loss = 0.7844752073287964, acc = 0.759765625\n",
      "Batch 94: loss = 0.83870530128479, acc = 0.7255859375\n",
      "Batch 95: loss = 0.8767729997634888, acc = 0.703125\n",
      "Batch 96: loss = 0.948055624961853, acc = 0.6845703125\n",
      "Batch 97: loss = 0.9304006099700928, acc = 0.7119140625\n",
      "Batch 98: loss = 0.8839288949966431, acc = 0.720703125\n",
      "Batch 99: loss = 0.8872246146202087, acc = 0.7099609375\n",
      "Batch 100: loss = 0.8811293840408325, acc = 0.69921875\n",
      "Batch 101: loss = 0.8966569900512695, acc = 0.7021484375\n",
      "Batch 102: loss = 0.9902640581130981, acc = 0.681640625\n",
      "Batch 103: loss = 0.8929792642593384, acc = 0.7041015625\n",
      "Batch 104: loss = 0.8265770077705383, acc = 0.7314453125\n",
      "Batch 105: loss = 0.9043283462524414, acc = 0.703125\n",
      "Batch 106: loss = 0.9402991533279419, acc = 0.6884765625\n",
      "Batch 107: loss = 0.8678096532821655, acc = 0.720703125\n",
      "Batch 108: loss = 0.887272834777832, acc = 0.69921875\n",
      "Batch 109: loss = 0.88112473487854, acc = 0.7001953125\n",
      "Batch 110: loss = 0.8002440929412842, acc = 0.732421875\n",
      "Batch 111: loss = 0.9865431785583496, acc = 0.6767578125\n",
      "Batch 112: loss = 0.8743412494659424, acc = 0.7109375\n",
      "Batch 113: loss = 0.9419564008712769, acc = 0.6962890625\n",
      "Batch 114: loss = 0.9428308010101318, acc = 0.7060546875\n",
      "Batch 115: loss = 0.9619265794754028, acc = 0.6962890625\n",
      "Batch 116: loss = 1.0263627767562866, acc = 0.6650390625\n",
      "Batch 117: loss = 0.8586514592170715, acc = 0.7236328125\n",
      "Batch 118: loss = 0.8225688934326172, acc = 0.734375\n",
      "Batch 119: loss = 0.9071922898292542, acc = 0.7080078125\n",
      "Batch 120: loss = 0.9634410738945007, acc = 0.677734375\n",
      "Batch 121: loss = 0.8878026008605957, acc = 0.7099609375\n",
      "Batch 122: loss = 0.890884280204773, acc = 0.705078125\n",
      "Batch 123: loss = 0.9211112260818481, acc = 0.7021484375\n",
      "Batch 124: loss = 0.9438952803611755, acc = 0.6806640625\n",
      "Batch 125: loss = 0.9561057686805725, acc = 0.67578125\n",
      "Batch 126: loss = 1.0086275339126587, acc = 0.6748046875\n",
      "\n",
      "Epoch 22/100\n",
      "Batch 1: loss = 1.1449061632156372, acc = 0.6455078125\n",
      "Batch 2: loss = 1.0561203956604004, acc = 0.65625\n",
      "Batch 3: loss = 0.961272656917572, acc = 0.6962890625\n",
      "Batch 4: loss = 0.9095282554626465, acc = 0.7236328125\n",
      "Batch 5: loss = 1.0404870510101318, acc = 0.66796875\n",
      "Batch 6: loss = 1.0205659866333008, acc = 0.654296875\n",
      "Batch 7: loss = 0.9749131202697754, acc = 0.6806640625\n",
      "Batch 8: loss = 0.9304062128067017, acc = 0.6962890625\n",
      "Batch 9: loss = 0.8535879850387573, acc = 0.7060546875\n",
      "Batch 10: loss = 0.855019211769104, acc = 0.728515625\n",
      "Batch 11: loss = 0.9435769319534302, acc = 0.689453125\n",
      "Batch 12: loss = 0.9525503516197205, acc = 0.67578125\n",
      "Batch 13: loss = 0.880123496055603, acc = 0.7060546875\n",
      "Batch 14: loss = 0.8695225715637207, acc = 0.7060546875\n",
      "Batch 15: loss = 0.8268880248069763, acc = 0.7333984375\n",
      "Batch 16: loss = 0.9398373365402222, acc = 0.6826171875\n",
      "Batch 17: loss = 0.9378492832183838, acc = 0.6962890625\n",
      "Batch 18: loss = 0.9336527585983276, acc = 0.6787109375\n",
      "Batch 19: loss = 0.8824639320373535, acc = 0.708984375\n",
      "Batch 20: loss = 0.8920097351074219, acc = 0.705078125\n",
      "Batch 21: loss = 1.0307366847991943, acc = 0.6650390625\n",
      "Batch 22: loss = 0.8707826733589172, acc = 0.7099609375\n",
      "Batch 23: loss = 0.8654163479804993, acc = 0.712890625\n",
      "Batch 24: loss = 0.8650514483451843, acc = 0.7109375\n",
      "Batch 25: loss = 0.819692850112915, acc = 0.732421875\n",
      "Batch 26: loss = 0.836707353591919, acc = 0.728515625\n",
      "Batch 27: loss = 0.9579869508743286, acc = 0.6953125\n",
      "Batch 28: loss = 0.9174419045448303, acc = 0.689453125\n",
      "Batch 29: loss = 0.9086045026779175, acc = 0.6982421875\n",
      "Batch 30: loss = 0.8343870639801025, acc = 0.732421875\n",
      "Batch 31: loss = 0.981880247592926, acc = 0.6884765625\n",
      "Batch 32: loss = 1.0699858665466309, acc = 0.6552734375\n",
      "Batch 33: loss = 0.8751765489578247, acc = 0.7197265625\n",
      "Batch 34: loss = 0.9434313774108887, acc = 0.6875\n",
      "Batch 35: loss = 0.9313753843307495, acc = 0.7109375\n",
      "Batch 36: loss = 0.9004431962966919, acc = 0.7138671875\n",
      "Batch 37: loss = 0.9118146896362305, acc = 0.7138671875\n",
      "Batch 38: loss = 0.9827342629432678, acc = 0.6796875\n",
      "Batch 39: loss = 0.9546076059341431, acc = 0.67578125\n",
      "Batch 40: loss = 0.8939512372016907, acc = 0.7158203125\n",
      "Batch 41: loss = 0.8131178617477417, acc = 0.734375\n",
      "Batch 42: loss = 0.8637880086898804, acc = 0.70703125\n",
      "Batch 43: loss = 0.9156521558761597, acc = 0.6923828125\n",
      "Batch 44: loss = 0.858504593372345, acc = 0.7314453125\n",
      "Batch 45: loss = 0.782400906085968, acc = 0.755859375\n",
      "Batch 46: loss = 0.8629335761070251, acc = 0.7275390625\n",
      "Batch 47: loss = 0.860884428024292, acc = 0.7275390625\n",
      "Batch 48: loss = 0.8375177979469299, acc = 0.7109375\n",
      "Batch 49: loss = 0.7661082744598389, acc = 0.7607421875\n",
      "Batch 50: loss = 0.8222037553787231, acc = 0.7451171875\n",
      "Batch 51: loss = 0.8257025480270386, acc = 0.7236328125\n",
      "Batch 52: loss = 0.9164612293243408, acc = 0.69921875\n",
      "Batch 53: loss = 0.9062440991401672, acc = 0.701171875\n",
      "Batch 54: loss = 0.8015776872634888, acc = 0.7431640625\n",
      "Batch 55: loss = 0.8131077289581299, acc = 0.732421875\n",
      "Batch 56: loss = 0.871878981590271, acc = 0.6982421875\n",
      "Batch 57: loss = 0.9486439228057861, acc = 0.671875\n",
      "Batch 58: loss = 0.9212729930877686, acc = 0.6923828125\n",
      "Batch 59: loss = 0.7730485796928406, acc = 0.763671875\n",
      "Batch 60: loss = 0.8832589387893677, acc = 0.7080078125\n",
      "Batch 61: loss = 0.9130586385726929, acc = 0.69921875\n",
      "Batch 62: loss = 1.0412871837615967, acc = 0.6572265625\n",
      "Batch 63: loss = 1.0295426845550537, acc = 0.650390625\n",
      "Batch 64: loss = 0.7506147623062134, acc = 0.7568359375\n",
      "Batch 65: loss = 0.9293524026870728, acc = 0.7060546875\n",
      "Batch 66: loss = 0.8935063481330872, acc = 0.7021484375\n",
      "Batch 67: loss = 0.8012230396270752, acc = 0.7255859375\n",
      "Batch 68: loss = 0.8927266597747803, acc = 0.716796875\n",
      "Batch 69: loss = 0.8494066596031189, acc = 0.7177734375\n",
      "Batch 70: loss = 0.9342244863510132, acc = 0.689453125\n",
      "Batch 71: loss = 0.8881446123123169, acc = 0.6904296875\n",
      "Batch 72: loss = 0.8416426181793213, acc = 0.72265625\n",
      "Batch 73: loss = 0.9424225091934204, acc = 0.69140625\n",
      "Batch 74: loss = 0.9062079787254333, acc = 0.6953125\n",
      "Batch 75: loss = 1.0038915872573853, acc = 0.6669921875\n",
      "Batch 76: loss = 0.9301530122756958, acc = 0.6982421875\n",
      "Batch 77: loss = 0.8290236592292786, acc = 0.7373046875\n",
      "Batch 78: loss = 0.8627415895462036, acc = 0.7041015625\n",
      "Batch 79: loss = 0.7634238004684448, acc = 0.7529296875\n",
      "Batch 80: loss = 0.8095423579216003, acc = 0.7109375\n",
      "Batch 81: loss = 0.8864173889160156, acc = 0.7099609375\n",
      "Batch 82: loss = 0.7740002870559692, acc = 0.7626953125\n",
      "Batch 83: loss = 0.8731036186218262, acc = 0.7138671875\n",
      "Batch 84: loss = 0.8454398512840271, acc = 0.734375\n",
      "Batch 85: loss = 0.9543541073799133, acc = 0.681640625\n",
      "Batch 86: loss = 0.9069066643714905, acc = 0.7041015625\n",
      "Batch 87: loss = 0.8519570231437683, acc = 0.7177734375\n",
      "Batch 88: loss = 0.9873064756393433, acc = 0.6884765625\n",
      "Batch 89: loss = 0.9078081250190735, acc = 0.7119140625\n",
      "Batch 90: loss = 0.951499879360199, acc = 0.6982421875\n",
      "Batch 91: loss = 0.9450235366821289, acc = 0.6865234375\n",
      "Batch 92: loss = 0.9113215208053589, acc = 0.6982421875\n",
      "Batch 93: loss = 0.7814834713935852, acc = 0.7509765625\n",
      "Batch 94: loss = 0.8184831142425537, acc = 0.73046875\n",
      "Batch 95: loss = 0.8368649482727051, acc = 0.7197265625\n",
      "Batch 96: loss = 0.9048910140991211, acc = 0.6943359375\n",
      "Batch 97: loss = 0.8951874375343323, acc = 0.7197265625\n",
      "Batch 98: loss = 0.85508793592453, acc = 0.732421875\n",
      "Batch 99: loss = 0.8820734024047852, acc = 0.7099609375\n",
      "Batch 100: loss = 0.882764458656311, acc = 0.703125\n",
      "Batch 101: loss = 0.8593155741691589, acc = 0.7158203125\n",
      "Batch 102: loss = 0.9703741669654846, acc = 0.6826171875\n",
      "Batch 103: loss = 0.8915530443191528, acc = 0.70703125\n",
      "Batch 104: loss = 0.8127045631408691, acc = 0.732421875\n",
      "Batch 105: loss = 0.8564234972000122, acc = 0.7255859375\n",
      "Batch 106: loss = 0.9229919910430908, acc = 0.6904296875\n",
      "Batch 107: loss = 0.8731414079666138, acc = 0.7158203125\n",
      "Batch 108: loss = 0.8842244148254395, acc = 0.71484375\n",
      "Batch 109: loss = 0.8566453456878662, acc = 0.708984375\n",
      "Batch 110: loss = 0.8048080205917358, acc = 0.7373046875\n",
      "Batch 111: loss = 0.9783671498298645, acc = 0.6865234375\n",
      "Batch 112: loss = 0.8619891405105591, acc = 0.7216796875\n",
      "Batch 113: loss = 0.9227232933044434, acc = 0.6943359375\n",
      "Batch 114: loss = 0.9377438426017761, acc = 0.703125\n",
      "Batch 115: loss = 0.9532074928283691, acc = 0.6923828125\n",
      "Batch 116: loss = 0.9867943525314331, acc = 0.67578125\n",
      "Batch 117: loss = 0.819920539855957, acc = 0.732421875\n",
      "Batch 118: loss = 0.7912625074386597, acc = 0.7294921875\n",
      "Batch 119: loss = 0.8939785957336426, acc = 0.6962890625\n",
      "Batch 120: loss = 0.9178680181503296, acc = 0.70703125\n",
      "Batch 121: loss = 0.8823742866516113, acc = 0.7080078125\n",
      "Batch 122: loss = 0.8598589897155762, acc = 0.70703125\n",
      "Batch 123: loss = 0.889991283416748, acc = 0.7041015625\n",
      "Batch 124: loss = 0.9305805563926697, acc = 0.6923828125\n",
      "Batch 125: loss = 0.9513654708862305, acc = 0.685546875\n",
      "Batch 126: loss = 0.9495630264282227, acc = 0.6904296875\n",
      "\n",
      "Epoch 23/100\n",
      "Batch 1: loss = 1.1060627698898315, acc = 0.6435546875\n",
      "Batch 2: loss = 1.0161458253860474, acc = 0.6826171875\n",
      "Batch 3: loss = 0.9454967975616455, acc = 0.708984375\n",
      "Batch 4: loss = 0.8987261056900024, acc = 0.703125\n",
      "Batch 5: loss = 0.9889990091323853, acc = 0.681640625\n",
      "Batch 6: loss = 1.009565830230713, acc = 0.666015625\n",
      "Batch 7: loss = 0.9499678015708923, acc = 0.69921875\n",
      "Batch 8: loss = 0.8878570795059204, acc = 0.7041015625\n",
      "Batch 9: loss = 0.8433268070220947, acc = 0.720703125\n",
      "Batch 10: loss = 0.8107786178588867, acc = 0.736328125\n",
      "Batch 11: loss = 0.9428704977035522, acc = 0.6884765625\n",
      "Batch 12: loss = 0.9181355237960815, acc = 0.6982421875\n",
      "Batch 13: loss = 0.866002082824707, acc = 0.705078125\n",
      "Batch 14: loss = 0.8547259569168091, acc = 0.724609375\n",
      "Batch 15: loss = 0.8413709998130798, acc = 0.734375\n",
      "Batch 16: loss = 0.9373382329940796, acc = 0.697265625\n",
      "Batch 17: loss = 0.9197800159454346, acc = 0.701171875\n",
      "Batch 18: loss = 0.9178340435028076, acc = 0.7158203125\n",
      "Batch 19: loss = 0.8750722408294678, acc = 0.7275390625\n",
      "Batch 20: loss = 0.876031756401062, acc = 0.7138671875\n",
      "Batch 21: loss = 1.019471287727356, acc = 0.671875\n",
      "Batch 22: loss = 0.8840935230255127, acc = 0.6982421875\n",
      "Batch 23: loss = 0.8543475270271301, acc = 0.7177734375\n",
      "Batch 24: loss = 0.8447213172912598, acc = 0.705078125\n",
      "Batch 25: loss = 0.8016964793205261, acc = 0.7333984375\n",
      "Batch 26: loss = 0.8148986101150513, acc = 0.7333984375\n",
      "Batch 27: loss = 0.9360173344612122, acc = 0.703125\n",
      "Batch 28: loss = 0.8692164421081543, acc = 0.7216796875\n",
      "Batch 29: loss = 0.8961917757987976, acc = 0.7119140625\n",
      "Batch 30: loss = 0.8420296907424927, acc = 0.7353515625\n",
      "Batch 31: loss = 0.9504870176315308, acc = 0.6943359375\n",
      "Batch 32: loss = 1.0236380100250244, acc = 0.6708984375\n",
      "Batch 33: loss = 0.8699105978012085, acc = 0.7099609375\n",
      "Batch 34: loss = 0.9207136631011963, acc = 0.7021484375\n",
      "Batch 35: loss = 0.8978142738342285, acc = 0.7177734375\n",
      "Batch 36: loss = 0.89507657289505, acc = 0.705078125\n",
      "Batch 37: loss = 0.8859171271324158, acc = 0.7099609375\n",
      "Batch 38: loss = 0.9299949407577515, acc = 0.70703125\n",
      "Batch 39: loss = 0.9289765357971191, acc = 0.6962890625\n",
      "Batch 40: loss = 0.8741359114646912, acc = 0.720703125\n",
      "Batch 41: loss = 0.7998749613761902, acc = 0.7353515625\n",
      "Batch 42: loss = 0.8626530170440674, acc = 0.7099609375\n",
      "Batch 43: loss = 0.9153170585632324, acc = 0.6806640625\n",
      "Batch 44: loss = 0.8378316164016724, acc = 0.7119140625\n",
      "Batch 45: loss = 0.7566326260566711, acc = 0.7412109375\n",
      "Batch 46: loss = 0.8534337878227234, acc = 0.7109375\n",
      "Batch 47: loss = 0.8252829313278198, acc = 0.73046875\n",
      "Batch 48: loss = 0.7859688997268677, acc = 0.7490234375\n",
      "Batch 49: loss = 0.7868939638137817, acc = 0.7548828125\n",
      "Batch 50: loss = 0.7919615507125854, acc = 0.75\n",
      "Batch 51: loss = 0.8226776123046875, acc = 0.7216796875\n",
      "Batch 52: loss = 0.8990968465805054, acc = 0.7060546875\n",
      "Batch 53: loss = 0.8679497241973877, acc = 0.7294921875\n",
      "Batch 54: loss = 0.7743374109268188, acc = 0.7529296875\n",
      "Batch 55: loss = 0.7995225191116333, acc = 0.7353515625\n",
      "Batch 56: loss = 0.8679673671722412, acc = 0.71484375\n",
      "Batch 57: loss = 0.9601159691810608, acc = 0.6787109375\n",
      "Batch 58: loss = 0.9457061290740967, acc = 0.6728515625\n",
      "Batch 59: loss = 0.7391202449798584, acc = 0.7646484375\n",
      "Batch 60: loss = 0.8651123642921448, acc = 0.712890625\n",
      "Batch 61: loss = 0.8993242979049683, acc = 0.70703125\n",
      "Batch 62: loss = 1.0237853527069092, acc = 0.6484375\n",
      "Batch 63: loss = 0.9699221849441528, acc = 0.6796875\n",
      "Batch 64: loss = 0.7540106773376465, acc = 0.744140625\n",
      "Batch 65: loss = 0.9141340255737305, acc = 0.693359375\n",
      "Batch 66: loss = 0.8749446868896484, acc = 0.712890625\n",
      "Batch 67: loss = 0.8032205104827881, acc = 0.736328125\n",
      "Batch 68: loss = 0.8788410425186157, acc = 0.720703125\n",
      "Batch 69: loss = 0.8226213455200195, acc = 0.720703125\n",
      "Batch 70: loss = 0.9280624389648438, acc = 0.6923828125\n",
      "Batch 71: loss = 0.8702946305274963, acc = 0.712890625\n",
      "Batch 72: loss = 0.8152825236320496, acc = 0.7275390625\n",
      "Batch 73: loss = 0.9413348436355591, acc = 0.6923828125\n",
      "Batch 74: loss = 0.9238592386245728, acc = 0.6845703125\n",
      "Batch 75: loss = 1.0183135271072388, acc = 0.6669921875\n",
      "Batch 76: loss = 0.9146702885627747, acc = 0.7021484375\n",
      "Batch 77: loss = 0.7973159551620483, acc = 0.7353515625\n",
      "Batch 78: loss = 0.8552844524383545, acc = 0.7119140625\n",
      "Batch 79: loss = 0.7601100206375122, acc = 0.7470703125\n",
      "Batch 80: loss = 0.78703373670578, acc = 0.72265625\n",
      "Batch 81: loss = 0.8677676320075989, acc = 0.7255859375\n",
      "Batch 82: loss = 0.7602803111076355, acc = 0.751953125\n",
      "Batch 83: loss = 0.8435667157173157, acc = 0.7216796875\n",
      "Batch 84: loss = 0.8569824695587158, acc = 0.724609375\n",
      "Batch 85: loss = 0.9271146059036255, acc = 0.6953125\n",
      "Batch 86: loss = 0.9113266468048096, acc = 0.7060546875\n",
      "Batch 87: loss = 0.8325489163398743, acc = 0.7265625\n",
      "Batch 88: loss = 1.00779128074646, acc = 0.669921875\n",
      "Batch 89: loss = 0.8898633122444153, acc = 0.712890625\n",
      "Batch 90: loss = 0.9210553169250488, acc = 0.71484375\n",
      "Batch 91: loss = 0.9147668480873108, acc = 0.69140625\n",
      "Batch 92: loss = 0.8762578964233398, acc = 0.7080078125\n",
      "Batch 93: loss = 0.760982871055603, acc = 0.7548828125\n",
      "Batch 94: loss = 0.7981997728347778, acc = 0.7353515625\n",
      "Batch 95: loss = 0.8273465633392334, acc = 0.7080078125\n",
      "Batch 96: loss = 0.9094478487968445, acc = 0.6875\n",
      "Batch 97: loss = 0.8584713935852051, acc = 0.72265625\n",
      "Batch 98: loss = 0.8418406248092651, acc = 0.7236328125\n",
      "Batch 99: loss = 0.8473970293998718, acc = 0.7177734375\n",
      "Batch 100: loss = 0.8684978485107422, acc = 0.7099609375\n",
      "Batch 101: loss = 0.843553900718689, acc = 0.72265625\n",
      "Batch 102: loss = 0.9131689071655273, acc = 0.69921875\n",
      "Batch 103: loss = 0.8883662223815918, acc = 0.70703125\n",
      "Batch 104: loss = 0.8136388063430786, acc = 0.736328125\n",
      "Batch 105: loss = 0.8456352353096008, acc = 0.7373046875\n",
      "Batch 106: loss = 0.8885239958763123, acc = 0.703125\n",
      "Batch 107: loss = 0.8605269193649292, acc = 0.72265625\n",
      "Batch 108: loss = 0.855525016784668, acc = 0.71484375\n",
      "Batch 109: loss = 0.8168002367019653, acc = 0.7294921875\n",
      "Batch 110: loss = 0.768220067024231, acc = 0.7509765625\n",
      "Batch 111: loss = 0.9610000848770142, acc = 0.6845703125\n",
      "Batch 112: loss = 0.8403024077415466, acc = 0.7177734375\n",
      "Batch 113: loss = 0.8931643962860107, acc = 0.6953125\n",
      "Batch 114: loss = 0.9004324674606323, acc = 0.7177734375\n",
      "Batch 115: loss = 0.9209555983543396, acc = 0.697265625\n",
      "Batch 116: loss = 0.9503971338272095, acc = 0.6982421875\n",
      "Batch 117: loss = 0.8093791604042053, acc = 0.7392578125\n",
      "Batch 118: loss = 0.771340012550354, acc = 0.7236328125\n",
      "Batch 119: loss = 0.8673561215400696, acc = 0.7119140625\n",
      "Batch 120: loss = 0.8787767887115479, acc = 0.6962890625\n",
      "Batch 121: loss = 0.8269386887550354, acc = 0.7314453125\n",
      "Batch 122: loss = 0.8342924118041992, acc = 0.71875\n",
      "Batch 123: loss = 0.8750656843185425, acc = 0.7119140625\n",
      "Batch 124: loss = 0.9294747114181519, acc = 0.685546875\n",
      "Batch 125: loss = 0.9272028803825378, acc = 0.701171875\n",
      "Batch 126: loss = 0.9315299391746521, acc = 0.703125\n",
      "\n",
      "Epoch 24/100\n",
      "Batch 1: loss = 1.0692931413650513, acc = 0.66015625\n",
      "Batch 2: loss = 0.9934930801391602, acc = 0.689453125\n",
      "Batch 3: loss = 0.924372136592865, acc = 0.7001953125\n",
      "Batch 4: loss = 0.8960121870040894, acc = 0.708984375\n",
      "Batch 5: loss = 0.9481961727142334, acc = 0.6806640625\n",
      "Batch 6: loss = 0.9995825290679932, acc = 0.66015625\n",
      "Batch 7: loss = 0.9147918224334717, acc = 0.70703125\n",
      "Batch 8: loss = 0.8700541257858276, acc = 0.71875\n",
      "Batch 9: loss = 0.815922737121582, acc = 0.724609375\n",
      "Batch 10: loss = 0.7862610816955566, acc = 0.7431640625\n",
      "Batch 11: loss = 0.9174486994743347, acc = 0.701171875\n",
      "Batch 12: loss = 0.918372631072998, acc = 0.708984375\n",
      "Batch 13: loss = 0.8556386828422546, acc = 0.6962890625\n",
      "Batch 14: loss = 0.8501080274581909, acc = 0.7255859375\n",
      "Batch 15: loss = 0.8138210773468018, acc = 0.7265625\n",
      "Batch 16: loss = 0.9152214527130127, acc = 0.7119140625\n",
      "Batch 17: loss = 0.9104948043823242, acc = 0.7158203125\n",
      "Batch 18: loss = 0.8989574909210205, acc = 0.7109375\n",
      "Batch 19: loss = 0.835789680480957, acc = 0.7392578125\n",
      "Batch 20: loss = 0.846513032913208, acc = 0.728515625\n",
      "Batch 21: loss = 0.974769115447998, acc = 0.669921875\n",
      "Batch 22: loss = 0.8540615439414978, acc = 0.7080078125\n",
      "Batch 23: loss = 0.8474864959716797, acc = 0.7138671875\n",
      "Batch 24: loss = 0.836397647857666, acc = 0.71484375\n",
      "Batch 25: loss = 0.7946487665176392, acc = 0.7412109375\n",
      "Batch 26: loss = 0.8083971738815308, acc = 0.7265625\n",
      "Batch 27: loss = 0.9558770060539246, acc = 0.68359375\n",
      "Batch 28: loss = 0.8721424341201782, acc = 0.708984375\n",
      "Batch 29: loss = 0.8703315258026123, acc = 0.7138671875\n",
      "Batch 30: loss = 0.8014435768127441, acc = 0.73828125\n",
      "Batch 31: loss = 0.9536420702934265, acc = 0.701171875\n",
      "Batch 32: loss = 1.0287699699401855, acc = 0.671875\n",
      "Batch 33: loss = 0.8634567856788635, acc = 0.7177734375\n",
      "Batch 34: loss = 0.8975552320480347, acc = 0.705078125\n",
      "Batch 35: loss = 0.8723344802856445, acc = 0.7236328125\n",
      "Batch 36: loss = 0.8522075414657593, acc = 0.7216796875\n",
      "Batch 37: loss = 0.8668829202651978, acc = 0.701171875\n",
      "Batch 38: loss = 0.9190855026245117, acc = 0.6982421875\n",
      "Batch 39: loss = 0.9039710760116577, acc = 0.697265625\n",
      "Batch 40: loss = 0.8753458261489868, acc = 0.724609375\n",
      "Batch 41: loss = 0.7918539047241211, acc = 0.7314453125\n",
      "Batch 42: loss = 0.8340942859649658, acc = 0.7138671875\n",
      "Batch 43: loss = 0.8893910646438599, acc = 0.6962890625\n",
      "Batch 44: loss = 0.8275864124298096, acc = 0.7412109375\n",
      "Batch 45: loss = 0.7176576852798462, acc = 0.76171875\n",
      "Batch 46: loss = 0.8146232962608337, acc = 0.7275390625\n",
      "Batch 47: loss = 0.794536292552948, acc = 0.7373046875\n",
      "Batch 48: loss = 0.7567789554595947, acc = 0.740234375\n",
      "Batch 49: loss = 0.7638798952102661, acc = 0.7646484375\n",
      "Batch 50: loss = 0.7738199830055237, acc = 0.7578125\n",
      "Batch 51: loss = 0.7950390577316284, acc = 0.7158203125\n",
      "Batch 52: loss = 0.8664921522140503, acc = 0.7158203125\n",
      "Batch 53: loss = 0.8375378847122192, acc = 0.7294921875\n",
      "Batch 54: loss = 0.7360514402389526, acc = 0.7626953125\n",
      "Batch 55: loss = 0.7709031105041504, acc = 0.755859375\n",
      "Batch 56: loss = 0.8417934775352478, acc = 0.716796875\n",
      "Batch 57: loss = 0.9105269312858582, acc = 0.69140625\n",
      "Batch 58: loss = 0.9291685819625854, acc = 0.6875\n",
      "Batch 59: loss = 0.7309119701385498, acc = 0.7666015625\n",
      "Batch 60: loss = 0.8220252990722656, acc = 0.7216796875\n",
      "Batch 61: loss = 0.859390377998352, acc = 0.732421875\n",
      "Batch 62: loss = 1.0393421649932861, acc = 0.64453125\n",
      "Batch 63: loss = 0.9653853178024292, acc = 0.6748046875\n",
      "Batch 64: loss = 0.7446280717849731, acc = 0.751953125\n",
      "Batch 65: loss = 0.8751240968704224, acc = 0.7041015625\n",
      "Batch 66: loss = 0.8506284952163696, acc = 0.7099609375\n",
      "Batch 67: loss = 0.7819472551345825, acc = 0.7314453125\n",
      "Batch 68: loss = 0.874347984790802, acc = 0.724609375\n",
      "Batch 69: loss = 0.7985186576843262, acc = 0.736328125\n",
      "Batch 70: loss = 0.9316630363464355, acc = 0.6884765625\n",
      "Batch 71: loss = 0.8781611919403076, acc = 0.697265625\n",
      "Batch 72: loss = 0.8041155934333801, acc = 0.7333984375\n",
      "Batch 73: loss = 0.9171144366264343, acc = 0.708984375\n",
      "Batch 74: loss = 0.8951598405838013, acc = 0.703125\n",
      "Batch 75: loss = 0.982441782951355, acc = 0.6591796875\n",
      "Batch 76: loss = 0.8924171924591064, acc = 0.6884765625\n",
      "Batch 77: loss = 0.813256025314331, acc = 0.7314453125\n",
      "Batch 78: loss = 0.8515338897705078, acc = 0.7236328125\n",
      "Batch 79: loss = 0.7286734580993652, acc = 0.7431640625\n",
      "Batch 80: loss = 0.7645608186721802, acc = 0.7353515625\n",
      "Batch 81: loss = 0.8215510249137878, acc = 0.7353515625\n",
      "Batch 82: loss = 0.7504293322563171, acc = 0.7587890625\n",
      "Batch 83: loss = 0.8611098527908325, acc = 0.7216796875\n",
      "Batch 84: loss = 0.8169970512390137, acc = 0.736328125\n",
      "Batch 85: loss = 0.8994898200035095, acc = 0.7119140625\n",
      "Batch 86: loss = 0.8901857733726501, acc = 0.7060546875\n",
      "Batch 87: loss = 0.8250913619995117, acc = 0.73046875\n",
      "Batch 88: loss = 0.9808993339538574, acc = 0.7138671875\n",
      "Batch 89: loss = 0.8774799108505249, acc = 0.7158203125\n",
      "Batch 90: loss = 0.8925514221191406, acc = 0.7119140625\n",
      "Batch 91: loss = 0.8861944675445557, acc = 0.712890625\n",
      "Batch 92: loss = 0.8402602672576904, acc = 0.7197265625\n",
      "Batch 93: loss = 0.7278411388397217, acc = 0.7705078125\n",
      "Batch 94: loss = 0.7791187763214111, acc = 0.7490234375\n",
      "Batch 95: loss = 0.8165806531906128, acc = 0.7275390625\n",
      "Batch 96: loss = 0.8897868394851685, acc = 0.70703125\n",
      "Batch 97: loss = 0.8402459621429443, acc = 0.7275390625\n",
      "Batch 98: loss = 0.8267620801925659, acc = 0.73828125\n",
      "Batch 99: loss = 0.8425242304801941, acc = 0.7119140625\n",
      "Batch 100: loss = 0.8571680784225464, acc = 0.708984375\n",
      "Batch 101: loss = 0.8601106405258179, acc = 0.71484375\n",
      "Batch 102: loss = 0.9334924221038818, acc = 0.6865234375\n",
      "Batch 103: loss = 0.8573625683784485, acc = 0.720703125\n",
      "Batch 104: loss = 0.7992261052131653, acc = 0.736328125\n",
      "Batch 105: loss = 0.8193537592887878, acc = 0.7314453125\n",
      "Batch 106: loss = 0.8835339546203613, acc = 0.708984375\n",
      "Batch 107: loss = 0.8260862827301025, acc = 0.734375\n",
      "Batch 108: loss = 0.8477530479431152, acc = 0.7216796875\n",
      "Batch 109: loss = 0.8180346488952637, acc = 0.7216796875\n",
      "Batch 110: loss = 0.7627871632575989, acc = 0.751953125\n",
      "Batch 111: loss = 0.9242449998855591, acc = 0.7001953125\n",
      "Batch 112: loss = 0.8179215788841248, acc = 0.7373046875\n",
      "Batch 113: loss = 0.8712741136550903, acc = 0.703125\n",
      "Batch 114: loss = 0.9029240608215332, acc = 0.7119140625\n",
      "Batch 115: loss = 0.9081741571426392, acc = 0.7080078125\n",
      "Batch 116: loss = 0.9383001327514648, acc = 0.7001953125\n",
      "Batch 117: loss = 0.7860300540924072, acc = 0.7412109375\n",
      "Batch 118: loss = 0.7567076086997986, acc = 0.734375\n",
      "Batch 119: loss = 0.8442738056182861, acc = 0.7099609375\n",
      "Batch 120: loss = 0.8701666593551636, acc = 0.7060546875\n",
      "Batch 121: loss = 0.8387807011604309, acc = 0.72265625\n",
      "Batch 122: loss = 0.8242701292037964, acc = 0.73046875\n",
      "Batch 123: loss = 0.8638033270835876, acc = 0.7236328125\n",
      "Batch 124: loss = 0.8810977935791016, acc = 0.6884765625\n",
      "Batch 125: loss = 0.915822446346283, acc = 0.7236328125\n",
      "Batch 126: loss = 0.9217582941055298, acc = 0.697265625\n",
      "\n",
      "Epoch 25/100\n",
      "Batch 1: loss = 1.0507017374038696, acc = 0.6748046875\n",
      "Batch 2: loss = 0.9821957945823669, acc = 0.7001953125\n",
      "Batch 3: loss = 0.8705862760543823, acc = 0.72265625\n",
      "Batch 4: loss = 0.8620008230209351, acc = 0.7197265625\n",
      "Batch 5: loss = 0.9399747848510742, acc = 0.7060546875\n",
      "Batch 6: loss = 0.9563845992088318, acc = 0.6787109375\n",
      "Batch 7: loss = 0.9226187467575073, acc = 0.7001953125\n",
      "Batch 8: loss = 0.8416669368743896, acc = 0.71875\n",
      "Batch 9: loss = 0.7989953756332397, acc = 0.7314453125\n",
      "Batch 10: loss = 0.7677392363548279, acc = 0.7568359375\n",
      "Batch 11: loss = 0.8962849974632263, acc = 0.7021484375\n",
      "Batch 12: loss = 0.9019895792007446, acc = 0.69921875\n",
      "Batch 13: loss = 0.8393415212631226, acc = 0.724609375\n",
      "Batch 14: loss = 0.819713294506073, acc = 0.7412109375\n",
      "Batch 15: loss = 0.8347665071487427, acc = 0.740234375\n",
      "Batch 16: loss = 0.8762148022651672, acc = 0.7099609375\n",
      "Batch 17: loss = 0.884880542755127, acc = 0.7119140625\n",
      "Batch 18: loss = 0.8935325145721436, acc = 0.7216796875\n",
      "Batch 19: loss = 0.7950775623321533, acc = 0.7490234375\n",
      "Batch 20: loss = 0.81132972240448, acc = 0.7119140625\n",
      "Batch 21: loss = 0.9531291723251343, acc = 0.6904296875\n",
      "Batch 22: loss = 0.8337923288345337, acc = 0.7255859375\n",
      "Batch 23: loss = 0.8121950030326843, acc = 0.7314453125\n",
      "Batch 24: loss = 0.8217570781707764, acc = 0.71875\n",
      "Batch 25: loss = 0.7675567269325256, acc = 0.751953125\n",
      "Batch 26: loss = 0.7930150628089905, acc = 0.7431640625\n",
      "Batch 27: loss = 0.9088555574417114, acc = 0.7001953125\n",
      "Batch 28: loss = 0.8524819612503052, acc = 0.7109375\n",
      "Batch 29: loss = 0.827887773513794, acc = 0.7470703125\n",
      "Batch 30: loss = 0.775132417678833, acc = 0.7392578125\n",
      "Batch 31: loss = 0.8946415185928345, acc = 0.70703125\n",
      "Batch 32: loss = 0.9734683036804199, acc = 0.6875\n",
      "Batch 33: loss = 0.8732199668884277, acc = 0.708984375\n",
      "Batch 34: loss = 0.8851741552352905, acc = 0.7138671875\n",
      "Batch 35: loss = 0.877193808555603, acc = 0.72265625\n",
      "Batch 36: loss = 0.8286529779434204, acc = 0.7275390625\n",
      "Batch 37: loss = 0.8263144493103027, acc = 0.7265625\n",
      "Batch 38: loss = 0.8938847780227661, acc = 0.72265625\n",
      "Batch 39: loss = 0.8740931749343872, acc = 0.7060546875\n",
      "Batch 40: loss = 0.8314234018325806, acc = 0.7216796875\n",
      "Batch 41: loss = 0.7731948494911194, acc = 0.740234375\n",
      "Batch 42: loss = 0.815324068069458, acc = 0.71875\n",
      "Batch 43: loss = 0.8800431489944458, acc = 0.701171875\n",
      "Batch 44: loss = 0.8027698993682861, acc = 0.736328125\n",
      "Batch 45: loss = 0.7527698278427124, acc = 0.751953125\n",
      "Batch 46: loss = 0.799565315246582, acc = 0.732421875\n",
      "Batch 47: loss = 0.8089722394943237, acc = 0.7333984375\n",
      "Batch 48: loss = 0.7626456618309021, acc = 0.7529296875\n",
      "Batch 49: loss = 0.7555617094039917, acc = 0.7607421875\n",
      "Batch 50: loss = 0.7701302766799927, acc = 0.759765625\n",
      "Batch 51: loss = 0.7681769132614136, acc = 0.7275390625\n",
      "Batch 52: loss = 0.8715784549713135, acc = 0.71875\n",
      "Batch 53: loss = 0.8292557001113892, acc = 0.724609375\n",
      "Batch 54: loss = 0.7286143898963928, acc = 0.7666015625\n",
      "Batch 55: loss = 0.7468472719192505, acc = 0.767578125\n",
      "Batch 56: loss = 0.8174986839294434, acc = 0.732421875\n",
      "Batch 57: loss = 0.9030420780181885, acc = 0.6943359375\n",
      "Batch 58: loss = 0.9143768548965454, acc = 0.69921875\n",
      "Batch 59: loss = 0.7011200189590454, acc = 0.7763671875\n",
      "Batch 60: loss = 0.818150520324707, acc = 0.734375\n",
      "Batch 61: loss = 0.8472928404808044, acc = 0.728515625\n",
      "Batch 62: loss = 0.9977189302444458, acc = 0.6435546875\n",
      "Batch 63: loss = 0.9793087244033813, acc = 0.6826171875\n",
      "Batch 64: loss = 0.7257097959518433, acc = 0.75\n",
      "Batch 65: loss = 0.8871580362319946, acc = 0.708984375\n",
      "Batch 66: loss = 0.8373150825500488, acc = 0.7177734375\n",
      "Batch 67: loss = 0.7889515161514282, acc = 0.7255859375\n",
      "Batch 68: loss = 0.877626895904541, acc = 0.7177734375\n",
      "Batch 69: loss = 0.7976532578468323, acc = 0.73828125\n",
      "Batch 70: loss = 0.9077935814857483, acc = 0.705078125\n",
      "Batch 71: loss = 0.8477101922035217, acc = 0.7197265625\n",
      "Batch 72: loss = 0.7991655468940735, acc = 0.7353515625\n",
      "Batch 73: loss = 0.9158967733383179, acc = 0.6923828125\n",
      "Batch 74: loss = 0.8777190446853638, acc = 0.6904296875\n",
      "Batch 75: loss = 0.9555954337120056, acc = 0.6787109375\n",
      "Batch 76: loss = 0.8640142679214478, acc = 0.7080078125\n",
      "Batch 77: loss = 0.787499189376831, acc = 0.748046875\n",
      "Batch 78: loss = 0.828200101852417, acc = 0.7314453125\n",
      "Batch 79: loss = 0.7199335694313049, acc = 0.7509765625\n",
      "Batch 80: loss = 0.7579821348190308, acc = 0.73046875\n",
      "Batch 81: loss = 0.8234165906906128, acc = 0.7353515625\n",
      "Batch 82: loss = 0.7532563209533691, acc = 0.76171875\n",
      "Batch 83: loss = 0.8203820586204529, acc = 0.7216796875\n",
      "Batch 84: loss = 0.7942848205566406, acc = 0.740234375\n",
      "Batch 85: loss = 0.8880079984664917, acc = 0.7080078125\n",
      "Batch 86: loss = 0.8598532676696777, acc = 0.7138671875\n",
      "Batch 87: loss = 0.8025082349777222, acc = 0.728515625\n",
      "Batch 88: loss = 0.9597078561782837, acc = 0.6875\n",
      "Batch 89: loss = 0.8647070527076721, acc = 0.720703125\n",
      "Batch 90: loss = 0.889055609703064, acc = 0.7080078125\n",
      "Batch 91: loss = 0.8827444911003113, acc = 0.70703125\n",
      "Batch 92: loss = 0.8428711891174316, acc = 0.724609375\n",
      "Batch 93: loss = 0.7253912091255188, acc = 0.7626953125\n",
      "Batch 94: loss = 0.7689844369888306, acc = 0.7421875\n",
      "Batch 95: loss = 0.794064998626709, acc = 0.7392578125\n",
      "Batch 96: loss = 0.8883758783340454, acc = 0.6826171875\n",
      "Batch 97: loss = 0.8243389129638672, acc = 0.7431640625\n",
      "Batch 98: loss = 0.8110443949699402, acc = 0.7431640625\n",
      "Batch 99: loss = 0.8504911065101624, acc = 0.7109375\n",
      "Batch 100: loss = 0.8665315508842468, acc = 0.697265625\n",
      "Batch 101: loss = 0.8173699378967285, acc = 0.7236328125\n",
      "Batch 102: loss = 0.9000462293624878, acc = 0.7138671875\n",
      "Batch 103: loss = 0.8347994089126587, acc = 0.724609375\n",
      "Batch 104: loss = 0.7694679498672485, acc = 0.7470703125\n",
      "Batch 105: loss = 0.7913179993629456, acc = 0.75\n",
      "Batch 106: loss = 0.8659744262695312, acc = 0.7060546875\n",
      "Batch 107: loss = 0.7992459535598755, acc = 0.7333984375\n",
      "Batch 108: loss = 0.8431073427200317, acc = 0.708984375\n",
      "Batch 109: loss = 0.7934480905532837, acc = 0.73046875\n",
      "Batch 110: loss = 0.7592517137527466, acc = 0.74609375\n",
      "Batch 111: loss = 0.9377111196517944, acc = 0.697265625\n",
      "Batch 112: loss = 0.8199920654296875, acc = 0.7431640625\n",
      "Batch 113: loss = 0.8719815015792847, acc = 0.703125\n",
      "Batch 114: loss = 0.8615351915359497, acc = 0.7314453125\n",
      "Batch 115: loss = 0.8940863609313965, acc = 0.6962890625\n",
      "Batch 116: loss = 0.928072452545166, acc = 0.708984375\n",
      "Batch 117: loss = 0.7904430627822876, acc = 0.7353515625\n",
      "Batch 118: loss = 0.739811897277832, acc = 0.7529296875\n",
      "Batch 119: loss = 0.824577808380127, acc = 0.7353515625\n",
      "Batch 120: loss = 0.8634864687919617, acc = 0.7294921875\n",
      "Batch 121: loss = 0.8103008270263672, acc = 0.7333984375\n",
      "Batch 122: loss = 0.8194022178649902, acc = 0.724609375\n",
      "Batch 123: loss = 0.8603454232215881, acc = 0.720703125\n",
      "Batch 124: loss = 0.8648964166641235, acc = 0.701171875\n",
      "Batch 125: loss = 0.8975716233253479, acc = 0.701171875\n",
      "Batch 126: loss = 0.9095147252082825, acc = 0.716796875\n",
      "\n",
      "Epoch 26/100\n",
      "Batch 1: loss = 1.034191608428955, acc = 0.6865234375\n",
      "Batch 2: loss = 0.9491269588470459, acc = 0.6982421875\n",
      "Batch 3: loss = 0.8651061058044434, acc = 0.70703125\n",
      "Batch 4: loss = 0.8571300506591797, acc = 0.7314453125\n",
      "Batch 5: loss = 0.8919910192489624, acc = 0.716796875\n",
      "Batch 6: loss = 0.9295335412025452, acc = 0.6943359375\n",
      "Batch 7: loss = 0.8825867176055908, acc = 0.7119140625\n",
      "Batch 8: loss = 0.8253998756408691, acc = 0.7314453125\n",
      "Batch 9: loss = 0.784040629863739, acc = 0.744140625\n",
      "Batch 10: loss = 0.7678378820419312, acc = 0.7548828125\n",
      "Batch 11: loss = 0.8738541603088379, acc = 0.7021484375\n",
      "Batch 12: loss = 0.8694189786911011, acc = 0.703125\n",
      "Batch 13: loss = 0.8188230991363525, acc = 0.7236328125\n",
      "Batch 14: loss = 0.8183411359786987, acc = 0.7509765625\n",
      "Batch 15: loss = 0.8094184398651123, acc = 0.7431640625\n",
      "Batch 16: loss = 0.8746063709259033, acc = 0.720703125\n",
      "Batch 17: loss = 0.8872413039207458, acc = 0.7119140625\n",
      "Batch 18: loss = 0.863875687122345, acc = 0.7177734375\n",
      "Batch 19: loss = 0.7950486540794373, acc = 0.748046875\n",
      "Batch 20: loss = 0.8057284355163574, acc = 0.74609375\n",
      "Batch 21: loss = 0.9140758514404297, acc = 0.7001953125\n",
      "Batch 22: loss = 0.8006477355957031, acc = 0.7431640625\n",
      "Batch 23: loss = 0.8061313629150391, acc = 0.7275390625\n",
      "Batch 24: loss = 0.7961382865905762, acc = 0.7392578125\n",
      "Batch 25: loss = 0.7494869232177734, acc = 0.759765625\n",
      "Batch 26: loss = 0.76957106590271, acc = 0.7578125\n",
      "Batch 27: loss = 0.8994982242584229, acc = 0.712890625\n",
      "Batch 28: loss = 0.8488414287567139, acc = 0.7119140625\n",
      "Batch 29: loss = 0.7965540885925293, acc = 0.744140625\n",
      "Batch 30: loss = 0.7715942859649658, acc = 0.7490234375\n",
      "Batch 31: loss = 0.8902164697647095, acc = 0.720703125\n",
      "Batch 32: loss = 0.948194146156311, acc = 0.6953125\n",
      "Batch 33: loss = 0.8188139200210571, acc = 0.7255859375\n",
      "Batch 34: loss = 0.8599200248718262, acc = 0.716796875\n",
      "Batch 35: loss = 0.8502838015556335, acc = 0.7265625\n",
      "Batch 36: loss = 0.8024888038635254, acc = 0.7431640625\n",
      "Batch 37: loss = 0.8031773567199707, acc = 0.7333984375\n",
      "Batch 38: loss = 0.8766807913780212, acc = 0.712890625\n",
      "Batch 39: loss = 0.8458760976791382, acc = 0.73046875\n",
      "Batch 40: loss = 0.8272969722747803, acc = 0.732421875\n",
      "Batch 41: loss = 0.7435328960418701, acc = 0.7568359375\n",
      "Batch 42: loss = 0.8029784560203552, acc = 0.73046875\n",
      "Batch 43: loss = 0.835689127445221, acc = 0.70703125\n",
      "Batch 44: loss = 0.7884963750839233, acc = 0.7490234375\n",
      "Batch 45: loss = 0.7300435304641724, acc = 0.7490234375\n",
      "Batch 46: loss = 0.7805044054985046, acc = 0.740234375\n",
      "Batch 47: loss = 0.770115077495575, acc = 0.744140625\n",
      "Batch 48: loss = 0.7475734949111938, acc = 0.751953125\n",
      "Batch 49: loss = 0.7394931316375732, acc = 0.7685546875\n",
      "Batch 50: loss = 0.7236745357513428, acc = 0.7666015625\n",
      "Batch 51: loss = 0.7463957071304321, acc = 0.744140625\n",
      "Batch 52: loss = 0.8295074701309204, acc = 0.740234375\n",
      "Batch 53: loss = 0.8147643804550171, acc = 0.7470703125\n",
      "Batch 54: loss = 0.6967836618423462, acc = 0.7744140625\n",
      "Batch 55: loss = 0.7466390132904053, acc = 0.7587890625\n",
      "Batch 56: loss = 0.8061996102333069, acc = 0.732421875\n",
      "Batch 57: loss = 0.8953665494918823, acc = 0.6923828125\n",
      "Batch 58: loss = 0.906818687915802, acc = 0.7158203125\n",
      "Batch 59: loss = 0.6811043620109558, acc = 0.7900390625\n",
      "Batch 60: loss = 0.8091732263565063, acc = 0.7255859375\n",
      "Batch 61: loss = 0.8379358053207397, acc = 0.740234375\n",
      "Batch 62: loss = 0.9913814067840576, acc = 0.662109375\n",
      "Batch 63: loss = 0.9123799204826355, acc = 0.6953125\n",
      "Batch 64: loss = 0.7011202573776245, acc = 0.7724609375\n",
      "Batch 65: loss = 0.8656116724014282, acc = 0.712890625\n",
      "Batch 66: loss = 0.8440598249435425, acc = 0.7216796875\n",
      "Batch 67: loss = 0.780082106590271, acc = 0.736328125\n",
      "Batch 68: loss = 0.8302409052848816, acc = 0.73046875\n",
      "Batch 69: loss = 0.7854028940200806, acc = 0.7373046875\n",
      "Batch 70: loss = 0.8518484830856323, acc = 0.7177734375\n",
      "Batch 71: loss = 0.8323236107826233, acc = 0.7255859375\n",
      "Batch 72: loss = 0.7605857849121094, acc = 0.7421875\n",
      "Batch 73: loss = 0.8614583611488342, acc = 0.7255859375\n",
      "Batch 74: loss = 0.8683356642723083, acc = 0.7080078125\n",
      "Batch 75: loss = 0.9186054468154907, acc = 0.7021484375\n",
      "Batch 76: loss = 0.8479647636413574, acc = 0.7021484375\n",
      "Batch 77: loss = 0.7705791592597961, acc = 0.7578125\n",
      "Batch 78: loss = 0.8208800554275513, acc = 0.7333984375\n",
      "Batch 79: loss = 0.7075285315513611, acc = 0.7529296875\n",
      "Batch 80: loss = 0.7619550228118896, acc = 0.7373046875\n",
      "Batch 81: loss = 0.8134708404541016, acc = 0.740234375\n",
      "Batch 82: loss = 0.7132011651992798, acc = 0.767578125\n",
      "Batch 83: loss = 0.8000833988189697, acc = 0.724609375\n",
      "Batch 84: loss = 0.7828035354614258, acc = 0.7470703125\n",
      "Batch 85: loss = 0.8992177248001099, acc = 0.701171875\n",
      "Batch 86: loss = 0.8807753324508667, acc = 0.7138671875\n",
      "Batch 87: loss = 0.7930728197097778, acc = 0.7470703125\n",
      "Batch 88: loss = 0.9657465219497681, acc = 0.7001953125\n",
      "Batch 89: loss = 0.8288692235946655, acc = 0.7353515625\n",
      "Batch 90: loss = 0.8643096685409546, acc = 0.724609375\n",
      "Batch 91: loss = 0.8547201156616211, acc = 0.72265625\n",
      "Batch 92: loss = 0.8227483630180359, acc = 0.73046875\n",
      "Batch 93: loss = 0.69732266664505, acc = 0.7724609375\n",
      "Batch 94: loss = 0.7347414493560791, acc = 0.759765625\n",
      "Batch 95: loss = 0.7815130352973938, acc = 0.7353515625\n",
      "Batch 96: loss = 0.8707078695297241, acc = 0.70703125\n",
      "Batch 97: loss = 0.8040911555290222, acc = 0.7373046875\n",
      "Batch 98: loss = 0.7802156805992126, acc = 0.734375\n",
      "Batch 99: loss = 0.8256986141204834, acc = 0.7197265625\n",
      "Batch 100: loss = 0.8308606147766113, acc = 0.71484375\n",
      "Batch 101: loss = 0.8113255500793457, acc = 0.736328125\n",
      "Batch 102: loss = 0.883061408996582, acc = 0.7119140625\n",
      "Batch 103: loss = 0.8101023435592651, acc = 0.73828125\n",
      "Batch 104: loss = 0.747045636177063, acc = 0.7421875\n",
      "Batch 105: loss = 0.8024734258651733, acc = 0.72265625\n",
      "Batch 106: loss = 0.8520128726959229, acc = 0.712890625\n",
      "Batch 107: loss = 0.7989155054092407, acc = 0.7490234375\n",
      "Batch 108: loss = 0.8305491209030151, acc = 0.7060546875\n",
      "Batch 109: loss = 0.7849764823913574, acc = 0.7333984375\n",
      "Batch 110: loss = 0.7303214073181152, acc = 0.7587890625\n",
      "Batch 111: loss = 0.9145506024360657, acc = 0.7080078125\n",
      "Batch 112: loss = 0.7884174585342407, acc = 0.7373046875\n",
      "Batch 113: loss = 0.8315925002098083, acc = 0.7216796875\n",
      "Batch 114: loss = 0.8360093832015991, acc = 0.7333984375\n",
      "Batch 115: loss = 0.8772435784339905, acc = 0.7099609375\n",
      "Batch 116: loss = 0.9035895466804504, acc = 0.7001953125\n",
      "Batch 117: loss = 0.7609155178070068, acc = 0.7412109375\n",
      "Batch 118: loss = 0.7185388803482056, acc = 0.7646484375\n",
      "Batch 119: loss = 0.8227331638336182, acc = 0.7421875\n",
      "Batch 120: loss = 0.8387380838394165, acc = 0.7177734375\n",
      "Batch 121: loss = 0.788296103477478, acc = 0.7392578125\n",
      "Batch 122: loss = 0.7921425104141235, acc = 0.73828125\n",
      "Batch 123: loss = 0.8122864961624146, acc = 0.7412109375\n",
      "Batch 124: loss = 0.849094033241272, acc = 0.70703125\n",
      "Batch 125: loss = 0.8994598388671875, acc = 0.6982421875\n",
      "Batch 126: loss = 0.8801579475402832, acc = 0.7177734375\n",
      "\n",
      "Epoch 27/100\n",
      "Batch 1: loss = 1.0052682161331177, acc = 0.6982421875\n",
      "Batch 2: loss = 0.9386022090911865, acc = 0.7080078125\n",
      "Batch 3: loss = 0.8870768547058105, acc = 0.71484375\n",
      "Batch 4: loss = 0.8478987812995911, acc = 0.7353515625\n",
      "Batch 5: loss = 0.9093508124351501, acc = 0.69921875\n",
      "Batch 6: loss = 0.9249974489212036, acc = 0.6923828125\n",
      "Batch 7: loss = 0.8521027565002441, acc = 0.712890625\n",
      "Batch 8: loss = 0.8142116069793701, acc = 0.728515625\n",
      "Batch 9: loss = 0.7870290279388428, acc = 0.744140625\n",
      "Batch 10: loss = 0.7148988246917725, acc = 0.76953125\n",
      "Batch 11: loss = 0.8671949505805969, acc = 0.69921875\n",
      "Batch 12: loss = 0.8470691442489624, acc = 0.7255859375\n",
      "Batch 13: loss = 0.802651047706604, acc = 0.7119140625\n",
      "Batch 14: loss = 0.775919497013092, acc = 0.7431640625\n",
      "Batch 15: loss = 0.7742726802825928, acc = 0.7470703125\n",
      "Batch 16: loss = 0.8453263640403748, acc = 0.7216796875\n",
      "Batch 17: loss = 0.8266623020172119, acc = 0.7353515625\n",
      "Batch 18: loss = 0.8495088815689087, acc = 0.7412109375\n",
      "Batch 19: loss = 0.8017969727516174, acc = 0.7412109375\n",
      "Batch 20: loss = 0.7876712679862976, acc = 0.724609375\n",
      "Batch 21: loss = 0.8966881036758423, acc = 0.705078125\n",
      "Batch 22: loss = 0.8026490211486816, acc = 0.7431640625\n",
      "Batch 23: loss = 0.7706074714660645, acc = 0.7421875\n",
      "Batch 24: loss = 0.7698584198951721, acc = 0.7373046875\n",
      "Batch 25: loss = 0.7236843109130859, acc = 0.75390625\n",
      "Batch 26: loss = 0.772984504699707, acc = 0.7431640625\n",
      "Batch 27: loss = 0.8957567811012268, acc = 0.7109375\n",
      "Batch 28: loss = 0.8242982625961304, acc = 0.7275390625\n",
      "Batch 29: loss = 0.7891260385513306, acc = 0.7451171875\n",
      "Batch 30: loss = 0.7540253400802612, acc = 0.75390625\n",
      "Batch 31: loss = 0.8538745641708374, acc = 0.72265625\n",
      "Batch 32: loss = 0.957226574420929, acc = 0.697265625\n",
      "Batch 33: loss = 0.7960039377212524, acc = 0.7412109375\n",
      "Batch 34: loss = 0.8389987945556641, acc = 0.7265625\n",
      "Batch 35: loss = 0.8157069087028503, acc = 0.73828125\n",
      "Batch 36: loss = 0.7898452281951904, acc = 0.7373046875\n",
      "Batch 37: loss = 0.7647585868835449, acc = 0.7490234375\n",
      "Batch 38: loss = 0.8623338341712952, acc = 0.7197265625\n",
      "Batch 39: loss = 0.8386058807373047, acc = 0.720703125\n",
      "Batch 40: loss = 0.8086370825767517, acc = 0.728515625\n",
      "Batch 41: loss = 0.7365728616714478, acc = 0.74609375\n",
      "Batch 42: loss = 0.7572603821754456, acc = 0.7490234375\n",
      "Batch 43: loss = 0.8151403069496155, acc = 0.71875\n",
      "Batch 44: loss = 0.7463723421096802, acc = 0.75390625\n",
      "Batch 45: loss = 0.6939286589622498, acc = 0.7744140625\n",
      "Batch 46: loss = 0.7476945519447327, acc = 0.75\n",
      "Batch 47: loss = 0.7595961093902588, acc = 0.7568359375\n",
      "Batch 48: loss = 0.7399805784225464, acc = 0.7490234375\n",
      "Batch 49: loss = 0.6992139220237732, acc = 0.7802734375\n",
      "Batch 50: loss = 0.7095906734466553, acc = 0.7646484375\n",
      "Batch 51: loss = 0.7191238403320312, acc = 0.74609375\n",
      "Batch 52: loss = 0.8132470846176147, acc = 0.734375\n",
      "Batch 53: loss = 0.7949090600013733, acc = 0.728515625\n",
      "Batch 54: loss = 0.6862030029296875, acc = 0.7841796875\n",
      "Batch 55: loss = 0.7344033718109131, acc = 0.767578125\n",
      "Batch 56: loss = 0.7986619472503662, acc = 0.740234375\n",
      "Batch 57: loss = 0.893511176109314, acc = 0.7060546875\n",
      "Batch 58: loss = 0.8882383108139038, acc = 0.6982421875\n",
      "Batch 59: loss = 0.6752690076828003, acc = 0.783203125\n",
      "Batch 60: loss = 0.7794575691223145, acc = 0.73828125\n",
      "Batch 61: loss = 0.7976073026657104, acc = 0.7431640625\n",
      "Batch 62: loss = 0.9576703310012817, acc = 0.6640625\n",
      "Batch 63: loss = 0.9356929659843445, acc = 0.6884765625\n",
      "Batch 64: loss = 0.6858834028244019, acc = 0.7666015625\n",
      "Batch 65: loss = 0.8524473905563354, acc = 0.7177734375\n",
      "Batch 66: loss = 0.8103922605514526, acc = 0.7333984375\n",
      "Batch 67: loss = 0.7217060923576355, acc = 0.76171875\n",
      "Batch 68: loss = 0.8158308863639832, acc = 0.740234375\n",
      "Batch 69: loss = 0.7500609159469604, acc = 0.7529296875\n",
      "Batch 70: loss = 0.8576000928878784, acc = 0.716796875\n",
      "Batch 71: loss = 0.8228184580802917, acc = 0.7109375\n",
      "Batch 72: loss = 0.7919735908508301, acc = 0.74609375\n",
      "Batch 73: loss = 0.8559808731079102, acc = 0.716796875\n",
      "Batch 74: loss = 0.8641036748886108, acc = 0.701171875\n",
      "Batch 75: loss = 0.9164833426475525, acc = 0.7158203125\n",
      "Batch 76: loss = 0.848518967628479, acc = 0.712890625\n",
      "Batch 77: loss = 0.7634086608886719, acc = 0.7587890625\n",
      "Batch 78: loss = 0.8028093576431274, acc = 0.7373046875\n",
      "Batch 79: loss = 0.7039533257484436, acc = 0.7607421875\n",
      "Batch 80: loss = 0.7453003525733948, acc = 0.7236328125\n",
      "Batch 81: loss = 0.798025369644165, acc = 0.7490234375\n",
      "Batch 82: loss = 0.7144606113433838, acc = 0.765625\n",
      "Batch 83: loss = 0.7850122451782227, acc = 0.740234375\n",
      "Batch 84: loss = 0.7673372030258179, acc = 0.7451171875\n",
      "Batch 85: loss = 0.8617913722991943, acc = 0.701171875\n",
      "Batch 86: loss = 0.8164819478988647, acc = 0.734375\n",
      "Batch 87: loss = 0.7608738541603088, acc = 0.7529296875\n",
      "Batch 88: loss = 0.9121327996253967, acc = 0.70703125\n",
      "Batch 89: loss = 0.8369795083999634, acc = 0.728515625\n",
      "Batch 90: loss = 0.8424655199050903, acc = 0.724609375\n",
      "Batch 91: loss = 0.8458499908447266, acc = 0.703125\n",
      "Batch 92: loss = 0.7976608276367188, acc = 0.728515625\n",
      "Batch 93: loss = 0.6887270212173462, acc = 0.77734375\n",
      "Batch 94: loss = 0.7389772534370422, acc = 0.7587890625\n",
      "Batch 95: loss = 0.7542333602905273, acc = 0.7353515625\n",
      "Batch 96: loss = 0.8338210582733154, acc = 0.7177734375\n",
      "Batch 97: loss = 0.7978457808494568, acc = 0.7509765625\n",
      "Batch 98: loss = 0.768183708190918, acc = 0.7392578125\n",
      "Batch 99: loss = 0.8139513731002808, acc = 0.720703125\n",
      "Batch 100: loss = 0.8045512437820435, acc = 0.716796875\n",
      "Batch 101: loss = 0.7739957571029663, acc = 0.7548828125\n",
      "Batch 102: loss = 0.8657128810882568, acc = 0.71484375\n",
      "Batch 103: loss = 0.7903391122817993, acc = 0.7373046875\n",
      "Batch 104: loss = 0.7207550406455994, acc = 0.751953125\n",
      "Batch 105: loss = 0.758791446685791, acc = 0.75390625\n",
      "Batch 106: loss = 0.822684645652771, acc = 0.728515625\n",
      "Batch 107: loss = 0.7646017074584961, acc = 0.7470703125\n",
      "Batch 108: loss = 0.7831097841262817, acc = 0.744140625\n",
      "Batch 109: loss = 0.7648537755012512, acc = 0.74609375\n",
      "Batch 110: loss = 0.7277782559394836, acc = 0.7568359375\n",
      "Batch 111: loss = 0.8761769533157349, acc = 0.703125\n",
      "Batch 112: loss = 0.7693603038787842, acc = 0.748046875\n",
      "Batch 113: loss = 0.8420969843864441, acc = 0.7119140625\n",
      "Batch 114: loss = 0.8228464722633362, acc = 0.7392578125\n",
      "Batch 115: loss = 0.83339524269104, acc = 0.7294921875\n",
      "Batch 116: loss = 0.9053977727890015, acc = 0.7060546875\n",
      "Batch 117: loss = 0.7520236968994141, acc = 0.751953125\n",
      "Batch 118: loss = 0.6870108246803284, acc = 0.7783203125\n",
      "Batch 119: loss = 0.7813804745674133, acc = 0.748046875\n",
      "Batch 120: loss = 0.8202270269393921, acc = 0.7197265625\n",
      "Batch 121: loss = 0.7821085453033447, acc = 0.7392578125\n",
      "Batch 122: loss = 0.7536654472351074, acc = 0.732421875\n",
      "Batch 123: loss = 0.797431468963623, acc = 0.748046875\n",
      "Batch 124: loss = 0.8335678577423096, acc = 0.7119140625\n",
      "Batch 125: loss = 0.8403673768043518, acc = 0.7177734375\n",
      "Batch 126: loss = 0.8611368536949158, acc = 0.7294921875\n",
      "\n",
      "Epoch 28/100\n",
      "Batch 1: loss = 0.9866131544113159, acc = 0.6953125\n",
      "Batch 2: loss = 0.92008376121521, acc = 0.70703125\n",
      "Batch 3: loss = 0.8138728141784668, acc = 0.7412109375\n",
      "Batch 4: loss = 0.8096359968185425, acc = 0.748046875\n",
      "Batch 5: loss = 0.874241054058075, acc = 0.712890625\n",
      "Batch 6: loss = 0.9011542797088623, acc = 0.7041015625\n",
      "Batch 7: loss = 0.8415841460227966, acc = 0.7177734375\n",
      "Batch 8: loss = 0.797961950302124, acc = 0.7392578125\n",
      "Batch 9: loss = 0.7374997735023499, acc = 0.76171875\n",
      "Batch 10: loss = 0.7415680885314941, acc = 0.751953125\n",
      "Batch 11: loss = 0.8405216932296753, acc = 0.7080078125\n",
      "Batch 12: loss = 0.8124523162841797, acc = 0.7216796875\n",
      "Batch 13: loss = 0.7777619361877441, acc = 0.736328125\n",
      "Batch 14: loss = 0.7706555724143982, acc = 0.7666015625\n",
      "Batch 15: loss = 0.7751798629760742, acc = 0.7431640625\n",
      "Batch 16: loss = 0.8506669998168945, acc = 0.72265625\n",
      "Batch 17: loss = 0.8374927043914795, acc = 0.7265625\n",
      "Batch 18: loss = 0.8208483457565308, acc = 0.7333984375\n",
      "Batch 19: loss = 0.7687283754348755, acc = 0.7490234375\n",
      "Batch 20: loss = 0.7828942537307739, acc = 0.7490234375\n",
      "Batch 21: loss = 0.8854905366897583, acc = 0.708984375\n",
      "Batch 22: loss = 0.7623509168624878, acc = 0.751953125\n",
      "Batch 23: loss = 0.7813518643379211, acc = 0.740234375\n",
      "Batch 24: loss = 0.7430793046951294, acc = 0.740234375\n",
      "Batch 25: loss = 0.7344467639923096, acc = 0.7646484375\n",
      "Batch 26: loss = 0.7515162229537964, acc = 0.7490234375\n",
      "Batch 27: loss = 0.8719593286514282, acc = 0.7138671875\n",
      "Batch 28: loss = 0.8141870498657227, acc = 0.72265625\n",
      "Batch 29: loss = 0.7975012063980103, acc = 0.7470703125\n",
      "Batch 30: loss = 0.7260600924491882, acc = 0.7578125\n",
      "Batch 31: loss = 0.8522375822067261, acc = 0.728515625\n",
      "Batch 32: loss = 0.9085761308670044, acc = 0.70703125\n",
      "Batch 33: loss = 0.7835229635238647, acc = 0.736328125\n",
      "Batch 34: loss = 0.8169098496437073, acc = 0.7197265625\n",
      "Batch 35: loss = 0.8175337910652161, acc = 0.7490234375\n",
      "Batch 36: loss = 0.7862889766693115, acc = 0.7314453125\n",
      "Batch 37: loss = 0.7574192881584167, acc = 0.759765625\n",
      "Batch 38: loss = 0.8431656360626221, acc = 0.740234375\n",
      "Batch 39: loss = 0.8349711298942566, acc = 0.7451171875\n",
      "Batch 40: loss = 0.8124098777770996, acc = 0.7314453125\n",
      "Batch 41: loss = 0.709186315536499, acc = 0.771484375\n",
      "Batch 42: loss = 0.7391061782836914, acc = 0.755859375\n",
      "Batch 43: loss = 0.8013601899147034, acc = 0.72265625\n",
      "Batch 44: loss = 0.731126070022583, acc = 0.7685546875\n",
      "Batch 45: loss = 0.6924241781234741, acc = 0.76171875\n",
      "Batch 46: loss = 0.7514281272888184, acc = 0.7548828125\n",
      "Batch 47: loss = 0.749014675617218, acc = 0.759765625\n",
      "Batch 48: loss = 0.702357292175293, acc = 0.75390625\n",
      "Batch 49: loss = 0.6713706254959106, acc = 0.7861328125\n",
      "Batch 50: loss = 0.7032899856567383, acc = 0.767578125\n",
      "Batch 51: loss = 0.6918814182281494, acc = 0.7626953125\n",
      "Batch 52: loss = 0.7997651696205139, acc = 0.73828125\n",
      "Batch 53: loss = 0.7791957855224609, acc = 0.740234375\n",
      "Batch 54: loss = 0.6833595037460327, acc = 0.767578125\n",
      "Batch 55: loss = 0.6943383812904358, acc = 0.7705078125\n",
      "Batch 56: loss = 0.7913788557052612, acc = 0.7236328125\n",
      "Batch 57: loss = 0.8506515026092529, acc = 0.708984375\n",
      "Batch 58: loss = 0.8515637516975403, acc = 0.7138671875\n",
      "Batch 59: loss = 0.6553358435630798, acc = 0.7900390625\n",
      "Batch 60: loss = 0.7694128751754761, acc = 0.7373046875\n",
      "Batch 61: loss = 0.7756309509277344, acc = 0.7529296875\n",
      "Batch 62: loss = 0.9193636178970337, acc = 0.6806640625\n",
      "Batch 63: loss = 0.9197510480880737, acc = 0.6904296875\n",
      "Batch 64: loss = 0.6552079319953918, acc = 0.78125\n",
      "Batch 65: loss = 0.8269044756889343, acc = 0.7275390625\n",
      "Batch 66: loss = 0.7946438193321228, acc = 0.7294921875\n",
      "Batch 67: loss = 0.740851104259491, acc = 0.755859375\n",
      "Batch 68: loss = 0.8008397817611694, acc = 0.7353515625\n",
      "Batch 69: loss = 0.7356324791908264, acc = 0.751953125\n",
      "Batch 70: loss = 0.8517172336578369, acc = 0.7080078125\n",
      "Batch 71: loss = 0.8221457004547119, acc = 0.7236328125\n",
      "Batch 72: loss = 0.7491857409477234, acc = 0.7431640625\n",
      "Batch 73: loss = 0.8593961596488953, acc = 0.7197265625\n",
      "Batch 74: loss = 0.8164420127868652, acc = 0.7265625\n",
      "Batch 75: loss = 0.8957931995391846, acc = 0.7001953125\n",
      "Batch 76: loss = 0.8267523050308228, acc = 0.724609375\n",
      "Batch 77: loss = 0.7539016008377075, acc = 0.7568359375\n",
      "Batch 78: loss = 0.7880693674087524, acc = 0.7412109375\n",
      "Batch 79: loss = 0.6726011037826538, acc = 0.7744140625\n",
      "Batch 80: loss = 0.7352092266082764, acc = 0.7412109375\n",
      "Batch 81: loss = 0.7823392748832703, acc = 0.7578125\n",
      "Batch 82: loss = 0.6803006529808044, acc = 0.7890625\n",
      "Batch 83: loss = 0.757693350315094, acc = 0.7470703125\n",
      "Batch 84: loss = 0.7376763820648193, acc = 0.7470703125\n",
      "Batch 85: loss = 0.8641291856765747, acc = 0.71484375\n",
      "Batch 86: loss = 0.8035823106765747, acc = 0.7216796875\n",
      "Batch 87: loss = 0.7586352825164795, acc = 0.759765625\n",
      "Batch 88: loss = 0.9118496775627136, acc = 0.712890625\n",
      "Batch 89: loss = 0.8032985925674438, acc = 0.72265625\n",
      "Batch 90: loss = 0.816439151763916, acc = 0.7529296875\n",
      "Batch 91: loss = 0.8410979509353638, acc = 0.7216796875\n",
      "Batch 92: loss = 0.8008413910865784, acc = 0.7314453125\n",
      "Batch 93: loss = 0.6614153385162354, acc = 0.7783203125\n",
      "Batch 94: loss = 0.7178247570991516, acc = 0.76953125\n",
      "Batch 95: loss = 0.7696409225463867, acc = 0.74609375\n",
      "Batch 96: loss = 0.8127108812332153, acc = 0.7333984375\n",
      "Batch 97: loss = 0.7567011117935181, acc = 0.748046875\n",
      "Batch 98: loss = 0.754476010799408, acc = 0.765625\n",
      "Batch 99: loss = 0.7831665277481079, acc = 0.732421875\n",
      "Batch 100: loss = 0.8003231287002563, acc = 0.7216796875\n",
      "Batch 101: loss = 0.7637953758239746, acc = 0.7578125\n",
      "Batch 102: loss = 0.8608700037002563, acc = 0.7060546875\n",
      "Batch 103: loss = 0.7602235078811646, acc = 0.751953125\n",
      "Batch 104: loss = 0.71548992395401, acc = 0.767578125\n",
      "Batch 105: loss = 0.7528525590896606, acc = 0.7568359375\n",
      "Batch 106: loss = 0.7934710383415222, acc = 0.734375\n",
      "Batch 107: loss = 0.7480708360671997, acc = 0.7509765625\n",
      "Batch 108: loss = 0.7921456098556519, acc = 0.7392578125\n",
      "Batch 109: loss = 0.7579126358032227, acc = 0.751953125\n",
      "Batch 110: loss = 0.7024182081222534, acc = 0.7646484375\n",
      "Batch 111: loss = 0.8876223564147949, acc = 0.71484375\n",
      "Batch 112: loss = 0.7619945406913757, acc = 0.7490234375\n",
      "Batch 113: loss = 0.7977651953697205, acc = 0.71484375\n",
      "Batch 114: loss = 0.804581880569458, acc = 0.7548828125\n",
      "Batch 115: loss = 0.8268485069274902, acc = 0.7197265625\n",
      "Batch 116: loss = 0.8719130754470825, acc = 0.71484375\n",
      "Batch 117: loss = 0.7278323173522949, acc = 0.7548828125\n",
      "Batch 118: loss = 0.6791083812713623, acc = 0.771484375\n",
      "Batch 119: loss = 0.7741170525550842, acc = 0.740234375\n",
      "Batch 120: loss = 0.7969684600830078, acc = 0.73828125\n",
      "Batch 121: loss = 0.7601526379585266, acc = 0.7490234375\n",
      "Batch 122: loss = 0.7249821424484253, acc = 0.7431640625\n",
      "Batch 123: loss = 0.7895809412002563, acc = 0.744140625\n",
      "Batch 124: loss = 0.8074430227279663, acc = 0.7353515625\n",
      "Batch 125: loss = 0.8319528102874756, acc = 0.720703125\n",
      "Batch 126: loss = 0.8340917825698853, acc = 0.7353515625\n",
      "\n",
      "Epoch 29/100\n",
      "Batch 1: loss = 0.9390982985496521, acc = 0.7197265625\n",
      "Batch 2: loss = 0.8904553651809692, acc = 0.7119140625\n",
      "Batch 3: loss = 0.8253585696220398, acc = 0.74609375\n",
      "Batch 4: loss = 0.7845082879066467, acc = 0.751953125\n",
      "Batch 5: loss = 0.8560535907745361, acc = 0.720703125\n",
      "Batch 6: loss = 0.88103848695755, acc = 0.6982421875\n",
      "Batch 7: loss = 0.8005425930023193, acc = 0.74609375\n",
      "Batch 8: loss = 0.7794586420059204, acc = 0.7470703125\n",
      "Batch 9: loss = 0.7354319095611572, acc = 0.7587890625\n",
      "Batch 10: loss = 0.6861766576766968, acc = 0.7666015625\n",
      "Batch 11: loss = 0.7941349744796753, acc = 0.7431640625\n",
      "Batch 12: loss = 0.8158236145973206, acc = 0.7314453125\n",
      "Batch 13: loss = 0.7766283750534058, acc = 0.73828125\n",
      "Batch 14: loss = 0.7335500717163086, acc = 0.751953125\n",
      "Batch 15: loss = 0.7339618802070618, acc = 0.7666015625\n",
      "Batch 16: loss = 0.8406192064285278, acc = 0.7333984375\n",
      "Batch 17: loss = 0.8110367059707642, acc = 0.7421875\n",
      "Batch 18: loss = 0.8280885219573975, acc = 0.7353515625\n",
      "Batch 19: loss = 0.7381677627563477, acc = 0.751953125\n",
      "Batch 20: loss = 0.7434863448143005, acc = 0.74609375\n",
      "Batch 21: loss = 0.8569567799568176, acc = 0.7080078125\n",
      "Batch 22: loss = 0.7351627349853516, acc = 0.7607421875\n",
      "Batch 23: loss = 0.7576092481613159, acc = 0.732421875\n",
      "Batch 24: loss = 0.7227746248245239, acc = 0.7509765625\n",
      "Batch 25: loss = 0.7064251899719238, acc = 0.7744140625\n",
      "Batch 26: loss = 0.7309263944625854, acc = 0.7607421875\n",
      "Batch 27: loss = 0.850357174873352, acc = 0.7216796875\n",
      "Batch 28: loss = 0.7665603160858154, acc = 0.7529296875\n",
      "Batch 29: loss = 0.7762643694877625, acc = 0.7529296875\n",
      "Batch 30: loss = 0.7090965509414673, acc = 0.7578125\n",
      "Batch 31: loss = 0.793337345123291, acc = 0.748046875\n",
      "Batch 32: loss = 0.8886488676071167, acc = 0.701171875\n",
      "Batch 33: loss = 0.7530148029327393, acc = 0.75\n",
      "Batch 34: loss = 0.7981928586959839, acc = 0.7353515625\n",
      "Batch 35: loss = 0.7912858128547668, acc = 0.744140625\n",
      "Batch 36: loss = 0.7471389770507812, acc = 0.76953125\n",
      "Batch 37: loss = 0.7198306322097778, acc = 0.767578125\n",
      "Batch 38: loss = 0.7946187257766724, acc = 0.748046875\n",
      "Batch 39: loss = 0.8004729747772217, acc = 0.7314453125\n",
      "Batch 40: loss = 0.7699167728424072, acc = 0.7421875\n",
      "Batch 41: loss = 0.6678942441940308, acc = 0.779296875\n",
      "Batch 42: loss = 0.7223310470581055, acc = 0.7568359375\n",
      "Batch 43: loss = 0.7783299088478088, acc = 0.7236328125\n",
      "Batch 44: loss = 0.7056816816329956, acc = 0.7705078125\n",
      "Batch 45: loss = 0.6736435890197754, acc = 0.78125\n",
      "Batch 46: loss = 0.7311654090881348, acc = 0.7509765625\n",
      "Batch 47: loss = 0.7306894063949585, acc = 0.7548828125\n",
      "Batch 48: loss = 0.7012341022491455, acc = 0.76953125\n",
      "Batch 49: loss = 0.6774968504905701, acc = 0.7861328125\n",
      "Batch 50: loss = 0.6865116357803345, acc = 0.7783203125\n",
      "Batch 51: loss = 0.7122058272361755, acc = 0.7470703125\n",
      "Batch 52: loss = 0.7906155586242676, acc = 0.734375\n",
      "Batch 53: loss = 0.7311794757843018, acc = 0.759765625\n",
      "Batch 54: loss = 0.6427606344223022, acc = 0.79296875\n",
      "Batch 55: loss = 0.6846926212310791, acc = 0.7822265625\n",
      "Batch 56: loss = 0.7835478186607361, acc = 0.740234375\n",
      "Batch 57: loss = 0.8184290528297424, acc = 0.7177734375\n",
      "Batch 58: loss = 0.8463334441184998, acc = 0.716796875\n",
      "Batch 59: loss = 0.6438469290733337, acc = 0.7822265625\n",
      "Batch 60: loss = 0.7533775568008423, acc = 0.7431640625\n",
      "Batch 61: loss = 0.7489436864852905, acc = 0.763671875\n",
      "Batch 62: loss = 0.9035378694534302, acc = 0.6923828125\n",
      "Batch 63: loss = 0.8624939322471619, acc = 0.7060546875\n",
      "Batch 64: loss = 0.6659740209579468, acc = 0.771484375\n",
      "Batch 65: loss = 0.8031138181686401, acc = 0.7353515625\n",
      "Batch 66: loss = 0.7877691984176636, acc = 0.7470703125\n",
      "Batch 67: loss = 0.7232338190078735, acc = 0.7705078125\n",
      "Batch 68: loss = 0.8087857961654663, acc = 0.73828125\n",
      "Batch 69: loss = 0.7320091724395752, acc = 0.7578125\n",
      "Batch 70: loss = 0.8394802212715149, acc = 0.7236328125\n",
      "Batch 71: loss = 0.7803085446357727, acc = 0.734375\n",
      "Batch 72: loss = 0.7125921845436096, acc = 0.755859375\n",
      "Batch 73: loss = 0.8234232664108276, acc = 0.734375\n",
      "Batch 74: loss = 0.8201678991317749, acc = 0.7353515625\n",
      "Batch 75: loss = 0.8945642113685608, acc = 0.7119140625\n",
      "Batch 76: loss = 0.8227405548095703, acc = 0.7333984375\n",
      "Batch 77: loss = 0.7461838722229004, acc = 0.763671875\n",
      "Batch 78: loss = 0.7745547294616699, acc = 0.7470703125\n",
      "Batch 79: loss = 0.6748031377792358, acc = 0.7666015625\n",
      "Batch 80: loss = 0.7209835052490234, acc = 0.732421875\n",
      "Batch 81: loss = 0.7777268886566162, acc = 0.7529296875\n",
      "Batch 82: loss = 0.6701675653457642, acc = 0.7822265625\n",
      "Batch 83: loss = 0.7468993067741394, acc = 0.74609375\n",
      "Batch 84: loss = 0.7633102536201477, acc = 0.7509765625\n",
      "Batch 85: loss = 0.8353711366653442, acc = 0.7119140625\n",
      "Batch 86: loss = 0.8320431709289551, acc = 0.728515625\n",
      "Batch 87: loss = 0.7163729071617126, acc = 0.7744140625\n",
      "Batch 88: loss = 0.8954352140426636, acc = 0.7080078125\n",
      "Batch 89: loss = 0.7843875885009766, acc = 0.7548828125\n",
      "Batch 90: loss = 0.814915120601654, acc = 0.73828125\n",
      "Batch 91: loss = 0.804111123085022, acc = 0.72265625\n",
      "Batch 92: loss = 0.7540112137794495, acc = 0.75\n",
      "Batch 93: loss = 0.6432773470878601, acc = 0.7978515625\n",
      "Batch 94: loss = 0.6992071866989136, acc = 0.771484375\n",
      "Batch 95: loss = 0.7308324575424194, acc = 0.75\n",
      "Batch 96: loss = 0.8049877882003784, acc = 0.71875\n",
      "Batch 97: loss = 0.7635199427604675, acc = 0.75390625\n",
      "Batch 98: loss = 0.7285922169685364, acc = 0.767578125\n",
      "Batch 99: loss = 0.7787814736366272, acc = 0.73046875\n",
      "Batch 100: loss = 0.7773783206939697, acc = 0.7236328125\n",
      "Batch 101: loss = 0.7566214799880981, acc = 0.744140625\n",
      "Batch 102: loss = 0.8290287256240845, acc = 0.7265625\n",
      "Batch 103: loss = 0.7790347337722778, acc = 0.755859375\n",
      "Batch 104: loss = 0.694769561290741, acc = 0.7607421875\n",
      "Batch 105: loss = 0.7474712133407593, acc = 0.7431640625\n",
      "Batch 106: loss = 0.8027653694152832, acc = 0.7294921875\n",
      "Batch 107: loss = 0.7575864791870117, acc = 0.7509765625\n",
      "Batch 108: loss = 0.7637050151824951, acc = 0.740234375\n",
      "Batch 109: loss = 0.7414901256561279, acc = 0.748046875\n",
      "Batch 110: loss = 0.6987138986587524, acc = 0.7783203125\n",
      "Batch 111: loss = 0.8490065336227417, acc = 0.7275390625\n",
      "Batch 112: loss = 0.709513247013092, acc = 0.76171875\n",
      "Batch 113: loss = 0.7826890349388123, acc = 0.734375\n",
      "Batch 114: loss = 0.7937624454498291, acc = 0.7412109375\n",
      "Batch 115: loss = 0.8047454357147217, acc = 0.732421875\n",
      "Batch 116: loss = 0.8245227336883545, acc = 0.7353515625\n",
      "Batch 117: loss = 0.7266359329223633, acc = 0.763671875\n",
      "Batch 118: loss = 0.6733022332191467, acc = 0.7685546875\n",
      "Batch 119: loss = 0.7592110633850098, acc = 0.7548828125\n",
      "Batch 120: loss = 0.7834329605102539, acc = 0.73046875\n",
      "Batch 121: loss = 0.7857857346534729, acc = 0.7421875\n",
      "Batch 122: loss = 0.7389758825302124, acc = 0.75390625\n",
      "Batch 123: loss = 0.7684955596923828, acc = 0.751953125\n",
      "Batch 124: loss = 0.7999914288520813, acc = 0.7275390625\n",
      "Batch 125: loss = 0.8000637888908386, acc = 0.7373046875\n",
      "Batch 126: loss = 0.8347356915473938, acc = 0.736328125\n",
      "\n",
      "Epoch 30/100\n",
      "Batch 1: loss = 0.9443337321281433, acc = 0.7158203125\n",
      "Batch 2: loss = 0.8554916381835938, acc = 0.7216796875\n",
      "Batch 3: loss = 0.8251845836639404, acc = 0.740234375\n",
      "Batch 4: loss = 0.7791345715522766, acc = 0.7470703125\n",
      "Batch 5: loss = 0.8423130512237549, acc = 0.7275390625\n",
      "Batch 6: loss = 0.8472879528999329, acc = 0.71484375\n",
      "Batch 7: loss = 0.8003275394439697, acc = 0.7412109375\n",
      "Batch 8: loss = 0.7605990171432495, acc = 0.7333984375\n",
      "Batch 9: loss = 0.7194884419441223, acc = 0.767578125\n",
      "Batch 10: loss = 0.6826890110969543, acc = 0.7666015625\n",
      "Batch 11: loss = 0.7854403257369995, acc = 0.744140625\n",
      "Batch 12: loss = 0.7719895839691162, acc = 0.740234375\n",
      "Batch 13: loss = 0.7302464842796326, acc = 0.7431640625\n",
      "Batch 14: loss = 0.729522705078125, acc = 0.76953125\n",
      "Batch 15: loss = 0.7182438969612122, acc = 0.7763671875\n",
      "Batch 16: loss = 0.7929389476776123, acc = 0.7392578125\n",
      "Batch 17: loss = 0.7938185930252075, acc = 0.740234375\n",
      "Batch 18: loss = 0.794411838054657, acc = 0.740234375\n",
      "Batch 19: loss = 0.7032250761985779, acc = 0.771484375\n",
      "Batch 20: loss = 0.7385817170143127, acc = 0.7587890625\n",
      "Batch 21: loss = 0.818631649017334, acc = 0.7216796875\n",
      "Batch 22: loss = 0.7419773936271667, acc = 0.763671875\n",
      "Batch 23: loss = 0.7476961016654968, acc = 0.740234375\n",
      "Batch 24: loss = 0.7324249744415283, acc = 0.7490234375\n",
      "Batch 25: loss = 0.7042347192764282, acc = 0.7822265625\n",
      "Batch 26: loss = 0.7170438766479492, acc = 0.75390625\n",
      "Batch 27: loss = 0.8346301317214966, acc = 0.7373046875\n",
      "Batch 28: loss = 0.7516329884529114, acc = 0.7470703125\n",
      "Batch 29: loss = 0.75006502866745, acc = 0.755859375\n",
      "Batch 30: loss = 0.6941910982131958, acc = 0.7685546875\n",
      "Batch 31: loss = 0.783538281917572, acc = 0.7451171875\n",
      "Batch 32: loss = 0.8759068846702576, acc = 0.7216796875\n",
      "Batch 33: loss = 0.736666738986969, acc = 0.7587890625\n",
      "Batch 34: loss = 0.7812772393226624, acc = 0.7509765625\n",
      "Batch 35: loss = 0.763884961605072, acc = 0.759765625\n",
      "Batch 36: loss = 0.7215165495872498, acc = 0.76171875\n",
      "Batch 37: loss = 0.7164788842201233, acc = 0.7685546875\n",
      "Batch 38: loss = 0.7820520997047424, acc = 0.7333984375\n",
      "Batch 39: loss = 0.7602383494377136, acc = 0.7392578125\n",
      "Batch 40: loss = 0.7581475973129272, acc = 0.76171875\n",
      "Batch 41: loss = 0.6728070974349976, acc = 0.783203125\n",
      "Batch 42: loss = 0.7227757573127747, acc = 0.7666015625\n",
      "Batch 43: loss = 0.7574632167816162, acc = 0.73828125\n",
      "Batch 44: loss = 0.6636093854904175, acc = 0.779296875\n",
      "Batch 45: loss = 0.6414531469345093, acc = 0.7802734375\n",
      "Batch 46: loss = 0.7062234878540039, acc = 0.7646484375\n",
      "Batch 47: loss = 0.7056924104690552, acc = 0.7724609375\n",
      "Batch 48: loss = 0.6982322931289673, acc = 0.75390625\n",
      "Batch 49: loss = 0.6357519030570984, acc = 0.791015625\n",
      "Batch 50: loss = 0.682454526424408, acc = 0.7861328125\n",
      "Batch 51: loss = 0.672034502029419, acc = 0.7763671875\n",
      "Batch 52: loss = 0.7748595476150513, acc = 0.7490234375\n",
      "Batch 53: loss = 0.7210773825645447, acc = 0.7685546875\n",
      "Batch 54: loss = 0.6013975739479065, acc = 0.798828125\n",
      "Batch 55: loss = 0.6691418886184692, acc = 0.7666015625\n",
      "Batch 56: loss = 0.7615822553634644, acc = 0.748046875\n",
      "Batch 57: loss = 0.820732593536377, acc = 0.7158203125\n",
      "Batch 58: loss = 0.8286721706390381, acc = 0.7265625\n",
      "Batch 59: loss = 0.629391074180603, acc = 0.8046875\n",
      "Batch 60: loss = 0.7314095497131348, acc = 0.7666015625\n",
      "Batch 61: loss = 0.7622687816619873, acc = 0.759765625\n",
      "Batch 62: loss = 0.8701520562171936, acc = 0.7001953125\n",
      "Batch 63: loss = 0.828981339931488, acc = 0.71875\n",
      "Batch 64: loss = 0.6483232975006104, acc = 0.787109375\n",
      "Batch 65: loss = 0.7787222862243652, acc = 0.74609375\n",
      "Batch 66: loss = 0.7848595380783081, acc = 0.7431640625\n",
      "Batch 67: loss = 0.7050427198410034, acc = 0.76171875\n",
      "Batch 68: loss = 0.7899426221847534, acc = 0.728515625\n",
      "Batch 69: loss = 0.6931947469711304, acc = 0.7666015625\n",
      "Batch 70: loss = 0.7806366086006165, acc = 0.7412109375\n",
      "Batch 71: loss = 0.7935898303985596, acc = 0.732421875\n",
      "Batch 72: loss = 0.6988813281059265, acc = 0.771484375\n",
      "Batch 73: loss = 0.8013001680374146, acc = 0.74609375\n",
      "Batch 74: loss = 0.7901527881622314, acc = 0.7392578125\n",
      "Batch 75: loss = 0.8570927381515503, acc = 0.7119140625\n",
      "Batch 76: loss = 0.7788645029067993, acc = 0.7412109375\n",
      "Batch 77: loss = 0.7117816209793091, acc = 0.787109375\n",
      "Batch 78: loss = 0.7594083547592163, acc = 0.7509765625\n",
      "Batch 79: loss = 0.684327244758606, acc = 0.7724609375\n",
      "Batch 80: loss = 0.7001088261604309, acc = 0.75390625\n",
      "Batch 81: loss = 0.7506668567657471, acc = 0.7548828125\n",
      "Batch 82: loss = 0.6809471845626831, acc = 0.7763671875\n",
      "Batch 83: loss = 0.7458114624023438, acc = 0.7509765625\n",
      "Batch 84: loss = 0.747978925704956, acc = 0.7490234375\n",
      "Batch 85: loss = 0.8455265760421753, acc = 0.701171875\n",
      "Batch 86: loss = 0.7696969509124756, acc = 0.75\n",
      "Batch 87: loss = 0.7030477523803711, acc = 0.771484375\n",
      "Batch 88: loss = 0.8661103844642639, acc = 0.7265625\n",
      "Batch 89: loss = 0.7712056636810303, acc = 0.7705078125\n",
      "Batch 90: loss = 0.7878857851028442, acc = 0.7470703125\n",
      "Batch 91: loss = 0.7853198051452637, acc = 0.744140625\n",
      "Batch 92: loss = 0.7647671103477478, acc = 0.7451171875\n",
      "Batch 93: loss = 0.659755289554596, acc = 0.7861328125\n",
      "Batch 94: loss = 0.6813008785247803, acc = 0.78125\n",
      "Batch 95: loss = 0.7098660469055176, acc = 0.7529296875\n",
      "Batch 96: loss = 0.7904682755470276, acc = 0.7333984375\n",
      "Batch 97: loss = 0.7369457483291626, acc = 0.76953125\n",
      "Batch 98: loss = 0.7000875473022461, acc = 0.771484375\n",
      "Batch 99: loss = 0.7841169834136963, acc = 0.7490234375\n",
      "Batch 100: loss = 0.7741276025772095, acc = 0.7333984375\n",
      "Batch 101: loss = 0.74177086353302, acc = 0.7548828125\n",
      "Batch 102: loss = 0.8091500997543335, acc = 0.732421875\n",
      "Batch 103: loss = 0.7555582523345947, acc = 0.7470703125\n",
      "Batch 104: loss = 0.6784898042678833, acc = 0.76171875\n",
      "Batch 105: loss = 0.6967644691467285, acc = 0.78125\n",
      "Batch 106: loss = 0.7800040245056152, acc = 0.7431640625\n",
      "Batch 107: loss = 0.7415710687637329, acc = 0.7607421875\n",
      "Batch 108: loss = 0.7785563468933105, acc = 0.7392578125\n",
      "Batch 109: loss = 0.7128429412841797, acc = 0.748046875\n",
      "Batch 110: loss = 0.6925725936889648, acc = 0.783203125\n",
      "Batch 111: loss = 0.8282669186592102, acc = 0.7373046875\n",
      "Batch 112: loss = 0.7290493845939636, acc = 0.7470703125\n",
      "Batch 113: loss = 0.7719495296478271, acc = 0.740234375\n",
      "Batch 114: loss = 0.7772464156150818, acc = 0.7666015625\n",
      "Batch 115: loss = 0.7690117359161377, acc = 0.744140625\n",
      "Batch 116: loss = 0.8220017552375793, acc = 0.736328125\n",
      "Batch 117: loss = 0.6805084347724915, acc = 0.765625\n",
      "Batch 118: loss = 0.645378828048706, acc = 0.7861328125\n",
      "Batch 119: loss = 0.7496654987335205, acc = 0.755859375\n",
      "Batch 120: loss = 0.7527148723602295, acc = 0.73828125\n",
      "Batch 121: loss = 0.7235140800476074, acc = 0.7763671875\n",
      "Batch 122: loss = 0.7297749519348145, acc = 0.75390625\n",
      "Batch 123: loss = 0.7497326135635376, acc = 0.75390625\n",
      "Batch 124: loss = 0.7701640129089355, acc = 0.7294921875\n",
      "Batch 125: loss = 0.8068137764930725, acc = 0.7353515625\n",
      "Batch 126: loss = 0.8232101202011108, acc = 0.7314453125\n",
      "\n",
      "Epoch 31/100\n",
      "Batch 1: loss = 0.9315738081932068, acc = 0.7080078125\n",
      "Batch 2: loss = 0.8612189292907715, acc = 0.7099609375\n",
      "Batch 3: loss = 0.7724776268005371, acc = 0.7529296875\n",
      "Batch 4: loss = 0.7498994469642639, acc = 0.7685546875\n",
      "Batch 5: loss = 0.8163350820541382, acc = 0.7421875\n",
      "Batch 6: loss = 0.8433201313018799, acc = 0.7236328125\n",
      "Batch 7: loss = 0.7681356072425842, acc = 0.7431640625\n",
      "Batch 8: loss = 0.7476882338523865, acc = 0.7568359375\n",
      "Batch 9: loss = 0.7071409225463867, acc = 0.7548828125\n",
      "Batch 10: loss = 0.6538971662521362, acc = 0.783203125\n",
      "Batch 11: loss = 0.7604210376739502, acc = 0.7587890625\n",
      "Batch 12: loss = 0.7677238583564758, acc = 0.734375\n",
      "Batch 13: loss = 0.7311797738075256, acc = 0.7529296875\n",
      "Batch 14: loss = 0.7153424620628357, acc = 0.76171875\n",
      "Batch 15: loss = 0.6851813197135925, acc = 0.78515625\n",
      "Batch 16: loss = 0.7906047105789185, acc = 0.7412109375\n",
      "Batch 17: loss = 0.7885197401046753, acc = 0.76171875\n",
      "Batch 18: loss = 0.771321177482605, acc = 0.759765625\n",
      "Batch 19: loss = 0.7142578363418579, acc = 0.7646484375\n",
      "Batch 20: loss = 0.7233704328536987, acc = 0.748046875\n",
      "Batch 21: loss = 0.7957650423049927, acc = 0.7216796875\n",
      "Batch 22: loss = 0.7102578282356262, acc = 0.759765625\n",
      "Batch 23: loss = 0.7298661470413208, acc = 0.7431640625\n",
      "Batch 24: loss = 0.7183294296264648, acc = 0.7578125\n",
      "Batch 25: loss = 0.6983767747879028, acc = 0.76953125\n",
      "Batch 26: loss = 0.6836287975311279, acc = 0.765625\n",
      "Batch 27: loss = 0.8022792339324951, acc = 0.7294921875\n",
      "Batch 28: loss = 0.7547332048416138, acc = 0.755859375\n",
      "Batch 29: loss = 0.7345731258392334, acc = 0.759765625\n",
      "Batch 30: loss = 0.671482264995575, acc = 0.771484375\n",
      "Batch 31: loss = 0.7954721450805664, acc = 0.744140625\n",
      "Batch 32: loss = 0.8423380851745605, acc = 0.72265625\n",
      "Batch 33: loss = 0.7078348994255066, acc = 0.775390625\n",
      "Batch 34: loss = 0.7593250870704651, acc = 0.7490234375\n",
      "Batch 35: loss = 0.7406340837478638, acc = 0.7568359375\n",
      "Batch 36: loss = 0.710746169090271, acc = 0.771484375\n",
      "Batch 37: loss = 0.7228877544403076, acc = 0.771484375\n",
      "Batch 38: loss = 0.7596742510795593, acc = 0.7431640625\n",
      "Batch 39: loss = 0.7585066556930542, acc = 0.751953125\n",
      "Batch 40: loss = 0.757416844367981, acc = 0.767578125\n",
      "Batch 41: loss = 0.6582579612731934, acc = 0.7822265625\n",
      "Batch 42: loss = 0.7165746092796326, acc = 0.763671875\n",
      "Batch 43: loss = 0.7328258752822876, acc = 0.75390625\n",
      "Batch 44: loss = 0.687265932559967, acc = 0.7705078125\n",
      "Batch 45: loss = 0.6483101844787598, acc = 0.79296875\n",
      "Batch 46: loss = 0.6971579790115356, acc = 0.76953125\n",
      "Batch 47: loss = 0.706015944480896, acc = 0.7783203125\n",
      "Batch 48: loss = 0.6960397958755493, acc = 0.7626953125\n",
      "Batch 49: loss = 0.6410620212554932, acc = 0.7861328125\n",
      "Batch 50: loss = 0.6776889562606812, acc = 0.7880859375\n",
      "Batch 51: loss = 0.6488158702850342, acc = 0.7783203125\n",
      "Batch 52: loss = 0.7495414018630981, acc = 0.7509765625\n",
      "Batch 53: loss = 0.7202086448669434, acc = 0.7666015625\n",
      "Batch 54: loss = 0.6108752489089966, acc = 0.80078125\n",
      "Batch 55: loss = 0.6504004001617432, acc = 0.7822265625\n",
      "Batch 56: loss = 0.7380321621894836, acc = 0.7529296875\n",
      "Batch 57: loss = 0.8011502027511597, acc = 0.7353515625\n",
      "Batch 58: loss = 0.798058032989502, acc = 0.734375\n",
      "Batch 59: loss = 0.6124205589294434, acc = 0.7900390625\n",
      "Batch 60: loss = 0.713732123374939, acc = 0.7607421875\n",
      "Batch 61: loss = 0.7113786339759827, acc = 0.787109375\n",
      "Batch 62: loss = 0.8511804938316345, acc = 0.7177734375\n",
      "Batch 63: loss = 0.8386610746383667, acc = 0.7265625\n",
      "Batch 64: loss = 0.6118409633636475, acc = 0.7861328125\n",
      "Batch 65: loss = 0.7794317603111267, acc = 0.7451171875\n",
      "Batch 66: loss = 0.7537193298339844, acc = 0.7451171875\n",
      "Batch 67: loss = 0.6963575482368469, acc = 0.7724609375\n",
      "Batch 68: loss = 0.7592782974243164, acc = 0.751953125\n",
      "Batch 69: loss = 0.6709153652191162, acc = 0.7822265625\n",
      "Batch 70: loss = 0.7998580932617188, acc = 0.7509765625\n",
      "Batch 71: loss = 0.7522037029266357, acc = 0.75390625\n",
      "Batch 72: loss = 0.6983263492584229, acc = 0.7724609375\n",
      "Batch 73: loss = 0.7819027304649353, acc = 0.7412109375\n",
      "Batch 74: loss = 0.8003878593444824, acc = 0.7353515625\n",
      "Batch 75: loss = 0.8755688071250916, acc = 0.70703125\n",
      "Batch 76: loss = 0.7641894817352295, acc = 0.73828125\n",
      "Batch 77: loss = 0.70809006690979, acc = 0.7705078125\n",
      "Batch 78: loss = 0.754439115524292, acc = 0.7587890625\n",
      "Batch 79: loss = 0.6686327457427979, acc = 0.7685546875\n",
      "Batch 80: loss = 0.6859270334243774, acc = 0.7587890625\n",
      "Batch 81: loss = 0.7393667101860046, acc = 0.7626953125\n",
      "Batch 82: loss = 0.6749887466430664, acc = 0.7900390625\n",
      "Batch 83: loss = 0.7158114314079285, acc = 0.7548828125\n",
      "Batch 84: loss = 0.6892584562301636, acc = 0.765625\n",
      "Batch 85: loss = 0.8214858174324036, acc = 0.724609375\n",
      "Batch 86: loss = 0.7730942964553833, acc = 0.7333984375\n",
      "Batch 87: loss = 0.7228732109069824, acc = 0.763671875\n",
      "Batch 88: loss = 0.877995491027832, acc = 0.7099609375\n",
      "Batch 89: loss = 0.7759898900985718, acc = 0.755859375\n",
      "Batch 90: loss = 0.7824621796607971, acc = 0.7470703125\n",
      "Batch 91: loss = 0.7519801259040833, acc = 0.759765625\n",
      "Batch 92: loss = 0.7386672496795654, acc = 0.751953125\n",
      "Batch 93: loss = 0.6409182548522949, acc = 0.7958984375\n",
      "Batch 94: loss = 0.6915615797042847, acc = 0.78515625\n",
      "Batch 95: loss = 0.7227269411087036, acc = 0.748046875\n",
      "Batch 96: loss = 0.7827825546264648, acc = 0.73046875\n",
      "Batch 97: loss = 0.7331976890563965, acc = 0.7705078125\n",
      "Batch 98: loss = 0.7039907574653625, acc = 0.7685546875\n",
      "Batch 99: loss = 0.7337956428527832, acc = 0.7548828125\n",
      "Batch 100: loss = 0.7521559000015259, acc = 0.7314453125\n",
      "Batch 101: loss = 0.7470428943634033, acc = 0.7509765625\n",
      "Batch 102: loss = 0.7982203960418701, acc = 0.734375\n",
      "Batch 103: loss = 0.7218888998031616, acc = 0.76171875\n",
      "Batch 104: loss = 0.6842373609542847, acc = 0.7744140625\n",
      "Batch 105: loss = 0.7181867361068726, acc = 0.767578125\n",
      "Batch 106: loss = 0.7720334529876709, acc = 0.740234375\n",
      "Batch 107: loss = 0.7472343444824219, acc = 0.7529296875\n",
      "Batch 108: loss = 0.7211019992828369, acc = 0.7568359375\n",
      "Batch 109: loss = 0.7109167575836182, acc = 0.7587890625\n",
      "Batch 110: loss = 0.6659087538719177, acc = 0.78515625\n",
      "Batch 111: loss = 0.813764214515686, acc = 0.7275390625\n",
      "Batch 112: loss = 0.7414714097976685, acc = 0.75390625\n",
      "Batch 113: loss = 0.7662279605865479, acc = 0.7412109375\n",
      "Batch 114: loss = 0.7714483737945557, acc = 0.7548828125\n",
      "Batch 115: loss = 0.7624597549438477, acc = 0.744140625\n",
      "Batch 116: loss = 0.8117773532867432, acc = 0.736328125\n",
      "Batch 117: loss = 0.6989346742630005, acc = 0.7763671875\n",
      "Batch 118: loss = 0.6406673789024353, acc = 0.7802734375\n",
      "Batch 119: loss = 0.7275354862213135, acc = 0.759765625\n",
      "Batch 120: loss = 0.7205380201339722, acc = 0.751953125\n",
      "Batch 121: loss = 0.7297468185424805, acc = 0.7744140625\n",
      "Batch 122: loss = 0.7138923406600952, acc = 0.77734375\n",
      "Batch 123: loss = 0.7398761510848999, acc = 0.7548828125\n",
      "Batch 124: loss = 0.8037341833114624, acc = 0.716796875\n",
      "Batch 125: loss = 0.7796617746353149, acc = 0.744140625\n",
      "Batch 126: loss = 0.7822864055633545, acc = 0.7451171875\n",
      "\n",
      "Epoch 32/100\n",
      "Batch 1: loss = 0.9162499904632568, acc = 0.71484375\n",
      "Batch 2: loss = 0.8242734670639038, acc = 0.73046875\n",
      "Batch 3: loss = 0.7789539694786072, acc = 0.7548828125\n",
      "Batch 4: loss = 0.7473795413970947, acc = 0.7685546875\n",
      "Batch 5: loss = 0.8007595539093018, acc = 0.75390625\n",
      "Batch 6: loss = 0.8099009990692139, acc = 0.72265625\n",
      "Batch 7: loss = 0.7692908048629761, acc = 0.755859375\n",
      "Batch 8: loss = 0.7286604046821594, acc = 0.7490234375\n",
      "Batch 9: loss = 0.6765938997268677, acc = 0.78515625\n",
      "Batch 10: loss = 0.636849045753479, acc = 0.783203125\n",
      "Batch 11: loss = 0.7825218439102173, acc = 0.7373046875\n",
      "Batch 12: loss = 0.745275616645813, acc = 0.7626953125\n",
      "Batch 13: loss = 0.7058059573173523, acc = 0.7548828125\n",
      "Batch 14: loss = 0.7180978655815125, acc = 0.7666015625\n",
      "Batch 15: loss = 0.6869949102401733, acc = 0.775390625\n",
      "Batch 16: loss = 0.7691863775253296, acc = 0.7451171875\n",
      "Batch 17: loss = 0.7470174431800842, acc = 0.7578125\n",
      "Batch 18: loss = 0.7478736639022827, acc = 0.759765625\n",
      "Batch 19: loss = 0.6863538026809692, acc = 0.763671875\n",
      "Batch 20: loss = 0.7040249109268188, acc = 0.7578125\n",
      "Batch 21: loss = 0.7926271557807922, acc = 0.73046875\n",
      "Batch 22: loss = 0.7017549276351929, acc = 0.767578125\n",
      "Batch 23: loss = 0.7167864441871643, acc = 0.76171875\n",
      "Batch 24: loss = 0.7143699526786804, acc = 0.75390625\n",
      "Batch 25: loss = 0.6834656000137329, acc = 0.7783203125\n",
      "Batch 26: loss = 0.6920155882835388, acc = 0.7734375\n",
      "Batch 27: loss = 0.8242598176002502, acc = 0.728515625\n",
      "Batch 28: loss = 0.723335862159729, acc = 0.771484375\n",
      "Batch 29: loss = 0.7284866571426392, acc = 0.7646484375\n",
      "Batch 30: loss = 0.670650064945221, acc = 0.7666015625\n",
      "Batch 31: loss = 0.7652404308319092, acc = 0.763671875\n",
      "Batch 32: loss = 0.844139575958252, acc = 0.7265625\n",
      "Batch 33: loss = 0.7046517133712769, acc = 0.7685546875\n",
      "Batch 34: loss = 0.7466880083084106, acc = 0.7587890625\n",
      "Batch 35: loss = 0.7176370620727539, acc = 0.7734375\n",
      "Batch 36: loss = 0.7006981372833252, acc = 0.7744140625\n",
      "Batch 37: loss = 0.6752941608428955, acc = 0.7861328125\n",
      "Batch 38: loss = 0.7254154682159424, acc = 0.7529296875\n",
      "Batch 39: loss = 0.7250843048095703, acc = 0.7421875\n",
      "Batch 40: loss = 0.7288874983787537, acc = 0.74609375\n",
      "Batch 41: loss = 0.6414012312889099, acc = 0.7783203125\n",
      "Batch 42: loss = 0.6865452527999878, acc = 0.763671875\n",
      "Batch 43: loss = 0.7259640097618103, acc = 0.763671875\n",
      "Batch 44: loss = 0.654955267906189, acc = 0.78515625\n",
      "Batch 45: loss = 0.61449134349823, acc = 0.80859375\n",
      "Batch 46: loss = 0.6976813077926636, acc = 0.7626953125\n",
      "Batch 47: loss = 0.6999541521072388, acc = 0.7802734375\n",
      "Batch 48: loss = 0.6794017553329468, acc = 0.771484375\n",
      "Batch 49: loss = 0.6306601166725159, acc = 0.7978515625\n",
      "Batch 50: loss = 0.6454060673713684, acc = 0.794921875\n",
      "Batch 51: loss = 0.6643241047859192, acc = 0.7744140625\n",
      "Batch 52: loss = 0.7488755583763123, acc = 0.765625\n",
      "Batch 53: loss = 0.6926149129867554, acc = 0.77734375\n",
      "Batch 54: loss = 0.6100995540618896, acc = 0.8046875\n",
      "Batch 55: loss = 0.6394290328025818, acc = 0.78125\n",
      "Batch 56: loss = 0.6960991621017456, acc = 0.7568359375\n",
      "Batch 57: loss = 0.7989104986190796, acc = 0.7255859375\n",
      "Batch 58: loss = 0.7937370538711548, acc = 0.734375\n",
      "Batch 59: loss = 0.6080926656723022, acc = 0.8076171875\n",
      "Batch 60: loss = 0.7074010372161865, acc = 0.765625\n",
      "Batch 61: loss = 0.6743069291114807, acc = 0.78515625\n",
      "Batch 62: loss = 0.8363109230995178, acc = 0.7265625\n",
      "Batch 63: loss = 0.8126316666603088, acc = 0.7333984375\n",
      "Batch 64: loss = 0.6129934787750244, acc = 0.791015625\n",
      "Batch 65: loss = 0.7407901287078857, acc = 0.75390625\n",
      "Batch 66: loss = 0.7078593373298645, acc = 0.7705078125\n",
      "Batch 67: loss = 0.6697014570236206, acc = 0.779296875\n",
      "Batch 68: loss = 0.7369945645332336, acc = 0.7734375\n",
      "Batch 69: loss = 0.6588772535324097, acc = 0.7724609375\n",
      "Batch 70: loss = 0.7798020243644714, acc = 0.7548828125\n",
      "Batch 71: loss = 0.7356821298599243, acc = 0.755859375\n",
      "Batch 72: loss = 0.6941657662391663, acc = 0.7802734375\n",
      "Batch 73: loss = 0.7474846839904785, acc = 0.75\n",
      "Batch 74: loss = 0.7782328128814697, acc = 0.732421875\n",
      "Batch 75: loss = 0.8355671167373657, acc = 0.71875\n",
      "Batch 76: loss = 0.776741623878479, acc = 0.7431640625\n",
      "Batch 77: loss = 0.7022590637207031, acc = 0.767578125\n",
      "Batch 78: loss = 0.7312835454940796, acc = 0.76953125\n",
      "Batch 79: loss = 0.644153356552124, acc = 0.775390625\n",
      "Batch 80: loss = 0.6766251921653748, acc = 0.755859375\n",
      "Batch 81: loss = 0.73524409532547, acc = 0.763671875\n",
      "Batch 82: loss = 0.655105710029602, acc = 0.7822265625\n",
      "Batch 83: loss = 0.6889677047729492, acc = 0.751953125\n",
      "Batch 84: loss = 0.7029170989990234, acc = 0.763671875\n",
      "Batch 85: loss = 0.7817022800445557, acc = 0.744140625\n",
      "Batch 86: loss = 0.7597932815551758, acc = 0.75\n",
      "Batch 87: loss = 0.7021467685699463, acc = 0.76171875\n",
      "Batch 88: loss = 0.8433711528778076, acc = 0.72265625\n",
      "Batch 89: loss = 0.7313514351844788, acc = 0.7529296875\n",
      "Batch 90: loss = 0.7512578964233398, acc = 0.7568359375\n",
      "Batch 91: loss = 0.7623050212860107, acc = 0.7421875\n",
      "Batch 92: loss = 0.7143765687942505, acc = 0.7666015625\n",
      "Batch 93: loss = 0.6137099266052246, acc = 0.8056640625\n",
      "Batch 94: loss = 0.6452106833457947, acc = 0.7978515625\n",
      "Batch 95: loss = 0.6666836738586426, acc = 0.78125\n",
      "Batch 96: loss = 0.7531088590621948, acc = 0.7666015625\n",
      "Batch 97: loss = 0.7328945398330688, acc = 0.7685546875\n",
      "Batch 98: loss = 0.695159375667572, acc = 0.775390625\n",
      "Batch 99: loss = 0.7196237444877625, acc = 0.7548828125\n",
      "Batch 100: loss = 0.7671650648117065, acc = 0.71484375\n",
      "Batch 101: loss = 0.7073906660079956, acc = 0.767578125\n",
      "Batch 102: loss = 0.8100665211677551, acc = 0.7353515625\n",
      "Batch 103: loss = 0.7234755158424377, acc = 0.7646484375\n",
      "Batch 104: loss = 0.6447123885154724, acc = 0.7890625\n",
      "Batch 105: loss = 0.695530891418457, acc = 0.7724609375\n",
      "Batch 106: loss = 0.7091253995895386, acc = 0.748046875\n",
      "Batch 107: loss = 0.7094189524650574, acc = 0.759765625\n",
      "Batch 108: loss = 0.7280978560447693, acc = 0.7587890625\n",
      "Batch 109: loss = 0.6890573501586914, acc = 0.759765625\n",
      "Batch 110: loss = 0.6761058568954468, acc = 0.7822265625\n",
      "Batch 111: loss = 0.8235896229743958, acc = 0.7177734375\n",
      "Batch 112: loss = 0.7018528580665588, acc = 0.7666015625\n",
      "Batch 113: loss = 0.7351009249687195, acc = 0.7587890625\n",
      "Batch 114: loss = 0.7361102104187012, acc = 0.7578125\n",
      "Batch 115: loss = 0.7456552982330322, acc = 0.7431640625\n",
      "Batch 116: loss = 0.7852271795272827, acc = 0.75390625\n",
      "Batch 117: loss = 0.6650170683860779, acc = 0.791015625\n",
      "Batch 118: loss = 0.6156306862831116, acc = 0.7978515625\n",
      "Batch 119: loss = 0.709459662437439, acc = 0.7763671875\n",
      "Batch 120: loss = 0.7502492666244507, acc = 0.7490234375\n",
      "Batch 121: loss = 0.6987189650535583, acc = 0.7822265625\n",
      "Batch 122: loss = 0.6947158575057983, acc = 0.7646484375\n",
      "Batch 123: loss = 0.6858362555503845, acc = 0.7734375\n",
      "Batch 124: loss = 0.758550226688385, acc = 0.74609375\n",
      "Batch 125: loss = 0.7749361991882324, acc = 0.748046875\n",
      "Batch 126: loss = 0.7782363891601562, acc = 0.74609375\n",
      "\n",
      "Epoch 33/100\n",
      "Batch 1: loss = 0.8699197769165039, acc = 0.734375\n",
      "Batch 2: loss = 0.8277791142463684, acc = 0.72265625\n",
      "Batch 3: loss = 0.758468747138977, acc = 0.7490234375\n",
      "Batch 4: loss = 0.7443069815635681, acc = 0.7666015625\n",
      "Batch 5: loss = 0.7453198432922363, acc = 0.751953125\n",
      "Batch 6: loss = 0.7945581674575806, acc = 0.7412109375\n",
      "Batch 7: loss = 0.7467397451400757, acc = 0.751953125\n",
      "Batch 8: loss = 0.7030442953109741, acc = 0.759765625\n",
      "Batch 9: loss = 0.6940015554428101, acc = 0.7724609375\n",
      "Batch 10: loss = 0.6488480567932129, acc = 0.7880859375\n",
      "Batch 11: loss = 0.7393152713775635, acc = 0.7490234375\n",
      "Batch 12: loss = 0.7230219841003418, acc = 0.751953125\n",
      "Batch 13: loss = 0.6866136193275452, acc = 0.7646484375\n",
      "Batch 14: loss = 0.7161632776260376, acc = 0.7626953125\n",
      "Batch 15: loss = 0.6889334917068481, acc = 0.771484375\n",
      "Batch 16: loss = 0.7517567873001099, acc = 0.7626953125\n",
      "Batch 17: loss = 0.7277570366859436, acc = 0.765625\n",
      "Batch 18: loss = 0.7328411936759949, acc = 0.7744140625\n",
      "Batch 19: loss = 0.676116943359375, acc = 0.7861328125\n",
      "Batch 20: loss = 0.7153677344322205, acc = 0.7666015625\n",
      "Batch 21: loss = 0.7948407530784607, acc = 0.7236328125\n",
      "Batch 22: loss = 0.672329306602478, acc = 0.77734375\n",
      "Batch 23: loss = 0.7044256925582886, acc = 0.751953125\n",
      "Batch 24: loss = 0.6844208836555481, acc = 0.779296875\n",
      "Batch 25: loss = 0.6540657877922058, acc = 0.787109375\n",
      "Batch 26: loss = 0.692182719707489, acc = 0.7587890625\n",
      "Batch 27: loss = 0.8019495010375977, acc = 0.736328125\n",
      "Batch 28: loss = 0.7447885274887085, acc = 0.751953125\n",
      "Batch 29: loss = 0.7200855016708374, acc = 0.7763671875\n",
      "Batch 30: loss = 0.6654585599899292, acc = 0.76953125\n",
      "Batch 31: loss = 0.7507228851318359, acc = 0.7724609375\n",
      "Batch 32: loss = 0.8374205827713013, acc = 0.7314453125\n",
      "Batch 33: loss = 0.6782810688018799, acc = 0.7724609375\n",
      "Batch 34: loss = 0.7359912991523743, acc = 0.748046875\n",
      "Batch 35: loss = 0.7123754024505615, acc = 0.7724609375\n",
      "Batch 36: loss = 0.692161500453949, acc = 0.7685546875\n",
      "Batch 37: loss = 0.6684573888778687, acc = 0.78515625\n",
      "Batch 38: loss = 0.7188400030136108, acc = 0.7734375\n",
      "Batch 39: loss = 0.7193607091903687, acc = 0.755859375\n",
      "Batch 40: loss = 0.7150528430938721, acc = 0.7783203125\n",
      "Batch 41: loss = 0.6230177879333496, acc = 0.7744140625\n",
      "Batch 42: loss = 0.709445059299469, acc = 0.7783203125\n",
      "Batch 43: loss = 0.7325955629348755, acc = 0.7509765625\n",
      "Batch 44: loss = 0.6400049924850464, acc = 0.7919921875\n",
      "Batch 45: loss = 0.6140985488891602, acc = 0.80078125\n",
      "Batch 46: loss = 0.6691979169845581, acc = 0.78125\n",
      "Batch 47: loss = 0.6621467471122742, acc = 0.80078125\n",
      "Batch 48: loss = 0.650309681892395, acc = 0.7783203125\n",
      "Batch 49: loss = 0.5981241464614868, acc = 0.80859375\n",
      "Batch 50: loss = 0.6174038648605347, acc = 0.810546875\n",
      "Batch 51: loss = 0.6394141316413879, acc = 0.76953125\n",
      "Batch 52: loss = 0.7176904678344727, acc = 0.763671875\n",
      "Batch 53: loss = 0.6737076044082642, acc = 0.783203125\n",
      "Batch 54: loss = 0.5600932836532593, acc = 0.822265625\n",
      "Batch 55: loss = 0.6263307332992554, acc = 0.7998046875\n",
      "Batch 56: loss = 0.7012784481048584, acc = 0.7666015625\n",
      "Batch 57: loss = 0.7725908160209656, acc = 0.73046875\n",
      "Batch 58: loss = 0.7725319266319275, acc = 0.7421875\n",
      "Batch 59: loss = 0.5805764198303223, acc = 0.8115234375\n",
      "Batch 60: loss = 0.6750960350036621, acc = 0.7763671875\n",
      "Batch 61: loss = 0.6610596179962158, acc = 0.7939453125\n",
      "Batch 62: loss = 0.8260095119476318, acc = 0.7158203125\n",
      "Batch 63: loss = 0.7717460989952087, acc = 0.7421875\n",
      "Batch 64: loss = 0.5928545594215393, acc = 0.80859375\n",
      "Batch 65: loss = 0.7407110333442688, acc = 0.765625\n",
      "Batch 66: loss = 0.6915718913078308, acc = 0.763671875\n",
      "Batch 67: loss = 0.6250972747802734, acc = 0.7900390625\n",
      "Batch 68: loss = 0.7460741400718689, acc = 0.751953125\n",
      "Batch 69: loss = 0.6568767428398132, acc = 0.7724609375\n",
      "Batch 70: loss = 0.7461944222450256, acc = 0.7490234375\n",
      "Batch 71: loss = 0.742301881313324, acc = 0.748046875\n",
      "Batch 72: loss = 0.6738659143447876, acc = 0.7548828125\n",
      "Batch 73: loss = 0.7407887578010559, acc = 0.765625\n",
      "Batch 74: loss = 0.7404794692993164, acc = 0.75\n",
      "Batch 75: loss = 0.8365527391433716, acc = 0.720703125\n",
      "Batch 76: loss = 0.7453489303588867, acc = 0.7431640625\n",
      "Batch 77: loss = 0.6899108290672302, acc = 0.7822265625\n",
      "Batch 78: loss = 0.7292002439498901, acc = 0.7587890625\n",
      "Batch 79: loss = 0.6579670906066895, acc = 0.76953125\n",
      "Batch 80: loss = 0.6474206447601318, acc = 0.7646484375\n",
      "Batch 81: loss = 0.7224924564361572, acc = 0.7685546875\n",
      "Batch 82: loss = 0.6479920148849487, acc = 0.7919921875\n",
      "Batch 83: loss = 0.6727918386459351, acc = 0.775390625\n",
      "Batch 84: loss = 0.6829335689544678, acc = 0.7734375\n",
      "Batch 85: loss = 0.7824729084968567, acc = 0.71875\n",
      "Batch 86: loss = 0.758434534072876, acc = 0.7451171875\n",
      "Batch 87: loss = 0.6843023300170898, acc = 0.7626953125\n",
      "Batch 88: loss = 0.8268921375274658, acc = 0.7314453125\n",
      "Batch 89: loss = 0.7113606333732605, acc = 0.7861328125\n",
      "Batch 90: loss = 0.749638020992279, acc = 0.7607421875\n",
      "Batch 91: loss = 0.7673039436340332, acc = 0.73828125\n",
      "Batch 92: loss = 0.695380449295044, acc = 0.763671875\n",
      "Batch 93: loss = 0.63114333152771, acc = 0.802734375\n",
      "Batch 94: loss = 0.6487739086151123, acc = 0.8056640625\n",
      "Batch 95: loss = 0.6553294062614441, acc = 0.78515625\n",
      "Batch 96: loss = 0.7416650056838989, acc = 0.751953125\n",
      "Batch 97: loss = 0.7149978876113892, acc = 0.7529296875\n",
      "Batch 98: loss = 0.6805847883224487, acc = 0.7919921875\n",
      "Batch 99: loss = 0.7352989315986633, acc = 0.74609375\n",
      "Batch 100: loss = 0.7495541572570801, acc = 0.73828125\n",
      "Batch 101: loss = 0.6977150440216064, acc = 0.76953125\n",
      "Batch 102: loss = 0.7683798670768738, acc = 0.7470703125\n",
      "Batch 103: loss = 0.7392643690109253, acc = 0.7470703125\n",
      "Batch 104: loss = 0.6330851912498474, acc = 0.78125\n",
      "Batch 105: loss = 0.6735443472862244, acc = 0.783203125\n",
      "Batch 106: loss = 0.7105343341827393, acc = 0.7568359375\n",
      "Batch 107: loss = 0.6681533455848694, acc = 0.77734375\n",
      "Batch 108: loss = 0.7055777311325073, acc = 0.7626953125\n",
      "Batch 109: loss = 0.683414101600647, acc = 0.7685546875\n",
      "Batch 110: loss = 0.6795221567153931, acc = 0.779296875\n",
      "Batch 111: loss = 0.7834223508834839, acc = 0.7236328125\n",
      "Batch 112: loss = 0.7080619931221008, acc = 0.7685546875\n",
      "Batch 113: loss = 0.7304697036743164, acc = 0.7548828125\n",
      "Batch 114: loss = 0.7286555767059326, acc = 0.765625\n",
      "Batch 115: loss = 0.7579866647720337, acc = 0.7509765625\n",
      "Batch 116: loss = 0.7842344045639038, acc = 0.75390625\n",
      "Batch 117: loss = 0.6740416884422302, acc = 0.765625\n",
      "Batch 118: loss = 0.6062023043632507, acc = 0.791015625\n",
      "Batch 119: loss = 0.7165746688842773, acc = 0.775390625\n",
      "Batch 120: loss = 0.7310230135917664, acc = 0.7568359375\n",
      "Batch 121: loss = 0.7052747011184692, acc = 0.7724609375\n",
      "Batch 122: loss = 0.6634650826454163, acc = 0.779296875\n",
      "Batch 123: loss = 0.7006599307060242, acc = 0.7626953125\n",
      "Batch 124: loss = 0.7094924449920654, acc = 0.763671875\n",
      "Batch 125: loss = 0.7750122547149658, acc = 0.763671875\n",
      "Batch 126: loss = 0.7345256209373474, acc = 0.759765625\n",
      "\n",
      "Epoch 34/100\n",
      "Batch 1: loss = 0.8748412132263184, acc = 0.728515625\n",
      "Batch 2: loss = 0.802865743637085, acc = 0.720703125\n",
      "Batch 3: loss = 0.7454235553741455, acc = 0.7587890625\n",
      "Batch 4: loss = 0.6956495046615601, acc = 0.771484375\n",
      "Batch 5: loss = 0.7777601480484009, acc = 0.7451171875\n",
      "Batch 6: loss = 0.770179271697998, acc = 0.7490234375\n",
      "Batch 7: loss = 0.7116808891296387, acc = 0.7646484375\n",
      "Batch 8: loss = 0.6945589184761047, acc = 0.763671875\n",
      "Batch 9: loss = 0.6713767647743225, acc = 0.7685546875\n",
      "Batch 10: loss = 0.6323074102401733, acc = 0.7958984375\n",
      "Batch 11: loss = 0.7429429888725281, acc = 0.7578125\n",
      "Batch 12: loss = 0.6968132257461548, acc = 0.759765625\n",
      "Batch 13: loss = 0.6662455797195435, acc = 0.7802734375\n",
      "Batch 14: loss = 0.681198239326477, acc = 0.7724609375\n",
      "Batch 15: loss = 0.6633260250091553, acc = 0.779296875\n",
      "Batch 16: loss = 0.7571473121643066, acc = 0.7548828125\n",
      "Batch 17: loss = 0.7135359644889832, acc = 0.763671875\n",
      "Batch 18: loss = 0.7412914633750916, acc = 0.751953125\n",
      "Batch 19: loss = 0.6382457613945007, acc = 0.7958984375\n",
      "Batch 20: loss = 0.6779338717460632, acc = 0.7724609375\n",
      "Batch 21: loss = 0.7661746740341187, acc = 0.7333984375\n",
      "Batch 22: loss = 0.6726921796798706, acc = 0.7685546875\n",
      "Batch 23: loss = 0.6890406012535095, acc = 0.75\n",
      "Batch 24: loss = 0.646537184715271, acc = 0.77734375\n",
      "Batch 25: loss = 0.6364022493362427, acc = 0.791015625\n",
      "Batch 26: loss = 0.6529759168624878, acc = 0.791015625\n",
      "Batch 27: loss = 0.7732201814651489, acc = 0.736328125\n",
      "Batch 28: loss = 0.6980828046798706, acc = 0.7734375\n",
      "Batch 29: loss = 0.7137595415115356, acc = 0.7685546875\n",
      "Batch 30: loss = 0.6346346139907837, acc = 0.7939453125\n",
      "Batch 31: loss = 0.7148345708847046, acc = 0.77734375\n",
      "Batch 32: loss = 0.8062372207641602, acc = 0.740234375\n",
      "Batch 33: loss = 0.6785436272621155, acc = 0.76953125\n",
      "Batch 34: loss = 0.7025165557861328, acc = 0.76171875\n",
      "Batch 35: loss = 0.6940755844116211, acc = 0.765625\n",
      "Batch 36: loss = 0.6551802158355713, acc = 0.7880859375\n",
      "Batch 37: loss = 0.6510809659957886, acc = 0.7919921875\n",
      "Batch 38: loss = 0.7380638718605042, acc = 0.7548828125\n",
      "Batch 39: loss = 0.7048665285110474, acc = 0.759765625\n",
      "Batch 40: loss = 0.7177790403366089, acc = 0.765625\n",
      "Batch 41: loss = 0.6300921440124512, acc = 0.794921875\n",
      "Batch 42: loss = 0.6583535671234131, acc = 0.78125\n",
      "Batch 43: loss = 0.6789891719818115, acc = 0.7724609375\n",
      "Batch 44: loss = 0.6323122382164001, acc = 0.8017578125\n",
      "Batch 45: loss = 0.5851654410362244, acc = 0.8037109375\n",
      "Batch 46: loss = 0.6630842685699463, acc = 0.775390625\n",
      "Batch 47: loss = 0.6546674966812134, acc = 0.7861328125\n",
      "Batch 48: loss = 0.6418101787567139, acc = 0.787109375\n",
      "Batch 49: loss = 0.6227269172668457, acc = 0.798828125\n",
      "Batch 50: loss = 0.6156123280525208, acc = 0.796875\n",
      "Batch 51: loss = 0.6303216218948364, acc = 0.79296875\n",
      "Batch 52: loss = 0.704485297203064, acc = 0.76953125\n",
      "Batch 53: loss = 0.665867030620575, acc = 0.78515625\n",
      "Batch 54: loss = 0.5947140455245972, acc = 0.8134765625\n",
      "Batch 55: loss = 0.6059856414794922, acc = 0.7998046875\n",
      "Batch 56: loss = 0.6774499416351318, acc = 0.76171875\n",
      "Batch 57: loss = 0.7578423023223877, acc = 0.7412109375\n",
      "Batch 58: loss = 0.7534498572349548, acc = 0.7451171875\n",
      "Batch 59: loss = 0.5573886036872864, acc = 0.8271484375\n",
      "Batch 60: loss = 0.6792325973510742, acc = 0.7724609375\n",
      "Batch 61: loss = 0.6381716728210449, acc = 0.7978515625\n",
      "Batch 62: loss = 0.8394002914428711, acc = 0.7177734375\n",
      "Batch 63: loss = 0.7648731470108032, acc = 0.748046875\n",
      "Batch 64: loss = 0.5860775709152222, acc = 0.8017578125\n",
      "Batch 65: loss = 0.70199054479599, acc = 0.7685546875\n",
      "Batch 66: loss = 0.6794055700302124, acc = 0.771484375\n",
      "Batch 67: loss = 0.6370338201522827, acc = 0.791015625\n",
      "Batch 68: loss = 0.711340069770813, acc = 0.7626953125\n",
      "Batch 69: loss = 0.6315315365791321, acc = 0.8017578125\n",
      "Batch 70: loss = 0.723021388053894, acc = 0.7587890625\n",
      "Batch 71: loss = 0.7015438079833984, acc = 0.7646484375\n",
      "Batch 72: loss = 0.6343628168106079, acc = 0.787109375\n",
      "Batch 73: loss = 0.7360635995864868, acc = 0.7626953125\n",
      "Batch 74: loss = 0.7181276082992554, acc = 0.75\n",
      "Batch 75: loss = 0.7731258869171143, acc = 0.7412109375\n",
      "Batch 76: loss = 0.7323839664459229, acc = 0.748046875\n",
      "Batch 77: loss = 0.6829789876937866, acc = 0.779296875\n",
      "Batch 78: loss = 0.6978113651275635, acc = 0.7666015625\n",
      "Batch 79: loss = 0.6303099393844604, acc = 0.7802734375\n",
      "Batch 80: loss = 0.6546322107315063, acc = 0.7734375\n",
      "Batch 81: loss = 0.6947927474975586, acc = 0.7763671875\n",
      "Batch 82: loss = 0.6277644634246826, acc = 0.791015625\n",
      "Batch 83: loss = 0.66375732421875, acc = 0.783203125\n",
      "Batch 84: loss = 0.6719399094581604, acc = 0.765625\n",
      "Batch 85: loss = 0.7571039199829102, acc = 0.7412109375\n",
      "Batch 86: loss = 0.7178060412406921, acc = 0.7802734375\n",
      "Batch 87: loss = 0.662266731262207, acc = 0.7744140625\n",
      "Batch 88: loss = 0.8142237067222595, acc = 0.7431640625\n",
      "Batch 89: loss = 0.6985816359519958, acc = 0.7783203125\n",
      "Batch 90: loss = 0.7240188717842102, acc = 0.7548828125\n",
      "Batch 91: loss = 0.7288683652877808, acc = 0.75390625\n",
      "Batch 92: loss = 0.706684947013855, acc = 0.7587890625\n",
      "Batch 93: loss = 0.6080335378646851, acc = 0.802734375\n",
      "Batch 94: loss = 0.6425118446350098, acc = 0.7919921875\n",
      "Batch 95: loss = 0.6408120393753052, acc = 0.791015625\n",
      "Batch 96: loss = 0.7362022399902344, acc = 0.755859375\n",
      "Batch 97: loss = 0.6968933343887329, acc = 0.7783203125\n",
      "Batch 98: loss = 0.6663409471511841, acc = 0.7841796875\n",
      "Batch 99: loss = 0.6938003301620483, acc = 0.7646484375\n",
      "Batch 100: loss = 0.6935915946960449, acc = 0.7490234375\n",
      "Batch 101: loss = 0.6880237460136414, acc = 0.78125\n",
      "Batch 102: loss = 0.7473418712615967, acc = 0.7490234375\n",
      "Batch 103: loss = 0.7002286911010742, acc = 0.7587890625\n",
      "Batch 104: loss = 0.6332558393478394, acc = 0.7880859375\n",
      "Batch 105: loss = 0.6464780569076538, acc = 0.78125\n",
      "Batch 106: loss = 0.7188713550567627, acc = 0.751953125\n",
      "Batch 107: loss = 0.6891671419143677, acc = 0.779296875\n",
      "Batch 108: loss = 0.6790422201156616, acc = 0.7607421875\n",
      "Batch 109: loss = 0.6899224519729614, acc = 0.7685546875\n",
      "Batch 110: loss = 0.63116455078125, acc = 0.8046875\n",
      "Batch 111: loss = 0.7644513845443726, acc = 0.7490234375\n",
      "Batch 112: loss = 0.6717528700828552, acc = 0.7802734375\n",
      "Batch 113: loss = 0.7125613689422607, acc = 0.759765625\n",
      "Batch 114: loss = 0.7162255048751831, acc = 0.7734375\n",
      "Batch 115: loss = 0.7204002737998962, acc = 0.7705078125\n",
      "Batch 116: loss = 0.7731399536132812, acc = 0.76171875\n",
      "Batch 117: loss = 0.6342469453811646, acc = 0.787109375\n",
      "Batch 118: loss = 0.564992368221283, acc = 0.818359375\n",
      "Batch 119: loss = 0.6882948279380798, acc = 0.7783203125\n",
      "Batch 120: loss = 0.6940362453460693, acc = 0.7685546875\n",
      "Batch 121: loss = 0.6945590972900391, acc = 0.779296875\n",
      "Batch 122: loss = 0.6529957056045532, acc = 0.7880859375\n",
      "Batch 123: loss = 0.70770263671875, acc = 0.7734375\n",
      "Batch 124: loss = 0.7277257442474365, acc = 0.7548828125\n",
      "Batch 125: loss = 0.7597085237503052, acc = 0.763671875\n",
      "Batch 126: loss = 0.710411548614502, acc = 0.767578125\n",
      "\n",
      "Epoch 35/100\n",
      "Batch 1: loss = 0.8494230508804321, acc = 0.7353515625\n",
      "Batch 2: loss = 0.775138258934021, acc = 0.7392578125\n",
      "Batch 3: loss = 0.708024799823761, acc = 0.763671875\n",
      "Batch 4: loss = 0.679947018623352, acc = 0.7802734375\n",
      "Batch 5: loss = 0.7487812042236328, acc = 0.76171875\n",
      "Batch 6: loss = 0.736508846282959, acc = 0.75\n",
      "Batch 7: loss = 0.6940089464187622, acc = 0.76171875\n",
      "Batch 8: loss = 0.6937435865402222, acc = 0.7587890625\n",
      "Batch 9: loss = 0.6715619564056396, acc = 0.7783203125\n",
      "Batch 10: loss = 0.6023304462432861, acc = 0.794921875\n",
      "Batch 11: loss = 0.6988462209701538, acc = 0.7646484375\n",
      "Batch 12: loss = 0.7029616236686707, acc = 0.7607421875\n",
      "Batch 13: loss = 0.666395366191864, acc = 0.7880859375\n",
      "Batch 14: loss = 0.6775885820388794, acc = 0.78125\n",
      "Batch 15: loss = 0.6576774716377258, acc = 0.7763671875\n",
      "Batch 16: loss = 0.6938349604606628, acc = 0.763671875\n",
      "Batch 17: loss = 0.7049233913421631, acc = 0.7705078125\n",
      "Batch 18: loss = 0.7405858635902405, acc = 0.7685546875\n",
      "Batch 19: loss = 0.6549777388572693, acc = 0.7734375\n",
      "Batch 20: loss = 0.6724410653114319, acc = 0.78125\n",
      "Batch 21: loss = 0.7298088669776917, acc = 0.75\n",
      "Batch 22: loss = 0.684735119342804, acc = 0.7763671875\n",
      "Batch 23: loss = 0.6723203659057617, acc = 0.7666015625\n",
      "Batch 24: loss = 0.6600606441497803, acc = 0.7685546875\n",
      "Batch 25: loss = 0.6184237003326416, acc = 0.7880859375\n",
      "Batch 26: loss = 0.6385689973831177, acc = 0.7978515625\n",
      "Batch 27: loss = 0.7834293246269226, acc = 0.7431640625\n",
      "Batch 28: loss = 0.7033219337463379, acc = 0.75390625\n",
      "Batch 29: loss = 0.6932337284088135, acc = 0.771484375\n",
      "Batch 30: loss = 0.6342649459838867, acc = 0.779296875\n",
      "Batch 31: loss = 0.6818119287490845, acc = 0.7783203125\n",
      "Batch 32: loss = 0.797666072845459, acc = 0.73828125\n",
      "Batch 33: loss = 0.6560418605804443, acc = 0.771484375\n",
      "Batch 34: loss = 0.712360143661499, acc = 0.7646484375\n",
      "Batch 35: loss = 0.6852661371231079, acc = 0.77734375\n",
      "Batch 36: loss = 0.641097903251648, acc = 0.787109375\n",
      "Batch 37: loss = 0.6191104650497437, acc = 0.806640625\n",
      "Batch 38: loss = 0.6866968870162964, acc = 0.783203125\n",
      "Batch 39: loss = 0.6836884617805481, acc = 0.7783203125\n",
      "Batch 40: loss = 0.6826680302619934, acc = 0.7822265625\n",
      "Batch 41: loss = 0.6070829629898071, acc = 0.783203125\n",
      "Batch 42: loss = 0.6232184767723083, acc = 0.7802734375\n",
      "Batch 43: loss = 0.7271534204483032, acc = 0.755859375\n",
      "Batch 44: loss = 0.6266176700592041, acc = 0.79296875\n",
      "Batch 45: loss = 0.594355583190918, acc = 0.7958984375\n",
      "Batch 46: loss = 0.6383734941482544, acc = 0.791015625\n",
      "Batch 47: loss = 0.6451610326766968, acc = 0.7919921875\n",
      "Batch 48: loss = 0.6176009774208069, acc = 0.7958984375\n",
      "Batch 49: loss = 0.5745875239372253, acc = 0.8037109375\n",
      "Batch 50: loss = 0.5998048186302185, acc = 0.8134765625\n",
      "Batch 51: loss = 0.6191197037696838, acc = 0.78125\n",
      "Batch 52: loss = 0.684971809387207, acc = 0.7724609375\n",
      "Batch 53: loss = 0.6685106158256531, acc = 0.7958984375\n",
      "Batch 54: loss = 0.5591491460800171, acc = 0.814453125\n",
      "Batch 55: loss = 0.5838954448699951, acc = 0.818359375\n",
      "Batch 56: loss = 0.6558315753936768, acc = 0.771484375\n",
      "Batch 57: loss = 0.7254691123962402, acc = 0.751953125\n",
      "Batch 58: loss = 0.742436408996582, acc = 0.75390625\n",
      "Batch 59: loss = 0.565243124961853, acc = 0.8232421875\n",
      "Batch 60: loss = 0.6394202709197998, acc = 0.7822265625\n",
      "Batch 61: loss = 0.6577311158180237, acc = 0.7890625\n",
      "Batch 62: loss = 0.7616921663284302, acc = 0.73828125\n",
      "Batch 63: loss = 0.7457279562950134, acc = 0.759765625\n",
      "Batch 64: loss = 0.5829823613166809, acc = 0.8212890625\n",
      "Batch 65: loss = 0.6941116452217102, acc = 0.767578125\n",
      "Batch 66: loss = 0.6822969913482666, acc = 0.7919921875\n",
      "Batch 67: loss = 0.6333054304122925, acc = 0.7939453125\n",
      "Batch 68: loss = 0.6906759142875671, acc = 0.7626953125\n",
      "Batch 69: loss = 0.6233549118041992, acc = 0.7939453125\n",
      "Batch 70: loss = 0.7130489349365234, acc = 0.7568359375\n",
      "Batch 71: loss = 0.694754958152771, acc = 0.7734375\n",
      "Batch 72: loss = 0.617364227771759, acc = 0.79296875\n",
      "Batch 73: loss = 0.7150353193283081, acc = 0.751953125\n",
      "Batch 74: loss = 0.7143193483352661, acc = 0.7470703125\n",
      "Batch 75: loss = 0.7754184603691101, acc = 0.732421875\n",
      "Batch 76: loss = 0.729081392288208, acc = 0.7529296875\n",
      "Batch 77: loss = 0.6771526336669922, acc = 0.7880859375\n",
      "Batch 78: loss = 0.661853551864624, acc = 0.76953125\n",
      "Batch 79: loss = 0.6058744192123413, acc = 0.7978515625\n",
      "Batch 80: loss = 0.5938133597373962, acc = 0.794921875\n",
      "Batch 81: loss = 0.7077492475509644, acc = 0.7705078125\n",
      "Batch 82: loss = 0.6019690036773682, acc = 0.814453125\n",
      "Batch 83: loss = 0.6475808620452881, acc = 0.79296875\n",
      "Batch 84: loss = 0.6545964479446411, acc = 0.775390625\n",
      "Batch 85: loss = 0.7470589876174927, acc = 0.75390625\n",
      "Batch 86: loss = 0.692628800868988, acc = 0.783203125\n",
      "Batch 87: loss = 0.6609137058258057, acc = 0.779296875\n",
      "Batch 88: loss = 0.7723541259765625, acc = 0.7587890625\n",
      "Batch 89: loss = 0.6938486695289612, acc = 0.779296875\n",
      "Batch 90: loss = 0.7267583608627319, acc = 0.7509765625\n",
      "Batch 91: loss = 0.7170472145080566, acc = 0.7734375\n",
      "Batch 92: loss = 0.6833630204200745, acc = 0.7861328125\n",
      "Batch 93: loss = 0.6024721264839172, acc = 0.8095703125\n",
      "Batch 94: loss = 0.619361162185669, acc = 0.8017578125\n",
      "Batch 95: loss = 0.6550885438919067, acc = 0.79296875\n",
      "Batch 96: loss = 0.7050799131393433, acc = 0.7646484375\n",
      "Batch 97: loss = 0.6998302936553955, acc = 0.77734375\n",
      "Batch 98: loss = 0.6516134738922119, acc = 0.794921875\n",
      "Batch 99: loss = 0.6850650906562805, acc = 0.771484375\n",
      "Batch 100: loss = 0.6978224515914917, acc = 0.7607421875\n",
      "Batch 101: loss = 0.6738764643669128, acc = 0.791015625\n",
      "Batch 102: loss = 0.762032151222229, acc = 0.7548828125\n",
      "Batch 103: loss = 0.679049551486969, acc = 0.775390625\n",
      "Batch 104: loss = 0.6199035048484802, acc = 0.7802734375\n",
      "Batch 105: loss = 0.6229938864707947, acc = 0.7861328125\n",
      "Batch 106: loss = 0.6918704509735107, acc = 0.7607421875\n",
      "Batch 107: loss = 0.6530033349990845, acc = 0.7763671875\n",
      "Batch 108: loss = 0.6601210832595825, acc = 0.794921875\n",
      "Batch 109: loss = 0.6271647810935974, acc = 0.791015625\n",
      "Batch 110: loss = 0.5958305597305298, acc = 0.8134765625\n",
      "Batch 111: loss = 0.7746404409408569, acc = 0.7392578125\n",
      "Batch 112: loss = 0.6809123158454895, acc = 0.7783203125\n",
      "Batch 113: loss = 0.7302225828170776, acc = 0.7724609375\n",
      "Batch 114: loss = 0.7100238800048828, acc = 0.7705078125\n",
      "Batch 115: loss = 0.7012940645217896, acc = 0.7734375\n",
      "Batch 116: loss = 0.751433253288269, acc = 0.7578125\n",
      "Batch 117: loss = 0.6256563663482666, acc = 0.787109375\n",
      "Batch 118: loss = 0.5679407119750977, acc = 0.806640625\n",
      "Batch 119: loss = 0.7004594802856445, acc = 0.7646484375\n",
      "Batch 120: loss = 0.669508695602417, acc = 0.7890625\n",
      "Batch 121: loss = 0.6840072870254517, acc = 0.775390625\n",
      "Batch 122: loss = 0.6295382976531982, acc = 0.7958984375\n",
      "Batch 123: loss = 0.6715538501739502, acc = 0.7861328125\n",
      "Batch 124: loss = 0.6905438899993896, acc = 0.7734375\n",
      "Batch 125: loss = 0.7208946943283081, acc = 0.767578125\n",
      "Batch 126: loss = 0.7458288669586182, acc = 0.7509765625\n",
      "\n",
      "Epoch 36/100\n",
      "Batch 1: loss = 0.8366090655326843, acc = 0.7314453125\n",
      "Batch 2: loss = 0.74861741065979, acc = 0.7412109375\n",
      "Batch 3: loss = 0.711344838142395, acc = 0.775390625\n",
      "Batch 4: loss = 0.6872045993804932, acc = 0.7890625\n",
      "Batch 5: loss = 0.7325502038002014, acc = 0.7607421875\n",
      "Batch 6: loss = 0.7484010457992554, acc = 0.7607421875\n",
      "Batch 7: loss = 0.6877820491790771, acc = 0.76953125\n",
      "Batch 8: loss = 0.6690009832382202, acc = 0.76953125\n",
      "Batch 9: loss = 0.6245230436325073, acc = 0.80078125\n",
      "Batch 10: loss = 0.6210071444511414, acc = 0.794921875\n",
      "Batch 11: loss = 0.6758609414100647, acc = 0.7685546875\n",
      "Batch 12: loss = 0.6700644493103027, acc = 0.7724609375\n",
      "Batch 13: loss = 0.6342250108718872, acc = 0.7802734375\n",
      "Batch 14: loss = 0.6658406853675842, acc = 0.787109375\n",
      "Batch 15: loss = 0.6384082436561584, acc = 0.796875\n",
      "Batch 16: loss = 0.7177199125289917, acc = 0.775390625\n",
      "Batch 17: loss = 0.7038644552230835, acc = 0.7734375\n",
      "Batch 18: loss = 0.6909098625183105, acc = 0.7783203125\n",
      "Batch 19: loss = 0.6270495653152466, acc = 0.7958984375\n",
      "Batch 20: loss = 0.6509833335876465, acc = 0.7783203125\n",
      "Batch 21: loss = 0.7134717702865601, acc = 0.7578125\n",
      "Batch 22: loss = 0.6620946526527405, acc = 0.765625\n",
      "Batch 23: loss = 0.6533966660499573, acc = 0.7763671875\n",
      "Batch 24: loss = 0.6590300798416138, acc = 0.7783203125\n",
      "Batch 25: loss = 0.6426453590393066, acc = 0.791015625\n",
      "Batch 26: loss = 0.6266362071037292, acc = 0.7890625\n",
      "Batch 27: loss = 0.7540386915206909, acc = 0.748046875\n",
      "Batch 28: loss = 0.724679172039032, acc = 0.7529296875\n",
      "Batch 29: loss = 0.7056522965431213, acc = 0.767578125\n",
      "Batch 30: loss = 0.6312928199768066, acc = 0.7890625\n",
      "Batch 31: loss = 0.7065747976303101, acc = 0.7529296875\n",
      "Batch 32: loss = 0.787155032157898, acc = 0.7451171875\n",
      "Batch 33: loss = 0.6464115381240845, acc = 0.7939453125\n",
      "Batch 34: loss = 0.6967186331748962, acc = 0.7607421875\n",
      "Batch 35: loss = 0.6713422536849976, acc = 0.787109375\n",
      "Batch 36: loss = 0.6245267987251282, acc = 0.798828125\n",
      "Batch 37: loss = 0.6079758405685425, acc = 0.8037109375\n",
      "Batch 38: loss = 0.6794446706771851, acc = 0.7724609375\n",
      "Batch 39: loss = 0.6708597540855408, acc = 0.7763671875\n",
      "Batch 40: loss = 0.6862648129463196, acc = 0.7822265625\n",
      "Batch 41: loss = 0.6036609411239624, acc = 0.7919921875\n",
      "Batch 42: loss = 0.6244229674339294, acc = 0.7919921875\n",
      "Batch 43: loss = 0.6977012157440186, acc = 0.7685546875\n",
      "Batch 44: loss = 0.5968838334083557, acc = 0.806640625\n",
      "Batch 45: loss = 0.5928390622138977, acc = 0.794921875\n",
      "Batch 46: loss = 0.6280406713485718, acc = 0.7822265625\n",
      "Batch 47: loss = 0.6466296911239624, acc = 0.7900390625\n",
      "Batch 48: loss = 0.6244018077850342, acc = 0.7880859375\n",
      "Batch 49: loss = 0.5916070938110352, acc = 0.80078125\n",
      "Batch 50: loss = 0.6094387769699097, acc = 0.80859375\n",
      "Batch 51: loss = 0.6009213328361511, acc = 0.78515625\n",
      "Batch 52: loss = 0.6591411828994751, acc = 0.7685546875\n",
      "Batch 53: loss = 0.6363668441772461, acc = 0.7958984375\n",
      "Batch 54: loss = 0.5499163866043091, acc = 0.8251953125\n",
      "Batch 55: loss = 0.5802726745605469, acc = 0.81640625\n",
      "Batch 56: loss = 0.6336115002632141, acc = 0.7822265625\n",
      "Batch 57: loss = 0.6902799606323242, acc = 0.7734375\n",
      "Batch 58: loss = 0.726688802242279, acc = 0.7470703125\n",
      "Batch 59: loss = 0.533094048500061, acc = 0.8271484375\n",
      "Batch 60: loss = 0.6674298048019409, acc = 0.7783203125\n",
      "Batch 61: loss = 0.6136932373046875, acc = 0.7978515625\n",
      "Batch 62: loss = 0.7481480240821838, acc = 0.7529296875\n",
      "Batch 63: loss = 0.7342387437820435, acc = 0.755859375\n",
      "Batch 64: loss = 0.5992782115936279, acc = 0.794921875\n",
      "Batch 65: loss = 0.689734935760498, acc = 0.7705078125\n",
      "Batch 66: loss = 0.6827068328857422, acc = 0.7802734375\n",
      "Batch 67: loss = 0.6005953550338745, acc = 0.8017578125\n",
      "Batch 68: loss = 0.680972158908844, acc = 0.7802734375\n",
      "Batch 69: loss = 0.6092692017555237, acc = 0.798828125\n",
      "Batch 70: loss = 0.6847535967826843, acc = 0.759765625\n",
      "Batch 71: loss = 0.6728857755661011, acc = 0.7685546875\n",
      "Batch 72: loss = 0.618877112865448, acc = 0.79296875\n",
      "Batch 73: loss = 0.7235817909240723, acc = 0.759765625\n",
      "Batch 74: loss = 0.7191050052642822, acc = 0.7578125\n",
      "Batch 75: loss = 0.7737342119216919, acc = 0.748046875\n",
      "Batch 76: loss = 0.6960723400115967, acc = 0.7734375\n",
      "Batch 77: loss = 0.6659480333328247, acc = 0.78125\n",
      "Batch 78: loss = 0.7004967331886292, acc = 0.7646484375\n",
      "Batch 79: loss = 0.5989159345626831, acc = 0.80078125\n",
      "Batch 80: loss = 0.6084206700325012, acc = 0.78515625\n",
      "Batch 81: loss = 0.6772792339324951, acc = 0.7763671875\n",
      "Batch 82: loss = 0.6064874529838562, acc = 0.7998046875\n",
      "Batch 83: loss = 0.6374011039733887, acc = 0.7890625\n",
      "Batch 84: loss = 0.653262734413147, acc = 0.7861328125\n",
      "Batch 85: loss = 0.753969669342041, acc = 0.74609375\n",
      "Batch 86: loss = 0.6784900426864624, acc = 0.7744140625\n",
      "Batch 87: loss = 0.6402329206466675, acc = 0.7744140625\n",
      "Batch 88: loss = 0.8005077838897705, acc = 0.7353515625\n",
      "Batch 89: loss = 0.6834006309509277, acc = 0.783203125\n",
      "Batch 90: loss = 0.7064407467842102, acc = 0.7548828125\n",
      "Batch 91: loss = 0.7241894006729126, acc = 0.7626953125\n",
      "Batch 92: loss = 0.6733041405677795, acc = 0.7607421875\n",
      "Batch 93: loss = 0.5566328763961792, acc = 0.818359375\n",
      "Batch 94: loss = 0.6192950010299683, acc = 0.78515625\n",
      "Batch 95: loss = 0.6435782313346863, acc = 0.787109375\n",
      "Batch 96: loss = 0.6981090307235718, acc = 0.767578125\n",
      "Batch 97: loss = 0.6626178622245789, acc = 0.7900390625\n",
      "Batch 98: loss = 0.6350963711738586, acc = 0.7919921875\n",
      "Batch 99: loss = 0.668973445892334, acc = 0.7724609375\n",
      "Batch 100: loss = 0.6947470903396606, acc = 0.765625\n",
      "Batch 101: loss = 0.6462969779968262, acc = 0.7900390625\n",
      "Batch 102: loss = 0.7361963987350464, acc = 0.7568359375\n",
      "Batch 103: loss = 0.6633203029632568, acc = 0.791015625\n",
      "Batch 104: loss = 0.6046173572540283, acc = 0.798828125\n",
      "Batch 105: loss = 0.6384261846542358, acc = 0.7890625\n",
      "Batch 106: loss = 0.674676775932312, acc = 0.7646484375\n",
      "Batch 107: loss = 0.6450433731079102, acc = 0.787109375\n",
      "Batch 108: loss = 0.6496094465255737, acc = 0.7919921875\n",
      "Batch 109: loss = 0.6725980043411255, acc = 0.7685546875\n",
      "Batch 110: loss = 0.5803842544555664, acc = 0.8125\n",
      "Batch 111: loss = 0.7233366370201111, acc = 0.7529296875\n",
      "Batch 112: loss = 0.6782693862915039, acc = 0.779296875\n",
      "Batch 113: loss = 0.6976879835128784, acc = 0.763671875\n",
      "Batch 114: loss = 0.6773295402526855, acc = 0.7783203125\n",
      "Batch 115: loss = 0.6934524178504944, acc = 0.767578125\n",
      "Batch 116: loss = 0.7398657202720642, acc = 0.7607421875\n",
      "Batch 117: loss = 0.6043999195098877, acc = 0.7978515625\n",
      "Batch 118: loss = 0.5553989410400391, acc = 0.8095703125\n",
      "Batch 119: loss = 0.6756248474121094, acc = 0.78125\n",
      "Batch 120: loss = 0.6496589183807373, acc = 0.7802734375\n",
      "Batch 121: loss = 0.6737500429153442, acc = 0.783203125\n",
      "Batch 122: loss = 0.606740415096283, acc = 0.7978515625\n",
      "Batch 123: loss = 0.6652006506919861, acc = 0.779296875\n",
      "Batch 124: loss = 0.7017949819564819, acc = 0.7607421875\n",
      "Batch 125: loss = 0.7011399269104004, acc = 0.7744140625\n",
      "Batch 126: loss = 0.7093909978866577, acc = 0.7685546875\n",
      "\n",
      "Epoch 37/100\n",
      "Batch 1: loss = 0.7987662553787231, acc = 0.744140625\n",
      "Batch 2: loss = 0.7096871137619019, acc = 0.7685546875\n",
      "Batch 3: loss = 0.676720142364502, acc = 0.779296875\n",
      "Batch 4: loss = 0.6701734066009521, acc = 0.7734375\n",
      "Batch 5: loss = 0.7378535866737366, acc = 0.765625\n",
      "Batch 6: loss = 0.754337728023529, acc = 0.7509765625\n",
      "Batch 7: loss = 0.6489622592926025, acc = 0.791015625\n",
      "Batch 8: loss = 0.6729996800422668, acc = 0.775390625\n",
      "Batch 9: loss = 0.6377063393592834, acc = 0.7958984375\n",
      "Batch 10: loss = 0.5888149738311768, acc = 0.80078125\n",
      "Batch 11: loss = 0.6752693057060242, acc = 0.7802734375\n",
      "Batch 12: loss = 0.6416245698928833, acc = 0.7783203125\n",
      "Batch 13: loss = 0.6145050525665283, acc = 0.79296875\n",
      "Batch 14: loss = 0.6572655439376831, acc = 0.7919921875\n",
      "Batch 15: loss = 0.6175762414932251, acc = 0.7890625\n",
      "Batch 16: loss = 0.7153736352920532, acc = 0.7646484375\n",
      "Batch 17: loss = 0.6669951677322388, acc = 0.7783203125\n",
      "Batch 18: loss = 0.7177062034606934, acc = 0.76953125\n",
      "Batch 19: loss = 0.6070354580879211, acc = 0.7978515625\n",
      "Batch 20: loss = 0.6152361631393433, acc = 0.7919921875\n",
      "Batch 21: loss = 0.6927735209465027, acc = 0.7666015625\n",
      "Batch 22: loss = 0.6475409269332886, acc = 0.78125\n",
      "Batch 23: loss = 0.63139808177948, acc = 0.7744140625\n",
      "Batch 24: loss = 0.6350911855697632, acc = 0.7841796875\n",
      "Batch 25: loss = 0.6199229955673218, acc = 0.7978515625\n",
      "Batch 26: loss = 0.6521422266960144, acc = 0.794921875\n",
      "Batch 27: loss = 0.7462730407714844, acc = 0.7509765625\n",
      "Batch 28: loss = 0.7215405702590942, acc = 0.7626953125\n",
      "Batch 29: loss = 0.6827499866485596, acc = 0.775390625\n",
      "Batch 30: loss = 0.6168204545974731, acc = 0.7958984375\n",
      "Batch 31: loss = 0.6661980748176575, acc = 0.7880859375\n",
      "Batch 32: loss = 0.7695869207382202, acc = 0.7626953125\n",
      "Batch 33: loss = 0.6337864398956299, acc = 0.794921875\n",
      "Batch 34: loss = 0.669884204864502, acc = 0.779296875\n",
      "Batch 35: loss = 0.6406742334365845, acc = 0.7998046875\n",
      "Batch 36: loss = 0.6450085639953613, acc = 0.806640625\n",
      "Batch 37: loss = 0.6063834428787231, acc = 0.7978515625\n",
      "Batch 38: loss = 0.6570593118667603, acc = 0.7744140625\n",
      "Batch 39: loss = 0.6592961549758911, acc = 0.78515625\n",
      "Batch 40: loss = 0.6671453714370728, acc = 0.779296875\n",
      "Batch 41: loss = 0.5986825227737427, acc = 0.7978515625\n",
      "Batch 42: loss = 0.6224724054336548, acc = 0.794921875\n",
      "Batch 43: loss = 0.6757434010505676, acc = 0.7744140625\n",
      "Batch 44: loss = 0.5658532381057739, acc = 0.8115234375\n",
      "Batch 45: loss = 0.5583421587944031, acc = 0.8212890625\n",
      "Batch 46: loss = 0.6088094711303711, acc = 0.7919921875\n",
      "Batch 47: loss = 0.6225753426551819, acc = 0.7958984375\n",
      "Batch 48: loss = 0.5811013579368591, acc = 0.8095703125\n",
      "Batch 49: loss = 0.5821225643157959, acc = 0.8173828125\n",
      "Batch 50: loss = 0.612740695476532, acc = 0.791015625\n",
      "Batch 51: loss = 0.5951148271560669, acc = 0.7744140625\n",
      "Batch 52: loss = 0.6517294645309448, acc = 0.783203125\n",
      "Batch 53: loss = 0.6117575168609619, acc = 0.7919921875\n",
      "Batch 54: loss = 0.5070438385009766, acc = 0.8408203125\n",
      "Batch 55: loss = 0.5659980177879333, acc = 0.8134765625\n",
      "Batch 56: loss = 0.6297104358673096, acc = 0.7890625\n",
      "Batch 57: loss = 0.7110748887062073, acc = 0.765625\n",
      "Batch 58: loss = 0.7036092281341553, acc = 0.767578125\n",
      "Batch 59: loss = 0.5385109186172485, acc = 0.81640625\n",
      "Batch 60: loss = 0.6260010004043579, acc = 0.7802734375\n",
      "Batch 61: loss = 0.6266974806785583, acc = 0.814453125\n",
      "Batch 62: loss = 0.7493932247161865, acc = 0.7412109375\n",
      "Batch 63: loss = 0.7003751993179321, acc = 0.771484375\n",
      "Batch 64: loss = 0.5611010789871216, acc = 0.8173828125\n",
      "Batch 65: loss = 0.6539907455444336, acc = 0.7802734375\n",
      "Batch 66: loss = 0.6458512544631958, acc = 0.79296875\n",
      "Batch 67: loss = 0.5988081693649292, acc = 0.7919921875\n",
      "Batch 68: loss = 0.6914258003234863, acc = 0.7783203125\n",
      "Batch 69: loss = 0.5849720239639282, acc = 0.81640625\n",
      "Batch 70: loss = 0.7063382267951965, acc = 0.759765625\n",
      "Batch 71: loss = 0.6863678693771362, acc = 0.7783203125\n",
      "Batch 72: loss = 0.6034094095230103, acc = 0.791015625\n",
      "Batch 73: loss = 0.6963139772415161, acc = 0.76171875\n",
      "Batch 74: loss = 0.6804232597351074, acc = 0.7744140625\n",
      "Batch 75: loss = 0.7859159708023071, acc = 0.7353515625\n",
      "Batch 76: loss = 0.6813123226165771, acc = 0.7763671875\n",
      "Batch 77: loss = 0.6250185966491699, acc = 0.8037109375\n",
      "Batch 78: loss = 0.6473214626312256, acc = 0.783203125\n",
      "Batch 79: loss = 0.5899069309234619, acc = 0.8017578125\n",
      "Batch 80: loss = 0.6392489671707153, acc = 0.755859375\n",
      "Batch 81: loss = 0.659540593624115, acc = 0.7880859375\n",
      "Batch 82: loss = 0.5967531800270081, acc = 0.80078125\n",
      "Batch 83: loss = 0.6488634347915649, acc = 0.779296875\n",
      "Batch 84: loss = 0.6234435439109802, acc = 0.7919921875\n",
      "Batch 85: loss = 0.7129117250442505, acc = 0.7490234375\n",
      "Batch 86: loss = 0.69426429271698, acc = 0.7724609375\n",
      "Batch 87: loss = 0.6478826999664307, acc = 0.7783203125\n",
      "Batch 88: loss = 0.7697886228561401, acc = 0.75390625\n",
      "Batch 89: loss = 0.6612346172332764, acc = 0.7763671875\n",
      "Batch 90: loss = 0.6933822631835938, acc = 0.7666015625\n",
      "Batch 91: loss = 0.700503945350647, acc = 0.7578125\n",
      "Batch 92: loss = 0.6465643644332886, acc = 0.794921875\n",
      "Batch 93: loss = 0.5769046545028687, acc = 0.8173828125\n",
      "Batch 94: loss = 0.6230967044830322, acc = 0.802734375\n",
      "Batch 95: loss = 0.6189851760864258, acc = 0.7978515625\n",
      "Batch 96: loss = 0.7076253890991211, acc = 0.7607421875\n",
      "Batch 97: loss = 0.6800925731658936, acc = 0.7822265625\n",
      "Batch 98: loss = 0.6180839538574219, acc = 0.80859375\n",
      "Batch 99: loss = 0.6769550442695618, acc = 0.76953125\n",
      "Batch 100: loss = 0.685397744178772, acc = 0.7578125\n",
      "Batch 101: loss = 0.64003586769104, acc = 0.7919921875\n",
      "Batch 102: loss = 0.7194405198097229, acc = 0.76171875\n",
      "Batch 103: loss = 0.6552770137786865, acc = 0.791015625\n",
      "Batch 104: loss = 0.5850892066955566, acc = 0.8017578125\n",
      "Batch 105: loss = 0.6331223845481873, acc = 0.796875\n",
      "Batch 106: loss = 0.6438664197921753, acc = 0.7841796875\n",
      "Batch 107: loss = 0.6495423316955566, acc = 0.7861328125\n",
      "Batch 108: loss = 0.6590533256530762, acc = 0.78515625\n",
      "Batch 109: loss = 0.640282392501831, acc = 0.7724609375\n",
      "Batch 110: loss = 0.6045175790786743, acc = 0.7998046875\n",
      "Batch 111: loss = 0.720085620880127, acc = 0.77734375\n",
      "Batch 112: loss = 0.6421318054199219, acc = 0.7900390625\n",
      "Batch 113: loss = 0.6739606857299805, acc = 0.78125\n",
      "Batch 114: loss = 0.6684396862983704, acc = 0.7861328125\n",
      "Batch 115: loss = 0.6846340894699097, acc = 0.7646484375\n",
      "Batch 116: loss = 0.7088795304298401, acc = 0.7685546875\n",
      "Batch 117: loss = 0.6102429628372192, acc = 0.80078125\n",
      "Batch 118: loss = 0.5544253587722778, acc = 0.81640625\n",
      "Batch 119: loss = 0.6590788960456848, acc = 0.7919921875\n",
      "Batch 120: loss = 0.6521676778793335, acc = 0.794921875\n",
      "Batch 121: loss = 0.6546522378921509, acc = 0.7880859375\n",
      "Batch 122: loss = 0.6287384033203125, acc = 0.7900390625\n",
      "Batch 123: loss = 0.6365795135498047, acc = 0.79296875\n",
      "Batch 124: loss = 0.7064735889434814, acc = 0.751953125\n",
      "Batch 125: loss = 0.7109355926513672, acc = 0.7705078125\n",
      "Batch 126: loss = 0.6855160593986511, acc = 0.767578125\n",
      "\n",
      "Epoch 38/100\n",
      "Batch 1: loss = 0.7897444367408752, acc = 0.7451171875\n",
      "Batch 2: loss = 0.7132700085639954, acc = 0.7568359375\n",
      "Batch 3: loss = 0.6784869432449341, acc = 0.783203125\n",
      "Batch 4: loss = 0.6356174349784851, acc = 0.791015625\n",
      "Batch 5: loss = 0.7072542905807495, acc = 0.7666015625\n",
      "Batch 6: loss = 0.722260594367981, acc = 0.7666015625\n",
      "Batch 7: loss = 0.6705831289291382, acc = 0.7666015625\n",
      "Batch 8: loss = 0.6680735349655151, acc = 0.76171875\n",
      "Batch 9: loss = 0.6141467094421387, acc = 0.796875\n",
      "Batch 10: loss = 0.5771380066871643, acc = 0.8115234375\n",
      "Batch 11: loss = 0.6658684015274048, acc = 0.7744140625\n",
      "Batch 12: loss = 0.6466352939605713, acc = 0.7783203125\n",
      "Batch 13: loss = 0.6053100824356079, acc = 0.7900390625\n",
      "Batch 14: loss = 0.6583040952682495, acc = 0.7861328125\n",
      "Batch 15: loss = 0.6029555797576904, acc = 0.7958984375\n",
      "Batch 16: loss = 0.6725367307662964, acc = 0.7744140625\n",
      "Batch 17: loss = 0.6563195586204529, acc = 0.77734375\n",
      "Batch 18: loss = 0.711288332939148, acc = 0.765625\n",
      "Batch 19: loss = 0.6147956848144531, acc = 0.79296875\n",
      "Batch 20: loss = 0.6180832386016846, acc = 0.7958984375\n",
      "Batch 21: loss = 0.676300585269928, acc = 0.771484375\n",
      "Batch 22: loss = 0.5995432138442993, acc = 0.80078125\n",
      "Batch 23: loss = 0.6486366391181946, acc = 0.7802734375\n",
      "Batch 24: loss = 0.610917329788208, acc = 0.787109375\n",
      "Batch 25: loss = 0.5993162393569946, acc = 0.7978515625\n",
      "Batch 26: loss = 0.616075873374939, acc = 0.796875\n",
      "Batch 27: loss = 0.7488293647766113, acc = 0.7666015625\n",
      "Batch 28: loss = 0.6925371885299683, acc = 0.77734375\n",
      "Batch 29: loss = 0.6583548784255981, acc = 0.779296875\n",
      "Batch 30: loss = 0.5942782759666443, acc = 0.806640625\n",
      "Batch 31: loss = 0.6759227514266968, acc = 0.7724609375\n",
      "Batch 32: loss = 0.7460495233535767, acc = 0.7724609375\n",
      "Batch 33: loss = 0.6257725358009338, acc = 0.794921875\n",
      "Batch 34: loss = 0.6761524677276611, acc = 0.78125\n",
      "Batch 35: loss = 0.6317499876022339, acc = 0.794921875\n",
      "Batch 36: loss = 0.5913494229316711, acc = 0.7958984375\n",
      "Batch 37: loss = 0.5713449716567993, acc = 0.81640625\n",
      "Batch 38: loss = 0.6395602822303772, acc = 0.7919921875\n",
      "Batch 39: loss = 0.6593995094299316, acc = 0.7900390625\n",
      "Batch 40: loss = 0.6793772578239441, acc = 0.7578125\n",
      "Batch 41: loss = 0.5737686157226562, acc = 0.7978515625\n",
      "Batch 42: loss = 0.609850287437439, acc = 0.7939453125\n",
      "Batch 43: loss = 0.6705835461616516, acc = 0.7666015625\n",
      "Batch 44: loss = 0.5569796562194824, acc = 0.818359375\n",
      "Batch 45: loss = 0.5425596833229065, acc = 0.822265625\n",
      "Batch 46: loss = 0.610715389251709, acc = 0.7890625\n",
      "Batch 47: loss = 0.6117622256278992, acc = 0.798828125\n",
      "Batch 48: loss = 0.5916472673416138, acc = 0.8115234375\n",
      "Batch 49: loss = 0.5626157522201538, acc = 0.814453125\n",
      "Batch 50: loss = 0.5685786008834839, acc = 0.8203125\n",
      "Batch 51: loss = 0.5724413394927979, acc = 0.7998046875\n",
      "Batch 52: loss = 0.660256028175354, acc = 0.78125\n",
      "Batch 53: loss = 0.6063573956489563, acc = 0.8017578125\n",
      "Batch 54: loss = 0.5170598030090332, acc = 0.8388671875\n",
      "Batch 55: loss = 0.5775535106658936, acc = 0.798828125\n",
      "Batch 56: loss = 0.6413590908050537, acc = 0.7880859375\n",
      "Batch 57: loss = 0.7016509771347046, acc = 0.755859375\n",
      "Batch 58: loss = 0.6911579370498657, acc = 0.763671875\n",
      "Batch 59: loss = 0.5101190805435181, acc = 0.837890625\n",
      "Batch 60: loss = 0.6133223176002502, acc = 0.791015625\n",
      "Batch 61: loss = 0.5958837270736694, acc = 0.8154296875\n",
      "Batch 62: loss = 0.722141683101654, acc = 0.7451171875\n",
      "Batch 63: loss = 0.6692359447479248, acc = 0.779296875\n",
      "Batch 64: loss = 0.537969708442688, acc = 0.81640625\n",
      "Batch 65: loss = 0.6432827115058899, acc = 0.77734375\n",
      "Batch 66: loss = 0.6155011653900146, acc = 0.794921875\n",
      "Batch 67: loss = 0.586322546005249, acc = 0.798828125\n",
      "Batch 68: loss = 0.6664408445358276, acc = 0.779296875\n",
      "Batch 69: loss = 0.5503798127174377, acc = 0.82421875\n",
      "Batch 70: loss = 0.6772090196609497, acc = 0.7724609375\n",
      "Batch 71: loss = 0.655049741268158, acc = 0.77734375\n",
      "Batch 72: loss = 0.5910147428512573, acc = 0.7939453125\n",
      "Batch 73: loss = 0.6854722499847412, acc = 0.7763671875\n",
      "Batch 74: loss = 0.6708532571792603, acc = 0.763671875\n",
      "Batch 75: loss = 0.7598855495452881, acc = 0.75\n",
      "Batch 76: loss = 0.6776520013809204, acc = 0.7685546875\n",
      "Batch 77: loss = 0.638039767742157, acc = 0.80078125\n",
      "Batch 78: loss = 0.6488404870033264, acc = 0.779296875\n",
      "Batch 79: loss = 0.5817223787307739, acc = 0.8046875\n",
      "Batch 80: loss = 0.590842068195343, acc = 0.79296875\n",
      "Batch 81: loss = 0.6430661678314209, acc = 0.7939453125\n",
      "Batch 82: loss = 0.5902756452560425, acc = 0.814453125\n",
      "Batch 83: loss = 0.605709433555603, acc = 0.7958984375\n",
      "Batch 84: loss = 0.6015188694000244, acc = 0.794921875\n",
      "Batch 85: loss = 0.7013252377510071, acc = 0.7705078125\n",
      "Batch 86: loss = 0.6683100461959839, acc = 0.7734375\n",
      "Batch 87: loss = 0.6101267337799072, acc = 0.798828125\n",
      "Batch 88: loss = 0.7347474098205566, acc = 0.759765625\n",
      "Batch 89: loss = 0.635632336139679, acc = 0.794921875\n",
      "Batch 90: loss = 0.6837114095687866, acc = 0.7783203125\n",
      "Batch 91: loss = 0.670112669467926, acc = 0.791015625\n",
      "Batch 92: loss = 0.6349757313728333, acc = 0.77734375\n",
      "Batch 93: loss = 0.5547447204589844, acc = 0.8212890625\n",
      "Batch 94: loss = 0.5912377834320068, acc = 0.8154296875\n",
      "Batch 95: loss = 0.5958032011985779, acc = 0.8037109375\n",
      "Batch 96: loss = 0.651908278465271, acc = 0.7783203125\n",
      "Batch 97: loss = 0.6419374346733093, acc = 0.7861328125\n",
      "Batch 98: loss = 0.6074908971786499, acc = 0.7958984375\n",
      "Batch 99: loss = 0.6579944491386414, acc = 0.7763671875\n",
      "Batch 100: loss = 0.6438608169555664, acc = 0.7685546875\n",
      "Batch 101: loss = 0.6218669414520264, acc = 0.7783203125\n",
      "Batch 102: loss = 0.7037152647972107, acc = 0.7724609375\n",
      "Batch 103: loss = 0.649396538734436, acc = 0.798828125\n",
      "Batch 104: loss = 0.5768700838088989, acc = 0.8046875\n",
      "Batch 105: loss = 0.6223840713500977, acc = 0.7890625\n",
      "Batch 106: loss = 0.6528195142745972, acc = 0.7841796875\n",
      "Batch 107: loss = 0.6237075328826904, acc = 0.794921875\n",
      "Batch 108: loss = 0.6606276035308838, acc = 0.7822265625\n",
      "Batch 109: loss = 0.6343574523925781, acc = 0.7861328125\n",
      "Batch 110: loss = 0.5625735521316528, acc = 0.8212890625\n",
      "Batch 111: loss = 0.7121457457542419, acc = 0.7646484375\n",
      "Batch 112: loss = 0.6057528257369995, acc = 0.806640625\n",
      "Batch 113: loss = 0.6392556428909302, acc = 0.7890625\n",
      "Batch 114: loss = 0.6508017778396606, acc = 0.802734375\n",
      "Batch 115: loss = 0.6621417999267578, acc = 0.77734375\n",
      "Batch 116: loss = 0.6986522078514099, acc = 0.763671875\n",
      "Batch 117: loss = 0.6034709215164185, acc = 0.79296875\n",
      "Batch 118: loss = 0.5710746645927429, acc = 0.8046875\n",
      "Batch 119: loss = 0.6239974498748779, acc = 0.7919921875\n",
      "Batch 120: loss = 0.6263615489006042, acc = 0.7978515625\n",
      "Batch 121: loss = 0.6637491583824158, acc = 0.7783203125\n",
      "Batch 122: loss = 0.5664675235748291, acc = 0.8037109375\n",
      "Batch 123: loss = 0.6432778239250183, acc = 0.787109375\n",
      "Batch 124: loss = 0.6779983639717102, acc = 0.7666015625\n",
      "Batch 125: loss = 0.6968953013420105, acc = 0.775390625\n",
      "Batch 126: loss = 0.6580808162689209, acc = 0.791015625\n",
      "\n",
      "Epoch 39/100\n",
      "Batch 1: loss = 0.7736141085624695, acc = 0.771484375\n",
      "Batch 2: loss = 0.6933118104934692, acc = 0.76953125\n",
      "Batch 3: loss = 0.6499667167663574, acc = 0.8056640625\n",
      "Batch 4: loss = 0.6285527944564819, acc = 0.796875\n",
      "Batch 5: loss = 0.6871012449264526, acc = 0.7666015625\n",
      "Batch 6: loss = 0.6846551895141602, acc = 0.763671875\n",
      "Batch 7: loss = 0.6582851409912109, acc = 0.7763671875\n",
      "Batch 8: loss = 0.6296993494033813, acc = 0.791015625\n",
      "Batch 9: loss = 0.5996764898300171, acc = 0.8046875\n",
      "Batch 10: loss = 0.5597053170204163, acc = 0.81640625\n",
      "Batch 11: loss = 0.6600794792175293, acc = 0.7998046875\n",
      "Batch 12: loss = 0.631711483001709, acc = 0.7822265625\n",
      "Batch 13: loss = 0.5821189284324646, acc = 0.7998046875\n",
      "Batch 14: loss = 0.6165822744369507, acc = 0.7978515625\n",
      "Batch 15: loss = 0.5757030248641968, acc = 0.8134765625\n",
      "Batch 16: loss = 0.6719164848327637, acc = 0.7822265625\n",
      "Batch 17: loss = 0.6299182176589966, acc = 0.7900390625\n",
      "Batch 18: loss = 0.6724050641059875, acc = 0.7734375\n",
      "Batch 19: loss = 0.6053491234779358, acc = 0.7958984375\n",
      "Batch 20: loss = 0.602561891078949, acc = 0.798828125\n",
      "Batch 21: loss = 0.6639400720596313, acc = 0.767578125\n",
      "Batch 22: loss = 0.5965578556060791, acc = 0.7978515625\n",
      "Batch 23: loss = 0.6224744319915771, acc = 0.7880859375\n",
      "Batch 24: loss = 0.5997200012207031, acc = 0.806640625\n",
      "Batch 25: loss = 0.5813146829605103, acc = 0.798828125\n",
      "Batch 26: loss = 0.5968438386917114, acc = 0.798828125\n",
      "Batch 27: loss = 0.7361209392547607, acc = 0.7587890625\n",
      "Batch 28: loss = 0.668531596660614, acc = 0.76953125\n",
      "Batch 29: loss = 0.6396521329879761, acc = 0.798828125\n",
      "Batch 30: loss = 0.5890697836875916, acc = 0.7958984375\n",
      "Batch 31: loss = 0.6748307943344116, acc = 0.7783203125\n",
      "Batch 32: loss = 0.7043637037277222, acc = 0.7685546875\n",
      "Batch 33: loss = 0.6350303292274475, acc = 0.7900390625\n",
      "Batch 34: loss = 0.6475260257720947, acc = 0.787109375\n",
      "Batch 35: loss = 0.6338900327682495, acc = 0.8134765625\n",
      "Batch 36: loss = 0.5864145159721375, acc = 0.8173828125\n",
      "Batch 37: loss = 0.5807907581329346, acc = 0.8203125\n",
      "Batch 38: loss = 0.6265153884887695, acc = 0.7939453125\n",
      "Batch 39: loss = 0.6474250555038452, acc = 0.779296875\n",
      "Batch 40: loss = 0.6328258514404297, acc = 0.7880859375\n",
      "Batch 41: loss = 0.5734027028083801, acc = 0.80859375\n",
      "Batch 42: loss = 0.5963139533996582, acc = 0.7998046875\n",
      "Batch 43: loss = 0.6656641364097595, acc = 0.7607421875\n",
      "Batch 44: loss = 0.5738472938537598, acc = 0.8173828125\n",
      "Batch 45: loss = 0.5405117273330688, acc = 0.8095703125\n",
      "Batch 46: loss = 0.5795574188232422, acc = 0.794921875\n",
      "Batch 47: loss = 0.5867140293121338, acc = 0.8056640625\n",
      "Batch 48: loss = 0.5743422508239746, acc = 0.8037109375\n",
      "Batch 49: loss = 0.5572893023490906, acc = 0.826171875\n",
      "Batch 50: loss = 0.559062123298645, acc = 0.818359375\n",
      "Batch 51: loss = 0.5809187889099121, acc = 0.794921875\n",
      "Batch 52: loss = 0.6288119554519653, acc = 0.783203125\n",
      "Batch 53: loss = 0.6195577383041382, acc = 0.802734375\n",
      "Batch 54: loss = 0.5160800218582153, acc = 0.8310546875\n",
      "Batch 55: loss = 0.5592085123062134, acc = 0.8125\n",
      "Batch 56: loss = 0.5895105600357056, acc = 0.8017578125\n",
      "Batch 57: loss = 0.6686077117919922, acc = 0.7783203125\n",
      "Batch 58: loss = 0.6737807393074036, acc = 0.7666015625\n",
      "Batch 59: loss = 0.49527037143707275, acc = 0.833984375\n",
      "Batch 60: loss = 0.5943353176116943, acc = 0.8037109375\n",
      "Batch 61: loss = 0.5678893327713013, acc = 0.8173828125\n",
      "Batch 62: loss = 0.7078807353973389, acc = 0.7744140625\n",
      "Batch 63: loss = 0.6581497192382812, acc = 0.78125\n",
      "Batch 64: loss = 0.5141792297363281, acc = 0.8359375\n",
      "Batch 65: loss = 0.69024658203125, acc = 0.7666015625\n",
      "Batch 66: loss = 0.6063657999038696, acc = 0.80078125\n",
      "Batch 67: loss = 0.5939701795578003, acc = 0.794921875\n",
      "Batch 68: loss = 0.6247168779373169, acc = 0.794921875\n",
      "Batch 69: loss = 0.5387750864028931, acc = 0.822265625\n",
      "Batch 70: loss = 0.6724687814712524, acc = 0.775390625\n",
      "Batch 71: loss = 0.6513864994049072, acc = 0.77734375\n",
      "Batch 72: loss = 0.5826115608215332, acc = 0.7998046875\n",
      "Batch 73: loss = 0.6926597356796265, acc = 0.7724609375\n",
      "Batch 74: loss = 0.6546857953071594, acc = 0.775390625\n",
      "Batch 75: loss = 0.7453449368476868, acc = 0.7421875\n",
      "Batch 76: loss = 0.6675026416778564, acc = 0.78515625\n",
      "Batch 77: loss = 0.6157418489456177, acc = 0.8037109375\n",
      "Batch 78: loss = 0.6606256365776062, acc = 0.78125\n",
      "Batch 79: loss = 0.5869941115379333, acc = 0.796875\n",
      "Batch 80: loss = 0.5878419876098633, acc = 0.79296875\n",
      "Batch 81: loss = 0.6232176423072815, acc = 0.78515625\n",
      "Batch 82: loss = 0.5797038078308105, acc = 0.8212890625\n",
      "Batch 83: loss = 0.6223764419555664, acc = 0.796875\n",
      "Batch 84: loss = 0.6267990469932556, acc = 0.7978515625\n",
      "Batch 85: loss = 0.6692169308662415, acc = 0.7705078125\n",
      "Batch 86: loss = 0.6663936972618103, acc = 0.7841796875\n",
      "Batch 87: loss = 0.6210402846336365, acc = 0.7880859375\n",
      "Batch 88: loss = 0.7183012962341309, acc = 0.76953125\n",
      "Batch 89: loss = 0.6108263731002808, acc = 0.8046875\n",
      "Batch 90: loss = 0.6531604528427124, acc = 0.77734375\n",
      "Batch 91: loss = 0.6690140962600708, acc = 0.771484375\n",
      "Batch 92: loss = 0.6331328749656677, acc = 0.7998046875\n",
      "Batch 93: loss = 0.5384373068809509, acc = 0.8330078125\n",
      "Batch 94: loss = 0.5442380905151367, acc = 0.8232421875\n",
      "Batch 95: loss = 0.5814791917800903, acc = 0.8115234375\n",
      "Batch 96: loss = 0.6712418794631958, acc = 0.787109375\n",
      "Batch 97: loss = 0.6521130800247192, acc = 0.7958984375\n",
      "Batch 98: loss = 0.6087857484817505, acc = 0.8134765625\n",
      "Batch 99: loss = 0.6156055927276611, acc = 0.783203125\n",
      "Batch 100: loss = 0.6496849656105042, acc = 0.7744140625\n",
      "Batch 101: loss = 0.653096079826355, acc = 0.7802734375\n",
      "Batch 102: loss = 0.6727927923202515, acc = 0.771484375\n",
      "Batch 103: loss = 0.6437616348266602, acc = 0.791015625\n",
      "Batch 104: loss = 0.5800097584724426, acc = 0.798828125\n",
      "Batch 105: loss = 0.5806412696838379, acc = 0.8076171875\n",
      "Batch 106: loss = 0.6269046068191528, acc = 0.79296875\n",
      "Batch 107: loss = 0.6143198609352112, acc = 0.7998046875\n",
      "Batch 108: loss = 0.6123393177986145, acc = 0.8056640625\n",
      "Batch 109: loss = 0.6104803085327148, acc = 0.7939453125\n",
      "Batch 110: loss = 0.5590499043464661, acc = 0.81640625\n",
      "Batch 111: loss = 0.6576186418533325, acc = 0.7744140625\n",
      "Batch 112: loss = 0.6209134459495544, acc = 0.783203125\n",
      "Batch 113: loss = 0.6325579285621643, acc = 0.7978515625\n",
      "Batch 114: loss = 0.6602398157119751, acc = 0.7900390625\n",
      "Batch 115: loss = 0.6571029424667358, acc = 0.7861328125\n",
      "Batch 116: loss = 0.6833527684211731, acc = 0.7724609375\n",
      "Batch 117: loss = 0.5787450075149536, acc = 0.796875\n",
      "Batch 118: loss = 0.5421263575553894, acc = 0.8193359375\n",
      "Batch 119: loss = 0.6122133135795593, acc = 0.7978515625\n",
      "Batch 120: loss = 0.6209215521812439, acc = 0.78515625\n",
      "Batch 121: loss = 0.6543651819229126, acc = 0.7939453125\n",
      "Batch 122: loss = 0.5957139730453491, acc = 0.7978515625\n",
      "Batch 123: loss = 0.6470901966094971, acc = 0.7822265625\n",
      "Batch 124: loss = 0.6679121851921082, acc = 0.7705078125\n",
      "Batch 125: loss = 0.671919584274292, acc = 0.7763671875\n",
      "Batch 126: loss = 0.6742827892303467, acc = 0.775390625\n",
      "\n",
      "Epoch 40/100\n",
      "Batch 1: loss = 0.7481053471565247, acc = 0.763671875\n",
      "Batch 2: loss = 0.6821836829185486, acc = 0.7744140625\n",
      "Batch 3: loss = 0.65172278881073, acc = 0.7890625\n",
      "Batch 4: loss = 0.6064435839653015, acc = 0.810546875\n",
      "Batch 5: loss = 0.6893770098686218, acc = 0.7666015625\n",
      "Batch 6: loss = 0.7028127312660217, acc = 0.7646484375\n",
      "Batch 7: loss = 0.6453762054443359, acc = 0.79296875\n",
      "Batch 8: loss = 0.6116042137145996, acc = 0.79296875\n",
      "Batch 9: loss = 0.5798799395561218, acc = 0.814453125\n",
      "Batch 10: loss = 0.5530587434768677, acc = 0.81640625\n",
      "Batch 11: loss = 0.6522507071495056, acc = 0.78125\n",
      "Batch 12: loss = 0.6029770374298096, acc = 0.8017578125\n",
      "Batch 13: loss = 0.5713869333267212, acc = 0.8076171875\n",
      "Batch 14: loss = 0.6346890926361084, acc = 0.7861328125\n",
      "Batch 15: loss = 0.5570329427719116, acc = 0.826171875\n",
      "Batch 16: loss = 0.6387616395950317, acc = 0.7998046875\n",
      "Batch 17: loss = 0.625857949256897, acc = 0.7939453125\n",
      "Batch 18: loss = 0.6770320534706116, acc = 0.7822265625\n",
      "Batch 19: loss = 0.6182222962379456, acc = 0.8017578125\n",
      "Batch 20: loss = 0.5915800333023071, acc = 0.796875\n",
      "Batch 21: loss = 0.6636579632759094, acc = 0.7744140625\n",
      "Batch 22: loss = 0.5912189483642578, acc = 0.7890625\n",
      "Batch 23: loss = 0.6153780221939087, acc = 0.791015625\n",
      "Batch 24: loss = 0.6016885638237, acc = 0.7998046875\n",
      "Batch 25: loss = 0.5720925331115723, acc = 0.810546875\n",
      "Batch 26: loss = 0.5661067366600037, acc = 0.8232421875\n",
      "Batch 27: loss = 0.6967802047729492, acc = 0.779296875\n",
      "Batch 28: loss = 0.6673595905303955, acc = 0.7802734375\n",
      "Batch 29: loss = 0.6310903429985046, acc = 0.796875\n",
      "Batch 30: loss = 0.5750788450241089, acc = 0.8125\n",
      "Batch 31: loss = 0.6381890773773193, acc = 0.7900390625\n",
      "Batch 32: loss = 0.7036698460578918, acc = 0.77734375\n",
      "Batch 33: loss = 0.6041766405105591, acc = 0.7880859375\n",
      "Batch 34: loss = 0.6136199831962585, acc = 0.7998046875\n",
      "Batch 35: loss = 0.6298927068710327, acc = 0.794921875\n",
      "Batch 36: loss = 0.57389235496521, acc = 0.8134765625\n",
      "Batch 37: loss = 0.5573058128356934, acc = 0.8291015625\n",
      "Batch 38: loss = 0.6282705068588257, acc = 0.787109375\n",
      "Batch 39: loss = 0.6421597003936768, acc = 0.7841796875\n",
      "Batch 40: loss = 0.6440759897232056, acc = 0.7802734375\n",
      "Batch 41: loss = 0.5512250661849976, acc = 0.8134765625\n",
      "Batch 42: loss = 0.5911602973937988, acc = 0.8037109375\n",
      "Batch 43: loss = 0.6664822101593018, acc = 0.7705078125\n",
      "Batch 44: loss = 0.5564665794372559, acc = 0.8095703125\n",
      "Batch 45: loss = 0.5301450490951538, acc = 0.8349609375\n",
      "Batch 46: loss = 0.5640326738357544, acc = 0.8173828125\n",
      "Batch 47: loss = 0.6087846755981445, acc = 0.8046875\n",
      "Batch 48: loss = 0.5629014372825623, acc = 0.8193359375\n",
      "Batch 49: loss = 0.5599814057350159, acc = 0.8173828125\n",
      "Batch 50: loss = 0.5474057197570801, acc = 0.828125\n",
      "Batch 51: loss = 0.5589775443077087, acc = 0.80859375\n",
      "Batch 52: loss = 0.5920332074165344, acc = 0.79296875\n",
      "Batch 53: loss = 0.6023263931274414, acc = 0.8046875\n",
      "Batch 54: loss = 0.5038563013076782, acc = 0.8369140625\n",
      "Batch 55: loss = 0.5384875535964966, acc = 0.818359375\n",
      "Batch 56: loss = 0.5704911947250366, acc = 0.80859375\n",
      "Batch 57: loss = 0.6389402747154236, acc = 0.78515625\n",
      "Batch 58: loss = 0.6904465556144714, acc = 0.7666015625\n",
      "Batch 59: loss = 0.5071197152137756, acc = 0.83203125\n",
      "Batch 60: loss = 0.5916478633880615, acc = 0.798828125\n",
      "Batch 61: loss = 0.5736473798751831, acc = 0.8173828125\n",
      "Batch 62: loss = 0.6985126733779907, acc = 0.7763671875\n",
      "Batch 63: loss = 0.6248706579208374, acc = 0.7919921875\n",
      "Batch 64: loss = 0.5044806599617004, acc = 0.82421875\n",
      "Batch 65: loss = 0.6355562806129456, acc = 0.79296875\n",
      "Batch 66: loss = 0.599330484867096, acc = 0.8056640625\n",
      "Batch 67: loss = 0.5850955247879028, acc = 0.8076171875\n",
      "Batch 68: loss = 0.6267469525337219, acc = 0.794921875\n",
      "Batch 69: loss = 0.5508788824081421, acc = 0.8193359375\n",
      "Batch 70: loss = 0.6586015820503235, acc = 0.7841796875\n",
      "Batch 71: loss = 0.6331433653831482, acc = 0.7919921875\n",
      "Batch 72: loss = 0.5595197081565857, acc = 0.7958984375\n",
      "Batch 73: loss = 0.6395286917686462, acc = 0.7880859375\n",
      "Batch 74: loss = 0.6285730004310608, acc = 0.78515625\n",
      "Batch 75: loss = 0.7198104858398438, acc = 0.75390625\n",
      "Batch 76: loss = 0.6312218308448792, acc = 0.78515625\n",
      "Batch 77: loss = 0.5965763330459595, acc = 0.8125\n",
      "Batch 78: loss = 0.6210250854492188, acc = 0.796875\n",
      "Batch 79: loss = 0.5470041036605835, acc = 0.8076171875\n",
      "Batch 80: loss = 0.5723232626914978, acc = 0.7978515625\n",
      "Batch 81: loss = 0.6209518313407898, acc = 0.7900390625\n",
      "Batch 82: loss = 0.5838090181350708, acc = 0.822265625\n",
      "Batch 83: loss = 0.5697947144508362, acc = 0.7958984375\n",
      "Batch 84: loss = 0.608497142791748, acc = 0.8017578125\n",
      "Batch 85: loss = 0.6812126636505127, acc = 0.763671875\n",
      "Batch 86: loss = 0.6579495668411255, acc = 0.7861328125\n",
      "Batch 87: loss = 0.6463335752487183, acc = 0.7822265625\n",
      "Batch 88: loss = 0.7523711323738098, acc = 0.755859375\n",
      "Batch 89: loss = 0.6286343336105347, acc = 0.796875\n",
      "Batch 90: loss = 0.6230393648147583, acc = 0.7958984375\n",
      "Batch 91: loss = 0.6547943353652954, acc = 0.779296875\n",
      "Batch 92: loss = 0.6201958656311035, acc = 0.796875\n",
      "Batch 93: loss = 0.5278385281562805, acc = 0.822265625\n",
      "Batch 94: loss = 0.5884314775466919, acc = 0.8115234375\n",
      "Batch 95: loss = 0.5824227333068848, acc = 0.8046875\n",
      "Batch 96: loss = 0.6763899922370911, acc = 0.779296875\n",
      "Batch 97: loss = 0.6375664472579956, acc = 0.7890625\n",
      "Batch 98: loss = 0.5887197256088257, acc = 0.8154296875\n",
      "Batch 99: loss = 0.6401292085647583, acc = 0.787109375\n",
      "Batch 100: loss = 0.6206346750259399, acc = 0.77734375\n",
      "Batch 101: loss = 0.6096431612968445, acc = 0.79296875\n",
      "Batch 102: loss = 0.6589009165763855, acc = 0.7783203125\n",
      "Batch 103: loss = 0.6078565716743469, acc = 0.8056640625\n",
      "Batch 104: loss = 0.5309402346611023, acc = 0.830078125\n",
      "Batch 105: loss = 0.5753336548805237, acc = 0.8037109375\n",
      "Batch 106: loss = 0.6378393173217773, acc = 0.779296875\n",
      "Batch 107: loss = 0.6175281405448914, acc = 0.8076171875\n",
      "Batch 108: loss = 0.6073414087295532, acc = 0.796875\n",
      "Batch 109: loss = 0.5931987762451172, acc = 0.7958984375\n",
      "Batch 110: loss = 0.5505454540252686, acc = 0.826171875\n",
      "Batch 111: loss = 0.6614137887954712, acc = 0.78515625\n",
      "Batch 112: loss = 0.5953692197799683, acc = 0.7998046875\n",
      "Batch 113: loss = 0.6309419870376587, acc = 0.7822265625\n",
      "Batch 114: loss = 0.6292835474014282, acc = 0.7900390625\n",
      "Batch 115: loss = 0.6322684288024902, acc = 0.79296875\n",
      "Batch 116: loss = 0.6407343149185181, acc = 0.7861328125\n",
      "Batch 117: loss = 0.5503067970275879, acc = 0.8046875\n",
      "Batch 118: loss = 0.5196306109428406, acc = 0.8310546875\n",
      "Batch 119: loss = 0.6088837385177612, acc = 0.8017578125\n",
      "Batch 120: loss = 0.6397686004638672, acc = 0.7685546875\n",
      "Batch 121: loss = 0.6112836599349976, acc = 0.80078125\n",
      "Batch 122: loss = 0.5504593253135681, acc = 0.814453125\n",
      "Batch 123: loss = 0.6290324330329895, acc = 0.7919921875\n",
      "Batch 124: loss = 0.6376091241836548, acc = 0.78515625\n",
      "Batch 125: loss = 0.6321017742156982, acc = 0.7939453125\n",
      "Batch 126: loss = 0.6334335803985596, acc = 0.791015625\n",
      "Saved checkpoint to weights.40.h5\n",
      "\n",
      "Epoch 41/100\n",
      "Batch 1: loss = 0.7404685616493225, acc = 0.7734375\n",
      "Batch 2: loss = 0.653689980506897, acc = 0.7861328125\n",
      "Batch 3: loss = 0.6340150237083435, acc = 0.80078125\n",
      "Batch 4: loss = 0.6440660953521729, acc = 0.7900390625\n",
      "Batch 5: loss = 0.6498414278030396, acc = 0.78515625\n",
      "Batch 6: loss = 0.6826578974723816, acc = 0.7705078125\n",
      "Batch 7: loss = 0.5941224694252014, acc = 0.8037109375\n",
      "Batch 8: loss = 0.6119852662086487, acc = 0.8037109375\n",
      "Batch 9: loss = 0.582992434501648, acc = 0.810546875\n",
      "Batch 10: loss = 0.5502188205718994, acc = 0.8203125\n",
      "Batch 11: loss = 0.6369306445121765, acc = 0.787109375\n",
      "Batch 12: loss = 0.628247857093811, acc = 0.8017578125\n",
      "Batch 13: loss = 0.5719724893569946, acc = 0.80859375\n",
      "Batch 14: loss = 0.6342394351959229, acc = 0.7939453125\n",
      "Batch 15: loss = 0.5512617230415344, acc = 0.8203125\n",
      "Batch 16: loss = 0.6221587657928467, acc = 0.8056640625\n",
      "Batch 17: loss = 0.6250498294830322, acc = 0.7861328125\n",
      "Batch 18: loss = 0.6381969451904297, acc = 0.7958984375\n",
      "Batch 19: loss = 0.5772032737731934, acc = 0.822265625\n",
      "Batch 20: loss = 0.5887647867202759, acc = 0.80078125\n",
      "Batch 21: loss = 0.6404772996902466, acc = 0.7900390625\n",
      "Batch 22: loss = 0.5763387680053711, acc = 0.794921875\n",
      "Batch 23: loss = 0.6009705066680908, acc = 0.796875\n",
      "Batch 24: loss = 0.5819883942604065, acc = 0.810546875\n",
      "Batch 25: loss = 0.5577751398086548, acc = 0.8115234375\n",
      "Batch 26: loss = 0.5682016611099243, acc = 0.810546875\n",
      "Batch 27: loss = 0.7069587111473083, acc = 0.7646484375\n",
      "Batch 28: loss = 0.6128906011581421, acc = 0.7841796875\n",
      "Batch 29: loss = 0.6246846914291382, acc = 0.7958984375\n",
      "Batch 30: loss = 0.5946508646011353, acc = 0.7900390625\n",
      "Batch 31: loss = 0.6121472120285034, acc = 0.8095703125\n",
      "Batch 32: loss = 0.7169256210327148, acc = 0.7646484375\n",
      "Batch 33: loss = 0.5773870944976807, acc = 0.8046875\n",
      "Batch 34: loss = 0.6022158861160278, acc = 0.7978515625\n",
      "Batch 35: loss = 0.6117676496505737, acc = 0.7958984375\n",
      "Batch 36: loss = 0.5635725259780884, acc = 0.8251953125\n",
      "Batch 37: loss = 0.5624986290931702, acc = 0.802734375\n",
      "Batch 38: loss = 0.5991251468658447, acc = 0.8056640625\n",
      "Batch 39: loss = 0.597226619720459, acc = 0.7939453125\n",
      "Batch 40: loss = 0.6475522518157959, acc = 0.779296875\n",
      "Batch 41: loss = 0.5325833559036255, acc = 0.8173828125\n",
      "Batch 42: loss = 0.5784260034561157, acc = 0.806640625\n",
      "Batch 43: loss = 0.6464011669158936, acc = 0.78125\n",
      "Batch 44: loss = 0.5394260883331299, acc = 0.822265625\n",
      "Batch 45: loss = 0.5016128420829773, acc = 0.8203125\n",
      "Batch 46: loss = 0.5476016998291016, acc = 0.80859375\n",
      "Batch 47: loss = 0.5825304985046387, acc = 0.8134765625\n",
      "Batch 48: loss = 0.5574872493743896, acc = 0.8173828125\n",
      "Batch 49: loss = 0.5236627459526062, acc = 0.8310546875\n",
      "Batch 50: loss = 0.5226730108261108, acc = 0.8251953125\n",
      "Batch 51: loss = 0.5428577661514282, acc = 0.806640625\n",
      "Batch 52: loss = 0.6045311093330383, acc = 0.794921875\n",
      "Batch 53: loss = 0.58247971534729, acc = 0.80859375\n",
      "Batch 54: loss = 0.49567723274230957, acc = 0.837890625\n",
      "Batch 55: loss = 0.539696991443634, acc = 0.80859375\n",
      "Batch 56: loss = 0.5738258957862854, acc = 0.8076171875\n",
      "Batch 57: loss = 0.6586788892745972, acc = 0.76953125\n",
      "Batch 58: loss = 0.6699122786521912, acc = 0.7724609375\n",
      "Batch 59: loss = 0.5067551136016846, acc = 0.8291015625\n",
      "Batch 60: loss = 0.5820706486701965, acc = 0.80859375\n",
      "Batch 61: loss = 0.5663822889328003, acc = 0.8212890625\n",
      "Batch 62: loss = 0.6692209243774414, acc = 0.7802734375\n",
      "Batch 63: loss = 0.6466732025146484, acc = 0.7763671875\n",
      "Batch 64: loss = 0.48717808723449707, acc = 0.8291015625\n",
      "Batch 65: loss = 0.5880604982376099, acc = 0.8037109375\n",
      "Batch 66: loss = 0.6066787242889404, acc = 0.7900390625\n",
      "Batch 67: loss = 0.5478392839431763, acc = 0.8203125\n",
      "Batch 68: loss = 0.6330050230026245, acc = 0.79296875\n",
      "Batch 69: loss = 0.5264268517494202, acc = 0.837890625\n",
      "Batch 70: loss = 0.6208598017692566, acc = 0.796875\n",
      "Batch 71: loss = 0.641838014125824, acc = 0.7939453125\n",
      "Batch 72: loss = 0.5497313737869263, acc = 0.8291015625\n",
      "Batch 73: loss = 0.6318339705467224, acc = 0.791015625\n",
      "Batch 74: loss = 0.6167266368865967, acc = 0.7861328125\n",
      "Batch 75: loss = 0.7089466452598572, acc = 0.7451171875\n",
      "Batch 76: loss = 0.6439792513847351, acc = 0.775390625\n",
      "Batch 77: loss = 0.6022796630859375, acc = 0.798828125\n",
      "Batch 78: loss = 0.6337112188339233, acc = 0.7880859375\n",
      "Batch 79: loss = 0.5559952259063721, acc = 0.81640625\n",
      "Batch 80: loss = 0.5651613473892212, acc = 0.80078125\n",
      "Batch 81: loss = 0.6197617650032043, acc = 0.787109375\n",
      "Batch 82: loss = 0.5758970975875854, acc = 0.8232421875\n",
      "Batch 83: loss = 0.5663297772407532, acc = 0.798828125\n",
      "Batch 84: loss = 0.6183306574821472, acc = 0.796875\n",
      "Batch 85: loss = 0.6557823419570923, acc = 0.7783203125\n",
      "Batch 86: loss = 0.6506993174552917, acc = 0.783203125\n",
      "Batch 87: loss = 0.6113888025283813, acc = 0.7958984375\n",
      "Batch 88: loss = 0.7057647109031677, acc = 0.765625\n",
      "Batch 89: loss = 0.5795252323150635, acc = 0.818359375\n",
      "Batch 90: loss = 0.6401371955871582, acc = 0.7998046875\n",
      "Batch 91: loss = 0.629848837852478, acc = 0.78125\n",
      "Batch 92: loss = 0.5922038555145264, acc = 0.80859375\n",
      "Batch 93: loss = 0.5289187431335449, acc = 0.8232421875\n",
      "Batch 94: loss = 0.5663408041000366, acc = 0.8203125\n",
      "Batch 95: loss = 0.5730481147766113, acc = 0.8076171875\n",
      "Batch 96: loss = 0.648855447769165, acc = 0.77734375\n",
      "Batch 97: loss = 0.6127825975418091, acc = 0.8076171875\n",
      "Batch 98: loss = 0.6171238422393799, acc = 0.7939453125\n",
      "Batch 99: loss = 0.6171475648880005, acc = 0.7939453125\n",
      "Batch 100: loss = 0.6265024542808533, acc = 0.7763671875\n",
      "Batch 101: loss = 0.5801621675491333, acc = 0.8232421875\n",
      "Batch 102: loss = 0.6417723894119263, acc = 0.78515625\n",
      "Batch 103: loss = 0.5956658124923706, acc = 0.8037109375\n",
      "Batch 104: loss = 0.5412783622741699, acc = 0.8125\n",
      "Batch 105: loss = 0.5438652634620667, acc = 0.8251953125\n",
      "Batch 106: loss = 0.6143165230751038, acc = 0.78515625\n",
      "Batch 107: loss = 0.5783025026321411, acc = 0.8095703125\n",
      "Batch 108: loss = 0.6368908882141113, acc = 0.8037109375\n",
      "Batch 109: loss = 0.5830988883972168, acc = 0.80078125\n",
      "Batch 110: loss = 0.533061683177948, acc = 0.826171875\n",
      "Batch 111: loss = 0.6644530296325684, acc = 0.775390625\n",
      "Batch 112: loss = 0.5736112594604492, acc = 0.818359375\n",
      "Batch 113: loss = 0.6181397438049316, acc = 0.80078125\n",
      "Batch 114: loss = 0.5981583595275879, acc = 0.81640625\n",
      "Batch 115: loss = 0.6069276928901672, acc = 0.7939453125\n",
      "Batch 116: loss = 0.6068704128265381, acc = 0.8095703125\n",
      "Batch 117: loss = 0.5366131663322449, acc = 0.826171875\n",
      "Batch 118: loss = 0.5051987767219543, acc = 0.828125\n",
      "Batch 119: loss = 0.5944810509681702, acc = 0.80859375\n",
      "Batch 120: loss = 0.5937398076057434, acc = 0.7958984375\n",
      "Batch 121: loss = 0.6306546926498413, acc = 0.7978515625\n",
      "Batch 122: loss = 0.57659512758255, acc = 0.8056640625\n",
      "Batch 123: loss = 0.5844186544418335, acc = 0.8134765625\n",
      "Batch 124: loss = 0.6428333520889282, acc = 0.78125\n",
      "Batch 125: loss = 0.6544494032859802, acc = 0.7841796875\n",
      "Batch 126: loss = 0.6075681447982788, acc = 0.7939453125\n",
      "\n",
      "Epoch 42/100\n",
      "Batch 1: loss = 0.747633159160614, acc = 0.771484375\n",
      "Batch 2: loss = 0.6366664171218872, acc = 0.7939453125\n",
      "Batch 3: loss = 0.640060305595398, acc = 0.80078125\n",
      "Batch 4: loss = 0.6000036597251892, acc = 0.8046875\n",
      "Batch 5: loss = 0.6150468587875366, acc = 0.802734375\n",
      "Batch 6: loss = 0.6304091215133667, acc = 0.7919921875\n",
      "Batch 7: loss = 0.6018780469894409, acc = 0.8076171875\n",
      "Batch 8: loss = 0.5865365266799927, acc = 0.798828125\n",
      "Batch 9: loss = 0.5583121180534363, acc = 0.822265625\n",
      "Batch 10: loss = 0.5398597717285156, acc = 0.8271484375\n",
      "Batch 11: loss = 0.6304894685745239, acc = 0.8037109375\n",
      "Batch 12: loss = 0.6061371564865112, acc = 0.7880859375\n",
      "Batch 13: loss = 0.5602982640266418, acc = 0.8076171875\n",
      "Batch 14: loss = 0.5983102917671204, acc = 0.798828125\n",
      "Batch 15: loss = 0.5475716590881348, acc = 0.8095703125\n",
      "Batch 16: loss = 0.6260581016540527, acc = 0.798828125\n",
      "Batch 17: loss = 0.6259108185768127, acc = 0.7900390625\n",
      "Batch 18: loss = 0.6058015823364258, acc = 0.8017578125\n",
      "Batch 19: loss = 0.5859332084655762, acc = 0.8125\n",
      "Batch 20: loss = 0.5505658388137817, acc = 0.8115234375\n",
      "Batch 21: loss = 0.5875699520111084, acc = 0.806640625\n",
      "Batch 22: loss = 0.585394561290741, acc = 0.802734375\n",
      "Batch 23: loss = 0.5972931385040283, acc = 0.7900390625\n",
      "Batch 24: loss = 0.5621213912963867, acc = 0.814453125\n",
      "Batch 25: loss = 0.5464884042739868, acc = 0.8310546875\n",
      "Batch 26: loss = 0.5430796146392822, acc = 0.8134765625\n",
      "Batch 27: loss = 0.6550863981246948, acc = 0.7939453125\n",
      "Batch 28: loss = 0.6528457403182983, acc = 0.7744140625\n",
      "Batch 29: loss = 0.6165547370910645, acc = 0.8056640625\n",
      "Batch 30: loss = 0.5252712965011597, acc = 0.8330078125\n",
      "Batch 31: loss = 0.621949315071106, acc = 0.8046875\n",
      "Batch 32: loss = 0.663603663444519, acc = 0.779296875\n",
      "Batch 33: loss = 0.5890230536460876, acc = 0.8125\n",
      "Batch 34: loss = 0.5842344760894775, acc = 0.8046875\n",
      "Batch 35: loss = 0.5961845517158508, acc = 0.796875\n",
      "Batch 36: loss = 0.5665010213851929, acc = 0.8076171875\n",
      "Batch 37: loss = 0.4887009263038635, acc = 0.8427734375\n",
      "Batch 38: loss = 0.5778087973594666, acc = 0.814453125\n",
      "Batch 39: loss = 0.5811834335327148, acc = 0.8017578125\n",
      "Batch 40: loss = 0.6025055646896362, acc = 0.8017578125\n",
      "Batch 41: loss = 0.5440725088119507, acc = 0.830078125\n",
      "Batch 42: loss = 0.5821619033813477, acc = 0.802734375\n",
      "Batch 43: loss = 0.6254608035087585, acc = 0.78515625\n",
      "Batch 44: loss = 0.528182864189148, acc = 0.82421875\n",
      "Batch 45: loss = 0.5058098435401917, acc = 0.8369140625\n",
      "Batch 46: loss = 0.5447386503219604, acc = 0.8134765625\n",
      "Batch 47: loss = 0.5545039176940918, acc = 0.82421875\n",
      "Batch 48: loss = 0.5299252271652222, acc = 0.826171875\n",
      "Batch 49: loss = 0.5333034992218018, acc = 0.8203125\n",
      "Batch 50: loss = 0.5244796276092529, acc = 0.8291015625\n",
      "Batch 51: loss = 0.5510785579681396, acc = 0.7998046875\n",
      "Batch 52: loss = 0.5834760069847107, acc = 0.8046875\n",
      "Batch 53: loss = 0.5383564829826355, acc = 0.8388671875\n",
      "Batch 54: loss = 0.4688781201839447, acc = 0.84765625\n",
      "Batch 55: loss = 0.5044202208518982, acc = 0.828125\n",
      "Batch 56: loss = 0.5444844961166382, acc = 0.8125\n",
      "Batch 57: loss = 0.5973691940307617, acc = 0.8115234375\n",
      "Batch 58: loss = 0.6718454957008362, acc = 0.7802734375\n",
      "Batch 59: loss = 0.45048731565475464, acc = 0.857421875\n",
      "Batch 60: loss = 0.54607093334198, acc = 0.814453125\n",
      "Batch 61: loss = 0.5391895174980164, acc = 0.826171875\n",
      "Batch 62: loss = 0.6622382402420044, acc = 0.7802734375\n",
      "Batch 63: loss = 0.6080931425094604, acc = 0.7978515625\n",
      "Batch 64: loss = 0.48427534103393555, acc = 0.8330078125\n",
      "Batch 65: loss = 0.599036693572998, acc = 0.8125\n",
      "Batch 66: loss = 0.5791081190109253, acc = 0.8095703125\n",
      "Batch 67: loss = 0.5385431051254272, acc = 0.814453125\n",
      "Batch 68: loss = 0.6481170654296875, acc = 0.7783203125\n",
      "Batch 69: loss = 0.5539594888687134, acc = 0.8134765625\n",
      "Batch 70: loss = 0.6442281603813171, acc = 0.7939453125\n",
      "Batch 71: loss = 0.5939103364944458, acc = 0.80078125\n",
      "Batch 72: loss = 0.553797721862793, acc = 0.814453125\n",
      "Batch 73: loss = 0.6448431015014648, acc = 0.7890625\n",
      "Batch 74: loss = 0.6104878187179565, acc = 0.7890625\n",
      "Batch 75: loss = 0.7012161016464233, acc = 0.76953125\n",
      "Batch 76: loss = 0.657545268535614, acc = 0.77734375\n",
      "Batch 77: loss = 0.6116656064987183, acc = 0.794921875\n",
      "Batch 78: loss = 0.6151074171066284, acc = 0.7958984375\n",
      "Batch 79: loss = 0.5510787963867188, acc = 0.8095703125\n",
      "Batch 80: loss = 0.5460667610168457, acc = 0.81640625\n",
      "Batch 81: loss = 0.602159857749939, acc = 0.8037109375\n",
      "Batch 82: loss = 0.559798002243042, acc = 0.81640625\n",
      "Batch 83: loss = 0.5653375387191772, acc = 0.8154296875\n",
      "Batch 84: loss = 0.5761460065841675, acc = 0.8095703125\n",
      "Batch 85: loss = 0.6551050543785095, acc = 0.7861328125\n",
      "Batch 86: loss = 0.6329583525657654, acc = 0.796875\n",
      "Batch 87: loss = 0.6003774404525757, acc = 0.794921875\n",
      "Batch 88: loss = 0.7046091556549072, acc = 0.7578125\n",
      "Batch 89: loss = 0.6015292406082153, acc = 0.8125\n",
      "Batch 90: loss = 0.6227969527244568, acc = 0.7958984375\n",
      "Batch 91: loss = 0.6255928874015808, acc = 0.7880859375\n",
      "Batch 92: loss = 0.6161023378372192, acc = 0.7841796875\n",
      "Batch 93: loss = 0.5020703077316284, acc = 0.8388671875\n",
      "Batch 94: loss = 0.5290342569351196, acc = 0.828125\n",
      "Batch 95: loss = 0.559581458568573, acc = 0.8115234375\n",
      "Batch 96: loss = 0.6459575891494751, acc = 0.787109375\n",
      "Batch 97: loss = 0.5952955484390259, acc = 0.80078125\n",
      "Batch 98: loss = 0.5640363097190857, acc = 0.8203125\n",
      "Batch 99: loss = 0.6025278568267822, acc = 0.7890625\n",
      "Batch 100: loss = 0.6134160757064819, acc = 0.783203125\n",
      "Batch 101: loss = 0.5807550549507141, acc = 0.8134765625\n",
      "Batch 102: loss = 0.6149117350578308, acc = 0.7900390625\n",
      "Batch 103: loss = 0.5681203603744507, acc = 0.8056640625\n",
      "Batch 104: loss = 0.53265380859375, acc = 0.8125\n",
      "Batch 105: loss = 0.5448108911514282, acc = 0.822265625\n",
      "Batch 106: loss = 0.6222928762435913, acc = 0.7958984375\n",
      "Batch 107: loss = 0.5751948356628418, acc = 0.8056640625\n",
      "Batch 108: loss = 0.5899174809455872, acc = 0.8046875\n",
      "Batch 109: loss = 0.6016320586204529, acc = 0.78125\n",
      "Batch 110: loss = 0.49486544728279114, acc = 0.845703125\n",
      "Batch 111: loss = 0.644068717956543, acc = 0.7822265625\n",
      "Batch 112: loss = 0.5931061506271362, acc = 0.8037109375\n",
      "Batch 113: loss = 0.5948690176010132, acc = 0.802734375\n",
      "Batch 114: loss = 0.6046757698059082, acc = 0.8056640625\n",
      "Batch 115: loss = 0.6002124547958374, acc = 0.8046875\n",
      "Batch 116: loss = 0.6388022899627686, acc = 0.783203125\n",
      "Batch 117: loss = 0.5682127475738525, acc = 0.8232421875\n",
      "Batch 118: loss = 0.49771517515182495, acc = 0.8369140625\n",
      "Batch 119: loss = 0.5980626344680786, acc = 0.7998046875\n",
      "Batch 120: loss = 0.6075538396835327, acc = 0.80078125\n",
      "Batch 121: loss = 0.6308936476707458, acc = 0.8173828125\n",
      "Batch 122: loss = 0.560889482498169, acc = 0.8134765625\n",
      "Batch 123: loss = 0.5797239542007446, acc = 0.8203125\n",
      "Batch 124: loss = 0.625389575958252, acc = 0.794921875\n",
      "Batch 125: loss = 0.6355361938476562, acc = 0.7919921875\n",
      "Batch 126: loss = 0.6383848190307617, acc = 0.79296875\n",
      "\n",
      "Epoch 43/100\n",
      "Batch 1: loss = 0.7070831060409546, acc = 0.7802734375\n",
      "Batch 2: loss = 0.6692038178443909, acc = 0.7666015625\n",
      "Batch 3: loss = 0.6411060094833374, acc = 0.80078125\n",
      "Batch 4: loss = 0.5528967380523682, acc = 0.818359375\n",
      "Batch 5: loss = 0.6338092088699341, acc = 0.791015625\n",
      "Batch 6: loss = 0.6226234436035156, acc = 0.7998046875\n",
      "Batch 7: loss = 0.5639204978942871, acc = 0.826171875\n",
      "Batch 8: loss = 0.5754079818725586, acc = 0.8115234375\n",
      "Batch 9: loss = 0.5574171543121338, acc = 0.81640625\n",
      "Batch 10: loss = 0.4967503249645233, acc = 0.833984375\n",
      "Batch 11: loss = 0.6299892663955688, acc = 0.798828125\n",
      "Batch 12: loss = 0.5659322738647461, acc = 0.802734375\n",
      "Batch 13: loss = 0.5365374088287354, acc = 0.828125\n",
      "Batch 14: loss = 0.5612263083457947, acc = 0.8271484375\n",
      "Batch 15: loss = 0.5211232900619507, acc = 0.8349609375\n",
      "Batch 16: loss = 0.603422224521637, acc = 0.806640625\n",
      "Batch 17: loss = 0.5935578346252441, acc = 0.806640625\n",
      "Batch 18: loss = 0.6204737424850464, acc = 0.79296875\n",
      "Batch 19: loss = 0.5603775978088379, acc = 0.82421875\n",
      "Batch 20: loss = 0.5864509344100952, acc = 0.8134765625\n",
      "Batch 21: loss = 0.5927027463912964, acc = 0.8046875\n",
      "Batch 22: loss = 0.5606507062911987, acc = 0.806640625\n",
      "Batch 23: loss = 0.6045145988464355, acc = 0.78125\n",
      "Batch 24: loss = 0.543596625328064, acc = 0.810546875\n",
      "Batch 25: loss = 0.5234028697013855, acc = 0.828125\n",
      "Batch 26: loss = 0.5424007177352905, acc = 0.8134765625\n",
      "Batch 27: loss = 0.6630037426948547, acc = 0.779296875\n",
      "Batch 28: loss = 0.601538896560669, acc = 0.7919921875\n",
      "Batch 29: loss = 0.5693700909614563, acc = 0.8046875\n",
      "Batch 30: loss = 0.5433136224746704, acc = 0.8369140625\n",
      "Batch 31: loss = 0.6178407669067383, acc = 0.8095703125\n",
      "Batch 32: loss = 0.669241189956665, acc = 0.78515625\n",
      "Batch 33: loss = 0.562669038772583, acc = 0.80078125\n",
      "Batch 34: loss = 0.597608208656311, acc = 0.798828125\n",
      "Batch 35: loss = 0.5657578706741333, acc = 0.8212890625\n",
      "Batch 36: loss = 0.5492854118347168, acc = 0.818359375\n",
      "Batch 37: loss = 0.5149925947189331, acc = 0.8369140625\n",
      "Batch 38: loss = 0.5489581227302551, acc = 0.8134765625\n",
      "Batch 39: loss = 0.5358073115348816, acc = 0.8232421875\n",
      "Batch 40: loss = 0.5658308267593384, acc = 0.8115234375\n",
      "Batch 41: loss = 0.50577712059021, acc = 0.8212890625\n",
      "Batch 42: loss = 0.565068244934082, acc = 0.8154296875\n",
      "Batch 43: loss = 0.6319500207901001, acc = 0.7890625\n",
      "Batch 44: loss = 0.5229904651641846, acc = 0.83203125\n",
      "Batch 45: loss = 0.5010645389556885, acc = 0.8310546875\n",
      "Batch 46: loss = 0.5447661280632019, acc = 0.8095703125\n",
      "Batch 47: loss = 0.536290168762207, acc = 0.8232421875\n",
      "Batch 48: loss = 0.5024038553237915, acc = 0.837890625\n",
      "Batch 49: loss = 0.498365193605423, acc = 0.845703125\n",
      "Batch 50: loss = 0.525741457939148, acc = 0.83203125\n",
      "Batch 51: loss = 0.5012141466140747, acc = 0.830078125\n",
      "Batch 52: loss = 0.5865887999534607, acc = 0.810546875\n",
      "Batch 53: loss = 0.5630232691764832, acc = 0.8203125\n",
      "Batch 54: loss = 0.48260173201560974, acc = 0.8466796875\n",
      "Batch 55: loss = 0.5203914642333984, acc = 0.8193359375\n",
      "Batch 56: loss = 0.5760074853897095, acc = 0.791015625\n",
      "Batch 57: loss = 0.6283823251724243, acc = 0.7841796875\n",
      "Batch 58: loss = 0.6293823719024658, acc = 0.7822265625\n",
      "Batch 59: loss = 0.45770370960235596, acc = 0.84375\n",
      "Batch 60: loss = 0.5439810752868652, acc = 0.828125\n",
      "Batch 61: loss = 0.5405725240707397, acc = 0.8271484375\n",
      "Batch 62: loss = 0.6794236302375793, acc = 0.7734375\n",
      "Batch 63: loss = 0.6222333908081055, acc = 0.787109375\n",
      "Batch 64: loss = 0.4843516945838928, acc = 0.8349609375\n",
      "Batch 65: loss = 0.5805749893188477, acc = 0.7978515625\n",
      "Batch 66: loss = 0.5561826825141907, acc = 0.8203125\n",
      "Batch 67: loss = 0.5204652547836304, acc = 0.833984375\n",
      "Batch 68: loss = 0.5953109264373779, acc = 0.7939453125\n",
      "Batch 69: loss = 0.540412425994873, acc = 0.8251953125\n",
      "Batch 70: loss = 0.637641191482544, acc = 0.791015625\n",
      "Batch 71: loss = 0.5916147828102112, acc = 0.80078125\n",
      "Batch 72: loss = 0.54936683177948, acc = 0.8173828125\n",
      "Batch 73: loss = 0.6213558316230774, acc = 0.802734375\n",
      "Batch 74: loss = 0.5988706350326538, acc = 0.7880859375\n",
      "Batch 75: loss = 0.6757063865661621, acc = 0.78125\n",
      "Batch 76: loss = 0.6374361515045166, acc = 0.7890625\n",
      "Batch 77: loss = 0.5652329921722412, acc = 0.806640625\n",
      "Batch 78: loss = 0.599536657333374, acc = 0.8056640625\n",
      "Batch 79: loss = 0.5521847605705261, acc = 0.8095703125\n",
      "Batch 80: loss = 0.5248895883560181, acc = 0.802734375\n",
      "Batch 81: loss = 0.5775649547576904, acc = 0.8046875\n",
      "Batch 82: loss = 0.5501121878623962, acc = 0.8291015625\n",
      "Batch 83: loss = 0.5415037870407104, acc = 0.822265625\n",
      "Batch 84: loss = 0.563407301902771, acc = 0.8076171875\n",
      "Batch 85: loss = 0.626550555229187, acc = 0.7939453125\n",
      "Batch 86: loss = 0.588352620601654, acc = 0.8056640625\n",
      "Batch 87: loss = 0.5624057054519653, acc = 0.8017578125\n",
      "Batch 88: loss = 0.6769986152648926, acc = 0.7783203125\n",
      "Batch 89: loss = 0.5979819297790527, acc = 0.7939453125\n",
      "Batch 90: loss = 0.6232955455780029, acc = 0.7998046875\n",
      "Batch 91: loss = 0.6052858233451843, acc = 0.802734375\n",
      "Batch 92: loss = 0.5895200967788696, acc = 0.802734375\n",
      "Batch 93: loss = 0.5114444494247437, acc = 0.8330078125\n",
      "Batch 94: loss = 0.5423282980918884, acc = 0.81640625\n",
      "Batch 95: loss = 0.5435067415237427, acc = 0.8037109375\n",
      "Batch 96: loss = 0.6398355960845947, acc = 0.779296875\n",
      "Batch 97: loss = 0.5867476463317871, acc = 0.8203125\n",
      "Batch 98: loss = 0.5870668888092041, acc = 0.802734375\n",
      "Batch 99: loss = 0.59988933801651, acc = 0.78515625\n",
      "Batch 100: loss = 0.5766865611076355, acc = 0.7958984375\n",
      "Batch 101: loss = 0.5678709149360657, acc = 0.8125\n",
      "Batch 102: loss = 0.6020580530166626, acc = 0.8056640625\n",
      "Batch 103: loss = 0.5426542162895203, acc = 0.818359375\n",
      "Batch 104: loss = 0.5336071252822876, acc = 0.814453125\n",
      "Batch 105: loss = 0.5463967323303223, acc = 0.822265625\n",
      "Batch 106: loss = 0.6139394044876099, acc = 0.7880859375\n",
      "Batch 107: loss = 0.560614287853241, acc = 0.810546875\n",
      "Batch 108: loss = 0.6048921942710876, acc = 0.79296875\n",
      "Batch 109: loss = 0.5781086683273315, acc = 0.8125\n",
      "Batch 110: loss = 0.4936637282371521, acc = 0.8369140625\n",
      "Batch 111: loss = 0.6347355246543884, acc = 0.783203125\n",
      "Batch 112: loss = 0.5716344714164734, acc = 0.814453125\n",
      "Batch 113: loss = 0.5669119358062744, acc = 0.8076171875\n",
      "Batch 114: loss = 0.5950690507888794, acc = 0.814453125\n",
      "Batch 115: loss = 0.6048852205276489, acc = 0.8056640625\n",
      "Batch 116: loss = 0.6141471862792969, acc = 0.7939453125\n",
      "Batch 117: loss = 0.5373216867446899, acc = 0.822265625\n",
      "Batch 118: loss = 0.4924030900001526, acc = 0.830078125\n",
      "Batch 119: loss = 0.5688506960868835, acc = 0.80859375\n",
      "Batch 120: loss = 0.5840809345245361, acc = 0.810546875\n",
      "Batch 121: loss = 0.6286216974258423, acc = 0.7939453125\n",
      "Batch 122: loss = 0.5367690324783325, acc = 0.8203125\n",
      "Batch 123: loss = 0.5717461109161377, acc = 0.80859375\n",
      "Batch 124: loss = 0.6293924450874329, acc = 0.7841796875\n",
      "Batch 125: loss = 0.5954487323760986, acc = 0.7998046875\n",
      "Batch 126: loss = 0.5933271646499634, acc = 0.80859375\n",
      "\n",
      "Epoch 44/100\n",
      "Batch 1: loss = 0.6989977359771729, acc = 0.7822265625\n",
      "Batch 2: loss = 0.6209396719932556, acc = 0.7822265625\n",
      "Batch 3: loss = 0.5901643633842468, acc = 0.8125\n",
      "Batch 4: loss = 0.5645149946212769, acc = 0.8095703125\n",
      "Batch 5: loss = 0.6201440691947937, acc = 0.7998046875\n",
      "Batch 6: loss = 0.654344916343689, acc = 0.7939453125\n",
      "Batch 7: loss = 0.5485645532608032, acc = 0.8173828125\n",
      "Batch 8: loss = 0.6022095680236816, acc = 0.802734375\n",
      "Batch 9: loss = 0.597734272480011, acc = 0.81640625\n",
      "Batch 10: loss = 0.5034359693527222, acc = 0.82421875\n",
      "Batch 11: loss = 0.5976500511169434, acc = 0.7978515625\n",
      "Batch 12: loss = 0.5748768448829651, acc = 0.8017578125\n",
      "Batch 13: loss = 0.5162414908409119, acc = 0.822265625\n",
      "Batch 14: loss = 0.5870024561882019, acc = 0.8134765625\n",
      "Batch 15: loss = 0.4889693558216095, acc = 0.84375\n",
      "Batch 16: loss = 0.6034377813339233, acc = 0.798828125\n",
      "Batch 17: loss = 0.6043250560760498, acc = 0.81640625\n",
      "Batch 18: loss = 0.6282215118408203, acc = 0.7958984375\n",
      "Batch 19: loss = 0.5639940500259399, acc = 0.7998046875\n",
      "Batch 20: loss = 0.5550333857536316, acc = 0.8193359375\n",
      "Batch 21: loss = 0.6166560649871826, acc = 0.78125\n",
      "Batch 22: loss = 0.5606362819671631, acc = 0.806640625\n",
      "Batch 23: loss = 0.5587825775146484, acc = 0.7998046875\n",
      "Batch 24: loss = 0.5689724683761597, acc = 0.80078125\n",
      "Batch 25: loss = 0.5513822436332703, acc = 0.8251953125\n",
      "Batch 26: loss = 0.5678379535675049, acc = 0.8095703125\n",
      "Batch 27: loss = 0.6440907120704651, acc = 0.7919921875\n",
      "Batch 28: loss = 0.595862865447998, acc = 0.7958984375\n",
      "Batch 29: loss = 0.5713048577308655, acc = 0.828125\n",
      "Batch 30: loss = 0.5212529897689819, acc = 0.828125\n",
      "Batch 31: loss = 0.5855420827865601, acc = 0.8125\n",
      "Batch 32: loss = 0.6533079147338867, acc = 0.7802734375\n",
      "Batch 33: loss = 0.565222978591919, acc = 0.80859375\n",
      "Batch 34: loss = 0.5944496393203735, acc = 0.7978515625\n",
      "Batch 35: loss = 0.5590623617172241, acc = 0.8125\n",
      "Batch 36: loss = 0.5191870927810669, acc = 0.828125\n",
      "Batch 37: loss = 0.48728305101394653, acc = 0.837890625\n",
      "Batch 38: loss = 0.5432325005531311, acc = 0.818359375\n",
      "Batch 39: loss = 0.53341144323349, acc = 0.826171875\n",
      "Batch 40: loss = 0.5590746402740479, acc = 0.8046875\n",
      "Batch 41: loss = 0.49211716651916504, acc = 0.8271484375\n",
      "Batch 42: loss = 0.5341955423355103, acc = 0.822265625\n",
      "Batch 43: loss = 0.5839880704879761, acc = 0.7900390625\n",
      "Batch 44: loss = 0.5133317112922668, acc = 0.8359375\n",
      "Batch 45: loss = 0.4878714680671692, acc = 0.8359375\n",
      "Batch 46: loss = 0.5243325233459473, acc = 0.826171875\n",
      "Batch 47: loss = 0.5562621355056763, acc = 0.8134765625\n",
      "Batch 48: loss = 0.5214011073112488, acc = 0.81640625\n",
      "Batch 49: loss = 0.48877882957458496, acc = 0.841796875\n",
      "Batch 50: loss = 0.4886648654937744, acc = 0.8408203125\n",
      "Batch 51: loss = 0.520380973815918, acc = 0.8193359375\n",
      "Batch 52: loss = 0.5115288496017456, acc = 0.8310546875\n",
      "Batch 53: loss = 0.5569636821746826, acc = 0.8125\n",
      "Batch 54: loss = 0.4773572087287903, acc = 0.8447265625\n",
      "Batch 55: loss = 0.4658935070037842, acc = 0.8408203125\n",
      "Batch 56: loss = 0.5287895202636719, acc = 0.8125\n",
      "Batch 57: loss = 0.6066581010818481, acc = 0.78515625\n",
      "Batch 58: loss = 0.6362451314926147, acc = 0.791015625\n",
      "Batch 59: loss = 0.47002407908439636, acc = 0.84375\n",
      "Batch 60: loss = 0.5314275622367859, acc = 0.8203125\n",
      "Batch 61: loss = 0.5431135892868042, acc = 0.8115234375\n",
      "Batch 62: loss = 0.6275266408920288, acc = 0.8017578125\n",
      "Batch 63: loss = 0.5881126523017883, acc = 0.8056640625\n",
      "Batch 64: loss = 0.4744608998298645, acc = 0.84765625\n",
      "Batch 65: loss = 0.5789597034454346, acc = 0.80859375\n",
      "Batch 66: loss = 0.5577353239059448, acc = 0.8115234375\n",
      "Batch 67: loss = 0.520266056060791, acc = 0.822265625\n",
      "Batch 68: loss = 0.6001450419425964, acc = 0.8017578125\n",
      "Batch 69: loss = 0.5223739147186279, acc = 0.8173828125\n",
      "Batch 70: loss = 0.6293261051177979, acc = 0.7900390625\n",
      "Batch 71: loss = 0.5526689291000366, acc = 0.8212890625\n",
      "Batch 72: loss = 0.5321932435035706, acc = 0.83203125\n",
      "Batch 73: loss = 0.6286435127258301, acc = 0.7890625\n",
      "Batch 74: loss = 0.5948299169540405, acc = 0.7978515625\n",
      "Batch 75: loss = 0.6479607820510864, acc = 0.78515625\n",
      "Batch 76: loss = 0.6221834421157837, acc = 0.7919921875\n",
      "Batch 77: loss = 0.5458744168281555, acc = 0.8271484375\n",
      "Batch 78: loss = 0.5812108516693115, acc = 0.818359375\n",
      "Batch 79: loss = 0.5643922090530396, acc = 0.80078125\n",
      "Batch 80: loss = 0.5428794622421265, acc = 0.8115234375\n",
      "Batch 81: loss = 0.5834745168685913, acc = 0.810546875\n",
      "Batch 82: loss = 0.5089214444160461, acc = 0.833984375\n",
      "Batch 83: loss = 0.5375497937202454, acc = 0.8310546875\n",
      "Batch 84: loss = 0.5638996362686157, acc = 0.81640625\n",
      "Batch 85: loss = 0.6043175458908081, acc = 0.787109375\n",
      "Batch 86: loss = 0.6003124713897705, acc = 0.7998046875\n",
      "Batch 87: loss = 0.5530640482902527, acc = 0.81640625\n",
      "Batch 88: loss = 0.6606404185295105, acc = 0.7861328125\n",
      "Batch 89: loss = 0.5760291814804077, acc = 0.8173828125\n",
      "Batch 90: loss = 0.616115391254425, acc = 0.7939453125\n",
      "Batch 91: loss = 0.5847558379173279, acc = 0.8046875\n",
      "Batch 92: loss = 0.5978152751922607, acc = 0.7919921875\n",
      "Batch 93: loss = 0.4824981093406677, acc = 0.845703125\n",
      "Batch 94: loss = 0.5037692785263062, acc = 0.845703125\n",
      "Batch 95: loss = 0.5272489786148071, acc = 0.8193359375\n",
      "Batch 96: loss = 0.5785822868347168, acc = 0.796875\n",
      "Batch 97: loss = 0.6108463406562805, acc = 0.7998046875\n",
      "Batch 98: loss = 0.5383020043373108, acc = 0.828125\n",
      "Batch 99: loss = 0.606191098690033, acc = 0.7939453125\n",
      "Batch 100: loss = 0.5886808633804321, acc = 0.7890625\n",
      "Batch 101: loss = 0.5596257448196411, acc = 0.81640625\n",
      "Batch 102: loss = 0.6055188775062561, acc = 0.8017578125\n",
      "Batch 103: loss = 0.5321516990661621, acc = 0.82421875\n",
      "Batch 104: loss = 0.5190220475196838, acc = 0.828125\n",
      "Batch 105: loss = 0.5113717317581177, acc = 0.82421875\n",
      "Batch 106: loss = 0.5863099098205566, acc = 0.798828125\n",
      "Batch 107: loss = 0.5702019929885864, acc = 0.814453125\n",
      "Batch 108: loss = 0.5545656681060791, acc = 0.818359375\n",
      "Batch 109: loss = 0.5859758853912354, acc = 0.791015625\n",
      "Batch 110: loss = 0.5308881998062134, acc = 0.8271484375\n",
      "Batch 111: loss = 0.6106542348861694, acc = 0.7978515625\n",
      "Batch 112: loss = 0.5708034634590149, acc = 0.81640625\n",
      "Batch 113: loss = 0.5808290839195251, acc = 0.8203125\n",
      "Batch 114: loss = 0.5713560581207275, acc = 0.8193359375\n",
      "Batch 115: loss = 0.5856624841690063, acc = 0.818359375\n",
      "Batch 116: loss = 0.613768994808197, acc = 0.802734375\n",
      "Batch 117: loss = 0.5215537548065186, acc = 0.83203125\n",
      "Batch 118: loss = 0.47585099935531616, acc = 0.8388671875\n",
      "Batch 119: loss = 0.5527245998382568, acc = 0.8154296875\n",
      "Batch 120: loss = 0.5702968835830688, acc = 0.80859375\n",
      "Batch 121: loss = 0.5951830148696899, acc = 0.8193359375\n",
      "Batch 122: loss = 0.5176957845687866, acc = 0.8291015625\n",
      "Batch 123: loss = 0.5596984624862671, acc = 0.8193359375\n",
      "Batch 124: loss = 0.6104645133018494, acc = 0.7783203125\n",
      "Batch 125: loss = 0.6332077980041504, acc = 0.796875\n",
      "Batch 126: loss = 0.6310144066810608, acc = 0.787109375\n",
      "\n",
      "Epoch 45/100\n",
      "Batch 1: loss = 0.6902377605438232, acc = 0.794921875\n",
      "Batch 2: loss = 0.6383895874023438, acc = 0.779296875\n",
      "Batch 3: loss = 0.6049740314483643, acc = 0.7998046875\n",
      "Batch 4: loss = 0.5417038202285767, acc = 0.8173828125\n",
      "Batch 5: loss = 0.5907409191131592, acc = 0.8037109375\n",
      "Batch 6: loss = 0.6175214052200317, acc = 0.787109375\n",
      "Batch 7: loss = 0.5547401905059814, acc = 0.8115234375\n",
      "Batch 8: loss = 0.5846918225288391, acc = 0.8115234375\n",
      "Batch 9: loss = 0.543417751789093, acc = 0.826171875\n",
      "Batch 10: loss = 0.5175617933273315, acc = 0.8330078125\n",
      "Batch 11: loss = 0.5958888530731201, acc = 0.8134765625\n",
      "Batch 12: loss = 0.5865101218223572, acc = 0.798828125\n",
      "Batch 13: loss = 0.5472012162208557, acc = 0.8125\n",
      "Batch 14: loss = 0.5826746225357056, acc = 0.814453125\n",
      "Batch 15: loss = 0.5061872005462646, acc = 0.837890625\n",
      "Batch 16: loss = 0.6214935183525085, acc = 0.794921875\n",
      "Batch 17: loss = 0.581922173500061, acc = 0.8115234375\n",
      "Batch 18: loss = 0.5922321081161499, acc = 0.814453125\n",
      "Batch 19: loss = 0.5459088683128357, acc = 0.814453125\n",
      "Batch 20: loss = 0.5410232543945312, acc = 0.8154296875\n",
      "Batch 21: loss = 0.5881767868995667, acc = 0.80859375\n",
      "Batch 22: loss = 0.5363332629203796, acc = 0.810546875\n",
      "Batch 23: loss = 0.5727688670158386, acc = 0.802734375\n",
      "Batch 24: loss = 0.5374885201454163, acc = 0.810546875\n",
      "Batch 25: loss = 0.5557068586349487, acc = 0.8125\n",
      "Batch 26: loss = 0.5444672107696533, acc = 0.828125\n",
      "Batch 27: loss = 0.6363446712493896, acc = 0.7978515625\n",
      "Batch 28: loss = 0.6008848547935486, acc = 0.794921875\n",
      "Batch 29: loss = 0.5994313955307007, acc = 0.80078125\n",
      "Batch 30: loss = 0.5228317975997925, acc = 0.8310546875\n",
      "Batch 31: loss = 0.5782160758972168, acc = 0.806640625\n",
      "Batch 32: loss = 0.6457624435424805, acc = 0.7861328125\n",
      "Batch 33: loss = 0.53276127576828, acc = 0.8203125\n",
      "Batch 34: loss = 0.5905063152313232, acc = 0.806640625\n",
      "Batch 35: loss = 0.5354867577552795, acc = 0.82421875\n",
      "Batch 36: loss = 0.5203001499176025, acc = 0.82421875\n",
      "Batch 37: loss = 0.47593235969543457, acc = 0.857421875\n",
      "Batch 38: loss = 0.5358846187591553, acc = 0.8271484375\n",
      "Batch 39: loss = 0.5321093797683716, acc = 0.818359375\n",
      "Batch 40: loss = 0.5542595386505127, acc = 0.8095703125\n",
      "Batch 41: loss = 0.4896121919155121, acc = 0.8447265625\n",
      "Batch 42: loss = 0.5401439070701599, acc = 0.8212890625\n",
      "Batch 43: loss = 0.5695355534553528, acc = 0.7978515625\n",
      "Batch 44: loss = 0.5005375742912292, acc = 0.8369140625\n",
      "Batch 45: loss = 0.4651772379875183, acc = 0.8466796875\n",
      "Batch 46: loss = 0.5269203186035156, acc = 0.8271484375\n",
      "Batch 47: loss = 0.5433241128921509, acc = 0.8251953125\n",
      "Batch 48: loss = 0.5112317204475403, acc = 0.8369140625\n",
      "Batch 49: loss = 0.4785504639148712, acc = 0.8486328125\n",
      "Batch 50: loss = 0.4589889645576477, acc = 0.8564453125\n",
      "Batch 51: loss = 0.4771386682987213, acc = 0.8203125\n",
      "Batch 52: loss = 0.5825169086456299, acc = 0.8154296875\n",
      "Batch 53: loss = 0.5144755840301514, acc = 0.822265625\n",
      "Batch 54: loss = 0.4402945339679718, acc = 0.853515625\n",
      "Batch 55: loss = 0.4756346344947815, acc = 0.8427734375\n",
      "Batch 56: loss = 0.5082263946533203, acc = 0.8251953125\n",
      "Batch 57: loss = 0.5966264009475708, acc = 0.8017578125\n",
      "Batch 58: loss = 0.6314995288848877, acc = 0.7861328125\n",
      "Batch 59: loss = 0.43768632411956787, acc = 0.8564453125\n",
      "Batch 60: loss = 0.554402232170105, acc = 0.8173828125\n",
      "Batch 61: loss = 0.5321186184883118, acc = 0.8349609375\n",
      "Batch 62: loss = 0.6441987752914429, acc = 0.7822265625\n",
      "Batch 63: loss = 0.5454753637313843, acc = 0.8232421875\n",
      "Batch 64: loss = 0.46807509660720825, acc = 0.8408203125\n",
      "Batch 65: loss = 0.5630912184715271, acc = 0.822265625\n",
      "Batch 66: loss = 0.5374020338058472, acc = 0.8271484375\n",
      "Batch 67: loss = 0.5103188753128052, acc = 0.8388671875\n",
      "Batch 68: loss = 0.5519168376922607, acc = 0.8134765625\n",
      "Batch 69: loss = 0.4979281425476074, acc = 0.83984375\n",
      "Batch 70: loss = 0.5844409465789795, acc = 0.8125\n",
      "Batch 71: loss = 0.5476980805397034, acc = 0.8193359375\n",
      "Batch 72: loss = 0.5061479806900024, acc = 0.84375\n",
      "Batch 73: loss = 0.5989813804626465, acc = 0.80078125\n",
      "Batch 74: loss = 0.594440221786499, acc = 0.80078125\n",
      "Batch 75: loss = 0.6368018388748169, acc = 0.7900390625\n",
      "Batch 76: loss = 0.6171407103538513, acc = 0.794921875\n",
      "Batch 77: loss = 0.5295183658599854, acc = 0.8193359375\n",
      "Batch 78: loss = 0.5725880265235901, acc = 0.8134765625\n",
      "Batch 79: loss = 0.5086373686790466, acc = 0.82421875\n",
      "Batch 80: loss = 0.5464690923690796, acc = 0.8203125\n",
      "Batch 81: loss = 0.5474692583084106, acc = 0.814453125\n",
      "Batch 82: loss = 0.5429578423500061, acc = 0.822265625\n",
      "Batch 83: loss = 0.5202447175979614, acc = 0.828125\n",
      "Batch 84: loss = 0.5581366419792175, acc = 0.8115234375\n",
      "Batch 85: loss = 0.6010308265686035, acc = 0.7998046875\n",
      "Batch 86: loss = 0.5610450506210327, acc = 0.822265625\n",
      "Batch 87: loss = 0.5189342498779297, acc = 0.8076171875\n",
      "Batch 88: loss = 0.675674319267273, acc = 0.767578125\n",
      "Batch 89: loss = 0.5614928007125854, acc = 0.830078125\n",
      "Batch 90: loss = 0.597260594367981, acc = 0.796875\n",
      "Batch 91: loss = 0.5749509334564209, acc = 0.80078125\n",
      "Batch 92: loss = 0.5678034424781799, acc = 0.8095703125\n",
      "Batch 93: loss = 0.4662055969238281, acc = 0.8447265625\n",
      "Batch 94: loss = 0.4619799256324768, acc = 0.8564453125\n",
      "Batch 95: loss = 0.5053111910820007, acc = 0.8330078125\n",
      "Batch 96: loss = 0.586803674697876, acc = 0.7998046875\n",
      "Batch 97: loss = 0.5802698135375977, acc = 0.802734375\n",
      "Batch 98: loss = 0.5358703136444092, acc = 0.8291015625\n",
      "Batch 99: loss = 0.5622406601905823, acc = 0.8271484375\n",
      "Batch 100: loss = 0.5905278325080872, acc = 0.796875\n",
      "Batch 101: loss = 0.5296103358268738, acc = 0.8193359375\n",
      "Batch 102: loss = 0.5759268999099731, acc = 0.810546875\n",
      "Batch 103: loss = 0.5518977642059326, acc = 0.8193359375\n",
      "Batch 104: loss = 0.5253021717071533, acc = 0.8212890625\n",
      "Batch 105: loss = 0.5177448987960815, acc = 0.830078125\n",
      "Batch 106: loss = 0.5661660432815552, acc = 0.7958984375\n",
      "Batch 107: loss = 0.515949010848999, acc = 0.8330078125\n",
      "Batch 108: loss = 0.5591411590576172, acc = 0.8154296875\n",
      "Batch 109: loss = 0.5302151441574097, acc = 0.826171875\n",
      "Batch 110: loss = 0.5259138941764832, acc = 0.82421875\n",
      "Batch 111: loss = 0.5776386857032776, acc = 0.802734375\n",
      "Batch 112: loss = 0.5384116172790527, acc = 0.8203125\n",
      "Batch 113: loss = 0.5721808671951294, acc = 0.8115234375\n",
      "Batch 114: loss = 0.5558155179023743, acc = 0.8232421875\n",
      "Batch 115: loss = 0.554737389087677, acc = 0.8154296875\n",
      "Batch 116: loss = 0.6088132858276367, acc = 0.7890625\n",
      "Batch 117: loss = 0.4949943423271179, acc = 0.833984375\n",
      "Batch 118: loss = 0.4666229486465454, acc = 0.845703125\n",
      "Batch 119: loss = 0.5386005640029907, acc = 0.8232421875\n",
      "Batch 120: loss = 0.5679396986961365, acc = 0.8037109375\n",
      "Batch 121: loss = 0.5700778365135193, acc = 0.8095703125\n",
      "Batch 122: loss = 0.518019437789917, acc = 0.8271484375\n",
      "Batch 123: loss = 0.5943930149078369, acc = 0.8076171875\n",
      "Batch 124: loss = 0.5923723578453064, acc = 0.7939453125\n",
      "Batch 125: loss = 0.5885005593299866, acc = 0.8076171875\n",
      "Batch 126: loss = 0.5918151140213013, acc = 0.814453125\n",
      "\n",
      "Epoch 46/100\n",
      "Batch 1: loss = 0.6722567677497864, acc = 0.79296875\n",
      "Batch 2: loss = 0.6406580805778503, acc = 0.783203125\n",
      "Batch 3: loss = 0.586213231086731, acc = 0.806640625\n",
      "Batch 4: loss = 0.5388401746749878, acc = 0.8271484375\n",
      "Batch 5: loss = 0.5876611471176147, acc = 0.80078125\n",
      "Batch 6: loss = 0.624241828918457, acc = 0.7880859375\n",
      "Batch 7: loss = 0.5579252243041992, acc = 0.8125\n",
      "Batch 8: loss = 0.5381731986999512, acc = 0.81640625\n",
      "Batch 9: loss = 0.513260006904602, acc = 0.837890625\n",
      "Batch 10: loss = 0.4671902656555176, acc = 0.8388671875\n",
      "Batch 11: loss = 0.5746743679046631, acc = 0.81640625\n",
      "Batch 12: loss = 0.5602539777755737, acc = 0.8095703125\n",
      "Batch 13: loss = 0.5143859386444092, acc = 0.83203125\n",
      "Batch 14: loss = 0.5617411136627197, acc = 0.82421875\n",
      "Batch 15: loss = 0.4867331385612488, acc = 0.8486328125\n",
      "Batch 16: loss = 0.5772561430931091, acc = 0.8076171875\n",
      "Batch 17: loss = 0.5897995233535767, acc = 0.8134765625\n",
      "Batch 18: loss = 0.5763976573944092, acc = 0.8037109375\n",
      "Batch 19: loss = 0.5495609045028687, acc = 0.818359375\n",
      "Batch 20: loss = 0.5192407369613647, acc = 0.826171875\n",
      "Batch 21: loss = 0.5678699612617493, acc = 0.7880859375\n",
      "Batch 22: loss = 0.5549120903015137, acc = 0.7958984375\n",
      "Batch 23: loss = 0.5488575100898743, acc = 0.806640625\n",
      "Batch 24: loss = 0.5241742134094238, acc = 0.818359375\n",
      "Batch 25: loss = 0.5407048463821411, acc = 0.8232421875\n",
      "Batch 26: loss = 0.5185126066207886, acc = 0.81640625\n",
      "Batch 27: loss = 0.6255395412445068, acc = 0.798828125\n",
      "Batch 28: loss = 0.5759813785552979, acc = 0.8017578125\n",
      "Batch 29: loss = 0.5578623414039612, acc = 0.81640625\n",
      "Batch 30: loss = 0.5127514600753784, acc = 0.8271484375\n",
      "Batch 31: loss = 0.5686694383621216, acc = 0.8095703125\n",
      "Batch 32: loss = 0.620311975479126, acc = 0.80078125\n",
      "Batch 33: loss = 0.5525143146514893, acc = 0.8056640625\n",
      "Batch 34: loss = 0.5614745020866394, acc = 0.8037109375\n",
      "Batch 35: loss = 0.5286942720413208, acc = 0.8212890625\n",
      "Batch 36: loss = 0.489404559135437, acc = 0.830078125\n",
      "Batch 37: loss = 0.4822808802127838, acc = 0.8310546875\n",
      "Batch 38: loss = 0.534225583076477, acc = 0.830078125\n",
      "Batch 39: loss = 0.528760552406311, acc = 0.833984375\n",
      "Batch 40: loss = 0.5391921997070312, acc = 0.8173828125\n",
      "Batch 41: loss = 0.48974794149398804, acc = 0.8271484375\n",
      "Batch 42: loss = 0.5465529561042786, acc = 0.810546875\n",
      "Batch 43: loss = 0.5731958150863647, acc = 0.7890625\n",
      "Batch 44: loss = 0.458116739988327, acc = 0.849609375\n",
      "Batch 45: loss = 0.5004681348800659, acc = 0.83203125\n",
      "Batch 46: loss = 0.5087916851043701, acc = 0.8212890625\n",
      "Batch 47: loss = 0.5032767653465271, acc = 0.841796875\n",
      "Batch 48: loss = 0.48027172684669495, acc = 0.8251953125\n",
      "Batch 49: loss = 0.43899789452552795, acc = 0.8544921875\n",
      "Batch 50: loss = 0.4559648036956787, acc = 0.8447265625\n",
      "Batch 51: loss = 0.5104714632034302, acc = 0.818359375\n",
      "Batch 52: loss = 0.5580499172210693, acc = 0.8115234375\n",
      "Batch 53: loss = 0.5264022350311279, acc = 0.8291015625\n",
      "Batch 54: loss = 0.4283894896507263, acc = 0.8603515625\n",
      "Batch 55: loss = 0.48461583256721497, acc = 0.8369140625\n",
      "Batch 56: loss = 0.5011401176452637, acc = 0.8291015625\n",
      "Batch 57: loss = 0.5710317492485046, acc = 0.7998046875\n",
      "Batch 58: loss = 0.614737331867218, acc = 0.7841796875\n",
      "Batch 59: loss = 0.42395222187042236, acc = 0.8583984375\n",
      "Batch 60: loss = 0.5351241827011108, acc = 0.826171875\n",
      "Batch 61: loss = 0.5022280216217041, acc = 0.849609375\n",
      "Batch 62: loss = 0.6049866080284119, acc = 0.802734375\n",
      "Batch 63: loss = 0.5446047782897949, acc = 0.814453125\n",
      "Batch 64: loss = 0.4583907723426819, acc = 0.8447265625\n",
      "Batch 65: loss = 0.5415276288986206, acc = 0.818359375\n",
      "Batch 66: loss = 0.5443658828735352, acc = 0.8271484375\n",
      "Batch 67: loss = 0.486123263835907, acc = 0.8427734375\n",
      "Batch 68: loss = 0.5694652795791626, acc = 0.8125\n",
      "Batch 69: loss = 0.47781282663345337, acc = 0.84765625\n",
      "Batch 70: loss = 0.6020627021789551, acc = 0.7890625\n",
      "Batch 71: loss = 0.5601203441619873, acc = 0.8134765625\n",
      "Batch 72: loss = 0.5153040885925293, acc = 0.8349609375\n",
      "Batch 73: loss = 0.5925325155258179, acc = 0.7978515625\n",
      "Batch 74: loss = 0.5637373924255371, acc = 0.7978515625\n",
      "Batch 75: loss = 0.6346563696861267, acc = 0.7705078125\n",
      "Batch 76: loss = 0.626174807548523, acc = 0.7880859375\n",
      "Batch 77: loss = 0.5260090827941895, acc = 0.8212890625\n",
      "Batch 78: loss = 0.5646085143089294, acc = 0.8212890625\n",
      "Batch 79: loss = 0.5072375535964966, acc = 0.8330078125\n",
      "Batch 80: loss = 0.5262945294380188, acc = 0.8056640625\n",
      "Batch 81: loss = 0.537459671497345, acc = 0.8251953125\n",
      "Batch 82: loss = 0.49498939514160156, acc = 0.8427734375\n",
      "Batch 83: loss = 0.52637779712677, acc = 0.81640625\n",
      "Batch 84: loss = 0.5663741827011108, acc = 0.8125\n",
      "Batch 85: loss = 0.589624285697937, acc = 0.8017578125\n",
      "Batch 86: loss = 0.5475359559059143, acc = 0.8193359375\n",
      "Batch 87: loss = 0.5386157035827637, acc = 0.8193359375\n",
      "Batch 88: loss = 0.6443684101104736, acc = 0.7841796875\n",
      "Batch 89: loss = 0.5601809024810791, acc = 0.818359375\n",
      "Batch 90: loss = 0.5839884281158447, acc = 0.814453125\n",
      "Batch 91: loss = 0.575915515422821, acc = 0.8095703125\n",
      "Batch 92: loss = 0.5768582224845886, acc = 0.8056640625\n",
      "Batch 93: loss = 0.4816661477088928, acc = 0.837890625\n",
      "Batch 94: loss = 0.49358174204826355, acc = 0.8349609375\n",
      "Batch 95: loss = 0.5248713493347168, acc = 0.828125\n",
      "Batch 96: loss = 0.5699112415313721, acc = 0.7978515625\n",
      "Batch 97: loss = 0.5924066305160522, acc = 0.8076171875\n",
      "Batch 98: loss = 0.4938598573207855, acc = 0.8427734375\n",
      "Batch 99: loss = 0.5492703914642334, acc = 0.8203125\n",
      "Batch 100: loss = 0.5774047374725342, acc = 0.7919921875\n",
      "Batch 101: loss = 0.5341151356697083, acc = 0.8203125\n",
      "Batch 102: loss = 0.5843914747238159, acc = 0.7998046875\n",
      "Batch 103: loss = 0.5165254473686218, acc = 0.83984375\n",
      "Batch 104: loss = 0.48242390155792236, acc = 0.828125\n",
      "Batch 105: loss = 0.48946595191955566, acc = 0.8330078125\n",
      "Batch 106: loss = 0.5527942180633545, acc = 0.8046875\n",
      "Batch 107: loss = 0.5360792279243469, acc = 0.8115234375\n",
      "Batch 108: loss = 0.5711498260498047, acc = 0.8056640625\n",
      "Batch 109: loss = 0.5501468181610107, acc = 0.814453125\n",
      "Batch 110: loss = 0.5149871110916138, acc = 0.837890625\n",
      "Batch 111: loss = 0.6160372495651245, acc = 0.7880859375\n",
      "Batch 112: loss = 0.5274412631988525, acc = 0.828125\n",
      "Batch 113: loss = 0.5451365113258362, acc = 0.8154296875\n",
      "Batch 114: loss = 0.5474902391433716, acc = 0.814453125\n",
      "Batch 115: loss = 0.5478060245513916, acc = 0.8193359375\n",
      "Batch 116: loss = 0.6025409698486328, acc = 0.8017578125\n",
      "Batch 117: loss = 0.4833943843841553, acc = 0.84375\n",
      "Batch 118: loss = 0.48385339975357056, acc = 0.833984375\n",
      "Batch 119: loss = 0.519850492477417, acc = 0.83203125\n",
      "Batch 120: loss = 0.5619910359382629, acc = 0.8037109375\n",
      "Batch 121: loss = 0.5887231826782227, acc = 0.796875\n",
      "Batch 122: loss = 0.5109385251998901, acc = 0.8271484375\n",
      "Batch 123: loss = 0.5446233749389648, acc = 0.8232421875\n",
      "Batch 124: loss = 0.5669870376586914, acc = 0.80859375\n",
      "Batch 125: loss = 0.5744526982307434, acc = 0.80859375\n",
      "Batch 126: loss = 0.5982075929641724, acc = 0.80859375\n",
      "\n",
      "Epoch 47/100\n",
      "Batch 1: loss = 0.6630843877792358, acc = 0.791015625\n",
      "Batch 2: loss = 0.5980337858200073, acc = 0.8076171875\n",
      "Batch 3: loss = 0.5556056499481201, acc = 0.8232421875\n",
      "Batch 4: loss = 0.5285824537277222, acc = 0.830078125\n",
      "Batch 5: loss = 0.5977016687393188, acc = 0.8115234375\n",
      "Batch 6: loss = 0.6059919595718384, acc = 0.810546875\n",
      "Batch 7: loss = 0.5190672874450684, acc = 0.830078125\n",
      "Batch 8: loss = 0.5361369848251343, acc = 0.8232421875\n",
      "Batch 9: loss = 0.5087692737579346, acc = 0.83984375\n",
      "Batch 10: loss = 0.4624177813529968, acc = 0.8466796875\n",
      "Batch 11: loss = 0.5814031958580017, acc = 0.8125\n",
      "Batch 12: loss = 0.5252193808555603, acc = 0.8271484375\n",
      "Batch 13: loss = 0.4943225681781769, acc = 0.8408203125\n",
      "Batch 14: loss = 0.5379476547241211, acc = 0.8203125\n",
      "Batch 15: loss = 0.49100324511528015, acc = 0.837890625\n",
      "Batch 16: loss = 0.551912248134613, acc = 0.8203125\n",
      "Batch 17: loss = 0.5429556369781494, acc = 0.8291015625\n",
      "Batch 18: loss = 0.5683284997940063, acc = 0.8203125\n",
      "Batch 19: loss = 0.5581446290016174, acc = 0.828125\n",
      "Batch 20: loss = 0.495922327041626, acc = 0.8330078125\n",
      "Batch 21: loss = 0.5620577335357666, acc = 0.8154296875\n",
      "Batch 22: loss = 0.5148169994354248, acc = 0.8193359375\n",
      "Batch 23: loss = 0.5449404716491699, acc = 0.8076171875\n",
      "Batch 24: loss = 0.5218526721000671, acc = 0.8310546875\n",
      "Batch 25: loss = 0.48975157737731934, acc = 0.841796875\n",
      "Batch 26: loss = 0.5095770359039307, acc = 0.8271484375\n",
      "Batch 27: loss = 0.585411787033081, acc = 0.806640625\n",
      "Batch 28: loss = 0.536848783493042, acc = 0.81640625\n",
      "Batch 29: loss = 0.5500805377960205, acc = 0.8095703125\n",
      "Batch 30: loss = 0.5022817254066467, acc = 0.828125\n",
      "Batch 31: loss = 0.5367089509963989, acc = 0.83203125\n",
      "Batch 32: loss = 0.6137535572052002, acc = 0.79296875\n",
      "Batch 33: loss = 0.5139445066452026, acc = 0.828125\n",
      "Batch 34: loss = 0.5625269412994385, acc = 0.7998046875\n",
      "Batch 35: loss = 0.5155483484268188, acc = 0.8271484375\n",
      "Batch 36: loss = 0.4889259338378906, acc = 0.8212890625\n",
      "Batch 37: loss = 0.480548620223999, acc = 0.8388671875\n",
      "Batch 38: loss = 0.5094301700592041, acc = 0.8369140625\n",
      "Batch 39: loss = 0.4742058515548706, acc = 0.8544921875\n",
      "Batch 40: loss = 0.5483015775680542, acc = 0.8125\n",
      "Batch 41: loss = 0.4622687101364136, acc = 0.8359375\n",
      "Batch 42: loss = 0.5127869844436646, acc = 0.81640625\n",
      "Batch 43: loss = 0.5583428144454956, acc = 0.796875\n",
      "Batch 44: loss = 0.46611499786376953, acc = 0.8486328125\n",
      "Batch 45: loss = 0.4497510492801666, acc = 0.859375\n",
      "Batch 46: loss = 0.516147255897522, acc = 0.8291015625\n",
      "Batch 47: loss = 0.4977421164512634, acc = 0.841796875\n",
      "Batch 48: loss = 0.503892719745636, acc = 0.828125\n",
      "Batch 49: loss = 0.47551172971725464, acc = 0.8369140625\n",
      "Batch 50: loss = 0.4568321704864502, acc = 0.857421875\n",
      "Batch 51: loss = 0.48284995555877686, acc = 0.8291015625\n",
      "Batch 52: loss = 0.522221565246582, acc = 0.8095703125\n",
      "Batch 53: loss = 0.514130711555481, acc = 0.81640625\n",
      "Batch 54: loss = 0.42465895414352417, acc = 0.87109375\n",
      "Batch 55: loss = 0.46922963857650757, acc = 0.8486328125\n",
      "Batch 56: loss = 0.5135906934738159, acc = 0.8173828125\n",
      "Batch 57: loss = 0.5757520198822021, acc = 0.802734375\n",
      "Batch 58: loss = 0.591261625289917, acc = 0.791015625\n",
      "Batch 59: loss = 0.4285832941532135, acc = 0.857421875\n",
      "Batch 60: loss = 0.49716463685035706, acc = 0.8330078125\n",
      "Batch 61: loss = 0.46207746863365173, acc = 0.8447265625\n",
      "Batch 62: loss = 0.5934534072875977, acc = 0.7998046875\n",
      "Batch 63: loss = 0.5171809792518616, acc = 0.8251953125\n",
      "Batch 64: loss = 0.44303447008132935, acc = 0.8486328125\n",
      "Batch 65: loss = 0.5462225675582886, acc = 0.8232421875\n",
      "Batch 66: loss = 0.5049962997436523, acc = 0.8212890625\n",
      "Batch 67: loss = 0.47970715165138245, acc = 0.8310546875\n",
      "Batch 68: loss = 0.5423545837402344, acc = 0.8173828125\n",
      "Batch 69: loss = 0.4903290271759033, acc = 0.833984375\n",
      "Batch 70: loss = 0.5884131193161011, acc = 0.8017578125\n",
      "Batch 71: loss = 0.5529483556747437, acc = 0.8134765625\n",
      "Batch 72: loss = 0.5088657140731812, acc = 0.822265625\n",
      "Batch 73: loss = 0.5805690884590149, acc = 0.8037109375\n",
      "Batch 74: loss = 0.5321104526519775, acc = 0.814453125\n",
      "Batch 75: loss = 0.650721549987793, acc = 0.7822265625\n",
      "Batch 76: loss = 0.576025128364563, acc = 0.8115234375\n",
      "Batch 77: loss = 0.5365164279937744, acc = 0.8115234375\n",
      "Batch 78: loss = 0.5305643081665039, acc = 0.8349609375\n",
      "Batch 79: loss = 0.49384939670562744, acc = 0.8447265625\n",
      "Batch 80: loss = 0.47474730014801025, acc = 0.83984375\n",
      "Batch 81: loss = 0.5595517158508301, acc = 0.8212890625\n",
      "Batch 82: loss = 0.4826399087905884, acc = 0.8486328125\n",
      "Batch 83: loss = 0.5155878067016602, acc = 0.8251953125\n",
      "Batch 84: loss = 0.5204838514328003, acc = 0.8232421875\n",
      "Batch 85: loss = 0.57483971118927, acc = 0.8125\n",
      "Batch 86: loss = 0.543347954750061, acc = 0.82421875\n",
      "Batch 87: loss = 0.5565574169158936, acc = 0.8125\n",
      "Batch 88: loss = 0.622922420501709, acc = 0.7998046875\n",
      "Batch 89: loss = 0.5418931841850281, acc = 0.8271484375\n",
      "Batch 90: loss = 0.5420598983764648, acc = 0.8271484375\n",
      "Batch 91: loss = 0.5704339742660522, acc = 0.80859375\n",
      "Batch 92: loss = 0.5487542152404785, acc = 0.822265625\n",
      "Batch 93: loss = 0.4873056709766388, acc = 0.8466796875\n",
      "Batch 94: loss = 0.48963961005210876, acc = 0.84765625\n",
      "Batch 95: loss = 0.4876556396484375, acc = 0.82421875\n",
      "Batch 96: loss = 0.5803723335266113, acc = 0.8056640625\n",
      "Batch 97: loss = 0.542976438999176, acc = 0.8125\n",
      "Batch 98: loss = 0.5059717297554016, acc = 0.8408203125\n",
      "Batch 99: loss = 0.5421574115753174, acc = 0.8232421875\n",
      "Batch 100: loss = 0.5509218573570251, acc = 0.8017578125\n",
      "Batch 101: loss = 0.4936840534210205, acc = 0.8330078125\n",
      "Batch 102: loss = 0.5805094242095947, acc = 0.80859375\n",
      "Batch 103: loss = 0.5218316316604614, acc = 0.814453125\n",
      "Batch 104: loss = 0.4798072874546051, acc = 0.84375\n",
      "Batch 105: loss = 0.48574215173721313, acc = 0.8359375\n",
      "Batch 106: loss = 0.5468947887420654, acc = 0.8056640625\n",
      "Batch 107: loss = 0.5055779814720154, acc = 0.8349609375\n",
      "Batch 108: loss = 0.5200420618057251, acc = 0.8251953125\n",
      "Batch 109: loss = 0.5184534788131714, acc = 0.8251953125\n",
      "Batch 110: loss = 0.49698513746261597, acc = 0.8369140625\n",
      "Batch 111: loss = 0.5608965754508972, acc = 0.8056640625\n",
      "Batch 112: loss = 0.49136990308761597, acc = 0.8408203125\n",
      "Batch 113: loss = 0.5370800495147705, acc = 0.806640625\n",
      "Batch 114: loss = 0.5263266563415527, acc = 0.8251953125\n",
      "Batch 115: loss = 0.5477092266082764, acc = 0.8271484375\n",
      "Batch 116: loss = 0.5657333135604858, acc = 0.8134765625\n",
      "Batch 117: loss = 0.48935598134994507, acc = 0.8330078125\n",
      "Batch 118: loss = 0.42246729135513306, acc = 0.8603515625\n",
      "Batch 119: loss = 0.5630640983581543, acc = 0.8076171875\n",
      "Batch 120: loss = 0.5297894477844238, acc = 0.822265625\n",
      "Batch 121: loss = 0.5772992968559265, acc = 0.8134765625\n",
      "Batch 122: loss = 0.498851478099823, acc = 0.830078125\n",
      "Batch 123: loss = 0.5535480976104736, acc = 0.802734375\n",
      "Batch 124: loss = 0.5887587070465088, acc = 0.8037109375\n",
      "Batch 125: loss = 0.5956891179084778, acc = 0.8056640625\n",
      "Batch 126: loss = 0.5437557101249695, acc = 0.826171875\n",
      "\n",
      "Epoch 48/100\n",
      "Batch 1: loss = 0.6671863794326782, acc = 0.794921875\n",
      "Batch 2: loss = 0.5843998789787292, acc = 0.806640625\n",
      "Batch 3: loss = 0.5773442387580872, acc = 0.8212890625\n",
      "Batch 4: loss = 0.5290500521659851, acc = 0.8359375\n",
      "Batch 5: loss = 0.5910022258758545, acc = 0.8037109375\n",
      "Batch 6: loss = 0.5763726234436035, acc = 0.806640625\n",
      "Batch 7: loss = 0.506604015827179, acc = 0.833984375\n",
      "Batch 8: loss = 0.5301386713981628, acc = 0.826171875\n",
      "Batch 9: loss = 0.5341913104057312, acc = 0.830078125\n",
      "Batch 10: loss = 0.4587815999984741, acc = 0.83984375\n",
      "Batch 11: loss = 0.5594766736030579, acc = 0.8154296875\n",
      "Batch 12: loss = 0.5185309648513794, acc = 0.8203125\n",
      "Batch 13: loss = 0.4808196425437927, acc = 0.833984375\n",
      "Batch 14: loss = 0.5404505133628845, acc = 0.822265625\n",
      "Batch 15: loss = 0.47669538855552673, acc = 0.857421875\n",
      "Batch 16: loss = 0.5572601556777954, acc = 0.826171875\n",
      "Batch 17: loss = 0.5152590870857239, acc = 0.8310546875\n",
      "Batch 18: loss = 0.559738278388977, acc = 0.822265625\n",
      "Batch 19: loss = 0.5127602815628052, acc = 0.8349609375\n",
      "Batch 20: loss = 0.5410386323928833, acc = 0.814453125\n",
      "Batch 21: loss = 0.5469516515731812, acc = 0.8193359375\n",
      "Batch 22: loss = 0.5247870683670044, acc = 0.81640625\n",
      "Batch 23: loss = 0.5795552134513855, acc = 0.8037109375\n",
      "Batch 24: loss = 0.5075281858444214, acc = 0.814453125\n",
      "Batch 25: loss = 0.5157897472381592, acc = 0.81640625\n",
      "Batch 26: loss = 0.5089473724365234, acc = 0.828125\n",
      "Batch 27: loss = 0.5822634696960449, acc = 0.8154296875\n",
      "Batch 28: loss = 0.5370596647262573, acc = 0.80859375\n",
      "Batch 29: loss = 0.49584412574768066, acc = 0.841796875\n",
      "Batch 30: loss = 0.4912289083003998, acc = 0.8447265625\n",
      "Batch 31: loss = 0.5441509485244751, acc = 0.83984375\n",
      "Batch 32: loss = 0.6127835512161255, acc = 0.8046875\n",
      "Batch 33: loss = 0.5521371960639954, acc = 0.8291015625\n",
      "Batch 34: loss = 0.5417155623435974, acc = 0.8134765625\n",
      "Batch 35: loss = 0.5515962839126587, acc = 0.818359375\n",
      "Batch 36: loss = 0.4745365381240845, acc = 0.83984375\n",
      "Batch 37: loss = 0.4727403521537781, acc = 0.8427734375\n",
      "Batch 38: loss = 0.504356324672699, acc = 0.84375\n",
      "Batch 39: loss = 0.4913071393966675, acc = 0.837890625\n",
      "Batch 40: loss = 0.5172487497329712, acc = 0.82421875\n",
      "Batch 41: loss = 0.46266597509384155, acc = 0.8369140625\n",
      "Batch 42: loss = 0.505628764629364, acc = 0.828125\n",
      "Batch 43: loss = 0.5344114303588867, acc = 0.8046875\n",
      "Batch 44: loss = 0.4680452346801758, acc = 0.845703125\n",
      "Batch 45: loss = 0.44270795583724976, acc = 0.849609375\n",
      "Batch 46: loss = 0.493387371301651, acc = 0.8369140625\n",
      "Batch 47: loss = 0.48912951350212097, acc = 0.845703125\n",
      "Batch 48: loss = 0.46609896421432495, acc = 0.84375\n",
      "Batch 49: loss = 0.47034159302711487, acc = 0.8427734375\n",
      "Batch 50: loss = 0.4774368703365326, acc = 0.8349609375\n",
      "Batch 51: loss = 0.46813148260116577, acc = 0.8310546875\n",
      "Batch 52: loss = 0.519658088684082, acc = 0.82421875\n",
      "Batch 53: loss = 0.5195608139038086, acc = 0.82421875\n",
      "Batch 54: loss = 0.4403618574142456, acc = 0.859375\n",
      "Batch 55: loss = 0.4674965739250183, acc = 0.83203125\n",
      "Batch 56: loss = 0.5272426605224609, acc = 0.8095703125\n",
      "Batch 57: loss = 0.5722171664237976, acc = 0.7900390625\n",
      "Batch 58: loss = 0.5762515664100647, acc = 0.806640625\n",
      "Batch 59: loss = 0.4221822917461395, acc = 0.857421875\n",
      "Batch 60: loss = 0.5283308625221252, acc = 0.8095703125\n",
      "Batch 61: loss = 0.49695780873298645, acc = 0.8359375\n",
      "Batch 62: loss = 0.5678971409797668, acc = 0.7939453125\n",
      "Batch 63: loss = 0.5350865125656128, acc = 0.8232421875\n",
      "Batch 64: loss = 0.4397449493408203, acc = 0.845703125\n",
      "Batch 65: loss = 0.5517545938491821, acc = 0.8115234375\n",
      "Batch 66: loss = 0.5126010775566101, acc = 0.833984375\n",
      "Batch 67: loss = 0.5011574029922485, acc = 0.8212890625\n",
      "Batch 68: loss = 0.5059918165206909, acc = 0.8271484375\n",
      "Batch 69: loss = 0.47666722536087036, acc = 0.83984375\n",
      "Batch 70: loss = 0.5668923854827881, acc = 0.80859375\n",
      "Batch 71: loss = 0.5318517684936523, acc = 0.8173828125\n",
      "Batch 72: loss = 0.46792975068092346, acc = 0.84765625\n",
      "Batch 73: loss = 0.5741109848022461, acc = 0.8125\n",
      "Batch 74: loss = 0.5498321652412415, acc = 0.810546875\n",
      "Batch 75: loss = 0.5916604399681091, acc = 0.8037109375\n",
      "Batch 76: loss = 0.5636867880821228, acc = 0.7998046875\n",
      "Batch 77: loss = 0.4826151728630066, acc = 0.83984375\n",
      "Batch 78: loss = 0.5346611738204956, acc = 0.8212890625\n",
      "Batch 79: loss = 0.4905284643173218, acc = 0.822265625\n",
      "Batch 80: loss = 0.4843522012233734, acc = 0.828125\n",
      "Batch 81: loss = 0.5238239765167236, acc = 0.8212890625\n",
      "Batch 82: loss = 0.4848233461380005, acc = 0.8447265625\n",
      "Batch 83: loss = 0.5154296159744263, acc = 0.8271484375\n",
      "Batch 84: loss = 0.5300828218460083, acc = 0.82421875\n",
      "Batch 85: loss = 0.5540742874145508, acc = 0.8154296875\n",
      "Batch 86: loss = 0.5380343794822693, acc = 0.830078125\n",
      "Batch 87: loss = 0.5188019275665283, acc = 0.8125\n",
      "Batch 88: loss = 0.641250491142273, acc = 0.77734375\n",
      "Batch 89: loss = 0.5351858139038086, acc = 0.830078125\n",
      "Batch 90: loss = 0.5364342927932739, acc = 0.82421875\n",
      "Batch 91: loss = 0.5450489521026611, acc = 0.81640625\n",
      "Batch 92: loss = 0.5344564318656921, acc = 0.841796875\n",
      "Batch 93: loss = 0.4289601445198059, acc = 0.853515625\n",
      "Batch 94: loss = 0.460408478975296, acc = 0.857421875\n",
      "Batch 95: loss = 0.4878230690956116, acc = 0.8330078125\n",
      "Batch 96: loss = 0.5769692063331604, acc = 0.8046875\n",
      "Batch 97: loss = 0.5354459285736084, acc = 0.8251953125\n",
      "Batch 98: loss = 0.5063794851303101, acc = 0.8330078125\n",
      "Batch 99: loss = 0.5372871160507202, acc = 0.8232421875\n",
      "Batch 100: loss = 0.5433837175369263, acc = 0.8154296875\n",
      "Batch 101: loss = 0.5178458094596863, acc = 0.826171875\n",
      "Batch 102: loss = 0.5655890703201294, acc = 0.81640625\n",
      "Batch 103: loss = 0.5262962579727173, acc = 0.8349609375\n",
      "Batch 104: loss = 0.48518767952919006, acc = 0.830078125\n",
      "Batch 105: loss = 0.49245357513427734, acc = 0.8369140625\n",
      "Batch 106: loss = 0.5708937048912048, acc = 0.80078125\n",
      "Batch 107: loss = 0.4934062957763672, acc = 0.83984375\n",
      "Batch 108: loss = 0.5135942101478577, acc = 0.8359375\n",
      "Batch 109: loss = 0.5250377058982849, acc = 0.8203125\n",
      "Batch 110: loss = 0.46064138412475586, acc = 0.857421875\n",
      "Batch 111: loss = 0.5702639818191528, acc = 0.81640625\n",
      "Batch 112: loss = 0.5164833068847656, acc = 0.83203125\n",
      "Batch 113: loss = 0.5260629653930664, acc = 0.8232421875\n",
      "Batch 114: loss = 0.5200532674789429, acc = 0.8193359375\n",
      "Batch 115: loss = 0.521519124507904, acc = 0.833984375\n",
      "Batch 116: loss = 0.584987461566925, acc = 0.814453125\n",
      "Batch 117: loss = 0.49131929874420166, acc = 0.8408203125\n",
      "Batch 118: loss = 0.4565766751766205, acc = 0.841796875\n",
      "Batch 119: loss = 0.5340909957885742, acc = 0.8212890625\n",
      "Batch 120: loss = 0.5063803791999817, acc = 0.83984375\n",
      "Batch 121: loss = 0.551637589931488, acc = 0.81640625\n",
      "Batch 122: loss = 0.481514036655426, acc = 0.8369140625\n",
      "Batch 123: loss = 0.4843267500400543, acc = 0.83984375\n",
      "Batch 124: loss = 0.48949098587036133, acc = 0.8349609375\n",
      "Batch 125: loss = 0.5625890493392944, acc = 0.810546875\n",
      "Batch 126: loss = 0.561972439289093, acc = 0.8046875\n",
      "\n",
      "Epoch 49/100\n",
      "Batch 1: loss = 0.6427686214447021, acc = 0.8046875\n",
      "Batch 2: loss = 0.5892853140830994, acc = 0.8115234375\n",
      "Batch 3: loss = 0.5603584051132202, acc = 0.8173828125\n",
      "Batch 4: loss = 0.5232455730438232, acc = 0.8193359375\n",
      "Batch 5: loss = 0.5699294805526733, acc = 0.8173828125\n",
      "Batch 6: loss = 0.5674460530281067, acc = 0.8134765625\n",
      "Batch 7: loss = 0.4774014949798584, acc = 0.8310546875\n",
      "Batch 8: loss = 0.5268677473068237, acc = 0.8251953125\n",
      "Batch 9: loss = 0.5186342597007751, acc = 0.830078125\n",
      "Batch 10: loss = 0.441446989774704, acc = 0.8466796875\n",
      "Batch 11: loss = 0.5401082634925842, acc = 0.8251953125\n",
      "Batch 12: loss = 0.5166457295417786, acc = 0.828125\n",
      "Batch 13: loss = 0.47753092646598816, acc = 0.8388671875\n",
      "Batch 14: loss = 0.547239363193512, acc = 0.8212890625\n",
      "Batch 15: loss = 0.4960561990737915, acc = 0.83203125\n",
      "Batch 16: loss = 0.5307948589324951, acc = 0.828125\n",
      "Batch 17: loss = 0.5523850321769714, acc = 0.80859375\n",
      "Batch 18: loss = 0.5527853965759277, acc = 0.8291015625\n",
      "Batch 19: loss = 0.4837561845779419, acc = 0.857421875\n",
      "Batch 20: loss = 0.5145848989486694, acc = 0.8271484375\n",
      "Batch 21: loss = 0.5004713535308838, acc = 0.83203125\n",
      "Batch 22: loss = 0.4977850317955017, acc = 0.8232421875\n",
      "Batch 23: loss = 0.5591402053833008, acc = 0.8017578125\n",
      "Batch 24: loss = 0.4968182444572449, acc = 0.8271484375\n",
      "Batch 25: loss = 0.5293540358543396, acc = 0.818359375\n",
      "Batch 26: loss = 0.4924532175064087, acc = 0.8359375\n",
      "Batch 27: loss = 0.5905261635780334, acc = 0.8154296875\n",
      "Batch 28: loss = 0.5615483522415161, acc = 0.8115234375\n",
      "Batch 29: loss = 0.537875771522522, acc = 0.8173828125\n",
      "Batch 30: loss = 0.4635224938392639, acc = 0.8525390625\n",
      "Batch 31: loss = 0.5446545481681824, acc = 0.828125\n",
      "Batch 32: loss = 0.5673397183418274, acc = 0.8076171875\n",
      "Batch 33: loss = 0.47614654898643494, acc = 0.83984375\n",
      "Batch 34: loss = 0.5121914744377136, acc = 0.822265625\n",
      "Batch 35: loss = 0.5187674760818481, acc = 0.826171875\n",
      "Batch 36: loss = 0.5188677906990051, acc = 0.818359375\n",
      "Batch 37: loss = 0.44193148612976074, acc = 0.85546875\n",
      "Batch 38: loss = 0.4697658121585846, acc = 0.849609375\n",
      "Batch 39: loss = 0.5108888745307922, acc = 0.830078125\n",
      "Batch 40: loss = 0.5404183864593506, acc = 0.8173828125\n",
      "Batch 41: loss = 0.462868869304657, acc = 0.8369140625\n",
      "Batch 42: loss = 0.49100086092948914, acc = 0.8486328125\n",
      "Batch 43: loss = 0.5341970324516296, acc = 0.810546875\n",
      "Batch 44: loss = 0.44099193811416626, acc = 0.85546875\n",
      "Batch 45: loss = 0.44177889823913574, acc = 0.849609375\n",
      "Batch 46: loss = 0.4896717071533203, acc = 0.8408203125\n",
      "Batch 47: loss = 0.5210047364234924, acc = 0.8330078125\n",
      "Batch 48: loss = 0.4609939157962799, acc = 0.8408203125\n",
      "Batch 49: loss = 0.453943133354187, acc = 0.8564453125\n",
      "Batch 50: loss = 0.45936667919158936, acc = 0.8544921875\n",
      "Batch 51: loss = 0.4551657438278198, acc = 0.845703125\n",
      "Batch 52: loss = 0.5293771028518677, acc = 0.81640625\n",
      "Batch 53: loss = 0.48447614908218384, acc = 0.84765625\n",
      "Batch 54: loss = 0.43705642223358154, acc = 0.8447265625\n",
      "Batch 55: loss = 0.4284821152687073, acc = 0.84375\n",
      "Batch 56: loss = 0.5240575075149536, acc = 0.8173828125\n",
      "Batch 57: loss = 0.5203686952590942, acc = 0.8212890625\n",
      "Batch 58: loss = 0.5628293752670288, acc = 0.8115234375\n",
      "Batch 59: loss = 0.40882885456085205, acc = 0.8603515625\n",
      "Batch 60: loss = 0.4908105731010437, acc = 0.8349609375\n",
      "Batch 61: loss = 0.4934080243110657, acc = 0.8359375\n",
      "Batch 62: loss = 0.5680325031280518, acc = 0.8056640625\n",
      "Batch 63: loss = 0.49345123767852783, acc = 0.8310546875\n",
      "Batch 64: loss = 0.4362407922744751, acc = 0.8525390625\n",
      "Batch 65: loss = 0.5111793279647827, acc = 0.8359375\n",
      "Batch 66: loss = 0.5314969420433044, acc = 0.8251953125\n",
      "Batch 67: loss = 0.4998934864997864, acc = 0.837890625\n",
      "Batch 68: loss = 0.5195131301879883, acc = 0.8330078125\n",
      "Batch 69: loss = 0.45875945687294006, acc = 0.853515625\n",
      "Batch 70: loss = 0.5372453927993774, acc = 0.822265625\n",
      "Batch 71: loss = 0.5155320167541504, acc = 0.8330078125\n",
      "Batch 72: loss = 0.5157395005226135, acc = 0.82421875\n",
      "Batch 73: loss = 0.5381485223770142, acc = 0.822265625\n",
      "Batch 74: loss = 0.5331227779388428, acc = 0.810546875\n",
      "Batch 75: loss = 0.5927942991256714, acc = 0.8017578125\n",
      "Batch 76: loss = 0.5869241952896118, acc = 0.8017578125\n",
      "Batch 77: loss = 0.5096781253814697, acc = 0.8369140625\n",
      "Batch 78: loss = 0.565402626991272, acc = 0.8095703125\n",
      "Batch 79: loss = 0.49737751483917236, acc = 0.8330078125\n",
      "Batch 80: loss = 0.4684102535247803, acc = 0.8330078125\n",
      "Batch 81: loss = 0.5484648942947388, acc = 0.8173828125\n",
      "Batch 82: loss = 0.4806159436702728, acc = 0.837890625\n",
      "Batch 83: loss = 0.46418142318725586, acc = 0.853515625\n",
      "Batch 84: loss = 0.5028260350227356, acc = 0.828125\n",
      "Batch 85: loss = 0.5658752918243408, acc = 0.8115234375\n",
      "Batch 86: loss = 0.5273609161376953, acc = 0.8134765625\n",
      "Batch 87: loss = 0.5075785517692566, acc = 0.822265625\n",
      "Batch 88: loss = 0.6059584617614746, acc = 0.7861328125\n",
      "Batch 89: loss = 0.5024169683456421, acc = 0.83984375\n",
      "Batch 90: loss = 0.534988284111023, acc = 0.82421875\n",
      "Batch 91: loss = 0.5470610857009888, acc = 0.8125\n",
      "Batch 92: loss = 0.49278590083122253, acc = 0.837890625\n",
      "Batch 93: loss = 0.4385267198085785, acc = 0.859375\n",
      "Batch 94: loss = 0.46954402327537537, acc = 0.857421875\n",
      "Batch 95: loss = 0.471346914768219, acc = 0.8349609375\n",
      "Batch 96: loss = 0.54982990026474, acc = 0.814453125\n",
      "Batch 97: loss = 0.5151888728141785, acc = 0.8291015625\n",
      "Batch 98: loss = 0.5234885215759277, acc = 0.8232421875\n",
      "Batch 99: loss = 0.5372941493988037, acc = 0.8212890625\n",
      "Batch 100: loss = 0.5405410528182983, acc = 0.80859375\n",
      "Batch 101: loss = 0.4851142466068268, acc = 0.8388671875\n",
      "Batch 102: loss = 0.5557506084442139, acc = 0.8056640625\n",
      "Batch 103: loss = 0.5033050775527954, acc = 0.833984375\n",
      "Batch 104: loss = 0.48768728971481323, acc = 0.830078125\n",
      "Batch 105: loss = 0.46734553575515747, acc = 0.849609375\n",
      "Batch 106: loss = 0.5146139860153198, acc = 0.8232421875\n",
      "Batch 107: loss = 0.48501211404800415, acc = 0.8359375\n",
      "Batch 108: loss = 0.49777811765670776, acc = 0.8251953125\n",
      "Batch 109: loss = 0.4907954931259155, acc = 0.83203125\n",
      "Batch 110: loss = 0.4674016535282135, acc = 0.84375\n",
      "Batch 111: loss = 0.5705447196960449, acc = 0.8203125\n",
      "Batch 112: loss = 0.49453532695770264, acc = 0.841796875\n",
      "Batch 113: loss = 0.5605821013450623, acc = 0.806640625\n",
      "Batch 114: loss = 0.5293935537338257, acc = 0.830078125\n",
      "Batch 115: loss = 0.5665853023529053, acc = 0.8125\n",
      "Batch 116: loss = 0.5577095150947571, acc = 0.814453125\n",
      "Batch 117: loss = 0.47432464361190796, acc = 0.849609375\n",
      "Batch 118: loss = 0.4448621869087219, acc = 0.861328125\n",
      "Batch 119: loss = 0.5014335513114929, acc = 0.83984375\n",
      "Batch 120: loss = 0.5218471884727478, acc = 0.8173828125\n",
      "Batch 121: loss = 0.5339455604553223, acc = 0.828125\n",
      "Batch 122: loss = 0.4785865545272827, acc = 0.8427734375\n",
      "Batch 123: loss = 0.49430811405181885, acc = 0.83203125\n",
      "Batch 124: loss = 0.5463588833808899, acc = 0.8134765625\n",
      "Batch 125: loss = 0.5296489000320435, acc = 0.8134765625\n",
      "Batch 126: loss = 0.5368468761444092, acc = 0.814453125\n",
      "\n",
      "Epoch 50/100\n",
      "Batch 1: loss = 0.6153357028961182, acc = 0.8115234375\n",
      "Batch 2: loss = 0.563148021697998, acc = 0.8125\n",
      "Batch 3: loss = 0.5481035709381104, acc = 0.83203125\n",
      "Batch 4: loss = 0.5346214175224304, acc = 0.822265625\n",
      "Batch 5: loss = 0.5414195656776428, acc = 0.8251953125\n",
      "Batch 6: loss = 0.5368924140930176, acc = 0.8193359375\n",
      "Batch 7: loss = 0.48111122846603394, acc = 0.841796875\n",
      "Batch 8: loss = 0.5175462961196899, acc = 0.826171875\n",
      "Batch 9: loss = 0.5086009502410889, acc = 0.8291015625\n",
      "Batch 10: loss = 0.456865131855011, acc = 0.8466796875\n",
      "Batch 11: loss = 0.5373954772949219, acc = 0.8232421875\n",
      "Batch 12: loss = 0.5003796815872192, acc = 0.8251953125\n",
      "Batch 13: loss = 0.44704312086105347, acc = 0.8388671875\n",
      "Batch 14: loss = 0.5376479625701904, acc = 0.8271484375\n",
      "Batch 15: loss = 0.4672377109527588, acc = 0.8427734375\n",
      "Batch 16: loss = 0.5489507913589478, acc = 0.80859375\n",
      "Batch 17: loss = 0.5631803274154663, acc = 0.81640625\n",
      "Batch 18: loss = 0.5500158071517944, acc = 0.8115234375\n",
      "Batch 19: loss = 0.539103090763092, acc = 0.841796875\n",
      "Batch 20: loss = 0.4936298429965973, acc = 0.828125\n",
      "Batch 21: loss = 0.5310273170471191, acc = 0.8251953125\n",
      "Batch 22: loss = 0.4974367618560791, acc = 0.8291015625\n",
      "Batch 23: loss = 0.535598874092102, acc = 0.8193359375\n",
      "Batch 24: loss = 0.48160314559936523, acc = 0.8310546875\n",
      "Batch 25: loss = 0.5354588031768799, acc = 0.837890625\n",
      "Batch 26: loss = 0.5055616497993469, acc = 0.8388671875\n",
      "Batch 27: loss = 0.5886735916137695, acc = 0.80078125\n",
      "Batch 28: loss = 0.5486700534820557, acc = 0.8134765625\n",
      "Batch 29: loss = 0.5267539024353027, acc = 0.8212890625\n",
      "Batch 30: loss = 0.486641526222229, acc = 0.84375\n",
      "Batch 31: loss = 0.5467123985290527, acc = 0.8310546875\n",
      "Batch 32: loss = 0.5662841796875, acc = 0.8115234375\n",
      "Batch 33: loss = 0.498578280210495, acc = 0.8330078125\n",
      "Batch 34: loss = 0.5141086578369141, acc = 0.8291015625\n",
      "Batch 35: loss = 0.5081502199172974, acc = 0.8251953125\n",
      "Batch 36: loss = 0.4583059251308441, acc = 0.8466796875\n",
      "Batch 37: loss = 0.44216275215148926, acc = 0.8486328125\n",
      "Batch 38: loss = 0.48340579867362976, acc = 0.84375\n",
      "Batch 39: loss = 0.46245941519737244, acc = 0.84375\n",
      "Batch 40: loss = 0.5289077758789062, acc = 0.8291015625\n",
      "Batch 41: loss = 0.45947426557540894, acc = 0.837890625\n",
      "Batch 42: loss = 0.45593199133872986, acc = 0.8486328125\n",
      "Batch 43: loss = 0.5300443172454834, acc = 0.8076171875\n",
      "Batch 44: loss = 0.42892009019851685, acc = 0.861328125\n",
      "Batch 45: loss = 0.42981863021850586, acc = 0.8623046875\n",
      "Batch 46: loss = 0.48114803433418274, acc = 0.8388671875\n",
      "Batch 47: loss = 0.4896475076675415, acc = 0.84765625\n",
      "Batch 48: loss = 0.46030566096305847, acc = 0.84375\n",
      "Batch 49: loss = 0.46211767196655273, acc = 0.853515625\n",
      "Batch 50: loss = 0.45396745204925537, acc = 0.8486328125\n",
      "Batch 51: loss = 0.4759126901626587, acc = 0.833984375\n",
      "Batch 52: loss = 0.49870118498802185, acc = 0.83203125\n",
      "Batch 53: loss = 0.48949265480041504, acc = 0.853515625\n",
      "Batch 54: loss = 0.39764460921287537, acc = 0.8701171875\n",
      "Batch 55: loss = 0.46356201171875, acc = 0.857421875\n",
      "Batch 56: loss = 0.5085350871086121, acc = 0.8251953125\n",
      "Batch 57: loss = 0.5095189809799194, acc = 0.8291015625\n",
      "Batch 58: loss = 0.5712893605232239, acc = 0.7998046875\n",
      "Batch 59: loss = 0.3992749750614166, acc = 0.8740234375\n",
      "Batch 60: loss = 0.4993428587913513, acc = 0.833984375\n",
      "Batch 61: loss = 0.4611770510673523, acc = 0.841796875\n",
      "Batch 62: loss = 0.5808672904968262, acc = 0.806640625\n",
      "Batch 63: loss = 0.528725266456604, acc = 0.8212890625\n",
      "Batch 64: loss = 0.44227105379104614, acc = 0.8642578125\n",
      "Batch 65: loss = 0.5466977953910828, acc = 0.818359375\n",
      "Batch 66: loss = 0.4806296229362488, acc = 0.841796875\n",
      "Batch 67: loss = 0.4919559955596924, acc = 0.8173828125\n",
      "Batch 68: loss = 0.509647011756897, acc = 0.826171875\n",
      "Batch 69: loss = 0.46963977813720703, acc = 0.8486328125\n",
      "Batch 70: loss = 0.5414125919342041, acc = 0.8271484375\n",
      "Batch 71: loss = 0.5358661413192749, acc = 0.8173828125\n",
      "Batch 72: loss = 0.4492298662662506, acc = 0.8564453125\n",
      "Batch 73: loss = 0.5296274423599243, acc = 0.8359375\n",
      "Batch 74: loss = 0.533389151096344, acc = 0.8125\n",
      "Batch 75: loss = 0.5834522843360901, acc = 0.802734375\n",
      "Batch 76: loss = 0.557022750377655, acc = 0.806640625\n",
      "Batch 77: loss = 0.508108913898468, acc = 0.8271484375\n",
      "Batch 78: loss = 0.5282855033874512, acc = 0.837890625\n",
      "Batch 79: loss = 0.4981726408004761, acc = 0.8212890625\n",
      "Batch 80: loss = 0.47653937339782715, acc = 0.8359375\n",
      "Batch 81: loss = 0.5157954692840576, acc = 0.8212890625\n",
      "Batch 82: loss = 0.4886360168457031, acc = 0.8310546875\n",
      "Batch 83: loss = 0.49065324664115906, acc = 0.8525390625\n",
      "Batch 84: loss = 0.4944411516189575, acc = 0.82421875\n",
      "Batch 85: loss = 0.5439212918281555, acc = 0.826171875\n",
      "Batch 86: loss = 0.5096381902694702, acc = 0.8310546875\n",
      "Batch 87: loss = 0.5292365550994873, acc = 0.80859375\n",
      "Batch 88: loss = 0.6052073240280151, acc = 0.7998046875\n",
      "Batch 89: loss = 0.521536648273468, acc = 0.830078125\n",
      "Batch 90: loss = 0.5590624213218689, acc = 0.8046875\n",
      "Batch 91: loss = 0.5152661800384521, acc = 0.8095703125\n",
      "Batch 92: loss = 0.5232675075531006, acc = 0.8408203125\n",
      "Batch 93: loss = 0.4479079842567444, acc = 0.8515625\n",
      "Batch 94: loss = 0.49085015058517456, acc = 0.8466796875\n",
      "Batch 95: loss = 0.4456368684768677, acc = 0.8515625\n",
      "Batch 96: loss = 0.5482852458953857, acc = 0.810546875\n",
      "Batch 97: loss = 0.5055406093597412, acc = 0.8349609375\n",
      "Batch 98: loss = 0.49001234769821167, acc = 0.8369140625\n",
      "Batch 99: loss = 0.520728349685669, acc = 0.8330078125\n",
      "Batch 100: loss = 0.539368748664856, acc = 0.822265625\n",
      "Batch 101: loss = 0.4791957139968872, acc = 0.8369140625\n",
      "Batch 102: loss = 0.5420482158660889, acc = 0.822265625\n",
      "Batch 103: loss = 0.48283660411834717, acc = 0.841796875\n",
      "Batch 104: loss = 0.4628830552101135, acc = 0.845703125\n",
      "Batch 105: loss = 0.4441148638725281, acc = 0.8486328125\n",
      "Batch 106: loss = 0.4985852539539337, acc = 0.8291015625\n",
      "Batch 107: loss = 0.4893319606781006, acc = 0.83203125\n",
      "Batch 108: loss = 0.5225369334220886, acc = 0.8369140625\n",
      "Batch 109: loss = 0.5058541297912598, acc = 0.8232421875\n",
      "Batch 110: loss = 0.4483674168586731, acc = 0.84765625\n",
      "Batch 111: loss = 0.5618841052055359, acc = 0.8115234375\n",
      "Batch 112: loss = 0.46640411019325256, acc = 0.845703125\n",
      "Batch 113: loss = 0.5186810493469238, acc = 0.830078125\n",
      "Batch 114: loss = 0.501798152923584, acc = 0.828125\n",
      "Batch 115: loss = 0.5136779546737671, acc = 0.81640625\n",
      "Batch 116: loss = 0.5319913029670715, acc = 0.8203125\n",
      "Batch 117: loss = 0.4744970202445984, acc = 0.8408203125\n",
      "Batch 118: loss = 0.42334604263305664, acc = 0.8720703125\n",
      "Batch 119: loss = 0.491873562335968, acc = 0.8310546875\n",
      "Batch 120: loss = 0.5267365574836731, acc = 0.818359375\n",
      "Batch 121: loss = 0.5405776500701904, acc = 0.8251953125\n",
      "Batch 122: loss = 0.48093879222869873, acc = 0.845703125\n",
      "Batch 123: loss = 0.4971187710762024, acc = 0.8427734375\n",
      "Batch 124: loss = 0.5405011177062988, acc = 0.826171875\n",
      "Batch 125: loss = 0.5214639902114868, acc = 0.830078125\n",
      "Batch 126: loss = 0.49670884013175964, acc = 0.8349609375\n",
      "\n",
      "Epoch 51/100\n",
      "Batch 1: loss = 0.6039354801177979, acc = 0.8076171875\n",
      "Batch 2: loss = 0.5436199903488159, acc = 0.8193359375\n",
      "Batch 3: loss = 0.5223433375358582, acc = 0.8359375\n",
      "Batch 4: loss = 0.4817269444465637, acc = 0.8525390625\n",
      "Batch 5: loss = 0.5278894901275635, acc = 0.83203125\n",
      "Batch 6: loss = 0.5088932514190674, acc = 0.845703125\n",
      "Batch 7: loss = 0.4991089403629303, acc = 0.8388671875\n",
      "Batch 8: loss = 0.5119502544403076, acc = 0.8310546875\n",
      "Batch 9: loss = 0.47510606050491333, acc = 0.8427734375\n",
      "Batch 10: loss = 0.42595189809799194, acc = 0.85546875\n",
      "Batch 11: loss = 0.5324322581291199, acc = 0.8291015625\n",
      "Batch 12: loss = 0.5056014657020569, acc = 0.8310546875\n",
      "Batch 13: loss = 0.45825329422950745, acc = 0.85546875\n",
      "Batch 14: loss = 0.5032260417938232, acc = 0.82421875\n",
      "Batch 15: loss = 0.44688117504119873, acc = 0.85546875\n",
      "Batch 16: loss = 0.5230945348739624, acc = 0.84375\n",
      "Batch 17: loss = 0.5031350255012512, acc = 0.826171875\n",
      "Batch 18: loss = 0.5153952240943909, acc = 0.83203125\n",
      "Batch 19: loss = 0.47887465357780457, acc = 0.83984375\n",
      "Batch 20: loss = 0.4802514910697937, acc = 0.833984375\n",
      "Batch 21: loss = 0.49990832805633545, acc = 0.837890625\n",
      "Batch 22: loss = 0.48787742853164673, acc = 0.8251953125\n",
      "Batch 23: loss = 0.5222926139831543, acc = 0.822265625\n",
      "Batch 24: loss = 0.47219324111938477, acc = 0.82421875\n",
      "Batch 25: loss = 0.4952237010002136, acc = 0.8388671875\n",
      "Batch 26: loss = 0.5174120664596558, acc = 0.8232421875\n",
      "Batch 27: loss = 0.5534710884094238, acc = 0.8095703125\n",
      "Batch 28: loss = 0.5531609058380127, acc = 0.80078125\n",
      "Batch 29: loss = 0.5142217874526978, acc = 0.8232421875\n",
      "Batch 30: loss = 0.46139824390411377, acc = 0.849609375\n",
      "Batch 31: loss = 0.5227363109588623, acc = 0.828125\n",
      "Batch 32: loss = 0.5460864305496216, acc = 0.826171875\n",
      "Batch 33: loss = 0.4978330135345459, acc = 0.83984375\n",
      "Batch 34: loss = 0.5328127145767212, acc = 0.818359375\n",
      "Batch 35: loss = 0.4873049259185791, acc = 0.8515625\n",
      "Batch 36: loss = 0.45525220036506653, acc = 0.8447265625\n",
      "Batch 37: loss = 0.44130831956863403, acc = 0.8564453125\n",
      "Batch 38: loss = 0.45810362696647644, acc = 0.861328125\n",
      "Batch 39: loss = 0.4909170866012573, acc = 0.845703125\n",
      "Batch 40: loss = 0.48944535851478577, acc = 0.826171875\n",
      "Batch 41: loss = 0.4286726415157318, acc = 0.85546875\n",
      "Batch 42: loss = 0.45306503772735596, acc = 0.8515625\n",
      "Batch 43: loss = 0.4893132448196411, acc = 0.8330078125\n",
      "Batch 44: loss = 0.4472965598106384, acc = 0.857421875\n",
      "Batch 45: loss = 0.407808393239975, acc = 0.8603515625\n",
      "Batch 46: loss = 0.47610270977020264, acc = 0.841796875\n",
      "Batch 47: loss = 0.4836270213127136, acc = 0.84375\n",
      "Batch 48: loss = 0.4585554599761963, acc = 0.85546875\n",
      "Batch 49: loss = 0.4462120831012726, acc = 0.8515625\n",
      "Batch 50: loss = 0.44425123929977417, acc = 0.8515625\n",
      "Batch 51: loss = 0.4561983346939087, acc = 0.845703125\n",
      "Batch 52: loss = 0.49976813793182373, acc = 0.826171875\n",
      "Batch 53: loss = 0.46365123987197876, acc = 0.8466796875\n",
      "Batch 54: loss = 0.39018261432647705, acc = 0.8671875\n",
      "Batch 55: loss = 0.4246515929698944, acc = 0.853515625\n",
      "Batch 56: loss = 0.4673958122730255, acc = 0.83203125\n",
      "Batch 57: loss = 0.5034536123275757, acc = 0.8154296875\n",
      "Batch 58: loss = 0.5612062215805054, acc = 0.810546875\n",
      "Batch 59: loss = 0.3985174298286438, acc = 0.88671875\n",
      "Batch 60: loss = 0.4548112154006958, acc = 0.849609375\n",
      "Batch 61: loss = 0.4581284523010254, acc = 0.845703125\n",
      "Batch 62: loss = 0.5331125259399414, acc = 0.8212890625\n",
      "Batch 63: loss = 0.5114992260932922, acc = 0.837890625\n",
      "Batch 64: loss = 0.4339292049407959, acc = 0.8681640625\n",
      "Batch 65: loss = 0.49731332063674927, acc = 0.83984375\n",
      "Batch 66: loss = 0.4985691010951996, acc = 0.8349609375\n",
      "Batch 67: loss = 0.469607949256897, acc = 0.84765625\n",
      "Batch 68: loss = 0.5022848844528198, acc = 0.8291015625\n",
      "Batch 69: loss = 0.4282705783843994, acc = 0.8515625\n",
      "Batch 70: loss = 0.5301061272621155, acc = 0.8203125\n",
      "Batch 71: loss = 0.5276713967323303, acc = 0.8193359375\n",
      "Batch 72: loss = 0.4893733859062195, acc = 0.833984375\n",
      "Batch 73: loss = 0.5360154509544373, acc = 0.81640625\n",
      "Batch 74: loss = 0.5065099596977234, acc = 0.8330078125\n",
      "Batch 75: loss = 0.5716232061386108, acc = 0.8095703125\n",
      "Batch 76: loss = 0.5300108790397644, acc = 0.8203125\n",
      "Batch 77: loss = 0.4757500886917114, acc = 0.8505859375\n",
      "Batch 78: loss = 0.5327374935150146, acc = 0.8271484375\n",
      "Batch 79: loss = 0.4480997323989868, acc = 0.84765625\n",
      "Batch 80: loss = 0.4485892057418823, acc = 0.837890625\n",
      "Batch 81: loss = 0.5248498320579529, acc = 0.8154296875\n",
      "Batch 82: loss = 0.46089595556259155, acc = 0.84375\n",
      "Batch 83: loss = 0.4889853000640869, acc = 0.8203125\n",
      "Batch 84: loss = 0.5100592374801636, acc = 0.8271484375\n",
      "Batch 85: loss = 0.5561901330947876, acc = 0.806640625\n",
      "Batch 86: loss = 0.4937446415424347, acc = 0.833984375\n",
      "Batch 87: loss = 0.4858183264732361, acc = 0.8330078125\n",
      "Batch 88: loss = 0.5823982954025269, acc = 0.8037109375\n",
      "Batch 89: loss = 0.5133904814720154, acc = 0.830078125\n",
      "Batch 90: loss = 0.5306831002235413, acc = 0.828125\n",
      "Batch 91: loss = 0.5093940496444702, acc = 0.8310546875\n",
      "Batch 92: loss = 0.5167314410209656, acc = 0.83203125\n",
      "Batch 93: loss = 0.42823928594589233, acc = 0.8671875\n",
      "Batch 94: loss = 0.4458954334259033, acc = 0.8583984375\n",
      "Batch 95: loss = 0.455693781375885, acc = 0.8486328125\n",
      "Batch 96: loss = 0.5005878210067749, acc = 0.82421875\n",
      "Batch 97: loss = 0.47297847270965576, acc = 0.8486328125\n",
      "Batch 98: loss = 0.5142142176628113, acc = 0.83203125\n",
      "Batch 99: loss = 0.5330885648727417, acc = 0.82421875\n",
      "Batch 100: loss = 0.4985871911048889, acc = 0.818359375\n",
      "Batch 101: loss = 0.47321492433547974, acc = 0.841796875\n",
      "Batch 102: loss = 0.505509078502655, acc = 0.8291015625\n",
      "Batch 103: loss = 0.49314433336257935, acc = 0.8310546875\n",
      "Batch 104: loss = 0.41419273614883423, acc = 0.8701171875\n",
      "Batch 105: loss = 0.40572303533554077, acc = 0.8671875\n",
      "Batch 106: loss = 0.5056716799736023, acc = 0.8271484375\n",
      "Batch 107: loss = 0.49571341276168823, acc = 0.8359375\n",
      "Batch 108: loss = 0.5007787942886353, acc = 0.833984375\n",
      "Batch 109: loss = 0.5247097611427307, acc = 0.82421875\n",
      "Batch 110: loss = 0.44049590826034546, acc = 0.859375\n",
      "Batch 111: loss = 0.5712403059005737, acc = 0.810546875\n",
      "Batch 112: loss = 0.45237141847610474, acc = 0.849609375\n",
      "Batch 113: loss = 0.4640641212463379, acc = 0.83984375\n",
      "Batch 114: loss = 0.48238804936408997, acc = 0.841796875\n",
      "Batch 115: loss = 0.49975070357322693, acc = 0.8408203125\n",
      "Batch 116: loss = 0.5194646120071411, acc = 0.833984375\n",
      "Batch 117: loss = 0.45266494154930115, acc = 0.8505859375\n",
      "Batch 118: loss = 0.44833821058273315, acc = 0.8515625\n",
      "Batch 119: loss = 0.5062590837478638, acc = 0.830078125\n",
      "Batch 120: loss = 0.46139365434646606, acc = 0.8447265625\n",
      "Batch 121: loss = 0.523332953453064, acc = 0.8212890625\n",
      "Batch 122: loss = 0.4553758502006531, acc = 0.8505859375\n",
      "Batch 123: loss = 0.48643380403518677, acc = 0.83984375\n",
      "Batch 124: loss = 0.5051935911178589, acc = 0.826171875\n",
      "Batch 125: loss = 0.5338821411132812, acc = 0.8291015625\n",
      "Batch 126: loss = 0.5284725427627563, acc = 0.8291015625\n",
      "\n",
      "Epoch 52/100\n",
      "Batch 1: loss = 0.57717365026474, acc = 0.8193359375\n",
      "Batch 2: loss = 0.5393664836883545, acc = 0.8125\n",
      "Batch 3: loss = 0.491667240858078, acc = 0.85546875\n",
      "Batch 4: loss = 0.4732785224914551, acc = 0.83984375\n",
      "Batch 5: loss = 0.5147708654403687, acc = 0.833984375\n",
      "Batch 6: loss = 0.5392867922782898, acc = 0.806640625\n",
      "Batch 7: loss = 0.460074245929718, acc = 0.8486328125\n",
      "Batch 8: loss = 0.47984248399734497, acc = 0.8466796875\n",
      "Batch 9: loss = 0.4679320752620697, acc = 0.8408203125\n",
      "Batch 10: loss = 0.3984232544898987, acc = 0.85546875\n",
      "Batch 11: loss = 0.4994177222251892, acc = 0.8330078125\n",
      "Batch 12: loss = 0.47783035039901733, acc = 0.8349609375\n",
      "Batch 13: loss = 0.4324682056903839, acc = 0.853515625\n",
      "Batch 14: loss = 0.4792559742927551, acc = 0.853515625\n",
      "Batch 15: loss = 0.46060463786125183, acc = 0.853515625\n",
      "Batch 16: loss = 0.49927639961242676, acc = 0.8271484375\n",
      "Batch 17: loss = 0.5169447064399719, acc = 0.8369140625\n",
      "Batch 18: loss = 0.49754494428634644, acc = 0.837890625\n",
      "Batch 19: loss = 0.48714640736579895, acc = 0.84375\n",
      "Batch 20: loss = 0.43955105543136597, acc = 0.845703125\n",
      "Batch 21: loss = 0.5013982653617859, acc = 0.8203125\n",
      "Batch 22: loss = 0.46747052669525146, acc = 0.8525390625\n",
      "Batch 23: loss = 0.5095389485359192, acc = 0.8232421875\n",
      "Batch 24: loss = 0.4853295087814331, acc = 0.83984375\n",
      "Batch 25: loss = 0.48694461584091187, acc = 0.853515625\n",
      "Batch 26: loss = 0.47314900159835815, acc = 0.8310546875\n",
      "Batch 27: loss = 0.5362802743911743, acc = 0.8203125\n",
      "Batch 28: loss = 0.5264135599136353, acc = 0.822265625\n",
      "Batch 29: loss = 0.4993733763694763, acc = 0.8359375\n",
      "Batch 30: loss = 0.4251287579536438, acc = 0.849609375\n",
      "Batch 31: loss = 0.49964895844459534, acc = 0.83984375\n",
      "Batch 32: loss = 0.5351508855819702, acc = 0.8193359375\n",
      "Batch 33: loss = 0.4795789122581482, acc = 0.841796875\n",
      "Batch 34: loss = 0.49171942472457886, acc = 0.8447265625\n",
      "Batch 35: loss = 0.482421338558197, acc = 0.841796875\n",
      "Batch 36: loss = 0.4356096386909485, acc = 0.853515625\n",
      "Batch 37: loss = 0.4384392499923706, acc = 0.857421875\n",
      "Batch 38: loss = 0.47746741771698, acc = 0.8388671875\n",
      "Batch 39: loss = 0.4531196653842926, acc = 0.8427734375\n",
      "Batch 40: loss = 0.48844999074935913, acc = 0.8447265625\n",
      "Batch 41: loss = 0.4330368638038635, acc = 0.8515625\n",
      "Batch 42: loss = 0.4611307978630066, acc = 0.8505859375\n",
      "Batch 43: loss = 0.4972766041755676, acc = 0.8330078125\n",
      "Batch 44: loss = 0.42825376987457275, acc = 0.8603515625\n",
      "Batch 45: loss = 0.4087478518486023, acc = 0.853515625\n",
      "Batch 46: loss = 0.44223666191101074, acc = 0.853515625\n",
      "Batch 47: loss = 0.44045883417129517, acc = 0.8564453125\n",
      "Batch 48: loss = 0.4365882873535156, acc = 0.84375\n",
      "Batch 49: loss = 0.44026854634284973, acc = 0.861328125\n",
      "Batch 50: loss = 0.42368876934051514, acc = 0.865234375\n",
      "Batch 51: loss = 0.44188451766967773, acc = 0.8466796875\n",
      "Batch 52: loss = 0.48005247116088867, acc = 0.83984375\n",
      "Batch 53: loss = 0.4508179724216461, acc = 0.84765625\n",
      "Batch 54: loss = 0.3818526864051819, acc = 0.873046875\n",
      "Batch 55: loss = 0.42964494228363037, acc = 0.8583984375\n",
      "Batch 56: loss = 0.45942074060440063, acc = 0.833984375\n",
      "Batch 57: loss = 0.5033725500106812, acc = 0.8193359375\n",
      "Batch 58: loss = 0.5522863864898682, acc = 0.798828125\n",
      "Batch 59: loss = 0.38872861862182617, acc = 0.875\n",
      "Batch 60: loss = 0.4308919310569763, acc = 0.8525390625\n",
      "Batch 61: loss = 0.4270089268684387, acc = 0.859375\n",
      "Batch 62: loss = 0.5597314238548279, acc = 0.8017578125\n",
      "Batch 63: loss = 0.4883711338043213, acc = 0.828125\n",
      "Batch 64: loss = 0.41047966480255127, acc = 0.8515625\n",
      "Batch 65: loss = 0.46579769253730774, acc = 0.8505859375\n",
      "Batch 66: loss = 0.4715227484703064, acc = 0.84375\n",
      "Batch 67: loss = 0.4606996774673462, acc = 0.845703125\n",
      "Batch 68: loss = 0.507314145565033, acc = 0.8173828125\n",
      "Batch 69: loss = 0.44081297516822815, acc = 0.8564453125\n",
      "Batch 70: loss = 0.5403014421463013, acc = 0.8125\n",
      "Batch 71: loss = 0.48988693952560425, acc = 0.84375\n",
      "Batch 72: loss = 0.43415021896362305, acc = 0.8427734375\n",
      "Batch 73: loss = 0.49644988775253296, acc = 0.830078125\n",
      "Batch 74: loss = 0.49891579151153564, acc = 0.8349609375\n",
      "Batch 75: loss = 0.5613607168197632, acc = 0.80078125\n",
      "Batch 76: loss = 0.5222721099853516, acc = 0.8193359375\n",
      "Batch 77: loss = 0.4747793674468994, acc = 0.8544921875\n",
      "Batch 78: loss = 0.4756682217121124, acc = 0.8447265625\n",
      "Batch 79: loss = 0.44174423813819885, acc = 0.8427734375\n",
      "Batch 80: loss = 0.4366428852081299, acc = 0.8515625\n",
      "Batch 81: loss = 0.4701344966888428, acc = 0.845703125\n",
      "Batch 82: loss = 0.4878699779510498, acc = 0.833984375\n",
      "Batch 83: loss = 0.48539865016937256, acc = 0.8427734375\n",
      "Batch 84: loss = 0.47163641452789307, acc = 0.8515625\n",
      "Batch 85: loss = 0.5474292635917664, acc = 0.8193359375\n",
      "Batch 86: loss = 0.5145024061203003, acc = 0.8271484375\n",
      "Batch 87: loss = 0.4793132245540619, acc = 0.837890625\n",
      "Batch 88: loss = 0.531274676322937, acc = 0.822265625\n",
      "Batch 89: loss = 0.49357566237449646, acc = 0.8408203125\n",
      "Batch 90: loss = 0.4784969389438629, acc = 0.837890625\n",
      "Batch 91: loss = 0.5014124512672424, acc = 0.8291015625\n",
      "Batch 92: loss = 0.533588171005249, acc = 0.8203125\n",
      "Batch 93: loss = 0.42569154500961304, acc = 0.857421875\n",
      "Batch 94: loss = 0.4540794789791107, acc = 0.861328125\n",
      "Batch 95: loss = 0.4280414581298828, acc = 0.861328125\n",
      "Batch 96: loss = 0.4989701509475708, acc = 0.8310546875\n",
      "Batch 97: loss = 0.4929468631744385, acc = 0.841796875\n",
      "Batch 98: loss = 0.48637792468070984, acc = 0.8369140625\n",
      "Batch 99: loss = 0.49390172958374023, acc = 0.83984375\n",
      "Batch 100: loss = 0.4716947674751282, acc = 0.8466796875\n",
      "Batch 101: loss = 0.46050751209259033, acc = 0.8505859375\n",
      "Batch 102: loss = 0.5199421644210815, acc = 0.8232421875\n",
      "Batch 103: loss = 0.4618770480155945, acc = 0.84765625\n",
      "Batch 104: loss = 0.4367612302303314, acc = 0.845703125\n",
      "Batch 105: loss = 0.4434155225753784, acc = 0.8505859375\n",
      "Batch 106: loss = 0.5064811706542969, acc = 0.8271484375\n",
      "Batch 107: loss = 0.47313493490219116, acc = 0.84375\n",
      "Batch 108: loss = 0.4606724679470062, acc = 0.849609375\n",
      "Batch 109: loss = 0.5051669478416443, acc = 0.8212890625\n",
      "Batch 110: loss = 0.43317097425460815, acc = 0.8583984375\n",
      "Batch 111: loss = 0.5396559834480286, acc = 0.8154296875\n",
      "Batch 112: loss = 0.4461403489112854, acc = 0.8583984375\n",
      "Batch 113: loss = 0.4699473977088928, acc = 0.8427734375\n",
      "Batch 114: loss = 0.49251121282577515, acc = 0.8349609375\n",
      "Batch 115: loss = 0.49824103713035583, acc = 0.83203125\n",
      "Batch 116: loss = 0.5044073462486267, acc = 0.8310546875\n",
      "Batch 117: loss = 0.45279088616371155, acc = 0.8466796875\n",
      "Batch 118: loss = 0.41364115476608276, acc = 0.8583984375\n",
      "Batch 119: loss = 0.4658341407775879, acc = 0.8427734375\n",
      "Batch 120: loss = 0.4913293719291687, acc = 0.826171875\n",
      "Batch 121: loss = 0.4942384660243988, acc = 0.8447265625\n",
      "Batch 122: loss = 0.4684373736381531, acc = 0.845703125\n",
      "Batch 123: loss = 0.5029971599578857, acc = 0.828125\n",
      "Batch 124: loss = 0.5058509111404419, acc = 0.828125\n",
      "Batch 125: loss = 0.49693381786346436, acc = 0.837890625\n",
      "Batch 126: loss = 0.49787166714668274, acc = 0.8271484375\n",
      "\n",
      "Epoch 53/100\n",
      "Batch 1: loss = 0.5590975284576416, acc = 0.8251953125\n",
      "Batch 2: loss = 0.5272988677024841, acc = 0.8173828125\n",
      "Batch 3: loss = 0.5060697793960571, acc = 0.828125\n",
      "Batch 4: loss = 0.43332546949386597, acc = 0.8515625\n",
      "Batch 5: loss = 0.5416108965873718, acc = 0.81640625\n",
      "Batch 6: loss = 0.5318107008934021, acc = 0.8212890625\n",
      "Batch 7: loss = 0.4494582712650299, acc = 0.8603515625\n",
      "Batch 8: loss = 0.5080206990242004, acc = 0.830078125\n",
      "Batch 9: loss = 0.46712252497673035, acc = 0.8349609375\n",
      "Batch 10: loss = 0.4309720993041992, acc = 0.857421875\n",
      "Batch 11: loss = 0.4899917244911194, acc = 0.8408203125\n",
      "Batch 12: loss = 0.46529924869537354, acc = 0.845703125\n",
      "Batch 13: loss = 0.4320991635322571, acc = 0.8486328125\n",
      "Batch 14: loss = 0.46743515133857727, acc = 0.8330078125\n",
      "Batch 15: loss = 0.44300171732902527, acc = 0.8564453125\n",
      "Batch 16: loss = 0.4842355251312256, acc = 0.845703125\n",
      "Batch 17: loss = 0.48601648211479187, acc = 0.833984375\n",
      "Batch 18: loss = 0.5061612129211426, acc = 0.837890625\n",
      "Batch 19: loss = 0.48506200313568115, acc = 0.83203125\n",
      "Batch 20: loss = 0.49072715640068054, acc = 0.8330078125\n",
      "Batch 21: loss = 0.500680148601532, acc = 0.83203125\n",
      "Batch 22: loss = 0.461590975522995, acc = 0.8427734375\n",
      "Batch 23: loss = 0.5137170553207397, acc = 0.8125\n",
      "Batch 24: loss = 0.4668962061405182, acc = 0.8369140625\n",
      "Batch 25: loss = 0.4867306649684906, acc = 0.8369140625\n",
      "Batch 26: loss = 0.4404063820838928, acc = 0.853515625\n",
      "Batch 27: loss = 0.4919164776802063, acc = 0.841796875\n",
      "Batch 28: loss = 0.5259594917297363, acc = 0.8212890625\n",
      "Batch 29: loss = 0.5017229318618774, acc = 0.84375\n",
      "Batch 30: loss = 0.44318467378616333, acc = 0.845703125\n",
      "Batch 31: loss = 0.46013322472572327, acc = 0.8515625\n",
      "Batch 32: loss = 0.5410195589065552, acc = 0.8271484375\n",
      "Batch 33: loss = 0.4716094136238098, acc = 0.8408203125\n",
      "Batch 34: loss = 0.4978433847427368, acc = 0.8251953125\n",
      "Batch 35: loss = 0.4893614947795868, acc = 0.8310546875\n",
      "Batch 36: loss = 0.42151114344596863, acc = 0.8515625\n",
      "Batch 37: loss = 0.4237019717693329, acc = 0.8642578125\n",
      "Batch 38: loss = 0.45224088430404663, acc = 0.8564453125\n",
      "Batch 39: loss = 0.4414542019367218, acc = 0.8525390625\n",
      "Batch 40: loss = 0.5030951499938965, acc = 0.822265625\n",
      "Batch 41: loss = 0.41402339935302734, acc = 0.8623046875\n",
      "Batch 42: loss = 0.48258495330810547, acc = 0.8427734375\n",
      "Batch 43: loss = 0.4913786053657532, acc = 0.8349609375\n",
      "Batch 44: loss = 0.4194387197494507, acc = 0.8662109375\n",
      "Batch 45: loss = 0.408816933631897, acc = 0.8603515625\n",
      "Batch 46: loss = 0.4322046637535095, acc = 0.85546875\n",
      "Batch 47: loss = 0.4447416365146637, acc = 0.8603515625\n",
      "Batch 48: loss = 0.41207918524742126, acc = 0.861328125\n",
      "Batch 49: loss = 0.43334901332855225, acc = 0.845703125\n",
      "Batch 50: loss = 0.42021191120147705, acc = 0.8623046875\n",
      "Batch 51: loss = 0.43714800477027893, acc = 0.857421875\n",
      "Batch 52: loss = 0.4800107479095459, acc = 0.837890625\n",
      "Batch 53: loss = 0.45072874426841736, acc = 0.857421875\n",
      "Batch 54: loss = 0.36863893270492554, acc = 0.869140625\n",
      "Batch 55: loss = 0.4251560568809509, acc = 0.8544921875\n",
      "Batch 56: loss = 0.47002655267715454, acc = 0.8310546875\n",
      "Batch 57: loss = 0.4810202717781067, acc = 0.8330078125\n",
      "Batch 58: loss = 0.5218238830566406, acc = 0.8173828125\n",
      "Batch 59: loss = 0.3607294261455536, acc = 0.87890625\n",
      "Batch 60: loss = 0.46251142024993896, acc = 0.845703125\n",
      "Batch 61: loss = 0.4198157787322998, acc = 0.8681640625\n",
      "Batch 62: loss = 0.5014493465423584, acc = 0.83203125\n",
      "Batch 63: loss = 0.48225104808807373, acc = 0.8349609375\n",
      "Batch 64: loss = 0.3880144953727722, acc = 0.8671875\n",
      "Batch 65: loss = 0.45933663845062256, acc = 0.8447265625\n",
      "Batch 66: loss = 0.465503066778183, acc = 0.8486328125\n",
      "Batch 67: loss = 0.4696727991104126, acc = 0.8447265625\n",
      "Batch 68: loss = 0.49770909547805786, acc = 0.83203125\n",
      "Batch 69: loss = 0.4378150701522827, acc = 0.8515625\n",
      "Batch 70: loss = 0.5548213720321655, acc = 0.7978515625\n",
      "Batch 71: loss = 0.5015349388122559, acc = 0.83203125\n",
      "Batch 72: loss = 0.449207067489624, acc = 0.8466796875\n",
      "Batch 73: loss = 0.49506863951683044, acc = 0.8359375\n",
      "Batch 74: loss = 0.49996864795684814, acc = 0.8408203125\n",
      "Batch 75: loss = 0.5486680269241333, acc = 0.822265625\n",
      "Batch 76: loss = 0.49541229009628296, acc = 0.837890625\n",
      "Batch 77: loss = 0.49140405654907227, acc = 0.8359375\n",
      "Batch 78: loss = 0.4785616397857666, acc = 0.8349609375\n",
      "Batch 79: loss = 0.44549012184143066, acc = 0.84765625\n",
      "Batch 80: loss = 0.4523475468158722, acc = 0.841796875\n",
      "Batch 81: loss = 0.48463642597198486, acc = 0.8427734375\n",
      "Batch 82: loss = 0.4473782181739807, acc = 0.8505859375\n",
      "Batch 83: loss = 0.47718364000320435, acc = 0.8427734375\n",
      "Batch 84: loss = 0.49446871876716614, acc = 0.837890625\n",
      "Batch 85: loss = 0.5155344605445862, acc = 0.8232421875\n",
      "Batch 86: loss = 0.5018725395202637, acc = 0.8349609375\n",
      "Batch 87: loss = 0.5023193359375, acc = 0.8193359375\n",
      "Batch 88: loss = 0.5732815265655518, acc = 0.818359375\n",
      "Batch 89: loss = 0.490376353263855, acc = 0.83984375\n",
      "Batch 90: loss = 0.49557965993881226, acc = 0.83984375\n",
      "Batch 91: loss = 0.5033736228942871, acc = 0.833984375\n",
      "Batch 92: loss = 0.4907107353210449, acc = 0.8427734375\n",
      "Batch 93: loss = 0.40697163343429565, acc = 0.86328125\n",
      "Batch 94: loss = 0.4354376196861267, acc = 0.8466796875\n",
      "Batch 95: loss = 0.4336474537849426, acc = 0.8486328125\n",
      "Batch 96: loss = 0.5180466175079346, acc = 0.82421875\n",
      "Batch 97: loss = 0.4851940870285034, acc = 0.8466796875\n",
      "Batch 98: loss = 0.4852927327156067, acc = 0.845703125\n",
      "Batch 99: loss = 0.5101395845413208, acc = 0.822265625\n",
      "Batch 100: loss = 0.47488999366760254, acc = 0.8369140625\n",
      "Batch 101: loss = 0.4570225179195404, acc = 0.8447265625\n",
      "Batch 102: loss = 0.4805909991264343, acc = 0.8369140625\n",
      "Batch 103: loss = 0.458279550075531, acc = 0.8603515625\n",
      "Batch 104: loss = 0.4592100977897644, acc = 0.8291015625\n",
      "Batch 105: loss = 0.43723034858703613, acc = 0.84765625\n",
      "Batch 106: loss = 0.4997500777244568, acc = 0.8212890625\n",
      "Batch 107: loss = 0.4851023554801941, acc = 0.845703125\n",
      "Batch 108: loss = 0.48580402135849, acc = 0.837890625\n",
      "Batch 109: loss = 0.46850162744522095, acc = 0.8310546875\n",
      "Batch 110: loss = 0.4163370728492737, acc = 0.8642578125\n",
      "Batch 111: loss = 0.48625725507736206, acc = 0.8388671875\n",
      "Batch 112: loss = 0.46149712800979614, acc = 0.8583984375\n",
      "Batch 113: loss = 0.4827861785888672, acc = 0.830078125\n",
      "Batch 114: loss = 0.5128991007804871, acc = 0.841796875\n",
      "Batch 115: loss = 0.5030383467674255, acc = 0.8447265625\n",
      "Batch 116: loss = 0.5330475568771362, acc = 0.8291015625\n",
      "Batch 117: loss = 0.4335034489631653, acc = 0.857421875\n",
      "Batch 118: loss = 0.41909366846084595, acc = 0.8662109375\n",
      "Batch 119: loss = 0.49355199933052063, acc = 0.841796875\n",
      "Batch 120: loss = 0.49087730050086975, acc = 0.8349609375\n",
      "Batch 121: loss = 0.4728255867958069, acc = 0.8525390625\n",
      "Batch 122: loss = 0.462144672870636, acc = 0.84375\n",
      "Batch 123: loss = 0.49605831503868103, acc = 0.8349609375\n",
      "Batch 124: loss = 0.4902505874633789, acc = 0.8310546875\n",
      "Batch 125: loss = 0.5167149901390076, acc = 0.8173828125\n",
      "Batch 126: loss = 0.5232496857643127, acc = 0.8046875\n",
      "\n",
      "Epoch 54/100\n",
      "Batch 1: loss = 0.5853483080863953, acc = 0.8193359375\n",
      "Batch 2: loss = 0.5032027363777161, acc = 0.8310546875\n",
      "Batch 3: loss = 0.4657980501651764, acc = 0.84765625\n",
      "Batch 4: loss = 0.43175774812698364, acc = 0.857421875\n",
      "Batch 5: loss = 0.5088251829147339, acc = 0.8271484375\n",
      "Batch 6: loss = 0.5153862237930298, acc = 0.8271484375\n",
      "Batch 7: loss = 0.4319922924041748, acc = 0.8515625\n",
      "Batch 8: loss = 0.4624871015548706, acc = 0.8466796875\n",
      "Batch 9: loss = 0.48146578669548035, acc = 0.8486328125\n",
      "Batch 10: loss = 0.41970694065093994, acc = 0.8564453125\n",
      "Batch 11: loss = 0.48193514347076416, acc = 0.8447265625\n",
      "Batch 12: loss = 0.4245595932006836, acc = 0.857421875\n",
      "Batch 13: loss = 0.41232234239578247, acc = 0.8623046875\n",
      "Batch 14: loss = 0.4475967586040497, acc = 0.849609375\n",
      "Batch 15: loss = 0.4257658123970032, acc = 0.8642578125\n",
      "Batch 16: loss = 0.4867333769798279, acc = 0.8291015625\n",
      "Batch 17: loss = 0.49552640318870544, acc = 0.8408203125\n",
      "Batch 18: loss = 0.4924483299255371, acc = 0.84375\n",
      "Batch 19: loss = 0.4897668957710266, acc = 0.84375\n",
      "Batch 20: loss = 0.4274883270263672, acc = 0.853515625\n",
      "Batch 21: loss = 0.45476770401000977, acc = 0.8603515625\n",
      "Batch 22: loss = 0.4440728724002838, acc = 0.83203125\n",
      "Batch 23: loss = 0.49029338359832764, acc = 0.8310546875\n",
      "Batch 24: loss = 0.44042864441871643, acc = 0.861328125\n",
      "Batch 25: loss = 0.48097753524780273, acc = 0.8359375\n",
      "Batch 26: loss = 0.4663458466529846, acc = 0.8427734375\n",
      "Batch 27: loss = 0.5157241821289062, acc = 0.8388671875\n",
      "Batch 28: loss = 0.48502880334854126, acc = 0.8369140625\n",
      "Batch 29: loss = 0.5011427402496338, acc = 0.83203125\n",
      "Batch 30: loss = 0.4381897747516632, acc = 0.849609375\n",
      "Batch 31: loss = 0.48446619510650635, acc = 0.8447265625\n",
      "Batch 32: loss = 0.48316946625709534, acc = 0.837890625\n",
      "Batch 33: loss = 0.454717755317688, acc = 0.8466796875\n",
      "Batch 34: loss = 0.4843618869781494, acc = 0.849609375\n",
      "Batch 35: loss = 0.46212098002433777, acc = 0.8310546875\n",
      "Batch 36: loss = 0.42265039682388306, acc = 0.853515625\n",
      "Batch 37: loss = 0.39906513690948486, acc = 0.8671875\n",
      "Batch 38: loss = 0.4567812383174896, acc = 0.8486328125\n",
      "Batch 39: loss = 0.42933738231658936, acc = 0.8544921875\n",
      "Batch 40: loss = 0.4840545356273651, acc = 0.8310546875\n",
      "Batch 41: loss = 0.4221358895301819, acc = 0.8564453125\n",
      "Batch 42: loss = 0.43696486949920654, acc = 0.8603515625\n",
      "Batch 43: loss = 0.4662385880947113, acc = 0.83984375\n",
      "Batch 44: loss = 0.41775035858154297, acc = 0.8544921875\n",
      "Batch 45: loss = 0.38305777311325073, acc = 0.8779296875\n",
      "Batch 46: loss = 0.433255672454834, acc = 0.845703125\n",
      "Batch 47: loss = 0.45791590213775635, acc = 0.853515625\n",
      "Batch 48: loss = 0.41957470774650574, acc = 0.8564453125\n",
      "Batch 49: loss = 0.4337250590324402, acc = 0.8623046875\n",
      "Batch 50: loss = 0.3817919194698334, acc = 0.86328125\n",
      "Batch 51: loss = 0.4333672821521759, acc = 0.8505859375\n",
      "Batch 52: loss = 0.47737497091293335, acc = 0.8330078125\n",
      "Batch 53: loss = 0.46411529183387756, acc = 0.8408203125\n",
      "Batch 54: loss = 0.3691183924674988, acc = 0.876953125\n",
      "Batch 55: loss = 0.39730632305145264, acc = 0.85546875\n",
      "Batch 56: loss = 0.449248731136322, acc = 0.8427734375\n",
      "Batch 57: loss = 0.48527923226356506, acc = 0.818359375\n",
      "Batch 58: loss = 0.5428060293197632, acc = 0.818359375\n",
      "Batch 59: loss = 0.3852543234825134, acc = 0.873046875\n",
      "Batch 60: loss = 0.44461148977279663, acc = 0.849609375\n",
      "Batch 61: loss = 0.41592490673065186, acc = 0.8564453125\n",
      "Batch 62: loss = 0.502362847328186, acc = 0.837890625\n",
      "Batch 63: loss = 0.47743919491767883, acc = 0.8369140625\n",
      "Batch 64: loss = 0.4171895980834961, acc = 0.869140625\n",
      "Batch 65: loss = 0.467279851436615, acc = 0.837890625\n",
      "Batch 66: loss = 0.45057371258735657, acc = 0.849609375\n",
      "Batch 67: loss = 0.4364231526851654, acc = 0.8583984375\n",
      "Batch 68: loss = 0.49457740783691406, acc = 0.8369140625\n",
      "Batch 69: loss = 0.4060553014278412, acc = 0.865234375\n",
      "Batch 70: loss = 0.5199286937713623, acc = 0.8232421875\n",
      "Batch 71: loss = 0.4925340712070465, acc = 0.830078125\n",
      "Batch 72: loss = 0.48054397106170654, acc = 0.84375\n",
      "Batch 73: loss = 0.5212832689285278, acc = 0.8251953125\n",
      "Batch 74: loss = 0.4942193925380707, acc = 0.8232421875\n",
      "Batch 75: loss = 0.5508277416229248, acc = 0.802734375\n",
      "Batch 76: loss = 0.5065451264381409, acc = 0.8271484375\n",
      "Batch 77: loss = 0.4907687306404114, acc = 0.8291015625\n",
      "Batch 78: loss = 0.47575339674949646, acc = 0.83984375\n",
      "Batch 79: loss = 0.45843827724456787, acc = 0.8447265625\n",
      "Batch 80: loss = 0.45223546028137207, acc = 0.841796875\n",
      "Batch 81: loss = 0.4983573853969574, acc = 0.845703125\n",
      "Batch 82: loss = 0.4553321301937103, acc = 0.8583984375\n",
      "Batch 83: loss = 0.49442625045776367, acc = 0.833984375\n",
      "Batch 84: loss = 0.4738938808441162, acc = 0.8369140625\n",
      "Batch 85: loss = 0.5147466659545898, acc = 0.8310546875\n",
      "Batch 86: loss = 0.4804324805736542, acc = 0.8349609375\n",
      "Batch 87: loss = 0.4534074664115906, acc = 0.85546875\n",
      "Batch 88: loss = 0.5341028571128845, acc = 0.8232421875\n",
      "Batch 89: loss = 0.4910968542098999, acc = 0.8515625\n",
      "Batch 90: loss = 0.5140759944915771, acc = 0.8359375\n",
      "Batch 91: loss = 0.49862197041511536, acc = 0.828125\n",
      "Batch 92: loss = 0.49171724915504456, acc = 0.8291015625\n",
      "Batch 93: loss = 0.42719870805740356, acc = 0.859375\n",
      "Batch 94: loss = 0.4264164865016937, acc = 0.8720703125\n",
      "Batch 95: loss = 0.4271104633808136, acc = 0.8623046875\n",
      "Batch 96: loss = 0.497072696685791, acc = 0.8271484375\n",
      "Batch 97: loss = 0.504447877407074, acc = 0.830078125\n",
      "Batch 98: loss = 0.4638823866844177, acc = 0.8486328125\n",
      "Batch 99: loss = 0.4787653982639313, acc = 0.8447265625\n",
      "Batch 100: loss = 0.4871824085712433, acc = 0.8310546875\n",
      "Batch 101: loss = 0.4566141963005066, acc = 0.84765625\n",
      "Batch 102: loss = 0.5466279983520508, acc = 0.8115234375\n",
      "Batch 103: loss = 0.4530431032180786, acc = 0.8447265625\n",
      "Batch 104: loss = 0.4246617555618286, acc = 0.865234375\n",
      "Batch 105: loss = 0.40056610107421875, acc = 0.8671875\n",
      "Batch 106: loss = 0.4856598973274231, acc = 0.8271484375\n",
      "Batch 107: loss = 0.4535585343837738, acc = 0.845703125\n",
      "Batch 108: loss = 0.45071008801460266, acc = 0.84765625\n",
      "Batch 109: loss = 0.4519221782684326, acc = 0.84765625\n",
      "Batch 110: loss = 0.4156636595726013, acc = 0.8671875\n",
      "Batch 111: loss = 0.5047141909599304, acc = 0.83203125\n",
      "Batch 112: loss = 0.4313947558403015, acc = 0.859375\n",
      "Batch 113: loss = 0.45197540521621704, acc = 0.84765625\n",
      "Batch 114: loss = 0.4705412983894348, acc = 0.84765625\n",
      "Batch 115: loss = 0.5184636116027832, acc = 0.8251953125\n",
      "Batch 116: loss = 0.5327054262161255, acc = 0.8427734375\n",
      "Batch 117: loss = 0.44130438566207886, acc = 0.8544921875\n",
      "Batch 118: loss = 0.4093637466430664, acc = 0.861328125\n",
      "Batch 119: loss = 0.46025794744491577, acc = 0.8525390625\n",
      "Batch 120: loss = 0.45885419845581055, acc = 0.8330078125\n",
      "Batch 121: loss = 0.5285296440124512, acc = 0.828125\n",
      "Batch 122: loss = 0.4330470860004425, acc = 0.8486328125\n",
      "Batch 123: loss = 0.4667827785015106, acc = 0.8408203125\n",
      "Batch 124: loss = 0.4825533926486969, acc = 0.8369140625\n",
      "Batch 125: loss = 0.5193798542022705, acc = 0.84375\n",
      "Batch 126: loss = 0.4999741315841675, acc = 0.8388671875\n",
      "\n",
      "Epoch 55/100\n",
      "Batch 1: loss = 0.5542135834693909, acc = 0.828125\n",
      "Batch 2: loss = 0.5246136784553528, acc = 0.822265625\n",
      "Batch 3: loss = 0.4753785729408264, acc = 0.8486328125\n",
      "Batch 4: loss = 0.42932403087615967, acc = 0.8623046875\n",
      "Batch 5: loss = 0.5076620578765869, acc = 0.8359375\n",
      "Batch 6: loss = 0.5021044611930847, acc = 0.8427734375\n",
      "Batch 7: loss = 0.4293094575405121, acc = 0.8525390625\n",
      "Batch 8: loss = 0.4608905017375946, acc = 0.83984375\n",
      "Batch 9: loss = 0.47483527660369873, acc = 0.8408203125\n",
      "Batch 10: loss = 0.41031700372695923, acc = 0.876953125\n",
      "Batch 11: loss = 0.48003095388412476, acc = 0.849609375\n",
      "Batch 12: loss = 0.4331541061401367, acc = 0.8544921875\n",
      "Batch 13: loss = 0.4468015134334564, acc = 0.845703125\n",
      "Batch 14: loss = 0.44498446583747864, acc = 0.8603515625\n",
      "Batch 15: loss = 0.43968117237091064, acc = 0.8505859375\n",
      "Batch 16: loss = 0.48975104093551636, acc = 0.830078125\n",
      "Batch 17: loss = 0.4548557996749878, acc = 0.8447265625\n",
      "Batch 18: loss = 0.47996169328689575, acc = 0.857421875\n",
      "Batch 19: loss = 0.47816818952560425, acc = 0.845703125\n",
      "Batch 20: loss = 0.43355607986450195, acc = 0.861328125\n",
      "Batch 21: loss = 0.47331756353378296, acc = 0.849609375\n",
      "Batch 22: loss = 0.4805482029914856, acc = 0.830078125\n",
      "Batch 23: loss = 0.47350674867630005, acc = 0.8349609375\n",
      "Batch 24: loss = 0.4564835727214813, acc = 0.8564453125\n",
      "Batch 25: loss = 0.44522786140441895, acc = 0.8515625\n",
      "Batch 26: loss = 0.41994357109069824, acc = 0.861328125\n",
      "Batch 27: loss = 0.5302879810333252, acc = 0.826171875\n",
      "Batch 28: loss = 0.47849488258361816, acc = 0.828125\n",
      "Batch 29: loss = 0.47450345754623413, acc = 0.8349609375\n",
      "Batch 30: loss = 0.4347054958343506, acc = 0.8447265625\n",
      "Batch 31: loss = 0.470159113407135, acc = 0.8486328125\n",
      "Batch 32: loss = 0.5171390771865845, acc = 0.8330078125\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "save_freq = 20\n",
    "for epoch in range(epochs):\n",
    "    print(f'\\nEpoch {epoch + 1}/{epochs}')\n",
    "\n",
    "    losses, accs = [], []\n",
    "\n",
    "    for i, (X, Y) in enumerate(read_batches(T, BATCH_SIZE)):\n",
    "\n",
    "        loss, acc = model.train_on_batch(X, Y)\n",
    "        print(f'Batch {i+1}: loss = {loss}, acc = {acc}')\n",
    "        losses.append(loss)\n",
    "        accs.append(acc)\n",
    "\n",
    "    # log.add_entry(np.average(losses), np.average(accs))\n",
    "\n",
    "    if (epoch + 1) % save_freq == 0:\n",
    "        save_weights(model, epoch + 1)\n",
    "        print('Saved checkpoint to', f'weights.{epoch+1}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e4efbb8-e589-4d95-a130-2bc923e2cd1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2470465495236336, 0.9164574032738095)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(losses), np.average(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14e5cc3f-d4e9-42f6-93f3-364302e085d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sample_model(vocab_size):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 512, batch_input_shape=(1, 1)))\n",
    "    for i in range(3):\n",
    "        model.add(LSTM(256, return_sequences=(i != 2), stateful=True))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(vocab_size))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c02980f-11e3-4c1b-ac98-6e01c0bd7241",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_sample_model(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7ca2ba8-a3b4-442a-8e47-8899cad20b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_weights(model, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff417d9c-45c1-46ec-afa3-a2bb59a92ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = np.zeros((1,1))\n",
    "batch[0, 0] = np.random.randint(86)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18e52095-9cfd-48bd-acca-51f51d3d9492",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict_on_batch(batch).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c229176b-5c3b-40b9-9e8a-6cf7321a39a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.random.choice(range(vocab_size), p=result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43698d40-daf8-411c-9d66-7c65c7a571d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_chars = 1000\n",
    "sampled = []\n",
    "for i in range(num_chars):\n",
    "    batch = np.zeros((1, 1))\n",
    "    if sampled:\n",
    "        batch[0, 0] = sampled[-1]\n",
    "    else:\n",
    "        batch[0, 0] = np.random.randint(vocab_size)\n",
    "    result = model.predict_on_batch(batch).ravel()\n",
    "    sample = np.random.choice(range(vocab_size), p=result)\n",
    "    sampled.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "022bd5d0-b52f-4e64-bc32-b528488067b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":\"B7\"d2c \"F#7\"e2c|\"Bm\"dcB \"E7\"B2G|\n",
      "\"A\"A2B c2d|\"A\"eab \"E7\"ega|\"A\"aec A2e|\n",
      "\"A\"fed c2A|\"E\"GB2 e3|\"E7\"efe dcB|\"A\"A3 -A2:|\n",
      "\n",
      "\n",
      "X: 101\n",
      "T:Garster Jig\n",
      "% Nottingham Music Database\n",
      "S:Chris Dewhurst 1980, via Phil Rowe\n",
      "M:6/8\n",
      "K:G\n",
      "G2A |\"G\"B2B BAG|\"B\"A2A AGF|\"C\"G2G GAB|\"G\"D2B \"G7\"c2d|\"C\"e3 \"G7\"ed^c|\\\n",
      "\"G\"B2c dBd|\n",
      "\"C\"e2c \"C7\"GAG|\"F\"A2A \"G7\"GAB|\"C\"c2c edc|\"G\"B2G G2B|\n",
      "\"C\"cdc efg|\"D7\"FGA AGF| [1\"F\"fAF \"C\"GEC||\n",
      "\n",
      "\n",
      "X: 300\n",
      "T:Jown Lagactsire\n",
      "% Nottingham Music Database\n",
      "S:Ganfs MacKay, via EF\n",
      "M:6/8\n",
      "K:A\n",
      "P:A\n",
      "|:e|\"A\"agf \"E7\"efg|\"A\"aga f2e|\"D\"fed \"A\"cde|\n",
      "\"D\"F2A \"A\"ABc|\"Bm/2\"d2B \"E7/g+\"c2B|\"A\"c3 \"A7/e\"c3|\\\n",
      "\"D\"d2d \"A\"e2d|\\\n",
      "\"D/f+\"d3 \"G\"d2:|\n",
      "P:B\n",
      "c/2d/2|\"A\"e2e c2e|\"D\"f2f f3|\"E7\"gfg gfe|\"A\"a3 \"D#m\"a2f|\n",
      "\"G\"gab \"D\"afd|\"A\"ecA gfe|\"Bm\"efe \"E7\"dcB|\"A\"A3 A2:|\n",
      "\n",
      "\n",
      "X: 229\n",
      "T:Male's Jig\n",
      "% Nottingham Music Database\n",
      "Y:AABBCC\n",
      "S:Folk Camp, via EF\n",
      "M:6/8\n",
      "K:D\n",
      "P:A\n",
      "|:F/2G/2|\"D\"A2D FED|\"G\"D2D D2B|\"A7\"ABc \"D\"d2A|\"Bm\"Bcd \"Em\"GBB|\n",
      "\"C\"cBc edc|\"G\"BcB \"D7\"cBA|\"G\"GAG \"Am\"AGA|\"D7\"FGA \"G\"G3:|\n",
      "\n",
      "\n",
      "X: 257\n",
      "T:Moddaber Mack\n",
      "% Nottingham Music Database\n",
      "S:FTB, \n"
     ]
    }
   ],
   "source": [
    "print(''.join(idx_to_char[c] for c in sampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a8cf8d9-f8ac-4b7a-83b6-f03c07aadec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Feb  4 07:28:27 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   22C    P0    25W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5405cea-b346-4cf8-be74-ac2136ba8ccb",
   "metadata": {},
   "source": [
    "# Pytorch Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b41e3be3-14f2-4d9d-b8de-32921e9034cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import random \n",
    "import pickle\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5d06b32-7e07-4ee7-9e05-10c5d857a6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./input.txt\") as f:\n",
    "    input_text = f.read()\n",
    "char_to_idx = {ch: i for (i, ch) in enumerate(sorted(list(set(input_text))))}\n",
    "idx_to_char = {i: ch for (ch, i) in char_to_idx.items()}\n",
    "\n",
    "vocab_size = len(char_to_idx)\n",
    "T = torch.tensor([char_to_idx[c] for c in input_text], dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2408e12-e749-424a-959d-7ab7181983f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "SEQ_LENGTH = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c619e338-732b-46d3-8697-987ba41510b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_batches(T, BATCH_SIZE):\n",
    "    NUM_CHAR_EACH_ROW = T.shape[0]//BATCH_SIZE\n",
    "    \n",
    "    for start in range(0, NUM_CHAR_EACH_ROW - SEQ_LENGTH, SEQ_LENGTH):\n",
    "        X = torch.zeros((BATCH_SIZE, SEQ_LENGTH), dtype=torch.int32)\n",
    "        Y = torch.zeros((BATCH_SIZE, SEQ_LENGTH, vocab_size))\n",
    "        for row in range(16):\n",
    "            for col in range(64):\n",
    "                X[row, col] = T[row*NUM_CHAR_EACH_ROW + start + col]\n",
    "                Y[row, col, T[row*NUM_CHAR_EACH_ROW + start + col + 1]] = 1\n",
    "        yield X , Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c9668cb6-4d28-4e57-a9e4-18555aee953e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharLSTM(nn.Module):\n",
    "    def __init__(self, n_hidden = 256, n_layers = 3, drop_prob = 0.2):\n",
    "        super(CharLSTM, self).__init__()\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_layers = n_layers\n",
    "        self.drop_prob = drop_prob\n",
    "        \n",
    "        self.emb = nn.Embedding(vocab_size, 512)\n",
    "        self.lstm = nn.LSTM(512, n_hidden, n_layers, dropout=drop_prob, batch_first=True)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        self.fc = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        embedded = self.emb(x)\n",
    "        out, hn = self.lstm(embedded, h)\n",
    "        out = self.dropout(out)\n",
    "        out = out.reshape(-1, self.n_hidden)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out, hn\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        h0 = torch.zeros(self.n_layers, batch_size, self.n_hidden).to(device)\n",
    "        c0 = torch.zeros(self.n_layers, batch_size, self.n_hidden).to(device)\n",
    "\n",
    "        return (h0,c0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d323d63-1e5c-40e7-baf6-71ce438fe78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = \"./Model_torch_weights\"\n",
    "def save_weights(model, epoch):\n",
    "    if not os.path.exists(MODEL_DIR):\n",
    "        os.makedirs(MODEL_DIR)\n",
    "    torch.save(model.state_dict(), os.path.join(MODEL_DIR, f\"weights.{epoch}.pt\"))\n",
    "def load_weights(model, epoch):\n",
    "    model.load_state_dict(torch.load(os.path.join(MODEL_DIR, f\"weights.{epoch}.pt\")))\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9235ccb2-5584-452a-b4de-94a38512fed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f58885be-f2dc-4192-ac71-bb92d04aaa58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5b798942-b29f-4904-b5ee-35cbd5690a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CharLSTM().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a24a38b-56cb-47e7-8fbd-aaf4679f9d55",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100\n",
      "Batch 1: loss = 4.458819389343262\n",
      "Batch 2: loss = 4.418922424316406\n",
      "Batch 3: loss = 4.371307373046875\n",
      "Batch 4: loss = 4.245875358581543\n",
      "Batch 5: loss = 3.9554805755615234\n",
      "Batch 6: loss = 3.6922225952148438\n",
      "Batch 7: loss = 3.541724920272827\n",
      "Batch 8: loss = 3.4940390586853027\n",
      "Batch 9: loss = 3.615858554840088\n",
      "Batch 10: loss = 3.5729775428771973\n",
      "Batch 11: loss = 3.3902955055236816\n",
      "Batch 12: loss = 3.455176591873169\n",
      "Batch 13: loss = 3.5163984298706055\n",
      "Batch 14: loss = 3.4540257453918457\n",
      "Batch 15: loss = 3.4996345043182373\n",
      "Batch 16: loss = 3.34891414642334\n",
      "Batch 17: loss = 3.302205801010132\n",
      "Batch 18: loss = 3.26393985748291\n",
      "Batch 19: loss = 3.4526662826538086\n",
      "Batch 20: loss = 3.401099681854248\n",
      "Batch 21: loss = 3.4457273483276367\n",
      "Batch 22: loss = 3.392259120941162\n",
      "Batch 23: loss = 3.2262730598449707\n",
      "Batch 24: loss = 3.369324207305908\n",
      "Batch 25: loss = 3.3640048503875732\n",
      "Batch 26: loss = 3.364295244216919\n",
      "Batch 27: loss = 3.1230974197387695\n",
      "Batch 28: loss = 3.2189364433288574\n",
      "Batch 29: loss = 3.3329062461853027\n",
      "Batch 30: loss = 3.2901315689086914\n",
      "Batch 31: loss = 3.1846461296081543\n",
      "Batch 32: loss = 3.264619827270508\n",
      "Batch 33: loss = 3.2585573196411133\n",
      "Batch 34: loss = 3.199845314025879\n",
      "Batch 35: loss = 3.161869525909424\n",
      "Batch 36: loss = 3.310790538787842\n",
      "Batch 37: loss = 3.241835594177246\n",
      "Batch 38: loss = 3.2184410095214844\n",
      "Batch 39: loss = 3.199820041656494\n",
      "Batch 40: loss = 3.1801018714904785\n",
      "Batch 41: loss = 3.1933534145355225\n",
      "Batch 42: loss = 3.0512490272521973\n",
      "Batch 43: loss = 3.0814828872680664\n",
      "Batch 44: loss = 3.2166576385498047\n",
      "Batch 45: loss = 3.189540386199951\n",
      "Batch 46: loss = 3.092592239379883\n",
      "Batch 47: loss = 3.1117279529571533\n",
      "Batch 48: loss = 3.0545217990875244\n",
      "Batch 49: loss = 3.1583101749420166\n",
      "Batch 50: loss = 3.073038339614868\n",
      "Batch 51: loss = 3.0250372886657715\n",
      "Batch 52: loss = 2.9844114780426025\n",
      "Batch 53: loss = 3.0694923400878906\n",
      "Batch 54: loss = 3.1292550563812256\n",
      "Batch 55: loss = 3.133714199066162\n",
      "Batch 56: loss = 2.955442428588867\n",
      "Batch 57: loss = 2.888321876525879\n",
      "Batch 58: loss = 3.0195438861846924\n",
      "Batch 59: loss = 3.0837082862854004\n",
      "Batch 60: loss = 2.9314684867858887\n",
      "Batch 61: loss = 2.931696891784668\n",
      "Batch 62: loss = 2.761763095855713\n",
      "Batch 63: loss = 2.9907331466674805\n",
      "Batch 64: loss = 2.9530067443847656\n",
      "Batch 65: loss = 2.780799388885498\n",
      "Batch 66: loss = 2.8197391033172607\n",
      "Batch 67: loss = 2.888817548751831\n",
      "Batch 68: loss = 2.8222153186798096\n",
      "Batch 69: loss = 2.7625436782836914\n",
      "Batch 70: loss = 2.6057400703430176\n",
      "Batch 71: loss = 2.7738914489746094\n",
      "Batch 72: loss = 2.8666627407073975\n",
      "Batch 73: loss = 2.69608211517334\n",
      "Batch 74: loss = 2.5631422996520996\n",
      "Batch 75: loss = 2.5541296005249023\n",
      "Batch 76: loss = 2.6506152153015137\n",
      "Batch 77: loss = 2.631948709487915\n",
      "Batch 78: loss = 2.516754627227783\n",
      "Batch 79: loss = 2.5571160316467285\n",
      "Batch 80: loss = 2.3509409427642822\n",
      "Batch 81: loss = 2.585925579071045\n",
      "Batch 82: loss = 2.697826862335205\n",
      "Batch 83: loss = 2.500336170196533\n",
      "Batch 84: loss = 2.4547882080078125\n",
      "Batch 85: loss = 2.28412127494812\n",
      "Batch 86: loss = 2.5833306312561035\n",
      "Batch 87: loss = 2.7452869415283203\n",
      "Batch 88: loss = 2.483060359954834\n",
      "Batch 89: loss = 2.5895402431488037\n",
      "Batch 90: loss = 2.5702452659606934\n",
      "Batch 91: loss = 2.3271117210388184\n",
      "Batch 92: loss = 2.410057783126831\n",
      "Batch 93: loss = 2.4969418048858643\n",
      "Batch 94: loss = 2.34891414642334\n",
      "Batch 95: loss = 2.2448811531066895\n",
      "Batch 96: loss = 2.2186496257781982\n",
      "Batch 97: loss = 2.4577646255493164\n",
      "Batch 98: loss = 2.4715890884399414\n",
      "Batch 99: loss = 2.199277639389038\n",
      "Batch 100: loss = 2.1981301307678223\n",
      "Batch 101: loss = 2.3542628288269043\n",
      "Batch 102: loss = 2.4726853370666504\n",
      "Batch 103: loss = 2.372640609741211\n",
      "Batch 104: loss = 2.198112964630127\n",
      "Batch 105: loss = 2.173438549041748\n",
      "Batch 106: loss = 2.230989456176758\n",
      "Batch 107: loss = 2.239773750305176\n",
      "Batch 108: loss = 2.1708106994628906\n",
      "Batch 109: loss = 2.0898728370666504\n",
      "Batch 110: loss = 2.239941120147705\n",
      "Batch 111: loss = 2.2457873821258545\n",
      "Batch 112: loss = 2.2212445735931396\n",
      "Batch 113: loss = 2.1647801399230957\n",
      "Batch 114: loss = 2.3051095008850098\n",
      "Batch 115: loss = 2.2332139015197754\n",
      "Batch 116: loss = 2.1536216735839844\n",
      "Batch 117: loss = 2.3265433311462402\n",
      "Batch 118: loss = 2.145090103149414\n",
      "Batch 119: loss = 2.05464506149292\n",
      "Batch 120: loss = 2.1374807357788086\n",
      "Batch 121: loss = 2.0801641941070557\n",
      "Batch 122: loss = 2.232893466949463\n",
      "Batch 123: loss = 2.1851766109466553\n",
      "Batch 124: loss = 2.055725574493408\n",
      "Batch 125: loss = 2.0110225677490234\n",
      "Batch 126: loss = 2.1632864475250244\n",
      "\n",
      "Epoch 2/100\n",
      "Batch 1: loss = 2.1634130477905273\n",
      "Batch 2: loss = 2.016005754470825\n",
      "Batch 3: loss = 2.179062843322754\n",
      "Batch 4: loss = 2.0121288299560547\n",
      "Batch 5: loss = 2.116572856903076\n",
      "Batch 6: loss = 2.121556520462036\n",
      "Batch 7: loss = 2.1455628871917725\n",
      "Batch 8: loss = 2.03633713722229\n",
      "Batch 9: loss = 2.036712884902954\n",
      "Batch 10: loss = 1.905588150024414\n",
      "Batch 11: loss = 1.9558756351470947\n",
      "Batch 12: loss = 2.042477607727051\n",
      "Batch 13: loss = 2.0077381134033203\n",
      "Batch 14: loss = 1.9261274337768555\n",
      "Batch 15: loss = 2.006804943084717\n",
      "Batch 16: loss = 2.012418508529663\n",
      "Batch 17: loss = 1.9544429779052734\n",
      "Batch 18: loss = 1.965852975845337\n",
      "Batch 19: loss = 2.0550758838653564\n",
      "Batch 20: loss = 1.9327096939086914\n",
      "Batch 21: loss = 2.075989246368408\n",
      "Batch 22: loss = 1.9200034141540527\n",
      "Batch 23: loss = 1.8751360177993774\n",
      "Batch 24: loss = 1.9771031141281128\n",
      "Batch 25: loss = 1.8643717765808105\n",
      "Batch 26: loss = 1.9090930223464966\n",
      "Batch 27: loss = 1.790033221244812\n",
      "Batch 28: loss = 1.8190666437149048\n",
      "Batch 29: loss = 1.8804738521575928\n",
      "Batch 30: loss = 1.8802396059036255\n",
      "Batch 31: loss = 1.8505983352661133\n",
      "Batch 32: loss = 2.0140764713287354\n",
      "Batch 33: loss = 1.9123585224151611\n",
      "Batch 34: loss = 1.8349313735961914\n",
      "Batch 35: loss = 1.847884178161621\n",
      "Batch 36: loss = 1.9818167686462402\n",
      "Batch 37: loss = 1.9506053924560547\n",
      "Batch 38: loss = 1.8805088996887207\n",
      "Batch 39: loss = 1.8297820091247559\n",
      "Batch 40: loss = 1.800045371055603\n",
      "Batch 41: loss = 1.77961266040802\n",
      "Batch 42: loss = 1.695198893547058\n",
      "Batch 43: loss = 1.729705572128296\n",
      "Batch 44: loss = 1.7696938514709473\n",
      "Batch 45: loss = 1.6944681406021118\n",
      "Batch 46: loss = 1.7462146282196045\n",
      "Batch 47: loss = 1.767009973526001\n",
      "Batch 48: loss = 1.654933214187622\n",
      "Batch 49: loss = 1.6681618690490723\n",
      "Batch 50: loss = 1.6671912670135498\n",
      "Batch 51: loss = 1.7251460552215576\n",
      "Batch 52: loss = 1.772814154624939\n",
      "Batch 53: loss = 1.7956486940383911\n",
      "Batch 54: loss = 1.7614905834197998\n",
      "Batch 55: loss = 1.8188514709472656\n",
      "Batch 56: loss = 1.657001256942749\n",
      "Batch 57: loss = 1.7632513046264648\n",
      "Batch 58: loss = 1.7500555515289307\n",
      "Batch 59: loss = 1.5996911525726318\n",
      "Batch 60: loss = 1.6863048076629639\n",
      "Batch 61: loss = 1.7777252197265625\n",
      "Batch 62: loss = 1.7555557489395142\n",
      "Batch 63: loss = 1.8437044620513916\n",
      "Batch 64: loss = 1.5166058540344238\n",
      "Batch 65: loss = 1.6303836107254028\n",
      "Batch 66: loss = 1.6179766654968262\n",
      "Batch 67: loss = 1.6593705415725708\n",
      "Batch 68: loss = 1.6459699869155884\n",
      "Batch 69: loss = 1.580179214477539\n",
      "Batch 70: loss = 1.705737829208374\n",
      "Batch 71: loss = 1.6417189836502075\n",
      "Batch 72: loss = 1.575439214706421\n",
      "Batch 73: loss = 1.6523516178131104\n",
      "Batch 74: loss = 1.6028708219528198\n",
      "Batch 75: loss = 1.6579563617706299\n",
      "Batch 76: loss = 1.665804147720337\n",
      "Batch 77: loss = 1.5328054428100586\n",
      "Batch 78: loss = 1.470529317855835\n",
      "Batch 79: loss = 1.4282773733139038\n",
      "Batch 80: loss = 1.4575270414352417\n",
      "Batch 81: loss = 1.5162973403930664\n",
      "Batch 82: loss = 1.5174152851104736\n",
      "Batch 83: loss = 1.5161137580871582\n",
      "Batch 84: loss = 1.5027390718460083\n",
      "Batch 85: loss = 1.5527716875076294\n",
      "Batch 86: loss = 1.5507142543792725\n",
      "Batch 87: loss = 1.5319087505340576\n",
      "Batch 88: loss = 1.7054598331451416\n",
      "Batch 89: loss = 1.625391960144043\n",
      "Batch 90: loss = 1.7136963605880737\n",
      "Batch 91: loss = 1.6172115802764893\n",
      "Batch 92: loss = 1.4475929737091064\n",
      "Batch 93: loss = 1.4577012062072754\n",
      "Batch 94: loss = 1.4969549179077148\n",
      "Batch 95: loss = 1.5103901624679565\n",
      "Batch 96: loss = 1.529564380645752\n",
      "Batch 97: loss = 1.5340137481689453\n",
      "Batch 98: loss = 1.54490065574646\n",
      "Batch 99: loss = 1.5293712615966797\n",
      "Batch 100: loss = 1.4786640405654907\n",
      "Batch 101: loss = 1.6066800355911255\n",
      "Batch 102: loss = 1.6230964660644531\n",
      "Batch 103: loss = 1.5851677656173706\n",
      "Batch 104: loss = 1.4524683952331543\n",
      "Batch 105: loss = 1.522825002670288\n",
      "Batch 106: loss = 1.5744119882583618\n",
      "Batch 107: loss = 1.5091769695281982\n",
      "Batch 108: loss = 1.4841017723083496\n",
      "Batch 109: loss = 1.4790204763412476\n",
      "Batch 110: loss = 1.4811819791793823\n",
      "Batch 111: loss = 1.6302357912063599\n",
      "Batch 112: loss = 1.4879465103149414\n",
      "Batch 113: loss = 1.47892427444458\n",
      "Batch 114: loss = 1.5969303846359253\n",
      "Batch 115: loss = 1.615551233291626\n",
      "Batch 116: loss = 1.5992497205734253\n",
      "Batch 117: loss = 1.4981558322906494\n",
      "Batch 118: loss = 1.487138032913208\n",
      "Batch 119: loss = 1.5651692152023315\n",
      "Batch 120: loss = 1.6277531385421753\n",
      "Batch 121: loss = 1.4357564449310303\n",
      "Batch 122: loss = 1.4526216983795166\n",
      "Batch 123: loss = 1.4804027080535889\n",
      "Batch 124: loss = 1.549980878829956\n",
      "Batch 125: loss = 1.4952654838562012\n",
      "Batch 126: loss = 1.5943711996078491\n",
      "\n",
      "Epoch 3/100\n",
      "Batch 1: loss = 1.597005844116211\n",
      "Batch 2: loss = 1.553788661956787\n",
      "Batch 3: loss = 1.612595558166504\n",
      "Batch 4: loss = 1.4764431715011597\n",
      "Batch 5: loss = 1.6396151781082153\n",
      "Batch 6: loss = 1.6226351261138916\n",
      "Batch 7: loss = 1.6322451829910278\n",
      "Batch 8: loss = 1.4547374248504639\n",
      "Batch 9: loss = 1.459052562713623\n",
      "Batch 10: loss = 1.3660268783569336\n",
      "Batch 11: loss = 1.4896937608718872\n",
      "Batch 12: loss = 1.6393089294433594\n",
      "Batch 13: loss = 1.5227693319320679\n",
      "Batch 14: loss = 1.398442029953003\n",
      "Batch 15: loss = 1.4574460983276367\n",
      "Batch 16: loss = 1.5735279321670532\n",
      "Batch 17: loss = 1.5362257957458496\n",
      "Batch 18: loss = 1.582350492477417\n",
      "Batch 19: loss = 1.5770201683044434\n",
      "Batch 20: loss = 1.4259655475616455\n",
      "Batch 21: loss = 1.6300973892211914\n",
      "Batch 22: loss = 1.4269394874572754\n",
      "Batch 23: loss = 1.4971115589141846\n",
      "Batch 24: loss = 1.5148321390151978\n",
      "Batch 25: loss = 1.3892751932144165\n",
      "Batch 26: loss = 1.4588050842285156\n",
      "Batch 27: loss = 1.4842443466186523\n",
      "Batch 28: loss = 1.4822452068328857\n",
      "Batch 29: loss = 1.415622591972351\n",
      "Batch 30: loss = 1.4438865184783936\n",
      "Batch 31: loss = 1.5030670166015625\n",
      "Batch 32: loss = 1.6768261194229126\n",
      "Batch 33: loss = 1.4894981384277344\n",
      "Batch 34: loss = 1.498608112335205\n",
      "Batch 35: loss = 1.513275146484375\n",
      "Batch 36: loss = 1.5367169380187988\n",
      "Batch 37: loss = 1.552225112915039\n",
      "Batch 38: loss = 1.5438722372055054\n",
      "Batch 39: loss = 1.5054636001586914\n",
      "Batch 40: loss = 1.4672234058380127\n",
      "Batch 41: loss = 1.4213616847991943\n",
      "Batch 42: loss = 1.3960621356964111\n",
      "Batch 43: loss = 1.428455114364624\n",
      "Batch 44: loss = 1.3826327323913574\n",
      "Batch 45: loss = 1.303486704826355\n",
      "Batch 46: loss = 1.398103952407837\n",
      "Batch 47: loss = 1.3839281797409058\n",
      "Batch 48: loss = 1.3077857494354248\n",
      "Batch 49: loss = 1.3088345527648926\n",
      "Batch 50: loss = 1.3286492824554443\n",
      "Batch 51: loss = 1.413737177848816\n",
      "Batch 52: loss = 1.5184311866760254\n",
      "Batch 53: loss = 1.4531564712524414\n",
      "Batch 54: loss = 1.3761579990386963\n",
      "Batch 55: loss = 1.4473623037338257\n",
      "Batch 56: loss = 1.3885447978973389\n",
      "Batch 57: loss = 1.4975262880325317\n",
      "Batch 58: loss = 1.4190510511398315\n",
      "Batch 59: loss = 1.2227412462234497\n",
      "Batch 60: loss = 1.3913222551345825\n",
      "Batch 61: loss = 1.4684792757034302\n",
      "Batch 62: loss = 1.5426701307296753\n",
      "Batch 63: loss = 1.5568130016326904\n",
      "Batch 64: loss = 1.1679844856262207\n",
      "Batch 65: loss = 1.3839612007141113\n",
      "Batch 66: loss = 1.3703627586364746\n",
      "Batch 67: loss = 1.3487650156021118\n",
      "Batch 68: loss = 1.3791273832321167\n",
      "Batch 69: loss = 1.3154560327529907\n",
      "Batch 70: loss = 1.4529316425323486\n",
      "Batch 71: loss = 1.3418452739715576\n",
      "Batch 72: loss = 1.3029088973999023\n",
      "Batch 73: loss = 1.4265828132629395\n",
      "Batch 74: loss = 1.4073843955993652\n",
      "Batch 75: loss = 1.468359351158142\n",
      "Batch 76: loss = 1.444869041442871\n",
      "Batch 77: loss = 1.2702937126159668\n",
      "Batch 78: loss = 1.2793134450912476\n",
      "Batch 79: loss = 1.1732513904571533\n",
      "Batch 80: loss = 1.2666864395141602\n",
      "Batch 81: loss = 1.2683770656585693\n",
      "Batch 82: loss = 1.242460012435913\n",
      "Batch 83: loss = 1.2986907958984375\n",
      "Batch 84: loss = 1.3055970668792725\n",
      "Batch 85: loss = 1.4032516479492188\n",
      "Batch 86: loss = 1.3412424325942993\n",
      "Batch 87: loss = 1.3031833171844482\n",
      "Batch 88: loss = 1.4933390617370605\n",
      "Batch 89: loss = 1.3548741340637207\n",
      "Batch 90: loss = 1.51027250289917\n",
      "Batch 91: loss = 1.4330568313598633\n",
      "Batch 92: loss = 1.2315807342529297\n",
      "Batch 93: loss = 1.2320386171340942\n",
      "Batch 94: loss = 1.2935750484466553\n",
      "Batch 95: loss = 1.3368229866027832\n",
      "Batch 96: loss = 1.3815100193023682\n",
      "Batch 97: loss = 1.3433221578598022\n",
      "Batch 98: loss = 1.349948525428772\n",
      "Batch 99: loss = 1.3799786567687988\n",
      "Batch 100: loss = 1.3313822746276855\n",
      "Batch 101: loss = 1.3921644687652588\n",
      "Batch 102: loss = 1.4177603721618652\n",
      "Batch 103: loss = 1.3990094661712646\n",
      "Batch 104: loss = 1.265825867652893\n",
      "Batch 105: loss = 1.3631004095077515\n",
      "Batch 106: loss = 1.394656777381897\n",
      "Batch 107: loss = 1.325537919998169\n",
      "Batch 108: loss = 1.3172976970672607\n",
      "Batch 109: loss = 1.340794324874878\n",
      "Batch 110: loss = 1.289907455444336\n",
      "Batch 111: loss = 1.4632319211959839\n",
      "Batch 112: loss = 1.3051567077636719\n",
      "Batch 113: loss = 1.3445618152618408\n",
      "Batch 114: loss = 1.4110815525054932\n",
      "Batch 115: loss = 1.4710813760757446\n",
      "Batch 116: loss = 1.4566154479980469\n",
      "Batch 117: loss = 1.2968614101409912\n",
      "Batch 118: loss = 1.324625015258789\n",
      "Batch 119: loss = 1.4119477272033691\n",
      "Batch 120: loss = 1.4588429927825928\n",
      "Batch 121: loss = 1.2912514209747314\n",
      "Batch 122: loss = 1.2741385698318481\n",
      "Batch 123: loss = 1.3344969749450684\n",
      "Batch 124: loss = 1.3951265811920166\n",
      "Batch 125: loss = 1.3802175521850586\n",
      "Batch 126: loss = 1.492417573928833\n",
      "\n",
      "Epoch 4/100\n",
      "Batch 1: loss = 1.4806177616119385\n",
      "Batch 2: loss = 1.4551458358764648\n",
      "Batch 3: loss = 1.4411356449127197\n",
      "Batch 4: loss = 1.3532313108444214\n",
      "Batch 5: loss = 1.5065791606903076\n",
      "Batch 6: loss = 1.490796685218811\n",
      "Batch 7: loss = 1.5185129642486572\n",
      "Batch 8: loss = 1.3409926891326904\n",
      "Batch 9: loss = 1.3442871570587158\n",
      "Batch 10: loss = 1.2383739948272705\n",
      "Batch 11: loss = 1.3878061771392822\n",
      "Batch 12: loss = 1.5170279741287231\n",
      "Batch 13: loss = 1.3895562887191772\n",
      "Batch 14: loss = 1.2699260711669922\n",
      "Batch 15: loss = 1.318458080291748\n",
      "Batch 16: loss = 1.454113483428955\n",
      "Batch 17: loss = 1.427929401397705\n",
      "Batch 18: loss = 1.447037935256958\n",
      "Batch 19: loss = 1.437162160873413\n",
      "Batch 20: loss = 1.2874739170074463\n",
      "Batch 21: loss = 1.5144684314727783\n",
      "Batch 22: loss = 1.3119651079177856\n",
      "Batch 23: loss = 1.3867108821868896\n",
      "Batch 24: loss = 1.364392638206482\n",
      "Batch 25: loss = 1.2534129619598389\n",
      "Batch 26: loss = 1.2912276983261108\n",
      "Batch 27: loss = 1.3745970726013184\n",
      "Batch 28: loss = 1.3755602836608887\n",
      "Batch 29: loss = 1.3049614429473877\n",
      "Batch 30: loss = 1.3057149648666382\n",
      "Batch 31: loss = 1.4328334331512451\n",
      "Batch 32: loss = 1.5656886100769043\n",
      "Batch 33: loss = 1.3786282539367676\n",
      "Batch 34: loss = 1.3979555368423462\n",
      "Batch 35: loss = 1.3997972011566162\n",
      "Batch 36: loss = 1.411926031112671\n",
      "Batch 37: loss = 1.4173871278762817\n",
      "Batch 38: loss = 1.425401210784912\n",
      "Batch 39: loss = 1.37013578414917\n",
      "Batch 40: loss = 1.3706142902374268\n",
      "Batch 41: loss = 1.2893187999725342\n",
      "Batch 42: loss = 1.3081679344177246\n",
      "Batch 43: loss = 1.3395917415618896\n",
      "Batch 44: loss = 1.299039602279663\n",
      "Batch 45: loss = 1.2071130275726318\n",
      "Batch 46: loss = 1.330214262008667\n",
      "Batch 47: loss = 1.2796417474746704\n",
      "Batch 48: loss = 1.2394938468933105\n",
      "Batch 49: loss = 1.1806715726852417\n",
      "Batch 50: loss = 1.2376576662063599\n",
      "Batch 51: loss = 1.2899107933044434\n",
      "Batch 52: loss = 1.4232354164123535\n",
      "Batch 53: loss = 1.3596280813217163\n",
      "Batch 54: loss = 1.271259069442749\n",
      "Batch 55: loss = 1.3399380445480347\n",
      "Batch 56: loss = 1.2977473735809326\n",
      "Batch 57: loss = 1.4039889574050903\n",
      "Batch 58: loss = 1.3371105194091797\n",
      "Batch 59: loss = 1.1204633712768555\n",
      "Batch 60: loss = 1.2959764003753662\n",
      "Batch 61: loss = 1.385634183883667\n",
      "Batch 62: loss = 1.5068376064300537\n",
      "Batch 63: loss = 1.4327666759490967\n",
      "Batch 64: loss = 1.0823540687561035\n",
      "Batch 65: loss = 1.3022887706756592\n",
      "Batch 66: loss = 1.284480094909668\n",
      "Batch 67: loss = 1.2543714046478271\n",
      "Batch 68: loss = 1.2804089784622192\n",
      "Batch 69: loss = 1.2502058744430542\n",
      "Batch 70: loss = 1.373589038848877\n",
      "Batch 71: loss = 1.2631564140319824\n",
      "Batch 72: loss = 1.197540283203125\n",
      "Batch 73: loss = 1.3427201509475708\n",
      "Batch 74: loss = 1.3342623710632324\n",
      "Batch 75: loss = 1.3840869665145874\n",
      "Batch 76: loss = 1.3596956729888916\n",
      "Batch 77: loss = 1.1892292499542236\n",
      "Batch 78: loss = 1.2224841117858887\n",
      "Batch 79: loss = 1.0895545482635498\n",
      "Batch 80: loss = 1.1842150688171387\n",
      "Batch 81: loss = 1.1909534931182861\n",
      "Batch 82: loss = 1.1079944372177124\n",
      "Batch 83: loss = 1.2233248949050903\n",
      "Batch 84: loss = 1.2227787971496582\n",
      "Batch 85: loss = 1.3595936298370361\n",
      "Batch 86: loss = 1.267765998840332\n",
      "Batch 87: loss = 1.1850793361663818\n",
      "Batch 88: loss = 1.4114608764648438\n",
      "Batch 89: loss = 1.2866936922073364\n",
      "Batch 90: loss = 1.398862361907959\n",
      "Batch 91: loss = 1.3401546478271484\n",
      "Batch 92: loss = 1.1752156019210815\n",
      "Batch 93: loss = 1.150955319404602\n",
      "Batch 94: loss = 1.2005090713500977\n",
      "Batch 95: loss = 1.2765971422195435\n",
      "Batch 96: loss = 1.307246208190918\n",
      "Batch 97: loss = 1.2728285789489746\n",
      "Batch 98: loss = 1.2455670833587646\n",
      "Batch 99: loss = 1.3003817796707153\n",
      "Batch 100: loss = 1.2597624063491821\n",
      "Batch 101: loss = 1.3038628101348877\n",
      "Batch 102: loss = 1.321609616279602\n",
      "Batch 103: loss = 1.299707293510437\n",
      "Batch 104: loss = 1.2000921964645386\n",
      "Batch 105: loss = 1.2873653173446655\n",
      "Batch 106: loss = 1.342667818069458\n",
      "Batch 107: loss = 1.253204107284546\n",
      "Batch 108: loss = 1.2378792762756348\n",
      "Batch 109: loss = 1.2748385667800903\n",
      "Batch 110: loss = 1.1911616325378418\n",
      "Batch 111: loss = 1.3902709484100342\n",
      "Batch 112: loss = 1.2241663932800293\n",
      "Batch 113: loss = 1.2830554246902466\n",
      "Batch 114: loss = 1.3354263305664062\n",
      "Batch 115: loss = 1.4022603034973145\n",
      "Batch 116: loss = 1.3780550956726074\n",
      "Batch 117: loss = 1.2271575927734375\n",
      "Batch 118: loss = 1.2234165668487549\n",
      "Batch 119: loss = 1.365769624710083\n",
      "Batch 120: loss = 1.3610503673553467\n",
      "Batch 121: loss = 1.2151306867599487\n",
      "Batch 122: loss = 1.2057740688323975\n",
      "Batch 123: loss = 1.2467501163482666\n",
      "Batch 124: loss = 1.3385623693466187\n",
      "Batch 125: loss = 1.3202989101409912\n",
      "Batch 126: loss = 1.4035091400146484\n",
      "\n",
      "Epoch 5/100\n",
      "Batch 1: loss = 1.3852660655975342\n",
      "Batch 2: loss = 1.398540735244751\n",
      "Batch 3: loss = 1.3494393825531006\n",
      "Batch 4: loss = 1.3145532608032227\n",
      "Batch 5: loss = 1.4483219385147095\n",
      "Batch 6: loss = 1.444205641746521\n",
      "Batch 7: loss = 1.4403825998306274\n",
      "Batch 8: loss = 1.2755210399627686\n",
      "Batch 9: loss = 1.2593133449554443\n",
      "Batch 10: loss = 1.1707746982574463\n",
      "Batch 11: loss = 1.315842628479004\n",
      "Batch 12: loss = 1.42680025100708\n",
      "Batch 13: loss = 1.309281587600708\n",
      "Batch 14: loss = 1.2162184715270996\n",
      "Batch 15: loss = 1.2356374263763428\n",
      "Batch 16: loss = 1.3903864622116089\n",
      "Batch 17: loss = 1.3301308155059814\n",
      "Batch 18: loss = 1.372544765472412\n",
      "Batch 19: loss = 1.3390791416168213\n",
      "Batch 20: loss = 1.2176454067230225\n",
      "Batch 21: loss = 1.4293851852416992\n",
      "Batch 22: loss = 1.2264599800109863\n",
      "Batch 23: loss = 1.3081153631210327\n",
      "Batch 24: loss = 1.2999353408813477\n",
      "Batch 25: loss = 1.1779389381408691\n",
      "Batch 26: loss = 1.2050524950027466\n",
      "Batch 27: loss = 1.3171122074127197\n",
      "Batch 28: loss = 1.2847243547439575\n",
      "Batch 29: loss = 1.2252869606018066\n",
      "Batch 30: loss = 1.200618028640747\n",
      "Batch 31: loss = 1.3588440418243408\n",
      "Batch 32: loss = 1.4891114234924316\n",
      "Batch 33: loss = 1.2942171096801758\n",
      "Batch 34: loss = 1.320817232131958\n",
      "Batch 35: loss = 1.3251395225524902\n",
      "Batch 36: loss = 1.2994441986083984\n",
      "Batch 37: loss = 1.3317821025848389\n",
      "Batch 38: loss = 1.355079174041748\n",
      "Batch 39: loss = 1.3046584129333496\n",
      "Batch 40: loss = 1.279766321182251\n",
      "Batch 41: loss = 1.2032341957092285\n",
      "Batch 42: loss = 1.2217812538146973\n",
      "Batch 43: loss = 1.2695379257202148\n",
      "Batch 44: loss = 1.1902263164520264\n",
      "Batch 45: loss = 1.1439011096954346\n",
      "Batch 46: loss = 1.2534282207489014\n",
      "Batch 47: loss = 1.2212655544281006\n",
      "Batch 48: loss = 1.164621114730835\n",
      "Batch 49: loss = 1.0911402702331543\n",
      "Batch 50: loss = 1.1756446361541748\n",
      "Batch 51: loss = 1.2048815488815308\n",
      "Batch 52: loss = 1.354960322380066\n",
      "Batch 53: loss = 1.3055925369262695\n",
      "Batch 54: loss = 1.1989459991455078\n",
      "Batch 55: loss = 1.2338593006134033\n",
      "Batch 56: loss = 1.2289447784423828\n",
      "Batch 57: loss = 1.3306856155395508\n",
      "Batch 58: loss = 1.2670294046401978\n",
      "Batch 59: loss = 1.0345698595046997\n",
      "Batch 60: loss = 1.2104694843292236\n",
      "Batch 61: loss = 1.289541482925415\n",
      "Batch 62: loss = 1.4296128749847412\n",
      "Batch 63: loss = 1.383650779724121\n",
      "Batch 64: loss = 1.0111218690872192\n",
      "Batch 65: loss = 1.2316404581069946\n",
      "Batch 66: loss = 1.2020305395126343\n",
      "Batch 67: loss = 1.176347255706787\n",
      "Batch 68: loss = 1.2209906578063965\n",
      "Batch 69: loss = 1.189729928970337\n",
      "Batch 70: loss = 1.304574966430664\n",
      "Batch 71: loss = 1.1829438209533691\n",
      "Batch 72: loss = 1.1296814680099487\n",
      "Batch 73: loss = 1.2772047519683838\n",
      "Batch 74: loss = 1.2942155599594116\n",
      "Batch 75: loss = 1.3433908224105835\n",
      "Batch 76: loss = 1.303299903869629\n",
      "Batch 77: loss = 1.1275949478149414\n",
      "Batch 78: loss = 1.1594440937042236\n",
      "Batch 79: loss = 1.0178728103637695\n",
      "Batch 80: loss = 1.1250799894332886\n",
      "Batch 81: loss = 1.1370359659194946\n",
      "Batch 82: loss = 1.0628048181533813\n",
      "Batch 83: loss = 1.1773498058319092\n",
      "Batch 84: loss = 1.1739814281463623\n",
      "Batch 85: loss = 1.3036277294158936\n",
      "Batch 86: loss = 1.2130463123321533\n",
      "Batch 87: loss = 1.135849118232727\n",
      "Batch 88: loss = 1.3565144538879395\n",
      "Batch 89: loss = 1.224384069442749\n",
      "Batch 90: loss = 1.3287382125854492\n",
      "Batch 91: loss = 1.2799487113952637\n",
      "Batch 92: loss = 1.1493451595306396\n",
      "Batch 93: loss = 1.0892184972763062\n",
      "Batch 94: loss = 1.1429908275604248\n",
      "Batch 95: loss = 1.175776481628418\n",
      "Batch 96: loss = 1.2166268825531006\n",
      "Batch 97: loss = 1.2202403545379639\n",
      "Batch 98: loss = 1.2006434202194214\n",
      "Batch 99: loss = 1.2338948249816895\n",
      "Batch 100: loss = 1.178877830505371\n",
      "Batch 101: loss = 1.2357017993927002\n",
      "Batch 102: loss = 1.2489566802978516\n",
      "Batch 103: loss = 1.240666151046753\n",
      "Batch 104: loss = 1.1426951885223389\n",
      "Batch 105: loss = 1.214296579360962\n",
      "Batch 106: loss = 1.2779319286346436\n",
      "Batch 107: loss = 1.1842354536056519\n",
      "Batch 108: loss = 1.1781107187271118\n",
      "Batch 109: loss = 1.2135193347930908\n",
      "Batch 110: loss = 1.1380891799926758\n",
      "Batch 111: loss = 1.3296678066253662\n",
      "Batch 112: loss = 1.1629929542541504\n",
      "Batch 113: loss = 1.2410465478897095\n",
      "Batch 114: loss = 1.2438383102416992\n",
      "Batch 115: loss = 1.3183155059814453\n",
      "Batch 116: loss = 1.3304022550582886\n",
      "Batch 117: loss = 1.1349928379058838\n",
      "Batch 118: loss = 1.1510090827941895\n",
      "Batch 119: loss = 1.2750818729400635\n",
      "Batch 120: loss = 1.3082547187805176\n",
      "Batch 121: loss = 1.1644240617752075\n",
      "Batch 122: loss = 1.1386475563049316\n",
      "Batch 123: loss = 1.1931215524673462\n",
      "Batch 124: loss = 1.2742282152175903\n",
      "Batch 125: loss = 1.260453462600708\n",
      "Batch 126: loss = 1.358727216720581\n",
      "\n",
      "Epoch 6/100\n",
      "Batch 1: loss = 1.333388328552246\n",
      "Batch 2: loss = 1.3370540142059326\n",
      "Batch 3: loss = 1.2605266571044922\n",
      "Batch 4: loss = 1.2459139823913574\n",
      "Batch 5: loss = 1.3735889196395874\n",
      "Batch 6: loss = 1.3910177946090698\n",
      "Batch 7: loss = 1.374575138092041\n",
      "Batch 8: loss = 1.2114551067352295\n",
      "Batch 9: loss = 1.2134900093078613\n",
      "Batch 10: loss = 1.1090116500854492\n",
      "Batch 11: loss = 1.2841211557388306\n",
      "Batch 12: loss = 1.3553788661956787\n",
      "Batch 13: loss = 1.2565383911132812\n",
      "Batch 14: loss = 1.1688673496246338\n",
      "Batch 15: loss = 1.175787329673767\n",
      "Batch 16: loss = 1.3109087944030762\n",
      "Batch 17: loss = 1.2535948753356934\n",
      "Batch 18: loss = 1.2987273931503296\n",
      "Batch 19: loss = 1.2468583583831787\n",
      "Batch 20: loss = 1.1701490879058838\n",
      "Batch 21: loss = 1.3646807670593262\n",
      "Batch 22: loss = 1.1789822578430176\n",
      "Batch 23: loss = 1.2108386754989624\n",
      "Batch 24: loss = 1.2055838108062744\n",
      "Batch 25: loss = 1.1020958423614502\n",
      "Batch 26: loss = 1.1504831314086914\n",
      "Batch 27: loss = 1.2734408378601074\n",
      "Batch 28: loss = 1.239912986755371\n",
      "Batch 29: loss = 1.1503689289093018\n",
      "Batch 30: loss = 1.1319563388824463\n",
      "Batch 31: loss = 1.280446171760559\n",
      "Batch 32: loss = 1.4135217666625977\n",
      "Batch 33: loss = 1.2170298099517822\n",
      "Batch 34: loss = 1.2507617473602295\n",
      "Batch 35: loss = 1.2436797618865967\n",
      "Batch 36: loss = 1.2391688823699951\n",
      "Batch 37: loss = 1.2628874778747559\n",
      "Batch 38: loss = 1.3034322261810303\n",
      "Batch 39: loss = 1.2388393878936768\n",
      "Batch 40: loss = 1.2142035961151123\n",
      "Batch 41: loss = 1.1611502170562744\n",
      "Batch 42: loss = 1.174760341644287\n",
      "Batch 43: loss = 1.2112414836883545\n",
      "Batch 44: loss = 1.1443452835083008\n",
      "Batch 45: loss = 1.086533784866333\n",
      "Batch 46: loss = 1.2146978378295898\n",
      "Batch 47: loss = 1.1621489524841309\n",
      "Batch 48: loss = 1.120314598083496\n",
      "Batch 49: loss = 1.0215141773223877\n",
      "Batch 50: loss = 1.0965514183044434\n",
      "Batch 51: loss = 1.1410118341445923\n",
      "Batch 52: loss = 1.2763350009918213\n",
      "Batch 53: loss = 1.232775092124939\n",
      "Batch 54: loss = 1.1177682876586914\n",
      "Batch 55: loss = 1.1684566736221313\n",
      "Batch 56: loss = 1.177788257598877\n",
      "Batch 57: loss = 1.2795915603637695\n",
      "Batch 58: loss = 1.2032570838928223\n",
      "Batch 59: loss = 0.9926644563674927\n",
      "Batch 60: loss = 1.143385887145996\n",
      "Batch 61: loss = 1.2434579133987427\n",
      "Batch 62: loss = 1.3789176940917969\n",
      "Batch 63: loss = 1.3136155605316162\n",
      "Batch 64: loss = 0.9868756532669067\n",
      "Batch 65: loss = 1.1717593669891357\n",
      "Batch 66: loss = 1.161069631576538\n",
      "Batch 67: loss = 1.118438482284546\n",
      "Batch 68: loss = 1.162818193435669\n",
      "Batch 69: loss = 1.1452240943908691\n",
      "Batch 70: loss = 1.2620267868041992\n",
      "Batch 71: loss = 1.1256561279296875\n",
      "Batch 72: loss = 1.0901687145233154\n",
      "Batch 73: loss = 1.210867166519165\n",
      "Batch 74: loss = 1.2196588516235352\n",
      "Batch 75: loss = 1.2785394191741943\n",
      "Batch 76: loss = 1.247315764427185\n",
      "Batch 77: loss = 1.0736100673675537\n",
      "Batch 78: loss = 1.0897756814956665\n",
      "Batch 79: loss = 0.9724166989326477\n",
      "Batch 80: loss = 1.0645477771759033\n",
      "Batch 81: loss = 1.0608330965042114\n",
      "Batch 82: loss = 0.9992081522941589\n",
      "Batch 83: loss = 1.1189191341400146\n",
      "Batch 84: loss = 1.1217248439788818\n",
      "Batch 85: loss = 1.2537903785705566\n",
      "Batch 86: loss = 1.159581184387207\n",
      "Batch 87: loss = 1.0787510871887207\n",
      "Batch 88: loss = 1.2976908683776855\n",
      "Batch 89: loss = 1.1480016708374023\n",
      "Batch 90: loss = 1.2521214485168457\n",
      "Batch 91: loss = 1.2381913661956787\n",
      "Batch 92: loss = 1.095443606376648\n",
      "Batch 93: loss = 1.0170197486877441\n",
      "Batch 94: loss = 1.0828590393066406\n",
      "Batch 95: loss = 1.122617483139038\n",
      "Batch 96: loss = 1.1693110466003418\n",
      "Batch 97: loss = 1.1537531614303589\n",
      "Batch 98: loss = 1.1394214630126953\n",
      "Batch 99: loss = 1.1586971282958984\n",
      "Batch 100: loss = 1.1469571590423584\n",
      "Batch 101: loss = 1.1628118753433228\n",
      "Batch 102: loss = 1.1923301219940186\n",
      "Batch 103: loss = 1.1630041599273682\n",
      "Batch 104: loss = 1.092972993850708\n",
      "Batch 105: loss = 1.1465709209442139\n",
      "Batch 106: loss = 1.2263617515563965\n",
      "Batch 107: loss = 1.131718397140503\n",
      "Batch 108: loss = 1.1293753385543823\n",
      "Batch 109: loss = 1.1514931917190552\n",
      "Batch 110: loss = 1.0830552577972412\n",
      "Batch 111: loss = 1.2569053173065186\n",
      "Batch 112: loss = 1.1041529178619385\n",
      "Batch 113: loss = 1.155356764793396\n",
      "Batch 114: loss = 1.2089282274246216\n",
      "Batch 115: loss = 1.2603927850723267\n",
      "Batch 116: loss = 1.261665940284729\n",
      "Batch 117: loss = 1.0776216983795166\n",
      "Batch 118: loss = 1.1065428256988525\n",
      "Batch 119: loss = 1.232513666152954\n",
      "Batch 120: loss = 1.2583978176116943\n",
      "Batch 121: loss = 1.1090892553329468\n",
      "Batch 122: loss = 1.0749413967132568\n",
      "Batch 123: loss = 1.1425902843475342\n",
      "Batch 124: loss = 1.216097116470337\n",
      "Batch 125: loss = 1.187626838684082\n",
      "Batch 126: loss = 1.2660149335861206\n",
      "\n",
      "Epoch 7/100\n",
      "Batch 1: loss = 1.2686123847961426\n",
      "Batch 2: loss = 1.27094566822052\n",
      "Batch 3: loss = 1.1981052160263062\n",
      "Batch 4: loss = 1.1986274719238281\n",
      "Batch 5: loss = 1.3231377601623535\n",
      "Batch 6: loss = 1.3144595623016357\n",
      "Batch 7: loss = 1.2956335544586182\n",
      "Batch 8: loss = 1.1728804111480713\n",
      "Batch 9: loss = 1.1504757404327393\n",
      "Batch 10: loss = 1.0485138893127441\n",
      "Batch 11: loss = 1.218869686126709\n",
      "Batch 12: loss = 1.2860915660858154\n",
      "Batch 13: loss = 1.1988437175750732\n",
      "Batch 14: loss = 1.1290810108184814\n",
      "Batch 15: loss = 1.1281126737594604\n",
      "Batch 16: loss = 1.2450562715530396\n",
      "Batch 17: loss = 1.1798509359359741\n",
      "Batch 18: loss = 1.2592536211013794\n",
      "Batch 19: loss = 1.1730490922927856\n",
      "Batch 20: loss = 1.0943691730499268\n",
      "Batch 21: loss = 1.3107349872589111\n",
      "Batch 22: loss = 1.0987778902053833\n",
      "Batch 23: loss = 1.1494317054748535\n",
      "Batch 24: loss = 1.1409260034561157\n",
      "Batch 25: loss = 1.053514838218689\n",
      "Batch 26: loss = 1.0874066352844238\n",
      "Batch 27: loss = 1.2222065925598145\n",
      "Batch 28: loss = 1.1675764322280884\n",
      "Batch 29: loss = 1.109907865524292\n",
      "Batch 30: loss = 1.0886027812957764\n",
      "Batch 31: loss = 1.2512547969818115\n",
      "Batch 32: loss = 1.3615643978118896\n",
      "Batch 33: loss = 1.189304232597351\n",
      "Batch 34: loss = 1.218967080116272\n",
      "Batch 35: loss = 1.1945405006408691\n",
      "Batch 36: loss = 1.1672840118408203\n",
      "Batch 37: loss = 1.197198748588562\n",
      "Batch 38: loss = 1.2197846174240112\n",
      "Batch 39: loss = 1.183328628540039\n",
      "Batch 40: loss = 1.1833359003067017\n",
      "Batch 41: loss = 1.1061289310455322\n",
      "Batch 42: loss = 1.120976448059082\n",
      "Batch 43: loss = 1.1422123908996582\n",
      "Batch 44: loss = 1.0548630952835083\n",
      "Batch 45: loss = 1.0215120315551758\n",
      "Batch 46: loss = 1.1258561611175537\n",
      "Batch 47: loss = 1.0796226263046265\n",
      "Batch 48: loss = 1.0590262413024902\n",
      "Batch 49: loss = 0.9934797286987305\n",
      "Batch 50: loss = 1.0517473220825195\n",
      "Batch 51: loss = 1.0778003931045532\n",
      "Batch 52: loss = 1.2031559944152832\n",
      "Batch 53: loss = 1.1745691299438477\n",
      "Batch 54: loss = 1.0917385816574097\n",
      "Batch 55: loss = 1.1242039203643799\n",
      "Batch 56: loss = 1.1229832172393799\n",
      "Batch 57: loss = 1.22446608543396\n",
      "Batch 58: loss = 1.1601171493530273\n",
      "Batch 59: loss = 0.934105396270752\n",
      "Batch 60: loss = 1.0923559665679932\n",
      "Batch 61: loss = 1.1554875373840332\n",
      "Batch 62: loss = 1.3365381956100464\n",
      "Batch 63: loss = 1.2428497076034546\n",
      "Batch 64: loss = 0.9385795593261719\n",
      "Batch 65: loss = 1.1353358030319214\n",
      "Batch 66: loss = 1.121656060218811\n",
      "Batch 67: loss = 1.065812587738037\n",
      "Batch 68: loss = 1.098522663116455\n",
      "Batch 69: loss = 1.1097474098205566\n",
      "Batch 70: loss = 1.194096565246582\n",
      "Batch 71: loss = 1.0611790418624878\n",
      "Batch 72: loss = 1.0046592950820923\n",
      "Batch 73: loss = 1.1761561632156372\n",
      "Batch 74: loss = 1.1704139709472656\n",
      "Batch 75: loss = 1.2239394187927246\n",
      "Batch 76: loss = 1.1958074569702148\n",
      "Batch 77: loss = 1.0327222347259521\n",
      "Batch 78: loss = 1.032443642616272\n",
      "Batch 79: loss = 0.9354839324951172\n",
      "Batch 80: loss = 1.0107431411743164\n",
      "Batch 81: loss = 1.0067895650863647\n",
      "Batch 82: loss = 0.9539766311645508\n",
      "Batch 83: loss = 1.0796196460723877\n",
      "Batch 84: loss = 1.0888773202896118\n",
      "Batch 85: loss = 1.1926522254943848\n",
      "Batch 86: loss = 1.0942291021347046\n",
      "Batch 87: loss = 1.0357038974761963\n",
      "Batch 88: loss = 1.2414836883544922\n",
      "Batch 89: loss = 1.0704448223114014\n",
      "Batch 90: loss = 1.2110651731491089\n",
      "Batch 91: loss = 1.1940786838531494\n",
      "Batch 92: loss = 1.039227843284607\n",
      "Batch 93: loss = 0.9894354343414307\n",
      "Batch 94: loss = 1.0338391065597534\n",
      "Batch 95: loss = 1.072455644607544\n",
      "Batch 96: loss = 1.1176164150238037\n",
      "Batch 97: loss = 1.0915570259094238\n",
      "Batch 98: loss = 1.0760960578918457\n",
      "Batch 99: loss = 1.1103451251983643\n",
      "Batch 100: loss = 1.0965478420257568\n",
      "Batch 101: loss = 1.1047511100769043\n",
      "Batch 102: loss = 1.1497979164123535\n",
      "Batch 103: loss = 1.1144113540649414\n",
      "Batch 104: loss = 1.0409338474273682\n",
      "Batch 105: loss = 1.1293869018554688\n",
      "Batch 106: loss = 1.1792888641357422\n",
      "Batch 107: loss = 1.0751981735229492\n",
      "Batch 108: loss = 1.0991430282592773\n",
      "Batch 109: loss = 1.071059226989746\n",
      "Batch 110: loss = 1.015514850616455\n",
      "Batch 111: loss = 1.215327262878418\n",
      "Batch 112: loss = 1.0445959568023682\n",
      "Batch 113: loss = 1.1256614923477173\n",
      "Batch 114: loss = 1.1547820568084717\n",
      "Batch 115: loss = 1.206221103668213\n",
      "Batch 116: loss = 1.2063169479370117\n",
      "Batch 117: loss = 1.041177749633789\n",
      "Batch 118: loss = 1.0210527181625366\n",
      "Batch 119: loss = 1.1667068004608154\n",
      "Batch 120: loss = 1.1935157775878906\n",
      "Batch 121: loss = 1.0846669673919678\n",
      "Batch 122: loss = 1.0418696403503418\n",
      "Batch 123: loss = 1.1173365116119385\n",
      "Batch 124: loss = 1.149409294128418\n",
      "Batch 125: loss = 1.135603666305542\n",
      "Batch 126: loss = 1.216217279434204\n",
      "\n",
      "Epoch 8/100\n",
      "Batch 1: loss = 1.2090076208114624\n",
      "Batch 2: loss = 1.2261056900024414\n",
      "Batch 3: loss = 1.1502726078033447\n",
      "Batch 4: loss = 1.1616857051849365\n",
      "Batch 5: loss = 1.2659149169921875\n",
      "Batch 6: loss = 1.2856216430664062\n",
      "Batch 7: loss = 1.2204179763793945\n",
      "Batch 8: loss = 1.108497142791748\n",
      "Batch 9: loss = 1.1007238626480103\n",
      "Batch 10: loss = 1.0093899965286255\n",
      "Batch 11: loss = 1.174576997756958\n",
      "Batch 12: loss = 1.2371034622192383\n",
      "Batch 13: loss = 1.1394338607788086\n",
      "Batch 14: loss = 1.0827311277389526\n",
      "Batch 15: loss = 1.0698342323303223\n",
      "Batch 16: loss = 1.1737086772918701\n",
      "Batch 17: loss = 1.1313883066177368\n",
      "Batch 18: loss = 1.1957802772521973\n",
      "Batch 19: loss = 1.1068239212036133\n",
      "Batch 20: loss = 1.0674412250518799\n",
      "Batch 21: loss = 1.2478485107421875\n",
      "Batch 22: loss = 1.0701017379760742\n",
      "Batch 23: loss = 1.099583625793457\n",
      "Batch 24: loss = 1.0702600479125977\n",
      "Batch 25: loss = 1.0269875526428223\n",
      "Batch 26: loss = 1.0521571636199951\n",
      "Batch 27: loss = 1.1774234771728516\n",
      "Batch 28: loss = 1.1413038969039917\n",
      "Batch 29: loss = 1.0731950998306274\n",
      "Batch 30: loss = 1.0411407947540283\n",
      "Batch 31: loss = 1.2032716274261475\n",
      "Batch 32: loss = 1.3352046012878418\n",
      "Batch 33: loss = 1.1320090293884277\n",
      "Batch 34: loss = 1.1665793657302856\n",
      "Batch 35: loss = 1.14091157913208\n",
      "Batch 36: loss = 1.101224660873413\n",
      "Batch 37: loss = 1.1450084447860718\n",
      "Batch 38: loss = 1.1697256565093994\n",
      "Batch 39: loss = 1.1233341693878174\n",
      "Batch 40: loss = 1.1172481775283813\n",
      "Batch 41: loss = 1.058024525642395\n",
      "Batch 42: loss = 1.0894052982330322\n",
      "Batch 43: loss = 1.1146900653839111\n",
      "Batch 44: loss = 1.0222517251968384\n",
      "Batch 45: loss = 0.9710527062416077\n",
      "Batch 46: loss = 1.0639042854309082\n",
      "Batch 47: loss = 1.04392409324646\n",
      "Batch 48: loss = 1.003206491470337\n",
      "Batch 49: loss = 0.94419264793396\n",
      "Batch 50: loss = 1.0033886432647705\n",
      "Batch 51: loss = 1.0286147594451904\n",
      "Batch 52: loss = 1.1348949670791626\n",
      "Batch 53: loss = 1.116142749786377\n",
      "Batch 54: loss = 1.0159615278244019\n",
      "Batch 55: loss = 1.0499675273895264\n",
      "Batch 56: loss = 1.0776455402374268\n",
      "Batch 57: loss = 1.155150294303894\n",
      "Batch 58: loss = 1.1007328033447266\n",
      "Batch 59: loss = 0.8958728313446045\n",
      "Batch 60: loss = 1.049456000328064\n",
      "Batch 61: loss = 1.1019103527069092\n",
      "Batch 62: loss = 1.2839421033859253\n",
      "Batch 63: loss = 1.2088117599487305\n",
      "Batch 64: loss = 0.8973562717437744\n",
      "Batch 65: loss = 1.104616403579712\n",
      "Batch 66: loss = 1.0560941696166992\n",
      "Batch 67: loss = 1.0221655368804932\n",
      "Batch 68: loss = 1.0319589376449585\n",
      "Batch 69: loss = 1.0591285228729248\n",
      "Batch 70: loss = 1.1591355800628662\n",
      "Batch 71: loss = 1.0233778953552246\n",
      "Batch 72: loss = 0.9733904600143433\n",
      "Batch 73: loss = 1.111696481704712\n",
      "Batch 74: loss = 1.1606470346450806\n",
      "Batch 75: loss = 1.1948800086975098\n",
      "Batch 76: loss = 1.1614422798156738\n",
      "Batch 77: loss = 0.9978331327438354\n",
      "Batch 78: loss = 0.9832935333251953\n",
      "Batch 79: loss = 0.8825720548629761\n",
      "Batch 80: loss = 0.9650688171386719\n",
      "Batch 81: loss = 0.98965984582901\n",
      "Batch 82: loss = 0.9204689264297485\n",
      "Batch 83: loss = 1.0163514614105225\n",
      "Batch 84: loss = 1.0265333652496338\n",
      "Batch 85: loss = 1.1493704319000244\n",
      "Batch 86: loss = 1.0464203357696533\n",
      "Batch 87: loss = 0.9850916862487793\n",
      "Batch 88: loss = 1.1860657930374146\n",
      "Batch 89: loss = 1.0585956573486328\n",
      "Batch 90: loss = 1.1519651412963867\n",
      "Batch 91: loss = 1.1485810279846191\n",
      "Batch 92: loss = 1.01175856590271\n",
      "Batch 93: loss = 0.9214504957199097\n",
      "Batch 94: loss = 0.9717940092086792\n",
      "Batch 95: loss = 1.027101993560791\n",
      "Batch 96: loss = 1.0671954154968262\n",
      "Batch 97: loss = 1.0465980768203735\n",
      "Batch 98: loss = 1.0091817378997803\n",
      "Batch 99: loss = 1.0605840682983398\n",
      "Batch 100: loss = 1.0498311519622803\n",
      "Batch 101: loss = 1.0687291622161865\n",
      "Batch 102: loss = 1.0938172340393066\n",
      "Batch 103: loss = 1.0907409191131592\n",
      "Batch 104: loss = 0.9955084323883057\n",
      "Batch 105: loss = 1.0702643394470215\n",
      "Batch 106: loss = 1.133845567703247\n",
      "Batch 107: loss = 1.0467557907104492\n",
      "Batch 108: loss = 1.0561532974243164\n",
      "Batch 109: loss = 1.0552371740341187\n",
      "Batch 110: loss = 0.9712783098220825\n",
      "Batch 111: loss = 1.1572753190994263\n",
      "Batch 112: loss = 1.0321588516235352\n",
      "Batch 113: loss = 1.0652296543121338\n",
      "Batch 114: loss = 1.1067270040512085\n",
      "Batch 115: loss = 1.1725895404815674\n",
      "Batch 116: loss = 1.1841808557510376\n",
      "Batch 117: loss = 1.0231132507324219\n",
      "Batch 118: loss = 1.0157771110534668\n",
      "Batch 119: loss = 1.1104059219360352\n",
      "Batch 120: loss = 1.1673781871795654\n",
      "Batch 121: loss = 1.0406088829040527\n",
      "Batch 122: loss = 0.9914879202842712\n",
      "Batch 123: loss = 1.0454405546188354\n",
      "Batch 124: loss = 1.1064000129699707\n",
      "Batch 125: loss = 1.1165099143981934\n",
      "Batch 126: loss = 1.159173607826233\n",
      "\n",
      "Epoch 9/100\n",
      "Batch 1: loss = 1.1439213752746582\n",
      "Batch 2: loss = 1.1792576313018799\n",
      "Batch 3: loss = 1.1127619743347168\n",
      "Batch 4: loss = 1.1257765293121338\n",
      "Batch 5: loss = 1.2264578342437744\n",
      "Batch 6: loss = 1.1988494396209717\n",
      "Batch 7: loss = 1.1764907836914062\n",
      "Batch 8: loss = 1.0576286315917969\n",
      "Batch 9: loss = 1.0270724296569824\n",
      "Batch 10: loss = 0.9833399653434753\n",
      "Batch 11: loss = 1.103348731994629\n",
      "Batch 12: loss = 1.1656670570373535\n",
      "Batch 13: loss = 1.085920810699463\n",
      "Batch 14: loss = 1.0466887950897217\n",
      "Batch 15: loss = 1.0143039226531982\n",
      "Batch 16: loss = 1.119499683380127\n",
      "Batch 17: loss = 1.0878257751464844\n",
      "Batch 18: loss = 1.1534048318862915\n",
      "Batch 19: loss = 1.0348000526428223\n",
      "Batch 20: loss = 1.0245426893234253\n",
      "Batch 21: loss = 1.1774802207946777\n",
      "Batch 22: loss = 1.0312011241912842\n",
      "Batch 23: loss = 1.0214307308197021\n",
      "Batch 24: loss = 1.0024549961090088\n",
      "Batch 25: loss = 0.9607155323028564\n",
      "Batch 26: loss = 0.990075945854187\n",
      "Batch 27: loss = 1.1237043142318726\n",
      "Batch 28: loss = 1.0768722295761108\n",
      "Batch 29: loss = 1.0156338214874268\n",
      "Batch 30: loss = 0.9934687614440918\n",
      "Batch 31: loss = 1.142707109451294\n",
      "Batch 32: loss = 1.255312442779541\n",
      "Batch 33: loss = 1.0862386226654053\n",
      "Batch 34: loss = 1.109147548675537\n",
      "Batch 35: loss = 1.095015048980713\n",
      "Batch 36: loss = 1.047690510749817\n",
      "Batch 37: loss = 1.097381591796875\n",
      "Batch 38: loss = 1.1548435688018799\n",
      "Batch 39: loss = 1.084841012954712\n",
      "Batch 40: loss = 1.0856192111968994\n",
      "Batch 41: loss = 0.9972474575042725\n",
      "Batch 42: loss = 1.0080946683883667\n",
      "Batch 43: loss = 1.0607236623764038\n",
      "Batch 44: loss = 0.9804784655570984\n",
      "Batch 45: loss = 0.9290868043899536\n",
      "Batch 46: loss = 1.0145536661148071\n",
      "Batch 47: loss = 0.9884154200553894\n",
      "Batch 48: loss = 0.9540549516677856\n",
      "Batch 49: loss = 0.8992624878883362\n",
      "Batch 50: loss = 0.9708442687988281\n",
      "Batch 51: loss = 0.9728133678436279\n",
      "Batch 52: loss = 1.102018117904663\n",
      "Batch 53: loss = 1.055070161819458\n",
      "Batch 54: loss = 0.9826784133911133\n",
      "Batch 55: loss = 1.0216522216796875\n",
      "Batch 56: loss = 1.046952247619629\n",
      "Batch 57: loss = 1.1101009845733643\n",
      "Batch 58: loss = 1.063029170036316\n",
      "Batch 59: loss = 0.8815830945968628\n",
      "Batch 60: loss = 1.0125747919082642\n",
      "Batch 61: loss = 1.059541940689087\n",
      "Batch 62: loss = 1.2586462497711182\n",
      "Batch 63: loss = 1.1379835605621338\n",
      "Batch 64: loss = 0.8697144389152527\n",
      "Batch 65: loss = 1.0309174060821533\n",
      "Batch 66: loss = 1.0526140928268433\n",
      "Batch 67: loss = 0.9871611595153809\n",
      "Batch 68: loss = 1.0489475727081299\n",
      "Batch 69: loss = 1.0263094902038574\n",
      "Batch 70: loss = 1.1442064046859741\n",
      "Batch 71: loss = 0.9976340532302856\n",
      "Batch 72: loss = 0.9524959325790405\n",
      "Batch 73: loss = 1.0884971618652344\n",
      "Batch 74: loss = 1.125568151473999\n",
      "Batch 75: loss = 1.1393851041793823\n",
      "Batch 76: loss = 1.0977451801300049\n",
      "Batch 77: loss = 0.9565426707267761\n",
      "Batch 78: loss = 0.974380612373352\n",
      "Batch 79: loss = 0.8706730604171753\n",
      "Batch 80: loss = 0.931397557258606\n",
      "Batch 81: loss = 0.940365195274353\n",
      "Batch 82: loss = 0.851013720035553\n",
      "Batch 83: loss = 0.9811848402023315\n",
      "Batch 84: loss = 0.9883630871772766\n",
      "Batch 85: loss = 1.1388485431671143\n",
      "Batch 86: loss = 1.0134336948394775\n",
      "Batch 87: loss = 0.9329896569252014\n",
      "Batch 88: loss = 1.1594232320785522\n",
      "Batch 89: loss = 1.0362052917480469\n",
      "Batch 90: loss = 1.1031358242034912\n",
      "Batch 91: loss = 1.1225699186325073\n",
      "Batch 92: loss = 0.9992539882659912\n",
      "Batch 93: loss = 0.8929940462112427\n",
      "Batch 94: loss = 0.9497008323669434\n",
      "Batch 95: loss = 0.9986225962638855\n",
      "Batch 96: loss = 1.020155668258667\n",
      "Batch 97: loss = 1.005527377128601\n",
      "Batch 98: loss = 0.9667312502861023\n",
      "Batch 99: loss = 1.0201530456542969\n",
      "Batch 100: loss = 1.0118004083633423\n",
      "Batch 101: loss = 1.0282683372497559\n",
      "Batch 102: loss = 1.0653207302093506\n",
      "Batch 103: loss = 1.0756640434265137\n",
      "Batch 104: loss = 0.9770187139511108\n",
      "Batch 105: loss = 1.0218991041183472\n",
      "Batch 106: loss = 1.0709195137023926\n",
      "Batch 107: loss = 0.9933346509933472\n",
      "Batch 108: loss = 1.0366498231887817\n",
      "Batch 109: loss = 1.0108976364135742\n",
      "Batch 110: loss = 0.941959023475647\n",
      "Batch 111: loss = 1.098764419555664\n",
      "Batch 112: loss = 0.994340181350708\n",
      "Batch 113: loss = 1.0183765888214111\n",
      "Batch 114: loss = 1.0624120235443115\n",
      "Batch 115: loss = 1.124049425125122\n",
      "Batch 116: loss = 1.1395728588104248\n",
      "Batch 117: loss = 0.9572319984436035\n",
      "Batch 118: loss = 0.9559286832809448\n",
      "Batch 119: loss = 1.0639758110046387\n",
      "Batch 120: loss = 1.1136460304260254\n",
      "Batch 121: loss = 0.994570791721344\n",
      "Batch 122: loss = 0.956231951713562\n",
      "Batch 123: loss = 1.0157458782196045\n",
      "Batch 124: loss = 1.092728614807129\n",
      "Batch 125: loss = 1.0747435092926025\n",
      "Batch 126: loss = 1.125891923904419\n",
      "\n",
      "Epoch 10/100\n",
      "Batch 1: loss = 1.128462791442871\n",
      "Batch 2: loss = 1.1725897789001465\n",
      "Batch 3: loss = 1.0785233974456787\n",
      "Batch 4: loss = 1.070845603942871\n",
      "Batch 5: loss = 1.1556587219238281\n",
      "Batch 6: loss = 1.1473100185394287\n",
      "Batch 7: loss = 1.1378815174102783\n",
      "Batch 8: loss = 1.0330315828323364\n",
      "Batch 9: loss = 0.9939274787902832\n",
      "Batch 10: loss = 0.9240655899047852\n",
      "Batch 11: loss = 1.0704995393753052\n",
      "Batch 12: loss = 1.1141388416290283\n",
      "Batch 13: loss = 1.0458592176437378\n",
      "Batch 14: loss = 1.0078681707382202\n",
      "Batch 15: loss = 0.9755535125732422\n",
      "Batch 16: loss = 1.0864837169647217\n",
      "Batch 17: loss = 1.0259006023406982\n",
      "Batch 18: loss = 1.088871955871582\n",
      "Batch 19: loss = 0.9936405420303345\n",
      "Batch 20: loss = 0.9791138172149658\n",
      "Batch 21: loss = 1.149195909500122\n",
      "Batch 22: loss = 0.9743527173995972\n",
      "Batch 23: loss = 1.0097002983093262\n",
      "Batch 24: loss = 0.9833003282546997\n",
      "Batch 25: loss = 0.9269518852233887\n",
      "Batch 26: loss = 0.9436289072036743\n",
      "Batch 27: loss = 1.0923064947128296\n",
      "Batch 28: loss = 1.0309362411499023\n",
      "Batch 29: loss = 0.9783551096916199\n",
      "Batch 30: loss = 0.9399735927581787\n",
      "Batch 31: loss = 1.1154149770736694\n",
      "Batch 32: loss = 1.1831884384155273\n",
      "Batch 33: loss = 1.0392519235610962\n",
      "Batch 34: loss = 1.0731236934661865\n",
      "Batch 35: loss = 1.0589945316314697\n",
      "Batch 36: loss = 1.0014607906341553\n",
      "Batch 37: loss = 1.0535707473754883\n",
      "Batch 38: loss = 1.101155400276184\n",
      "Batch 39: loss = 1.0860095024108887\n",
      "Batch 40: loss = 1.0612738132476807\n",
      "Batch 41: loss = 0.9549747705459595\n",
      "Batch 42: loss = 0.9727184772491455\n",
      "Batch 43: loss = 1.0214624404907227\n",
      "Batch 44: loss = 0.9378587007522583\n",
      "Batch 45: loss = 0.8754743337631226\n",
      "Batch 46: loss = 1.0098600387573242\n",
      "Batch 47: loss = 0.9747231006622314\n",
      "Batch 48: loss = 0.9251800179481506\n",
      "Batch 49: loss = 0.8624090552330017\n",
      "Batch 50: loss = 0.9316179752349854\n",
      "Batch 51: loss = 0.9627090692520142\n",
      "Batch 52: loss = 1.0666851997375488\n",
      "Batch 53: loss = 1.0147309303283691\n",
      "Batch 54: loss = 0.9559330940246582\n",
      "Batch 55: loss = 0.9446947574615479\n",
      "Batch 56: loss = 1.0181950330734253\n",
      "Batch 57: loss = 1.0962269306182861\n",
      "Batch 58: loss = 1.0297513008117676\n",
      "Batch 59: loss = 0.8399414420127869\n",
      "Batch 60: loss = 0.9959031343460083\n",
      "Batch 61: loss = 1.0331287384033203\n",
      "Batch 62: loss = 1.2368992567062378\n",
      "Batch 63: loss = 1.1101564168930054\n",
      "Batch 64: loss = 0.84347003698349\n",
      "Batch 65: loss = 1.0147768259048462\n",
      "Batch 66: loss = 0.9856683015823364\n",
      "Batch 67: loss = 0.9448567628860474\n",
      "Batch 68: loss = 1.018844723701477\n",
      "Batch 69: loss = 0.9818795919418335\n",
      "Batch 70: loss = 1.1020629405975342\n",
      "Batch 71: loss = 0.9681073427200317\n",
      "Batch 72: loss = 0.9098380208015442\n",
      "Batch 73: loss = 1.0582122802734375\n",
      "Batch 74: loss = 1.053357481956482\n",
      "Batch 75: loss = 1.102874755859375\n",
      "Batch 76: loss = 1.04779851436615\n",
      "Batch 77: loss = 0.9400664567947388\n",
      "Batch 78: loss = 0.9396463632583618\n",
      "Batch 79: loss = 0.8251604437828064\n",
      "Batch 80: loss = 0.9078569412231445\n",
      "Batch 81: loss = 0.9207913279533386\n",
      "Batch 82: loss = 0.82785964012146\n",
      "Batch 83: loss = 0.922498345375061\n",
      "Batch 84: loss = 0.9472187161445618\n",
      "Batch 85: loss = 1.0817434787750244\n",
      "Batch 86: loss = 0.9710725545883179\n",
      "Batch 87: loss = 0.9191640019416809\n",
      "Batch 88: loss = 1.145889401435852\n",
      "Batch 89: loss = 0.973793625831604\n",
      "Batch 90: loss = 1.0759398937225342\n",
      "Batch 91: loss = 1.085301399230957\n",
      "Batch 92: loss = 0.9588596820831299\n",
      "Batch 93: loss = 0.8563941717147827\n",
      "Batch 94: loss = 0.902550220489502\n",
      "Batch 95: loss = 0.9526780843734741\n",
      "Batch 96: loss = 0.9820358157157898\n",
      "Batch 97: loss = 0.9647616147994995\n",
      "Batch 98: loss = 0.9447098970413208\n",
      "Batch 99: loss = 0.9939961433410645\n",
      "Batch 100: loss = 0.969793438911438\n",
      "Batch 101: loss = 0.9600714445114136\n",
      "Batch 102: loss = 1.040155291557312\n",
      "Batch 103: loss = 0.9814906716346741\n",
      "Batch 104: loss = 0.9382299184799194\n",
      "Batch 105: loss = 0.9917467832565308\n",
      "Batch 106: loss = 1.0312644243240356\n",
      "Batch 107: loss = 0.9670641422271729\n",
      "Batch 108: loss = 0.9945963025093079\n",
      "Batch 109: loss = 0.9733110666275024\n",
      "Batch 110: loss = 0.9063025712966919\n",
      "Batch 111: loss = 1.0717823505401611\n",
      "Batch 112: loss = 0.9300640821456909\n",
      "Batch 113: loss = 1.0051820278167725\n",
      "Batch 114: loss = 1.0163886547088623\n",
      "Batch 115: loss = 1.0964417457580566\n",
      "Batch 116: loss = 1.1127601861953735\n",
      "Batch 117: loss = 0.9416733980178833\n",
      "Batch 118: loss = 0.9240267276763916\n",
      "Batch 119: loss = 1.034939169883728\n",
      "Batch 120: loss = 1.0637242794036865\n",
      "Batch 121: loss = 0.9523507952690125\n",
      "Batch 122: loss = 0.9259121417999268\n",
      "Batch 123: loss = 0.9732640981674194\n",
      "Batch 124: loss = 1.0263454914093018\n",
      "Batch 125: loss = 1.0426464080810547\n",
      "Batch 126: loss = 1.0913975238800049\n",
      "\n",
      "Epoch 11/100\n",
      "Batch 1: loss = 1.0824373960494995\n",
      "Batch 2: loss = 1.1508561372756958\n",
      "Batch 3: loss = 1.0372941493988037\n",
      "Batch 4: loss = 1.0121757984161377\n",
      "Batch 5: loss = 1.125396728515625\n",
      "Batch 6: loss = 1.1383323669433594\n",
      "Batch 7: loss = 1.105229139328003\n",
      "Batch 8: loss = 0.9801188707351685\n",
      "Batch 9: loss = 0.9340358972549438\n",
      "Batch 10: loss = 0.9121774435043335\n",
      "Batch 11: loss = 1.0794942378997803\n",
      "Batch 12: loss = 1.0431690216064453\n",
      "Batch 13: loss = 1.0014386177062988\n",
      "Batch 14: loss = 0.9873583316802979\n",
      "Batch 15: loss = 0.9311233758926392\n",
      "Batch 16: loss = 1.0314795970916748\n",
      "Batch 17: loss = 0.9738408327102661\n",
      "Batch 18: loss = 1.0256744623184204\n",
      "Batch 19: loss = 0.9608385562896729\n",
      "Batch 20: loss = 0.9725971221923828\n",
      "Batch 21: loss = 1.1064049005508423\n",
      "Batch 22: loss = 0.9630070924758911\n",
      "Batch 23: loss = 1.0000107288360596\n",
      "Batch 24: loss = 0.9344642758369446\n",
      "Batch 25: loss = 0.8893148303031921\n",
      "Batch 26: loss = 0.9235979318618774\n",
      "Batch 27: loss = 1.033124566078186\n",
      "Batch 28: loss = 0.981377124786377\n",
      "Batch 29: loss = 0.9607094526290894\n",
      "Batch 30: loss = 0.9159501791000366\n",
      "Batch 31: loss = 1.0761069059371948\n",
      "Batch 32: loss = 1.183321237564087\n",
      "Batch 33: loss = 1.0063862800598145\n",
      "Batch 34: loss = 1.0197327136993408\n",
      "Batch 35: loss = 0.9956581592559814\n",
      "Batch 36: loss = 0.9593026041984558\n",
      "Batch 37: loss = 1.0084993839263916\n",
      "Batch 38: loss = 1.0710439682006836\n",
      "Batch 39: loss = 1.0265933275222778\n",
      "Batch 40: loss = 1.0123133659362793\n",
      "Batch 41: loss = 0.900417685508728\n",
      "Batch 42: loss = 0.9302675724029541\n",
      "Batch 43: loss = 1.0063858032226562\n",
      "Batch 44: loss = 0.8907315731048584\n",
      "Batch 45: loss = 0.8469401597976685\n",
      "Batch 46: loss = 0.9564629793167114\n",
      "Batch 47: loss = 0.9405415058135986\n",
      "Batch 48: loss = 0.8793294429779053\n",
      "Batch 49: loss = 0.8473182916641235\n",
      "Batch 50: loss = 0.8723337650299072\n",
      "Batch 51: loss = 0.9187644124031067\n",
      "Batch 52: loss = 1.036017894744873\n",
      "Batch 53: loss = 0.9737339019775391\n",
      "Batch 54: loss = 0.8895859718322754\n",
      "Batch 55: loss = 0.9023794531822205\n",
      "Batch 56: loss = 0.9734309911727905\n",
      "Batch 57: loss = 1.0504465103149414\n",
      "Batch 58: loss = 0.980647087097168\n",
      "Batch 59: loss = 0.8238881826400757\n",
      "Batch 60: loss = 0.9709412455558777\n",
      "Batch 61: loss = 1.0177149772644043\n",
      "Batch 62: loss = 1.1548852920532227\n",
      "Batch 63: loss = 1.04573392868042\n",
      "Batch 64: loss = 0.8313915729522705\n",
      "Batch 65: loss = 1.0004284381866455\n",
      "Batch 66: loss = 0.99556565284729\n",
      "Batch 67: loss = 0.9068117141723633\n",
      "Batch 68: loss = 0.9597044587135315\n",
      "Batch 69: loss = 0.937535285949707\n",
      "Batch 70: loss = 1.0489541292190552\n",
      "Batch 71: loss = 0.9483940005302429\n",
      "Batch 72: loss = 0.8737295269966125\n",
      "Batch 73: loss = 1.0129305124282837\n",
      "Batch 74: loss = 1.0204623937606812\n",
      "Batch 75: loss = 1.0772850513458252\n",
      "Batch 76: loss = 1.0027897357940674\n",
      "Batch 77: loss = 0.8945358991622925\n",
      "Batch 78: loss = 0.9108178615570068\n",
      "Batch 79: loss = 0.7962161302566528\n",
      "Batch 80: loss = 0.8762887120246887\n",
      "Batch 81: loss = 0.9008721113204956\n",
      "Batch 82: loss = 0.8116233348846436\n",
      "Batch 83: loss = 0.9174365997314453\n",
      "Batch 84: loss = 0.9171967506408691\n",
      "Batch 85: loss = 1.0295251607894897\n",
      "Batch 86: loss = 0.9498553276062012\n",
      "Batch 87: loss = 0.8985289335250854\n",
      "Batch 88: loss = 1.107235074043274\n",
      "Batch 89: loss = 0.9499838352203369\n",
      "Batch 90: loss = 1.0415611267089844\n",
      "Batch 91: loss = 1.0434715747833252\n",
      "Batch 92: loss = 0.9307979941368103\n",
      "Batch 93: loss = 0.8470427989959717\n",
      "Batch 94: loss = 0.8708696365356445\n",
      "Batch 95: loss = 0.9262051582336426\n",
      "Batch 96: loss = 0.9609322547912598\n",
      "Batch 97: loss = 0.9376819729804993\n",
      "Batch 98: loss = 0.9069044589996338\n",
      "Batch 99: loss = 0.9623655676841736\n",
      "Batch 100: loss = 0.9499063491821289\n",
      "Batch 101: loss = 0.9525893926620483\n",
      "Batch 102: loss = 0.9788638353347778\n",
      "Batch 103: loss = 0.9693125486373901\n",
      "Batch 104: loss = 0.9243684411048889\n",
      "Batch 105: loss = 0.9461007714271545\n",
      "Batch 106: loss = 1.003636360168457\n",
      "Batch 107: loss = 0.9374527335166931\n",
      "Batch 108: loss = 0.9503164291381836\n",
      "Batch 109: loss = 0.9591506123542786\n",
      "Batch 110: loss = 0.8634912967681885\n",
      "Batch 111: loss = 1.0394755601882935\n",
      "Batch 112: loss = 0.9193878173828125\n",
      "Batch 113: loss = 0.9596500396728516\n",
      "Batch 114: loss = 0.9860439896583557\n",
      "Batch 115: loss = 1.0243079662322998\n",
      "Batch 116: loss = 1.0567362308502197\n",
      "Batch 117: loss = 0.8985047340393066\n",
      "Batch 118: loss = 0.8685078620910645\n",
      "Batch 119: loss = 0.9913350343704224\n",
      "Batch 120: loss = 1.0276851654052734\n",
      "Batch 121: loss = 0.9491367340087891\n",
      "Batch 122: loss = 0.8730330467224121\n",
      "Batch 123: loss = 0.9423189163208008\n",
      "Batch 124: loss = 1.0091991424560547\n",
      "Batch 125: loss = 1.0240747928619385\n",
      "Batch 126: loss = 1.0615605115890503\n",
      "\n",
      "Epoch 12/100\n",
      "Batch 1: loss = 1.0573153495788574\n",
      "Batch 2: loss = 1.0985838174819946\n",
      "Batch 3: loss = 0.9924944639205933\n",
      "Batch 4: loss = 0.9937607049942017\n",
      "Batch 5: loss = 1.0871615409851074\n",
      "Batch 6: loss = 1.1155900955200195\n",
      "Batch 7: loss = 1.0651130676269531\n",
      "Batch 8: loss = 0.9426915645599365\n",
      "Batch 9: loss = 0.9007395505905151\n",
      "Batch 10: loss = 0.8611883521080017\n",
      "Batch 11: loss = 1.0144646167755127\n",
      "Batch 12: loss = 1.0120395421981812\n",
      "Batch 13: loss = 0.962405800819397\n",
      "Batch 14: loss = 0.9295591115951538\n",
      "Batch 15: loss = 0.8840340375900269\n",
      "Batch 16: loss = 1.0284687280654907\n",
      "Batch 17: loss = 0.9824788570404053\n",
      "Batch 18: loss = 1.007692813873291\n",
      "Batch 19: loss = 0.9003801345825195\n",
      "Batch 20: loss = 0.9444683790206909\n",
      "Batch 21: loss = 1.059412956237793\n",
      "Batch 22: loss = 0.9275901317596436\n",
      "Batch 23: loss = 0.9269409775733948\n",
      "Batch 24: loss = 0.9296343326568604\n",
      "Batch 25: loss = 0.8666112422943115\n",
      "Batch 26: loss = 0.8801536560058594\n",
      "Batch 27: loss = 1.0246340036392212\n",
      "Batch 28: loss = 0.9731365442276001\n",
      "Batch 29: loss = 0.924957275390625\n",
      "Batch 30: loss = 0.8906744718551636\n",
      "Batch 31: loss = 1.0293140411376953\n",
      "Batch 32: loss = 1.1213988065719604\n",
      "Batch 33: loss = 0.958218514919281\n",
      "Batch 34: loss = 0.9840517640113831\n",
      "Batch 35: loss = 0.9705266952514648\n",
      "Batch 36: loss = 0.928415834903717\n",
      "Batch 37: loss = 0.9707484245300293\n",
      "Batch 38: loss = 1.0204551219940186\n",
      "Batch 39: loss = 0.9794485569000244\n",
      "Batch 40: loss = 0.9751468896865845\n",
      "Batch 41: loss = 0.8540321588516235\n",
      "Batch 42: loss = 0.9068901538848877\n",
      "Batch 43: loss = 0.9563256502151489\n",
      "Batch 44: loss = 0.8516281843185425\n",
      "Batch 45: loss = 0.8149712085723877\n",
      "Batch 46: loss = 0.898459792137146\n",
      "Batch 47: loss = 0.9034572243690491\n",
      "Batch 48: loss = 0.8786298036575317\n",
      "Batch 49: loss = 0.8155959844589233\n",
      "Batch 50: loss = 0.8644551634788513\n",
      "Batch 51: loss = 0.8642913103103638\n",
      "Batch 52: loss = 0.9948574304580688\n",
      "Batch 53: loss = 0.9349801540374756\n",
      "Batch 54: loss = 0.8827346563339233\n",
      "Batch 55: loss = 0.8753531575202942\n",
      "Batch 56: loss = 0.9502185583114624\n",
      "Batch 57: loss = 1.0186357498168945\n",
      "Batch 58: loss = 0.9609361886978149\n",
      "Batch 59: loss = 0.7950687408447266\n",
      "Batch 60: loss = 0.9183846712112427\n",
      "Batch 61: loss = 0.9590728282928467\n",
      "Batch 62: loss = 1.1254310607910156\n",
      "Batch 63: loss = 1.0495150089263916\n",
      "Batch 64: loss = 0.8240123391151428\n",
      "Batch 65: loss = 0.9776549339294434\n",
      "Batch 66: loss = 0.9460736513137817\n",
      "Batch 67: loss = 0.8795552253723145\n",
      "Batch 68: loss = 0.9510327577590942\n",
      "Batch 69: loss = 0.9138728380203247\n",
      "Batch 70: loss = 1.018787145614624\n",
      "Batch 71: loss = 0.8943161964416504\n",
      "Batch 72: loss = 0.8295754194259644\n",
      "Batch 73: loss = 0.9911892414093018\n",
      "Batch 74: loss = 1.0026051998138428\n",
      "Batch 75: loss = 1.0509146451950073\n",
      "Batch 76: loss = 0.9589942097663879\n",
      "Batch 77: loss = 0.8650196194648743\n",
      "Batch 78: loss = 0.8740283250808716\n",
      "Batch 79: loss = 0.7750580310821533\n",
      "Batch 80: loss = 0.8531245589256287\n",
      "Batch 81: loss = 0.8708527088165283\n",
      "Batch 82: loss = 0.7825217247009277\n",
      "Batch 83: loss = 0.8625892400741577\n",
      "Batch 84: loss = 0.882053554058075\n",
      "Batch 85: loss = 0.9887140989303589\n",
      "Batch 86: loss = 0.9316350817680359\n",
      "Batch 87: loss = 0.8493105173110962\n",
      "Batch 88: loss = 1.0733187198638916\n",
      "Batch 89: loss = 0.9359124898910522\n",
      "Batch 90: loss = 0.9935276508331299\n",
      "Batch 91: loss = 1.0160435438156128\n",
      "Batch 92: loss = 0.9160565137863159\n",
      "Batch 93: loss = 0.8006623983383179\n",
      "Batch 94: loss = 0.8508402109146118\n",
      "Batch 95: loss = 0.8984581828117371\n",
      "Batch 96: loss = 0.9375368356704712\n",
      "Batch 97: loss = 0.8834624886512756\n",
      "Batch 98: loss = 0.8858109712600708\n",
      "Batch 99: loss = 0.9120563268661499\n",
      "Batch 100: loss = 0.9359344244003296\n",
      "Batch 101: loss = 0.9495388269424438\n",
      "Batch 102: loss = 0.9389175176620483\n",
      "Batch 103: loss = 0.9595355987548828\n",
      "Batch 104: loss = 0.8779695630073547\n",
      "Batch 105: loss = 0.9216463565826416\n",
      "Batch 106: loss = 0.9957747459411621\n",
      "Batch 107: loss = 0.9125901460647583\n",
      "Batch 108: loss = 0.92368483543396\n",
      "Batch 109: loss = 0.9264575839042664\n",
      "Batch 110: loss = 0.8311452865600586\n",
      "Batch 111: loss = 0.9973940849304199\n",
      "Batch 112: loss = 0.8733967542648315\n",
      "Batch 113: loss = 0.9464566707611084\n",
      "Batch 114: loss = 0.9652495384216309\n",
      "Batch 115: loss = 1.0036840438842773\n",
      "Batch 116: loss = 1.0374677181243896\n",
      "Batch 117: loss = 0.8709607124328613\n",
      "Batch 118: loss = 0.8563535213470459\n",
      "Batch 119: loss = 0.9753586053848267\n",
      "Batch 120: loss = 1.0139328241348267\n",
      "Batch 121: loss = 0.9273109436035156\n",
      "Batch 122: loss = 0.8402754068374634\n",
      "Batch 123: loss = 0.9268276691436768\n",
      "Batch 124: loss = 0.9755734205245972\n",
      "Batch 125: loss = 1.0041574239730835\n",
      "Batch 126: loss = 0.9895131587982178\n",
      "\n",
      "Epoch 13/100\n",
      "Batch 1: loss = 1.0139378309249878\n",
      "Batch 2: loss = 1.0378968715667725\n",
      "Batch 3: loss = 0.9448989033699036\n",
      "Batch 4: loss = 0.9473701119422913\n",
      "Batch 5: loss = 1.0329577922821045\n",
      "Batch 6: loss = 1.0784399509429932\n",
      "Batch 7: loss = 1.034060001373291\n",
      "Batch 8: loss = 0.9181941747665405\n",
      "Batch 9: loss = 0.8963067531585693\n",
      "Batch 10: loss = 0.8459101915359497\n",
      "Batch 11: loss = 0.981304407119751\n",
      "Batch 12: loss = 0.987002432346344\n",
      "Batch 13: loss = 0.9287046194076538\n",
      "Batch 14: loss = 0.8913319110870361\n",
      "Batch 15: loss = 0.8705525398254395\n",
      "Batch 16: loss = 0.9903362393379211\n",
      "Batch 17: loss = 0.9215479493141174\n",
      "Batch 18: loss = 0.9554182291030884\n",
      "Batch 19: loss = 0.8666428327560425\n",
      "Batch 20: loss = 0.8893389701843262\n",
      "Batch 21: loss = 1.0146429538726807\n",
      "Batch 22: loss = 0.8919236660003662\n",
      "Batch 23: loss = 0.9121264219284058\n",
      "Batch 24: loss = 0.8700253963470459\n",
      "Batch 25: loss = 0.8442294001579285\n",
      "Batch 26: loss = 0.8365979790687561\n",
      "Batch 27: loss = 1.0242892503738403\n",
      "Batch 28: loss = 0.9320920705795288\n",
      "Batch 29: loss = 0.8952915668487549\n",
      "Batch 30: loss = 0.8497512340545654\n",
      "Batch 31: loss = 1.0085091590881348\n",
      "Batch 32: loss = 1.0649456977844238\n",
      "Batch 33: loss = 0.927687406539917\n",
      "Batch 34: loss = 0.9742887020111084\n",
      "Batch 35: loss = 0.9481565952301025\n",
      "Batch 36: loss = 0.8940432667732239\n",
      "Batch 37: loss = 0.9336975812911987\n",
      "Batch 38: loss = 0.9968844652175903\n",
      "Batch 39: loss = 0.9870537519454956\n",
      "Batch 40: loss = 0.9341537952423096\n",
      "Batch 41: loss = 0.8600167036056519\n",
      "Batch 42: loss = 0.8673076629638672\n",
      "Batch 43: loss = 0.9492467641830444\n",
      "Batch 44: loss = 0.8274781703948975\n",
      "Batch 45: loss = 0.7723489999771118\n",
      "Batch 46: loss = 0.8638049364089966\n",
      "Batch 47: loss = 0.8546478748321533\n",
      "Batch 48: loss = 0.8433922529220581\n",
      "Batch 49: loss = 0.7630994915962219\n",
      "Batch 50: loss = 0.8185166716575623\n",
      "Batch 51: loss = 0.8619570732116699\n",
      "Batch 52: loss = 0.9488919973373413\n",
      "Batch 53: loss = 0.9286283850669861\n",
      "Batch 54: loss = 0.8217295408248901\n",
      "Batch 55: loss = 0.8251984119415283\n",
      "Batch 56: loss = 0.9093927145004272\n",
      "Batch 57: loss = 1.0031733512878418\n",
      "Batch 58: loss = 0.9309227466583252\n",
      "Batch 59: loss = 0.7535606622695923\n",
      "Batch 60: loss = 0.8765228390693665\n",
      "Batch 61: loss = 0.9397517442703247\n",
      "Batch 62: loss = 1.0993833541870117\n",
      "Batch 63: loss = 0.9915340542793274\n",
      "Batch 64: loss = 0.7761070728302002\n",
      "Batch 65: loss = 0.9301882982254028\n",
      "Batch 66: loss = 0.9107197523117065\n",
      "Batch 67: loss = 0.8776761293411255\n",
      "Batch 68: loss = 0.892071008682251\n",
      "Batch 69: loss = 0.8894168734550476\n",
      "Batch 70: loss = 0.9862769842147827\n",
      "Batch 71: loss = 0.9161363244056702\n",
      "Batch 72: loss = 0.7994030714035034\n",
      "Batch 73: loss = 0.966385543346405\n",
      "Batch 74: loss = 0.9614435434341431\n",
      "Batch 75: loss = 1.0206146240234375\n",
      "Batch 76: loss = 0.952288031578064\n",
      "Batch 77: loss = 0.8562312126159668\n",
      "Batch 78: loss = 0.8409951329231262\n",
      "Batch 79: loss = 0.7530360221862793\n",
      "Batch 80: loss = 0.8347442746162415\n",
      "Batch 81: loss = 0.876844048500061\n",
      "Batch 82: loss = 0.7671897411346436\n",
      "Batch 83: loss = 0.8715587854385376\n",
      "Batch 84: loss = 0.8586246371269226\n",
      "Batch 85: loss = 0.9793733358383179\n",
      "Batch 86: loss = 0.9122923612594604\n",
      "Batch 87: loss = 0.832547664642334\n",
      "Batch 88: loss = 1.0514708757400513\n",
      "Batch 89: loss = 0.8942674994468689\n",
      "Batch 90: loss = 0.9821065664291382\n",
      "Batch 91: loss = 0.9925514459609985\n",
      "Batch 92: loss = 0.8826051950454712\n",
      "Batch 93: loss = 0.7645056843757629\n",
      "Batch 94: loss = 0.833685040473938\n",
      "Batch 95: loss = 0.8620955348014832\n",
      "Batch 96: loss = 0.9147977828979492\n",
      "Batch 97: loss = 0.8595427870750427\n",
      "Batch 98: loss = 0.8641510009765625\n",
      "Batch 99: loss = 0.9125834703445435\n",
      "Batch 100: loss = 0.8823744058609009\n",
      "Batch 101: loss = 0.8892382979393005\n",
      "Batch 102: loss = 0.9288654327392578\n",
      "Batch 103: loss = 0.9206610918045044\n",
      "Batch 104: loss = 0.860561192035675\n",
      "Batch 105: loss = 0.9102863669395447\n",
      "Batch 106: loss = 0.9478234052658081\n",
      "Batch 107: loss = 0.8851991295814514\n",
      "Batch 108: loss = 0.9079148769378662\n",
      "Batch 109: loss = 0.9144988059997559\n",
      "Batch 110: loss = 0.8249709606170654\n",
      "Batch 111: loss = 1.0036739110946655\n",
      "Batch 112: loss = 0.8766813278198242\n",
      "Batch 113: loss = 0.9074324369430542\n",
      "Batch 114: loss = 0.9617465734481812\n",
      "Batch 115: loss = 0.9872063398361206\n",
      "Batch 116: loss = 1.0290817022323608\n",
      "Batch 117: loss = 0.8460656404495239\n",
      "Batch 118: loss = 0.8181304335594177\n",
      "Batch 119: loss = 0.9349905252456665\n",
      "Batch 120: loss = 0.9632533192634583\n",
      "Batch 121: loss = 0.8973662853240967\n",
      "Batch 122: loss = 0.8166488409042358\n",
      "Batch 123: loss = 0.8867021203041077\n",
      "Batch 124: loss = 0.9545135498046875\n",
      "Batch 125: loss = 0.9500205516815186\n",
      "Batch 126: loss = 0.9497760534286499\n",
      "\n",
      "Epoch 14/100\n",
      "Batch 1: loss = 0.9842050075531006\n",
      "Batch 2: loss = 1.01181960105896\n",
      "Batch 3: loss = 0.954702615737915\n",
      "Batch 4: loss = 0.9467123746871948\n",
      "Batch 5: loss = 1.0216577053070068\n",
      "Batch 6: loss = 1.040177345275879\n",
      "Batch 7: loss = 1.0052399635314941\n",
      "Batch 8: loss = 0.8865318298339844\n",
      "Batch 9: loss = 0.837706446647644\n",
      "Batch 10: loss = 0.8293419480323792\n",
      "Batch 11: loss = 0.9451531767845154\n",
      "Batch 12: loss = 0.9425942897796631\n",
      "Batch 13: loss = 0.9054099321365356\n",
      "Batch 14: loss = 0.8534952998161316\n",
      "Batch 15: loss = 0.8509113788604736\n",
      "Batch 16: loss = 0.9519782066345215\n",
      "Batch 17: loss = 0.9102978706359863\n",
      "Batch 18: loss = 0.9478151798248291\n",
      "Batch 19: loss = 0.8573611974716187\n",
      "Batch 20: loss = 0.852903425693512\n",
      "Batch 21: loss = 1.0000720024108887\n",
      "Batch 22: loss = 0.8577715158462524\n",
      "Batch 23: loss = 0.8683162927627563\n",
      "Batch 24: loss = 0.8560383915901184\n",
      "Batch 25: loss = 0.8114562630653381\n",
      "Batch 26: loss = 0.8297315835952759\n",
      "Batch 27: loss = 0.9729611277580261\n",
      "Batch 28: loss = 0.9140427112579346\n",
      "Batch 29: loss = 0.864820122718811\n",
      "Batch 30: loss = 0.8312557935714722\n",
      "Batch 31: loss = 0.9659205675125122\n",
      "Batch 32: loss = 1.0327210426330566\n",
      "Batch 33: loss = 0.9088236093521118\n",
      "Batch 34: loss = 0.925407886505127\n",
      "Batch 35: loss = 0.9152840375900269\n",
      "Batch 36: loss = 0.8647600412368774\n",
      "Batch 37: loss = 0.8976955413818359\n",
      "Batch 38: loss = 0.9570120573043823\n",
      "Batch 39: loss = 0.9169914126396179\n",
      "Batch 40: loss = 0.9042073488235474\n",
      "Batch 41: loss = 0.8286762237548828\n",
      "Batch 42: loss = 0.8498603105545044\n",
      "Batch 43: loss = 0.9068248271942139\n",
      "Batch 44: loss = 0.8174670934677124\n",
      "Batch 45: loss = 0.7866586446762085\n",
      "Batch 46: loss = 0.8484783172607422\n",
      "Batch 47: loss = 0.8447095155715942\n",
      "Batch 48: loss = 0.8089385032653809\n",
      "Batch 49: loss = 0.7543054819107056\n",
      "Batch 50: loss = 0.8031404614448547\n",
      "Batch 51: loss = 0.8311206102371216\n",
      "Batch 52: loss = 0.9368902444839478\n",
      "Batch 53: loss = 0.8927204608917236\n",
      "Batch 54: loss = 0.7796266078948975\n",
      "Batch 55: loss = 0.8236676454544067\n",
      "Batch 56: loss = 0.897901177406311\n",
      "Batch 57: loss = 0.9805942177772522\n",
      "Batch 58: loss = 0.9011048078536987\n",
      "Batch 59: loss = 0.73289954662323\n",
      "Batch 60: loss = 0.8560298681259155\n",
      "Batch 61: loss = 0.932599663734436\n",
      "Batch 62: loss = 1.0894806385040283\n",
      "Batch 63: loss = 0.9446979761123657\n",
      "Batch 64: loss = 0.7500308156013489\n",
      "Batch 65: loss = 0.8883044719696045\n",
      "Batch 66: loss = 0.8914753198623657\n",
      "Batch 67: loss = 0.837411642074585\n",
      "Batch 68: loss = 0.8885686993598938\n",
      "Batch 69: loss = 0.8634697198867798\n",
      "Batch 70: loss = 0.9627103805541992\n",
      "Batch 71: loss = 0.8946758508682251\n",
      "Batch 72: loss = 0.808045506477356\n",
      "Batch 73: loss = 0.9026777744293213\n",
      "Batch 74: loss = 0.9238828420639038\n",
      "Batch 75: loss = 0.999281644821167\n",
      "Batch 76: loss = 0.9330229759216309\n",
      "Batch 77: loss = 0.83256995677948\n",
      "Batch 78: loss = 0.829086422920227\n",
      "Batch 79: loss = 0.7439149022102356\n",
      "Batch 80: loss = 0.8222376108169556\n",
      "Batch 81: loss = 0.8273847699165344\n",
      "Batch 82: loss = 0.7479931116104126\n",
      "Batch 83: loss = 0.831872820854187\n",
      "Batch 84: loss = 0.8090424537658691\n",
      "Batch 85: loss = 0.9564036130905151\n",
      "Batch 86: loss = 0.8756630420684814\n",
      "Batch 87: loss = 0.8145676851272583\n",
      "Batch 88: loss = 0.9993977546691895\n",
      "Batch 89: loss = 0.8695082664489746\n",
      "Batch 90: loss = 0.9528113603591919\n",
      "Batch 91: loss = 0.962448239326477\n",
      "Batch 92: loss = 0.8760930299758911\n",
      "Batch 93: loss = 0.7417827844619751\n",
      "Batch 94: loss = 0.7800958156585693\n",
      "Batch 95: loss = 0.8376167416572571\n",
      "Batch 96: loss = 0.9033499956130981\n",
      "Batch 97: loss = 0.8469569683074951\n",
      "Batch 98: loss = 0.819772481918335\n",
      "Batch 99: loss = 0.8711591958999634\n",
      "Batch 100: loss = 0.8448950052261353\n",
      "Batch 101: loss = 0.8740484714508057\n",
      "Batch 102: loss = 0.9032159447669983\n",
      "Batch 103: loss = 0.899504542350769\n",
      "Batch 104: loss = 0.8302674293518066\n",
      "Batch 105: loss = 0.8845865726470947\n",
      "Batch 106: loss = 0.9318829774856567\n",
      "Batch 107: loss = 0.8566543459892273\n",
      "Batch 108: loss = 0.876685619354248\n",
      "Batch 109: loss = 0.9051780104637146\n",
      "Batch 110: loss = 0.7803003787994385\n",
      "Batch 111: loss = 0.9671676754951477\n",
      "Batch 112: loss = 0.8544957637786865\n",
      "Batch 113: loss = 0.8915692567825317\n",
      "Batch 114: loss = 0.9322924613952637\n",
      "Batch 115: loss = 0.9447275400161743\n",
      "Batch 116: loss = 0.9839791655540466\n",
      "Batch 117: loss = 0.8188639879226685\n",
      "Batch 118: loss = 0.7941939830780029\n",
      "Batch 119: loss = 0.9067538976669312\n",
      "Batch 120: loss = 0.9305832386016846\n",
      "Batch 121: loss = 0.8506646156311035\n",
      "Batch 122: loss = 0.7940285801887512\n",
      "Batch 123: loss = 0.8648445010185242\n",
      "Batch 124: loss = 0.9335538148880005\n",
      "Batch 125: loss = 0.9395573139190674\n",
      "Batch 126: loss = 0.9522305727005005\n",
      "\n",
      "Epoch 15/100\n",
      "Batch 1: loss = 0.9590587615966797\n",
      "Batch 2: loss = 1.016972541809082\n",
      "Batch 3: loss = 0.9021404981613159\n",
      "Batch 4: loss = 0.8942489624023438\n",
      "Batch 5: loss = 1.0004289150238037\n",
      "Batch 6: loss = 1.0005526542663574\n",
      "Batch 7: loss = 0.9691286087036133\n",
      "Batch 8: loss = 0.8773860931396484\n",
      "Batch 9: loss = 0.8140630722045898\n",
      "Batch 10: loss = 0.7939884066581726\n",
      "Batch 11: loss = 0.924579381942749\n",
      "Batch 12: loss = 0.9188742637634277\n",
      "Batch 13: loss = 0.8660123348236084\n",
      "Batch 14: loss = 0.8491576910018921\n",
      "Batch 15: loss = 0.8332316279411316\n",
      "Batch 16: loss = 0.9192401170730591\n",
      "Batch 17: loss = 0.8782093524932861\n",
      "Batch 18: loss = 0.8888078927993774\n",
      "Batch 19: loss = 0.8279550075531006\n",
      "Batch 20: loss = 0.8596503734588623\n",
      "Batch 21: loss = 0.9744020104408264\n",
      "Batch 22: loss = 0.8282980918884277\n",
      "Batch 23: loss = 0.8638746738433838\n",
      "Batch 24: loss = 0.8036426305770874\n",
      "Batch 25: loss = 0.811587929725647\n",
      "Batch 26: loss = 0.7851360440254211\n",
      "Batch 27: loss = 0.9510112404823303\n",
      "Batch 28: loss = 0.8863765001296997\n",
      "Batch 29: loss = 0.8650037050247192\n",
      "Batch 30: loss = 0.8007256984710693\n",
      "Batch 31: loss = 0.954632043838501\n",
      "Batch 32: loss = 1.010291337966919\n",
      "Batch 33: loss = 0.9059370756149292\n",
      "Batch 34: loss = 0.9294453263282776\n",
      "Batch 35: loss = 0.8958065509796143\n",
      "Batch 36: loss = 0.8341367244720459\n",
      "Batch 37: loss = 0.8640103340148926\n",
      "Batch 38: loss = 0.9409394264221191\n",
      "Batch 39: loss = 0.9143944978713989\n",
      "Batch 40: loss = 0.8883553743362427\n",
      "Batch 41: loss = 0.812792181968689\n",
      "Batch 42: loss = 0.8414788842201233\n",
      "Batch 43: loss = 0.8739819526672363\n",
      "Batch 44: loss = 0.7650514841079712\n",
      "Batch 45: loss = 0.7413776516914368\n",
      "Batch 46: loss = 0.7983379364013672\n",
      "Batch 47: loss = 0.8511242270469666\n",
      "Batch 48: loss = 0.7896368503570557\n",
      "Batch 49: loss = 0.7492859363555908\n",
      "Batch 50: loss = 0.7924748659133911\n",
      "Batch 51: loss = 0.8038055896759033\n",
      "Batch 52: loss = 0.9160318970680237\n",
      "Batch 53: loss = 0.8665288686752319\n",
      "Batch 54: loss = 0.7688283920288086\n",
      "Batch 55: loss = 0.7806233167648315\n",
      "Batch 56: loss = 0.8615610599517822\n",
      "Batch 57: loss = 0.9421483278274536\n",
      "Batch 58: loss = 0.8902519941329956\n",
      "Batch 59: loss = 0.7221208810806274\n",
      "Batch 60: loss = 0.829800009727478\n",
      "Batch 61: loss = 0.8974244594573975\n",
      "Batch 62: loss = 1.0700490474700928\n",
      "Batch 63: loss = 0.9015898704528809\n",
      "Batch 64: loss = 0.7543300986289978\n",
      "Batch 65: loss = 0.8761911392211914\n",
      "Batch 66: loss = 0.8604449033737183\n",
      "Batch 67: loss = 0.8213465213775635\n",
      "Batch 68: loss = 0.8628267049789429\n",
      "Batch 69: loss = 0.8193104863166809\n",
      "Batch 70: loss = 0.9345227479934692\n",
      "Batch 71: loss = 0.8600112199783325\n",
      "Batch 72: loss = 0.8089745044708252\n",
      "Batch 73: loss = 0.922710657119751\n",
      "Batch 74: loss = 0.9397934675216675\n",
      "Batch 75: loss = 0.9927172064781189\n",
      "Batch 76: loss = 0.9230656623840332\n",
      "Batch 77: loss = 0.8088570237159729\n",
      "Batch 78: loss = 0.8179590702056885\n",
      "Batch 79: loss = 0.7158635854721069\n",
      "Batch 80: loss = 0.7927701473236084\n",
      "Batch 81: loss = 0.8120725154876709\n",
      "Batch 82: loss = 0.7311909198760986\n",
      "Batch 83: loss = 0.8155539035797119\n",
      "Batch 84: loss = 0.8163632750511169\n",
      "Batch 85: loss = 0.9393242001533508\n",
      "Batch 86: loss = 0.8537120819091797\n",
      "Batch 87: loss = 0.7805836200714111\n",
      "Batch 88: loss = 1.002046823501587\n",
      "Batch 89: loss = 0.860510528087616\n",
      "Batch 90: loss = 0.9021055698394775\n",
      "Batch 91: loss = 0.9414337277412415\n",
      "Batch 92: loss = 0.9094763994216919\n",
      "Batch 93: loss = 0.7220511436462402\n",
      "Batch 94: loss = 0.7494035959243774\n",
      "Batch 95: loss = 0.8246299028396606\n",
      "Batch 96: loss = 0.8696749210357666\n",
      "Batch 97: loss = 0.8377922773361206\n",
      "Batch 98: loss = 0.8169580698013306\n",
      "Batch 99: loss = 0.8448753356933594\n",
      "Batch 100: loss = 0.8658164143562317\n",
      "Batch 101: loss = 0.8443671464920044\n",
      "Batch 102: loss = 0.8898143768310547\n",
      "Batch 103: loss = 0.8585877418518066\n",
      "Batch 104: loss = 0.8043786287307739\n",
      "Batch 105: loss = 0.8745124340057373\n",
      "Batch 106: loss = 0.8870363235473633\n",
      "Batch 107: loss = 0.8389368653297424\n",
      "Batch 108: loss = 0.8561672568321228\n",
      "Batch 109: loss = 0.844415545463562\n",
      "Batch 110: loss = 0.785205602645874\n",
      "Batch 111: loss = 0.952744722366333\n",
      "Batch 112: loss = 0.840512216091156\n",
      "Batch 113: loss = 0.8993031978607178\n",
      "Batch 114: loss = 0.9096975326538086\n",
      "Batch 115: loss = 0.9501631259918213\n",
      "Batch 116: loss = 0.9732732772827148\n",
      "Batch 117: loss = 0.7925383448600769\n",
      "Batch 118: loss = 0.7666925191879272\n",
      "Batch 119: loss = 0.8895792365074158\n",
      "Batch 120: loss = 0.9246759414672852\n",
      "Batch 121: loss = 0.8486995697021484\n",
      "Batch 122: loss = 0.7709639072418213\n",
      "Batch 123: loss = 0.8203256130218506\n",
      "Batch 124: loss = 0.9100639820098877\n",
      "Batch 125: loss = 0.9130496978759766\n",
      "Batch 126: loss = 0.909706711769104\n",
      "\n",
      "Epoch 16/100\n",
      "Batch 1: loss = 0.9380021095275879\n",
      "Batch 2: loss = 0.9718483686447144\n",
      "Batch 3: loss = 0.8686380982398987\n",
      "Batch 4: loss = 0.8968663215637207\n",
      "Batch 5: loss = 0.9485620260238647\n",
      "Batch 6: loss = 0.9817574620246887\n",
      "Batch 7: loss = 0.9270645976066589\n",
      "Batch 8: loss = 0.8385275602340698\n",
      "Batch 9: loss = 0.7973911762237549\n",
      "Batch 10: loss = 0.7792650461196899\n",
      "Batch 11: loss = 0.9055955410003662\n",
      "Batch 12: loss = 0.8791277408599854\n",
      "Batch 13: loss = 0.8631798028945923\n",
      "Batch 14: loss = 0.822517454624176\n",
      "Batch 15: loss = 0.8111891746520996\n",
      "Batch 16: loss = 0.9136006832122803\n",
      "Batch 17: loss = 0.8657395839691162\n",
      "Batch 18: loss = 0.8992993235588074\n",
      "Batch 19: loss = 0.7873605489730835\n",
      "Batch 20: loss = 0.8321149349212646\n",
      "Batch 21: loss = 0.9121748805046082\n",
      "Batch 22: loss = 0.8004803657531738\n",
      "Batch 23: loss = 0.868492603302002\n",
      "Batch 24: loss = 0.781669020652771\n",
      "Batch 25: loss = 0.7749452590942383\n",
      "Batch 26: loss = 0.7909274101257324\n",
      "Batch 27: loss = 0.9193055033683777\n",
      "Batch 28: loss = 0.8870278596878052\n",
      "Batch 29: loss = 0.8550213575363159\n",
      "Batch 30: loss = 0.7766947150230408\n",
      "Batch 31: loss = 0.938494086265564\n",
      "Batch 32: loss = 0.9765434861183167\n",
      "Batch 33: loss = 0.8242961764335632\n",
      "Batch 34: loss = 0.8708194494247437\n",
      "Batch 35: loss = 0.8625959157943726\n",
      "Batch 36: loss = 0.7950462102890015\n",
      "Batch 37: loss = 0.8407007455825806\n",
      "Batch 38: loss = 0.917608380317688\n",
      "Batch 39: loss = 0.8659369945526123\n",
      "Batch 40: loss = 0.8505558967590332\n",
      "Batch 41: loss = 0.7814453840255737\n",
      "Batch 42: loss = 0.8119096755981445\n",
      "Batch 43: loss = 0.8517072200775146\n",
      "Batch 44: loss = 0.735039472579956\n",
      "Batch 45: loss = 0.7253251075744629\n",
      "Batch 46: loss = 0.7856889963150024\n",
      "Batch 47: loss = 0.8082596659660339\n",
      "Batch 48: loss = 0.7685613632202148\n",
      "Batch 49: loss = 0.732792854309082\n",
      "Batch 50: loss = 0.756324291229248\n",
      "Batch 51: loss = 0.7903410196304321\n",
      "Batch 52: loss = 0.8566581010818481\n",
      "Batch 53: loss = 0.8544710278511047\n",
      "Batch 54: loss = 0.7166149616241455\n",
      "Batch 55: loss = 0.7457910180091858\n",
      "Batch 56: loss = 0.8417807221412659\n",
      "Batch 57: loss = 0.9113815426826477\n",
      "Batch 58: loss = 0.8350652456283569\n",
      "Batch 59: loss = 0.6865764856338501\n",
      "Batch 60: loss = 0.8219877481460571\n",
      "Batch 61: loss = 0.8717706203460693\n",
      "Batch 62: loss = 1.0182292461395264\n",
      "Batch 63: loss = 0.9057719111442566\n",
      "Batch 64: loss = 0.7589645981788635\n",
      "Batch 65: loss = 0.8599048852920532\n",
      "Batch 66: loss = 0.8535040616989136\n",
      "Batch 67: loss = 0.785871148109436\n",
      "Batch 68: loss = 0.8520418405532837\n",
      "Batch 69: loss = 0.8103650212287903\n",
      "Batch 70: loss = 0.929547905921936\n",
      "Batch 71: loss = 0.8416844010353088\n",
      "Batch 72: loss = 0.7597929239273071\n",
      "Batch 73: loss = 0.8895666599273682\n",
      "Batch 74: loss = 0.892071008682251\n",
      "Batch 75: loss = 0.9281976819038391\n",
      "Batch 76: loss = 0.8819472789764404\n",
      "Batch 77: loss = 0.8152105212211609\n",
      "Batch 78: loss = 0.8019589781761169\n",
      "Batch 79: loss = 0.7122427225112915\n",
      "Batch 80: loss = 0.788853645324707\n",
      "Batch 81: loss = 0.795586109161377\n",
      "Batch 82: loss = 0.7032197117805481\n",
      "Batch 83: loss = 0.7751327753067017\n",
      "Batch 84: loss = 0.7812837362289429\n",
      "Batch 85: loss = 0.9290344715118408\n",
      "Batch 86: loss = 0.7927545309066772\n",
      "Batch 87: loss = 0.745270848274231\n",
      "Batch 88: loss = 0.9726930856704712\n",
      "Batch 89: loss = 0.8389027118682861\n",
      "Batch 90: loss = 0.9004994630813599\n",
      "Batch 91: loss = 0.9098502397537231\n",
      "Batch 92: loss = 0.8365103602409363\n",
      "Batch 93: loss = 0.7183277606964111\n",
      "Batch 94: loss = 0.7249389886856079\n",
      "Batch 95: loss = 0.8134371042251587\n",
      "Batch 96: loss = 0.8398144841194153\n",
      "Batch 97: loss = 0.8053855895996094\n",
      "Batch 98: loss = 0.7920116782188416\n",
      "Batch 99: loss = 0.845561146736145\n",
      "Batch 100: loss = 0.8321449160575867\n",
      "Batch 101: loss = 0.8456356525421143\n",
      "Batch 102: loss = 0.8671711683273315\n",
      "Batch 103: loss = 0.8511959910392761\n",
      "Batch 104: loss = 0.7856419086456299\n",
      "Batch 105: loss = 0.847470760345459\n",
      "Batch 106: loss = 0.8812228441238403\n",
      "Batch 107: loss = 0.8259816765785217\n",
      "Batch 108: loss = 0.8458031415939331\n",
      "Batch 109: loss = 0.8624666333198547\n",
      "Batch 110: loss = 0.7278858423233032\n",
      "Batch 111: loss = 0.8980205059051514\n",
      "Batch 112: loss = 0.8282994031906128\n",
      "Batch 113: loss = 0.854748010635376\n",
      "Batch 114: loss = 0.8817052841186523\n",
      "Batch 115: loss = 0.9172684550285339\n",
      "Batch 116: loss = 0.9466397762298584\n",
      "Batch 117: loss = 0.7764108180999756\n",
      "Batch 118: loss = 0.7430977821350098\n",
      "Batch 119: loss = 0.8612548112869263\n",
      "Batch 120: loss = 0.9270703196525574\n",
      "Batch 121: loss = 0.8051035404205322\n",
      "Batch 122: loss = 0.7528913021087646\n",
      "Batch 123: loss = 0.8313205242156982\n",
      "Batch 124: loss = 0.8905496597290039\n",
      "Batch 125: loss = 0.8970497846603394\n",
      "Batch 126: loss = 0.8908007144927979\n",
      "\n",
      "Epoch 17/100\n",
      "Batch 1: loss = 0.9389302730560303\n",
      "Batch 2: loss = 0.9575241804122925\n",
      "Batch 3: loss = 0.8683319687843323\n",
      "Batch 4: loss = 0.8419028520584106\n",
      "Batch 5: loss = 0.9109790921211243\n",
      "Batch 6: loss = 0.976008415222168\n",
      "Batch 7: loss = 0.9017224311828613\n",
      "Batch 8: loss = 0.8250448703765869\n",
      "Batch 9: loss = 0.8007694482803345\n",
      "Batch 10: loss = 0.7415580153465271\n",
      "Batch 11: loss = 0.8772693276405334\n",
      "Batch 12: loss = 0.8995143175125122\n",
      "Batch 13: loss = 0.8320865631103516\n",
      "Batch 14: loss = 0.8043438792228699\n",
      "Batch 15: loss = 0.768341600894928\n",
      "Batch 16: loss = 0.8947428464889526\n",
      "Batch 17: loss = 0.8478888273239136\n",
      "Batch 18: loss = 0.8598455190658569\n",
      "Batch 19: loss = 0.7779116630554199\n",
      "Batch 20: loss = 0.7986960411071777\n",
      "Batch 21: loss = 0.8784070611000061\n",
      "Batch 22: loss = 0.7998435497283936\n",
      "Batch 23: loss = 0.8207463026046753\n",
      "Batch 24: loss = 0.7561917304992676\n",
      "Batch 25: loss = 0.7548916339874268\n",
      "Batch 26: loss = 0.79038405418396\n",
      "Batch 27: loss = 0.916887104511261\n",
      "Batch 28: loss = 0.8562225103378296\n",
      "Batch 29: loss = 0.8124344348907471\n",
      "Batch 30: loss = 0.7465753555297852\n",
      "Batch 31: loss = 0.9103279113769531\n",
      "Batch 32: loss = 0.9511212706565857\n",
      "Batch 33: loss = 0.8348599672317505\n",
      "Batch 34: loss = 0.8558714389801025\n",
      "Batch 35: loss = 0.8420083522796631\n",
      "Batch 36: loss = 0.7934110164642334\n",
      "Batch 37: loss = 0.8101534843444824\n",
      "Batch 38: loss = 0.8874101638793945\n",
      "Batch 39: loss = 0.8345965147018433\n",
      "Batch 40: loss = 0.8283268213272095\n",
      "Batch 41: loss = 0.7668401002883911\n",
      "Batch 42: loss = 0.7884165048599243\n",
      "Batch 43: loss = 0.8217600584030151\n",
      "Batch 44: loss = 0.7308841347694397\n",
      "Batch 45: loss = 0.6832159757614136\n",
      "Batch 46: loss = 0.7711867094039917\n",
      "Batch 47: loss = 0.7684993743896484\n",
      "Batch 48: loss = 0.7558673620223999\n",
      "Batch 49: loss = 0.6959682703018188\n",
      "Batch 50: loss = 0.7596092224121094\n",
      "Batch 51: loss = 0.7594039440155029\n",
      "Batch 52: loss = 0.8466414213180542\n",
      "Batch 53: loss = 0.8457260131835938\n",
      "Batch 54: loss = 0.6935672760009766\n",
      "Batch 55: loss = 0.7144225835800171\n",
      "Batch 56: loss = 0.8051354289054871\n",
      "Batch 57: loss = 0.886014997959137\n",
      "Batch 58: loss = 0.8474613428115845\n",
      "Batch 59: loss = 0.6972758769989014\n",
      "Batch 60: loss = 0.8108701109886169\n",
      "Batch 61: loss = 0.840330183506012\n",
      "Batch 62: loss = 1.0277605056762695\n",
      "Batch 63: loss = 0.8539247512817383\n",
      "Batch 64: loss = 0.7087897062301636\n",
      "Batch 65: loss = 0.8364368677139282\n",
      "Batch 66: loss = 0.8411964178085327\n",
      "Batch 67: loss = 0.7657981514930725\n",
      "Batch 68: loss = 0.8097885847091675\n",
      "Batch 69: loss = 0.8055073022842407\n",
      "Batch 70: loss = 0.9130711555480957\n",
      "Batch 71: loss = 0.8150637745857239\n",
      "Batch 72: loss = 0.7619603872299194\n",
      "Batch 73: loss = 0.8802293539047241\n",
      "Batch 74: loss = 0.8635571002960205\n",
      "Batch 75: loss = 0.9225273728370667\n",
      "Batch 76: loss = 0.8537041544914246\n",
      "Batch 77: loss = 0.7679692506790161\n",
      "Batch 78: loss = 0.76644366979599\n",
      "Batch 79: loss = 0.708419680595398\n",
      "Batch 80: loss = 0.7624444365501404\n",
      "Batch 81: loss = 0.7698405981063843\n",
      "Batch 82: loss = 0.6745737791061401\n",
      "Batch 83: loss = 0.7677232623100281\n",
      "Batch 84: loss = 0.7571759223937988\n",
      "Batch 85: loss = 0.9027886986732483\n",
      "Batch 86: loss = 0.7934154272079468\n",
      "Batch 87: loss = 0.7598495483398438\n",
      "Batch 88: loss = 0.9652557373046875\n",
      "Batch 89: loss = 0.8114153146743774\n",
      "Batch 90: loss = 0.8608628511428833\n",
      "Batch 91: loss = 0.8786659836769104\n",
      "Batch 92: loss = 0.8414021730422974\n",
      "Batch 93: loss = 0.6812428832054138\n",
      "Batch 94: loss = 0.7214938998222351\n",
      "Batch 95: loss = 0.7950291037559509\n",
      "Batch 96: loss = 0.8425610065460205\n",
      "Batch 97: loss = 0.7877069711685181\n",
      "Batch 98: loss = 0.7605962753295898\n",
      "Batch 99: loss = 0.8219700455665588\n",
      "Batch 100: loss = 0.8268909454345703\n",
      "Batch 101: loss = 0.8149940967559814\n",
      "Batch 102: loss = 0.8537032008171082\n",
      "Batch 103: loss = 0.8104103803634644\n",
      "Batch 104: loss = 0.766743540763855\n",
      "Batch 105: loss = 0.8125648498535156\n",
      "Batch 106: loss = 0.8519679307937622\n",
      "Batch 107: loss = 0.8031151294708252\n",
      "Batch 108: loss = 0.8007301092147827\n",
      "Batch 109: loss = 0.8176823258399963\n",
      "Batch 110: loss = 0.720576286315918\n",
      "Batch 111: loss = 0.9351009130477905\n",
      "Batch 112: loss = 0.8120228052139282\n",
      "Batch 113: loss = 0.844793438911438\n",
      "Batch 114: loss = 0.8563510775566101\n",
      "Batch 115: loss = 0.8943074941635132\n",
      "Batch 116: loss = 0.9326798915863037\n",
      "Batch 117: loss = 0.7532157897949219\n",
      "Batch 118: loss = 0.7062517404556274\n",
      "Batch 119: loss = 0.84104984998703\n",
      "Batch 120: loss = 0.8724888563156128\n",
      "Batch 121: loss = 0.7924255132675171\n",
      "Batch 122: loss = 0.7407336235046387\n",
      "Batch 123: loss = 0.8444268703460693\n",
      "Batch 124: loss = 0.8769823908805847\n",
      "Batch 125: loss = 0.8949589729309082\n",
      "Batch 126: loss = 0.8850266933441162\n",
      "\n",
      "Epoch 18/100\n",
      "Batch 1: loss = 0.9092543721199036\n",
      "Batch 2: loss = 0.9432158470153809\n",
      "Batch 3: loss = 0.8379533886909485\n",
      "Batch 4: loss = 0.838874340057373\n",
      "Batch 5: loss = 0.9279740452766418\n",
      "Batch 6: loss = 0.9346381425857544\n",
      "Batch 7: loss = 0.8839610815048218\n",
      "Batch 8: loss = 0.8238738775253296\n",
      "Batch 9: loss = 0.7674916386604309\n",
      "Batch 10: loss = 0.7388969659805298\n",
      "Batch 11: loss = 0.8458662033081055\n",
      "Batch 12: loss = 0.8256844878196716\n",
      "Batch 13: loss = 0.8071311712265015\n",
      "Batch 14: loss = 0.7950328588485718\n",
      "Batch 15: loss = 0.7539136409759521\n",
      "Batch 16: loss = 0.8553831577301025\n",
      "Batch 17: loss = 0.8250283598899841\n",
      "Batch 18: loss = 0.8332679867744446\n",
      "Batch 19: loss = 0.7651783227920532\n",
      "Batch 20: loss = 0.7957203388214111\n",
      "Batch 21: loss = 0.873033881187439\n",
      "Batch 22: loss = 0.7665152549743652\n",
      "Batch 23: loss = 0.7992017269134521\n",
      "Batch 24: loss = 0.7420170307159424\n",
      "Batch 25: loss = 0.7215498685836792\n",
      "Batch 26: loss = 0.7345820665359497\n",
      "Batch 27: loss = 0.8864731788635254\n",
      "Batch 28: loss = 0.8497573137283325\n",
      "Batch 29: loss = 0.8184441328048706\n",
      "Batch 30: loss = 0.7388054132461548\n",
      "Batch 31: loss = 0.8764374852180481\n",
      "Batch 32: loss = 0.9281026124954224\n",
      "Batch 33: loss = 0.8098056316375732\n",
      "Batch 34: loss = 0.8276903629302979\n",
      "Batch 35: loss = 0.8241394758224487\n",
      "Batch 36: loss = 0.7427607774734497\n",
      "Batch 37: loss = 0.7729240655899048\n",
      "Batch 38: loss = 0.8574961423873901\n",
      "Batch 39: loss = 0.8311898708343506\n",
      "Batch 40: loss = 0.7991560697555542\n",
      "Batch 41: loss = 0.755998432636261\n",
      "Batch 42: loss = 0.7727169394493103\n",
      "Batch 43: loss = 0.8311961889266968\n",
      "Batch 44: loss = 0.7275779247283936\n",
      "Batch 45: loss = 0.671475887298584\n",
      "Batch 46: loss = 0.7501927018165588\n",
      "Batch 47: loss = 0.7502149343490601\n",
      "Batch 48: loss = 0.7224729061126709\n",
      "Batch 49: loss = 0.6953815221786499\n",
      "Batch 50: loss = 0.7123451232910156\n",
      "Batch 51: loss = 0.7529807090759277\n",
      "Batch 52: loss = 0.8403460383415222\n",
      "Batch 53: loss = 0.7944033145904541\n",
      "Batch 54: loss = 0.6816830039024353\n",
      "Batch 55: loss = 0.7026389241218567\n",
      "Batch 56: loss = 0.8164198994636536\n",
      "Batch 57: loss = 0.8572043776512146\n",
      "Batch 58: loss = 0.8054103851318359\n",
      "Batch 59: loss = 0.6454153060913086\n",
      "Batch 60: loss = 0.7636118531227112\n",
      "Batch 61: loss = 0.7961945533752441\n",
      "Batch 62: loss = 0.9823938608169556\n",
      "Batch 63: loss = 0.8307410478591919\n",
      "Batch 64: loss = 0.7000715732574463\n",
      "Batch 65: loss = 0.8130682706832886\n",
      "Batch 66: loss = 0.8034961223602295\n",
      "Batch 67: loss = 0.7554879784584045\n",
      "Batch 68: loss = 0.8009321093559265\n",
      "Batch 69: loss = 0.7668663263320923\n",
      "Batch 70: loss = 0.861757755279541\n",
      "Batch 71: loss = 0.8109159469604492\n",
      "Batch 72: loss = 0.7517656087875366\n",
      "Batch 73: loss = 0.8257776498794556\n",
      "Batch 74: loss = 0.8564777970314026\n",
      "Batch 75: loss = 0.9252283573150635\n",
      "Batch 76: loss = 0.8520177602767944\n",
      "Batch 77: loss = 0.7736417055130005\n",
      "Batch 78: loss = 0.7665153741836548\n",
      "Batch 79: loss = 0.6952968835830688\n",
      "Batch 80: loss = 0.7383920550346375\n",
      "Batch 81: loss = 0.7612447142601013\n",
      "Batch 82: loss = 0.6817657947540283\n",
      "Batch 83: loss = 0.7347920536994934\n",
      "Batch 84: loss = 0.7485955953598022\n",
      "Batch 85: loss = 0.87309330701828\n",
      "Batch 86: loss = 0.7883002758026123\n",
      "Batch 87: loss = 0.720944881439209\n",
      "Batch 88: loss = 0.944301187992096\n",
      "Batch 89: loss = 0.7961243391036987\n",
      "Batch 90: loss = 0.8439697027206421\n",
      "Batch 91: loss = 0.8520841598510742\n",
      "Batch 92: loss = 0.8020812273025513\n",
      "Batch 93: loss = 0.6690046787261963\n",
      "Batch 94: loss = 0.7175112962722778\n",
      "Batch 95: loss = 0.7888740301132202\n",
      "Batch 96: loss = 0.8059000372886658\n",
      "Batch 97: loss = 0.7557840347290039\n",
      "Batch 98: loss = 0.7879164814949036\n",
      "Batch 99: loss = 0.7726694345474243\n",
      "Batch 100: loss = 0.8113359808921814\n",
      "Batch 101: loss = 0.7902975082397461\n",
      "Batch 102: loss = 0.8190294504165649\n",
      "Batch 103: loss = 0.7933375835418701\n",
      "Batch 104: loss = 0.7877403497695923\n",
      "Batch 105: loss = 0.8300766944885254\n",
      "Batch 106: loss = 0.851414680480957\n",
      "Batch 107: loss = 0.7918107509613037\n",
      "Batch 108: loss = 0.8350932598114014\n",
      "Batch 109: loss = 0.8144456744194031\n",
      "Batch 110: loss = 0.7166823744773865\n",
      "Batch 111: loss = 0.8593463897705078\n",
      "Batch 112: loss = 0.7697917222976685\n",
      "Batch 113: loss = 0.8136749267578125\n",
      "Batch 114: loss = 0.8373321890830994\n",
      "Batch 115: loss = 0.8658739328384399\n",
      "Batch 116: loss = 0.8853287100791931\n",
      "Batch 117: loss = 0.7128197550773621\n",
      "Batch 118: loss = 0.7188037037849426\n",
      "Batch 119: loss = 0.7877049446105957\n",
      "Batch 120: loss = 0.8478415012359619\n",
      "Batch 121: loss = 0.7863293886184692\n",
      "Batch 122: loss = 0.7167810201644897\n",
      "Batch 123: loss = 0.7933282256126404\n",
      "Batch 124: loss = 0.8528515696525574\n",
      "Batch 125: loss = 0.8510900735855103\n",
      "Batch 126: loss = 0.8250812292098999\n",
      "\n",
      "Epoch 19/100\n",
      "Batch 1: loss = 0.8696206212043762\n",
      "Batch 2: loss = 0.9051526188850403\n",
      "Batch 3: loss = 0.8255615234375\n",
      "Batch 4: loss = 0.8260235786437988\n",
      "Batch 5: loss = 0.8910139799118042\n",
      "Batch 6: loss = 0.9365403652191162\n",
      "Batch 7: loss = 0.8256853222846985\n",
      "Batch 8: loss = 0.7940090298652649\n",
      "Batch 9: loss = 0.7137658596038818\n",
      "Batch 10: loss = 0.7093749046325684\n",
      "Batch 11: loss = 0.8148300051689148\n",
      "Batch 12: loss = 0.8120419383049011\n",
      "Batch 13: loss = 0.784859299659729\n",
      "Batch 14: loss = 0.7667346596717834\n",
      "Batch 15: loss = 0.76457679271698\n",
      "Batch 16: loss = 0.8451987504959106\n",
      "Batch 17: loss = 0.7940216064453125\n",
      "Batch 18: loss = 0.8111441135406494\n",
      "Batch 19: loss = 0.7237645983695984\n",
      "Batch 20: loss = 0.7711993455886841\n",
      "Batch 21: loss = 0.8577050566673279\n",
      "Batch 22: loss = 0.7322266101837158\n",
      "Batch 23: loss = 0.7909162044525146\n",
      "Batch 24: loss = 0.7166905403137207\n",
      "Batch 25: loss = 0.7260192632675171\n",
      "Batch 26: loss = 0.7253003120422363\n",
      "Batch 27: loss = 0.8616441488265991\n",
      "Batch 28: loss = 0.812282919883728\n",
      "Batch 29: loss = 0.7720521688461304\n",
      "Batch 30: loss = 0.727267324924469\n",
      "Batch 31: loss = 0.8771138191223145\n",
      "Batch 32: loss = 0.9192907810211182\n",
      "Batch 33: loss = 0.7877042889595032\n",
      "Batch 34: loss = 0.8123867511749268\n",
      "Batch 35: loss = 0.8177175521850586\n",
      "Batch 36: loss = 0.7413658499717712\n",
      "Batch 37: loss = 0.7735698223114014\n",
      "Batch 38: loss = 0.8146414160728455\n",
      "Batch 39: loss = 0.8031043410301208\n",
      "Batch 40: loss = 0.7996609210968018\n",
      "Batch 41: loss = 0.745189368724823\n",
      "Batch 42: loss = 0.7340333461761475\n",
      "Batch 43: loss = 0.8052644729614258\n",
      "Batch 44: loss = 0.7015262842178345\n",
      "Batch 45: loss = 0.6490373611450195\n",
      "Batch 46: loss = 0.7446871399879456\n",
      "Batch 47: loss = 0.7498814463615417\n",
      "Batch 48: loss = 0.7109955549240112\n",
      "Batch 49: loss = 0.6744403839111328\n",
      "Batch 50: loss = 0.7125589847564697\n",
      "Batch 51: loss = 0.7542741298675537\n",
      "Batch 52: loss = 0.8188410997390747\n",
      "Batch 53: loss = 0.8026268482208252\n",
      "Batch 54: loss = 0.6632028222084045\n",
      "Batch 55: loss = 0.6758993268013\n",
      "Batch 56: loss = 0.7847775816917419\n",
      "Batch 57: loss = 0.8387022614479065\n",
      "Batch 58: loss = 0.7978470325469971\n",
      "Batch 59: loss = 0.6136176586151123\n",
      "Batch 60: loss = 0.7453405857086182\n",
      "Batch 61: loss = 0.7668386101722717\n",
      "Batch 62: loss = 0.9433528184890747\n",
      "Batch 63: loss = 0.8113201856613159\n",
      "Batch 64: loss = 0.6921494007110596\n",
      "Batch 65: loss = 0.8081810474395752\n",
      "Batch 66: loss = 0.7847421169281006\n",
      "Batch 67: loss = 0.732344388961792\n",
      "Batch 68: loss = 0.7888932228088379\n",
      "Batch 69: loss = 0.7633824348449707\n",
      "Batch 70: loss = 0.866390585899353\n",
      "Batch 71: loss = 0.7971798181533813\n",
      "Batch 72: loss = 0.7072714567184448\n",
      "Batch 73: loss = 0.8498172760009766\n",
      "Batch 74: loss = 0.8290897607803345\n",
      "Batch 75: loss = 0.8698046207427979\n",
      "Batch 76: loss = 0.817457914352417\n",
      "Batch 77: loss = 0.7364736795425415\n",
      "Batch 78: loss = 0.7473145723342896\n",
      "Batch 79: loss = 0.6613380312919617\n",
      "Batch 80: loss = 0.725830078125\n",
      "Batch 81: loss = 0.737352728843689\n",
      "Batch 82: loss = 0.6567081809043884\n",
      "Batch 83: loss = 0.7231892347335815\n",
      "Batch 84: loss = 0.7406331896781921\n",
      "Batch 85: loss = 0.835127592086792\n",
      "Batch 86: loss = 0.7706814408302307\n",
      "Batch 87: loss = 0.6688550114631653\n",
      "Batch 88: loss = 0.9133858680725098\n",
      "Batch 89: loss = 0.7694419622421265\n",
      "Batch 90: loss = 0.8284231424331665\n",
      "Batch 91: loss = 0.8247562646865845\n",
      "Batch 92: loss = 0.8187766075134277\n",
      "Batch 93: loss = 0.649243950843811\n",
      "Batch 94: loss = 0.6985185146331787\n",
      "Batch 95: loss = 0.7651327848434448\n",
      "Batch 96: loss = 0.8320836424827576\n",
      "Batch 97: loss = 0.7443557381629944\n",
      "Batch 98: loss = 0.7396053671836853\n",
      "Batch 99: loss = 0.7773236632347107\n",
      "Batch 100: loss = 0.7945491075515747\n",
      "Batch 101: loss = 0.7734035849571228\n",
      "Batch 102: loss = 0.7927091121673584\n",
      "Batch 103: loss = 0.7787576913833618\n",
      "Batch 104: loss = 0.7218434810638428\n",
      "Batch 105: loss = 0.7547471523284912\n",
      "Batch 106: loss = 0.808290421962738\n",
      "Batch 107: loss = 0.75895094871521\n",
      "Batch 108: loss = 0.7936964631080627\n",
      "Batch 109: loss = 0.7860760688781738\n",
      "Batch 110: loss = 0.7154741287231445\n",
      "Batch 111: loss = 0.8491382002830505\n",
      "Batch 112: loss = 0.752562940120697\n",
      "Batch 113: loss = 0.8035827875137329\n",
      "Batch 114: loss = 0.8352755308151245\n",
      "Batch 115: loss = 0.8764715194702148\n",
      "Batch 116: loss = 0.9028266668319702\n",
      "Batch 117: loss = 0.715844988822937\n",
      "Batch 118: loss = 0.6724604964256287\n",
      "Batch 119: loss = 0.7955923080444336\n",
      "Batch 120: loss = 0.8250586986541748\n",
      "Batch 121: loss = 0.7580362558364868\n",
      "Batch 122: loss = 0.6998802423477173\n",
      "Batch 123: loss = 0.7988713383674622\n",
      "Batch 124: loss = 0.8232517242431641\n",
      "Batch 125: loss = 0.8373122215270996\n",
      "Batch 126: loss = 0.817039966583252\n",
      "\n",
      "Epoch 20/100\n",
      "Batch 1: loss = 0.8672462701797485\n",
      "Batch 2: loss = 0.899227499961853\n",
      "Batch 3: loss = 0.818854570388794\n",
      "Batch 4: loss = 0.8014247417449951\n",
      "Batch 5: loss = 0.8907935619354248\n",
      "Batch 6: loss = 0.8920489549636841\n",
      "Batch 7: loss = 0.8533854484558105\n",
      "Batch 8: loss = 0.7655009627342224\n",
      "Batch 9: loss = 0.7345277070999146\n",
      "Batch 10: loss = 0.6838545203208923\n",
      "Batch 11: loss = 0.796995997428894\n",
      "Batch 12: loss = 0.783645510673523\n",
      "Batch 13: loss = 0.7532786130905151\n",
      "Batch 14: loss = 0.7574490308761597\n",
      "Batch 15: loss = 0.7222514748573303\n",
      "Batch 16: loss = 0.8363040685653687\n",
      "Batch 17: loss = 0.7927020788192749\n",
      "Batch 18: loss = 0.7989093065261841\n",
      "Batch 19: loss = 0.7235803604125977\n",
      "Batch 20: loss = 0.7357980012893677\n",
      "Batch 21: loss = 0.8157182931900024\n",
      "Batch 22: loss = 0.7055053114891052\n",
      "Batch 23: loss = 0.7874802947044373\n",
      "Batch 24: loss = 0.6963542699813843\n",
      "Batch 25: loss = 0.689427375793457\n",
      "Batch 26: loss = 0.7107102870941162\n",
      "Batch 27: loss = 0.8447183966636658\n",
      "Batch 28: loss = 0.8038192391395569\n",
      "Batch 29: loss = 0.7441955804824829\n",
      "Batch 30: loss = 0.7005764842033386\n",
      "Batch 31: loss = 0.8416131138801575\n",
      "Batch 32: loss = 0.8886121511459351\n",
      "Batch 33: loss = 0.7731280326843262\n",
      "Batch 34: loss = 0.7898818254470825\n",
      "Batch 35: loss = 0.7807755470275879\n",
      "Batch 36: loss = 0.7328624725341797\n",
      "Batch 37: loss = 0.7453800439834595\n",
      "Batch 38: loss = 0.8243125677108765\n",
      "Batch 39: loss = 0.7659493684768677\n",
      "Batch 40: loss = 0.7614054679870605\n",
      "Batch 41: loss = 0.7148658037185669\n",
      "Batch 42: loss = 0.7497067451477051\n",
      "Batch 43: loss = 0.8045717477798462\n",
      "Batch 44: loss = 0.665712833404541\n",
      "Batch 45: loss = 0.6461776494979858\n",
      "Batch 46: loss = 0.7382731437683105\n",
      "Batch 47: loss = 0.7213600873947144\n",
      "Batch 48: loss = 0.6911460161209106\n",
      "Batch 49: loss = 0.6526371240615845\n",
      "Batch 50: loss = 0.6784524917602539\n",
      "Batch 51: loss = 0.7110866904258728\n",
      "Batch 52: loss = 0.7860183715820312\n",
      "Batch 53: loss = 0.7708324193954468\n",
      "Batch 54: loss = 0.6687042713165283\n",
      "Batch 55: loss = 0.6672036647796631\n",
      "Batch 56: loss = 0.7712509632110596\n",
      "Batch 57: loss = 0.8315029144287109\n",
      "Batch 58: loss = 0.7643740177154541\n",
      "Batch 59: loss = 0.604815661907196\n",
      "Batch 60: loss = 0.7070634961128235\n",
      "Batch 61: loss = 0.7661330103874207\n",
      "Batch 62: loss = 0.9439097046852112\n",
      "Batch 63: loss = 0.8081345558166504\n",
      "Batch 64: loss = 0.6805865168571472\n",
      "Batch 65: loss = 0.8076868057250977\n",
      "Batch 66: loss = 0.7759659290313721\n",
      "Batch 67: loss = 0.6965357065200806\n",
      "Batch 68: loss = 0.7749108672142029\n",
      "Batch 69: loss = 0.7559816837310791\n",
      "Batch 70: loss = 0.8472611904144287\n",
      "Batch 71: loss = 0.7554823756217957\n",
      "Batch 72: loss = 0.6929625272750854\n",
      "Batch 73: loss = 0.8163596391677856\n",
      "Batch 74: loss = 0.8294514417648315\n",
      "Batch 75: loss = 0.8491642475128174\n",
      "Batch 76: loss = 0.7953821420669556\n",
      "Batch 77: loss = 0.7500412464141846\n",
      "Batch 78: loss = 0.7374857664108276\n",
      "Batch 79: loss = 0.6608350872993469\n",
      "Batch 80: loss = 0.7280938029289246\n",
      "Batch 81: loss = 0.7325579524040222\n",
      "Batch 82: loss = 0.6326035261154175\n",
      "Batch 83: loss = 0.6922253370285034\n",
      "Batch 84: loss = 0.7027281522750854\n",
      "Batch 85: loss = 0.8435823917388916\n",
      "Batch 86: loss = 0.7326333522796631\n",
      "Batch 87: loss = 0.6896788477897644\n",
      "Batch 88: loss = 0.8976578116416931\n",
      "Batch 89: loss = 0.7430130839347839\n",
      "Batch 90: loss = 0.811959981918335\n",
      "Batch 91: loss = 0.8091729283332825\n",
      "Batch 92: loss = 0.7613334655761719\n",
      "Batch 93: loss = 0.6466518640518188\n",
      "Batch 94: loss = 0.6879339218139648\n",
      "Batch 95: loss = 0.7535715699195862\n",
      "Batch 96: loss = 0.785394549369812\n",
      "Batch 97: loss = 0.7377650141716003\n",
      "Batch 98: loss = 0.7130112648010254\n",
      "Batch 99: loss = 0.7638421654701233\n",
      "Batch 100: loss = 0.7598843574523926\n",
      "Batch 101: loss = 0.7410165071487427\n",
      "Batch 102: loss = 0.7675769329071045\n",
      "Batch 103: loss = 0.7666099071502686\n",
      "Batch 104: loss = 0.7486207485198975\n",
      "Batch 105: loss = 0.7713109254837036\n",
      "Batch 106: loss = 0.799509584903717\n",
      "Batch 107: loss = 0.7292039394378662\n",
      "Batch 108: loss = 0.7828823328018188\n",
      "Batch 109: loss = 0.7705695629119873\n",
      "Batch 110: loss = 0.6603221297264099\n",
      "Batch 111: loss = 0.838563084602356\n",
      "Batch 112: loss = 0.763477087020874\n",
      "Batch 113: loss = 0.7802198529243469\n",
      "Batch 114: loss = 0.8013644814491272\n",
      "Batch 115: loss = 0.8352946043014526\n",
      "Batch 116: loss = 0.8583937287330627\n",
      "Batch 117: loss = 0.6769326329231262\n",
      "Batch 118: loss = 0.6691315174102783\n",
      "Batch 119: loss = 0.7603282928466797\n",
      "Batch 120: loss = 0.8214922547340393\n",
      "Batch 121: loss = 0.747801661491394\n",
      "Batch 122: loss = 0.6661069393157959\n",
      "Batch 123: loss = 0.7564280033111572\n",
      "Batch 124: loss = 0.8196609020233154\n",
      "Batch 125: loss = 0.8270919919013977\n",
      "Batch 126: loss = 0.8096760511398315\n",
      "Saved checkpoint to weights.20.pt\n",
      "\n",
      "Epoch 21/100\n",
      "Batch 1: loss = 0.8507832288742065\n",
      "Batch 2: loss = 0.8949590921401978\n",
      "Batch 3: loss = 0.7913495302200317\n",
      "Batch 4: loss = 0.7800753116607666\n",
      "Batch 5: loss = 0.8521928787231445\n",
      "Batch 6: loss = 0.9025116562843323\n",
      "Batch 7: loss = 0.8383045196533203\n",
      "Batch 8: loss = 0.7715726494789124\n",
      "Batch 9: loss = 0.7338418960571289\n",
      "Batch 10: loss = 0.6731314659118652\n",
      "Batch 11: loss = 0.8092337846755981\n",
      "Batch 12: loss = 0.7736858129501343\n",
      "Batch 13: loss = 0.7583223581314087\n",
      "Batch 14: loss = 0.7286195755004883\n",
      "Batch 15: loss = 0.7002965807914734\n",
      "Batch 16: loss = 0.8209187984466553\n",
      "Batch 17: loss = 0.7567852735519409\n",
      "Batch 18: loss = 0.7800514698028564\n",
      "Batch 19: loss = 0.6943327188491821\n",
      "Batch 20: loss = 0.7111185789108276\n",
      "Batch 21: loss = 0.8185964226722717\n",
      "Batch 22: loss = 0.7039620876312256\n",
      "Batch 23: loss = 0.7624987363815308\n",
      "Batch 24: loss = 0.6841120719909668\n",
      "Batch 25: loss = 0.6985553503036499\n",
      "Batch 26: loss = 0.671369194984436\n",
      "Batch 27: loss = 0.8462947607040405\n",
      "Batch 28: loss = 0.7523255348205566\n",
      "Batch 29: loss = 0.7442243695259094\n",
      "Batch 30: loss = 0.6735900640487671\n",
      "Batch 31: loss = 0.8281222581863403\n",
      "Batch 32: loss = 0.8443505167961121\n",
      "Batch 33: loss = 0.7482073307037354\n",
      "Batch 34: loss = 0.794796347618103\n",
      "Batch 35: loss = 0.7705660462379456\n",
      "Batch 36: loss = 0.6788433790206909\n",
      "Batch 37: loss = 0.7412691116333008\n",
      "Batch 38: loss = 0.7693290710449219\n",
      "Batch 39: loss = 0.7519639730453491\n",
      "Batch 40: loss = 0.7577987909317017\n",
      "Batch 41: loss = 0.6915075182914734\n",
      "Batch 42: loss = 0.7323381900787354\n",
      "Batch 43: loss = 0.7969690561294556\n",
      "Batch 44: loss = 0.6759637594223022\n",
      "Batch 45: loss = 0.6391277313232422\n",
      "Batch 46: loss = 0.7006504535675049\n",
      "Batch 47: loss = 0.7137354612350464\n",
      "Batch 48: loss = 0.6735115051269531\n",
      "Batch 49: loss = 0.6431388854980469\n",
      "Batch 50: loss = 0.6886869668960571\n",
      "Batch 51: loss = 0.6882718801498413\n",
      "Batch 52: loss = 0.7815651893615723\n",
      "Batch 53: loss = 0.7159115076065063\n",
      "Batch 54: loss = 0.6267865896224976\n",
      "Batch 55: loss = 0.6579720973968506\n",
      "Batch 56: loss = 0.768667459487915\n",
      "Batch 57: loss = 0.7923933863639832\n",
      "Batch 58: loss = 0.7380620241165161\n",
      "Batch 59: loss = 0.6047046184539795\n",
      "Batch 60: loss = 0.7393842935562134\n",
      "Batch 61: loss = 0.7686524987220764\n",
      "Batch 62: loss = 0.9176429510116577\n",
      "Batch 63: loss = 0.7620880603790283\n",
      "Batch 64: loss = 0.6637895107269287\n",
      "Batch 65: loss = 0.7614244818687439\n",
      "Batch 66: loss = 0.777865469455719\n",
      "Batch 67: loss = 0.7016589641571045\n",
      "Batch 68: loss = 0.775428056716919\n",
      "Batch 69: loss = 0.7046186327934265\n",
      "Batch 70: loss = 0.8289008140563965\n",
      "Batch 71: loss = 0.7685089111328125\n",
      "Batch 72: loss = 0.6881344318389893\n",
      "Batch 73: loss = 0.7923783659934998\n",
      "Batch 74: loss = 0.801230788230896\n",
      "Batch 75: loss = 0.8499560356140137\n",
      "Batch 76: loss = 0.7806349992752075\n",
      "Batch 77: loss = 0.7314568161964417\n",
      "Batch 78: loss = 0.7115100622177124\n",
      "Batch 79: loss = 0.6253204345703125\n",
      "Batch 80: loss = 0.6926507949829102\n",
      "Batch 81: loss = 0.7066755890846252\n",
      "Batch 82: loss = 0.6455236673355103\n",
      "Batch 83: loss = 0.6695864200592041\n",
      "Batch 84: loss = 0.6861839890480042\n",
      "Batch 85: loss = 0.8377604484558105\n",
      "Batch 86: loss = 0.7045376896858215\n",
      "Batch 87: loss = 0.6900503635406494\n",
      "Batch 88: loss = 0.8737722635269165\n",
      "Batch 89: loss = 0.7343217134475708\n",
      "Batch 90: loss = 0.7894148230552673\n",
      "Batch 91: loss = 0.7901177406311035\n",
      "Batch 92: loss = 0.7731306552886963\n",
      "Batch 93: loss = 0.6182384490966797\n",
      "Batch 94: loss = 0.6565732955932617\n",
      "Batch 95: loss = 0.7285788059234619\n",
      "Batch 96: loss = 0.7742401361465454\n",
      "Batch 97: loss = 0.7138646245002747\n",
      "Batch 98: loss = 0.7324017882347107\n",
      "Batch 99: loss = 0.7428692579269409\n",
      "Batch 100: loss = 0.7571250796318054\n",
      "Batch 101: loss = 0.7497252225875854\n",
      "Batch 102: loss = 0.7441654205322266\n",
      "Batch 103: loss = 0.7545305490493774\n",
      "Batch 104: loss = 0.7166118621826172\n",
      "Batch 105: loss = 0.7507473230361938\n",
      "Batch 106: loss = 0.7821574211120605\n",
      "Batch 107: loss = 0.7480424642562866\n",
      "Batch 108: loss = 0.7861224412918091\n",
      "Batch 109: loss = 0.7572219371795654\n",
      "Batch 110: loss = 0.6502864956855774\n",
      "Batch 111: loss = 0.8182693123817444\n",
      "Batch 112: loss = 0.7662365436553955\n",
      "Batch 113: loss = 0.7469074726104736\n",
      "Batch 114: loss = 0.7824028134346008\n",
      "Batch 115: loss = 0.8149707913398743\n",
      "Batch 116: loss = 0.8364923596382141\n",
      "Batch 117: loss = 0.7037450075149536\n",
      "Batch 118: loss = 0.6515735387802124\n",
      "Batch 119: loss = 0.7682134509086609\n",
      "Batch 120: loss = 0.7782493829727173\n",
      "Batch 121: loss = 0.7276718616485596\n",
      "Batch 122: loss = 0.6573154330253601\n",
      "Batch 123: loss = 0.7545492649078369\n",
      "Batch 124: loss = 0.8045686483383179\n",
      "Batch 125: loss = 0.7994902729988098\n",
      "Batch 126: loss = 0.807985246181488\n",
      "\n",
      "Epoch 22/100\n",
      "Batch 1: loss = 0.8360521793365479\n",
      "Batch 2: loss = 0.828796923160553\n",
      "Batch 3: loss = 0.7404191493988037\n",
      "Batch 4: loss = 0.7534969449043274\n",
      "Batch 5: loss = 0.8258329629898071\n",
      "Batch 6: loss = 0.8586766719818115\n",
      "Batch 7: loss = 0.7813588380813599\n",
      "Batch 8: loss = 0.7241255044937134\n",
      "Batch 9: loss = 0.6840227842330933\n",
      "Batch 10: loss = 0.6546838283538818\n",
      "Batch 11: loss = 0.7544516921043396\n",
      "Batch 12: loss = 0.747626781463623\n",
      "Batch 13: loss = 0.720755398273468\n",
      "Batch 14: loss = 0.7032448053359985\n",
      "Batch 15: loss = 0.6701997518539429\n",
      "Batch 16: loss = 0.7858543395996094\n",
      "Batch 17: loss = 0.7398900985717773\n",
      "Batch 18: loss = 0.7549746036529541\n",
      "Batch 19: loss = 0.6816470623016357\n",
      "Batch 20: loss = 0.6989479660987854\n",
      "Batch 21: loss = 0.7578349113464355\n",
      "Batch 22: loss = 0.6858268976211548\n",
      "Batch 23: loss = 0.7541471719741821\n",
      "Batch 24: loss = 0.6825351715087891\n",
      "Batch 25: loss = 0.6730880737304688\n",
      "Batch 26: loss = 0.6940198540687561\n",
      "Batch 27: loss = 0.8250387907028198\n",
      "Batch 28: loss = 0.7658995985984802\n",
      "Batch 29: loss = 0.7435053586959839\n",
      "Batch 30: loss = 0.66162109375\n",
      "Batch 31: loss = 0.7853398323059082\n",
      "Batch 32: loss = 0.8110338449478149\n",
      "Batch 33: loss = 0.75889652967453\n",
      "Batch 34: loss = 0.7509777545928955\n",
      "Batch 35: loss = 0.7226647138595581\n",
      "Batch 36: loss = 0.6801106929779053\n",
      "Batch 37: loss = 0.7137599587440491\n",
      "Batch 38: loss = 0.7612569332122803\n",
      "Batch 39: loss = 0.7406748533248901\n",
      "Batch 40: loss = 0.6996791362762451\n",
      "Batch 41: loss = 0.6923964619636536\n",
      "Batch 42: loss = 0.7104102373123169\n",
      "Batch 43: loss = 0.7468688488006592\n",
      "Batch 44: loss = 0.6318116188049316\n",
      "Batch 45: loss = 0.6041701436042786\n",
      "Batch 46: loss = 0.6836481094360352\n",
      "Batch 47: loss = 0.7132511138916016\n",
      "Batch 48: loss = 0.6501657366752625\n",
      "Batch 49: loss = 0.6303157806396484\n",
      "Batch 50: loss = 0.6508395671844482\n",
      "Batch 51: loss = 0.6691068410873413\n",
      "Batch 52: loss = 0.7626049518585205\n",
      "Batch 53: loss = 0.7260512709617615\n",
      "Batch 54: loss = 0.6278616189956665\n",
      "Batch 55: loss = 0.6568616628646851\n",
      "Batch 56: loss = 0.7202674150466919\n",
      "Batch 57: loss = 0.7681565284729004\n",
      "Batch 58: loss = 0.750986635684967\n",
      "Batch 59: loss = 0.5886073112487793\n",
      "Batch 60: loss = 0.6971752047538757\n",
      "Batch 61: loss = 0.7353329658508301\n",
      "Batch 62: loss = 0.8595418930053711\n",
      "Batch 63: loss = 0.7468778491020203\n",
      "Batch 64: loss = 0.6572486162185669\n",
      "Batch 65: loss = 0.757321834564209\n",
      "Batch 66: loss = 0.7537893056869507\n",
      "Batch 67: loss = 0.6752636432647705\n",
      "Batch 68: loss = 0.7143146991729736\n",
      "Batch 69: loss = 0.7121529579162598\n",
      "Batch 70: loss = 0.8119601011276245\n",
      "Batch 71: loss = 0.7423025369644165\n",
      "Batch 72: loss = 0.6846297383308411\n",
      "Batch 73: loss = 0.7711355686187744\n",
      "Batch 74: loss = 0.7773746252059937\n",
      "Batch 75: loss = 0.8322387933731079\n",
      "Batch 76: loss = 0.7527763843536377\n",
      "Batch 77: loss = 0.7089338302612305\n",
      "Batch 78: loss = 0.7146158218383789\n",
      "Batch 79: loss = 0.6392359733581543\n",
      "Batch 80: loss = 0.7007444500923157\n",
      "Batch 81: loss = 0.7115544080734253\n",
      "Batch 82: loss = 0.6282045841217041\n",
      "Batch 83: loss = 0.6686802506446838\n",
      "Batch 84: loss = 0.7002099752426147\n",
      "Batch 85: loss = 0.7924427390098572\n",
      "Batch 86: loss = 0.7062393426895142\n",
      "Batch 87: loss = 0.654249906539917\n",
      "Batch 88: loss = 0.8745629191398621\n",
      "Batch 89: loss = 0.7008277177810669\n",
      "Batch 90: loss = 0.7557264566421509\n",
      "Batch 91: loss = 0.776602566242218\n",
      "Batch 92: loss = 0.752150297164917\n",
      "Batch 93: loss = 0.6266771554946899\n",
      "Batch 94: loss = 0.656969428062439\n",
      "Batch 95: loss = 0.6920304894447327\n",
      "Batch 96: loss = 0.7624495029449463\n",
      "Batch 97: loss = 0.6835637092590332\n",
      "Batch 98: loss = 0.6950219869613647\n",
      "Batch 99: loss = 0.7370766401290894\n",
      "Batch 100: loss = 0.7545451521873474\n",
      "Batch 101: loss = 0.6952756643295288\n",
      "Batch 102: loss = 0.7467536926269531\n",
      "Batch 103: loss = 0.7555829286575317\n",
      "Batch 104: loss = 0.6888992786407471\n",
      "Batch 105: loss = 0.7338846921920776\n",
      "Batch 106: loss = 0.767478346824646\n",
      "Batch 107: loss = 0.7001793384552002\n",
      "Batch 108: loss = 0.7175875306129456\n",
      "Batch 109: loss = 0.754965603351593\n",
      "Batch 110: loss = 0.6330338716506958\n",
      "Batch 111: loss = 0.7916792631149292\n",
      "Batch 112: loss = 0.7203596234321594\n",
      "Batch 113: loss = 0.7415998578071594\n",
      "Batch 114: loss = 0.7696937918663025\n",
      "Batch 115: loss = 0.7891315221786499\n",
      "Batch 116: loss = 0.8178083896636963\n",
      "Batch 117: loss = 0.6515311002731323\n",
      "Batch 118: loss = 0.6543020009994507\n",
      "Batch 119: loss = 0.7493382692337036\n",
      "Batch 120: loss = 0.7492782473564148\n",
      "Batch 121: loss = 0.7212241888046265\n",
      "Batch 122: loss = 0.645795464515686\n",
      "Batch 123: loss = 0.7532482743263245\n",
      "Batch 124: loss = 0.7921316027641296\n",
      "Batch 125: loss = 0.7755129337310791\n",
      "Batch 126: loss = 0.7462639808654785\n",
      "\n",
      "Epoch 23/100\n",
      "Batch 1: loss = 0.7803977727890015\n",
      "Batch 2: loss = 0.8169931173324585\n",
      "Batch 3: loss = 0.7341632843017578\n",
      "Batch 4: loss = 0.7220284938812256\n",
      "Batch 5: loss = 0.8167071342468262\n",
      "Batch 6: loss = 0.8387126922607422\n",
      "Batch 7: loss = 0.7759273052215576\n",
      "Batch 8: loss = 0.701256513595581\n",
      "Batch 9: loss = 0.6732801795005798\n",
      "Batch 10: loss = 0.6417096853256226\n",
      "Batch 11: loss = 0.756866991519928\n",
      "Batch 12: loss = 0.7524603605270386\n",
      "Batch 13: loss = 0.7149204015731812\n",
      "Batch 14: loss = 0.6983096599578857\n",
      "Batch 15: loss = 0.6537094116210938\n",
      "Batch 16: loss = 0.7919918298721313\n",
      "Batch 17: loss = 0.7259318828582764\n",
      "Batch 18: loss = 0.767723023891449\n",
      "Batch 19: loss = 0.6727880239486694\n",
      "Batch 20: loss = 0.7020765542984009\n",
      "Batch 21: loss = 0.7445409297943115\n",
      "Batch 22: loss = 0.6690185070037842\n",
      "Batch 23: loss = 0.7260973453521729\n",
      "Batch 24: loss = 0.6505472660064697\n",
      "Batch 25: loss = 0.6732481718063354\n",
      "Batch 26: loss = 0.6700568795204163\n",
      "Batch 27: loss = 0.8235388994216919\n",
      "Batch 28: loss = 0.7534352540969849\n",
      "Batch 29: loss = 0.735164225101471\n",
      "Batch 30: loss = 0.6450005769729614\n",
      "Batch 31: loss = 0.7858296632766724\n",
      "Batch 32: loss = 0.829283595085144\n",
      "Batch 33: loss = 0.7138173580169678\n",
      "Batch 34: loss = 0.7486648559570312\n",
      "Batch 35: loss = 0.7231308221817017\n",
      "Batch 36: loss = 0.6680662631988525\n",
      "Batch 37: loss = 0.7012259364128113\n",
      "Batch 38: loss = 0.7754477262496948\n",
      "Batch 39: loss = 0.7497996091842651\n",
      "Batch 40: loss = 0.7022640109062195\n",
      "Batch 41: loss = 0.6642535924911499\n",
      "Batch 42: loss = 0.7028063535690308\n",
      "Batch 43: loss = 0.7123889327049255\n",
      "Batch 44: loss = 0.6366591453552246\n",
      "Batch 45: loss = 0.6336103677749634\n",
      "Batch 46: loss = 0.6365371942520142\n",
      "Batch 47: loss = 0.7050363421440125\n",
      "Batch 48: loss = 0.6400611400604248\n",
      "Batch 49: loss = 0.586698055267334\n",
      "Batch 50: loss = 0.649925947189331\n",
      "Batch 51: loss = 0.6817876100540161\n",
      "Batch 52: loss = 0.7185982465744019\n",
      "Batch 53: loss = 0.6859384775161743\n",
      "Batch 54: loss = 0.5999958515167236\n",
      "Batch 55: loss = 0.6107467412948608\n",
      "Batch 56: loss = 0.7349668741226196\n",
      "Batch 57: loss = 0.7589698433876038\n",
      "Batch 58: loss = 0.7385375499725342\n",
      "Batch 59: loss = 0.5555068254470825\n",
      "Batch 60: loss = 0.6792146563529968\n",
      "Batch 61: loss = 0.7248508930206299\n",
      "Batch 62: loss = 0.8839265704154968\n",
      "Batch 63: loss = 0.7465789914131165\n",
      "Batch 64: loss = 0.6223095655441284\n",
      "Batch 65: loss = 0.7516920566558838\n",
      "Batch 66: loss = 0.7042996883392334\n",
      "Batch 67: loss = 0.6730338335037231\n",
      "Batch 68: loss = 0.6892318725585938\n",
      "Batch 69: loss = 0.6684674620628357\n",
      "Batch 70: loss = 0.8108242750167847\n",
      "Batch 71: loss = 0.7375278472900391\n",
      "Batch 72: loss = 0.6471138000488281\n",
      "Batch 73: loss = 0.7475875616073608\n",
      "Batch 74: loss = 0.7704641819000244\n",
      "Batch 75: loss = 0.8160961866378784\n",
      "Batch 76: loss = 0.7453755140304565\n",
      "Batch 77: loss = 0.7091900110244751\n",
      "Batch 78: loss = 0.7127541303634644\n",
      "Batch 79: loss = 0.5883102416992188\n",
      "Batch 80: loss = 0.6897904872894287\n",
      "Batch 81: loss = 0.713472306728363\n",
      "Batch 82: loss = 0.6277012825012207\n",
      "Batch 83: loss = 0.6790283918380737\n",
      "Batch 84: loss = 0.6434516906738281\n",
      "Batch 85: loss = 0.8157732486724854\n",
      "Batch 86: loss = 0.645708441734314\n",
      "Batch 87: loss = 0.6490104794502258\n",
      "Batch 88: loss = 0.8254146575927734\n",
      "Batch 89: loss = 0.6765651702880859\n",
      "Batch 90: loss = 0.7571771144866943\n",
      "Batch 91: loss = 0.7701013088226318\n",
      "Batch 92: loss = 0.7248052358627319\n",
      "Batch 93: loss = 0.599943995475769\n",
      "Batch 94: loss = 0.6169224977493286\n",
      "Batch 95: loss = 0.6792429685592651\n",
      "Batch 96: loss = 0.7332308888435364\n",
      "Batch 97: loss = 0.670961856842041\n",
      "Batch 98: loss = 0.6724787950515747\n",
      "Batch 99: loss = 0.7100381851196289\n",
      "Batch 100: loss = 0.7338099479675293\n",
      "Batch 101: loss = 0.686712384223938\n",
      "Batch 102: loss = 0.7199369668960571\n",
      "Batch 103: loss = 0.713401198387146\n",
      "Batch 104: loss = 0.664269208908081\n",
      "Batch 105: loss = 0.7058147192001343\n",
      "Batch 106: loss = 0.7310223579406738\n",
      "Batch 107: loss = 0.6872955560684204\n",
      "Batch 108: loss = 0.7162473797798157\n",
      "Batch 109: loss = 0.7209320664405823\n",
      "Batch 110: loss = 0.6389716863632202\n",
      "Batch 111: loss = 0.7724143862724304\n",
      "Batch 112: loss = 0.7101618051528931\n",
      "Batch 113: loss = 0.7664265632629395\n",
      "Batch 114: loss = 0.7781240940093994\n",
      "Batch 115: loss = 0.7802082300186157\n",
      "Batch 116: loss = 0.7925679683685303\n",
      "Batch 117: loss = 0.6330375671386719\n",
      "Batch 118: loss = 0.6384519934654236\n",
      "Batch 119: loss = 0.7288979291915894\n",
      "Batch 120: loss = 0.7611081004142761\n",
      "Batch 121: loss = 0.7072429656982422\n",
      "Batch 122: loss = 0.6481755375862122\n",
      "Batch 123: loss = 0.71327805519104\n",
      "Batch 124: loss = 0.7687739133834839\n",
      "Batch 125: loss = 0.747992992401123\n",
      "Batch 126: loss = 0.7252660989761353\n",
      "\n",
      "Epoch 24/100\n",
      "Batch 1: loss = 0.7750208973884583\n",
      "Batch 2: loss = 0.8142284154891968\n",
      "Batch 3: loss = 0.7462117671966553\n",
      "Batch 4: loss = 0.7006610631942749\n",
      "Batch 5: loss = 0.7769635915756226\n",
      "Batch 6: loss = 0.833035945892334\n",
      "Batch 7: loss = 0.7621818780899048\n",
      "Batch 8: loss = 0.694399356842041\n",
      "Batch 9: loss = 0.6921688318252563\n",
      "Batch 10: loss = 0.6480759382247925\n",
      "Batch 11: loss = 0.7216605544090271\n",
      "Batch 12: loss = 0.7170907258987427\n",
      "Batch 13: loss = 0.6921122670173645\n",
      "Batch 14: loss = 0.684967041015625\n",
      "Batch 15: loss = 0.6596989631652832\n",
      "Batch 16: loss = 0.7590097188949585\n",
      "Batch 17: loss = 0.704383373260498\n",
      "Batch 18: loss = 0.7411704063415527\n",
      "Batch 19: loss = 0.6425813436508179\n",
      "Batch 20: loss = 0.711840033531189\n",
      "Batch 21: loss = 0.7425757646560669\n",
      "Batch 22: loss = 0.6405385732650757\n",
      "Batch 23: loss = 0.720007598400116\n",
      "Batch 24: loss = 0.6273918747901917\n",
      "Batch 25: loss = 0.6429673433303833\n",
      "Batch 26: loss = 0.6451889276504517\n",
      "Batch 27: loss = 0.7838797569274902\n",
      "Batch 28: loss = 0.7282727956771851\n",
      "Batch 29: loss = 0.7163764238357544\n",
      "Batch 30: loss = 0.6328972578048706\n",
      "Batch 31: loss = 0.7463989853858948\n",
      "Batch 32: loss = 0.7935550212860107\n",
      "Batch 33: loss = 0.704573392868042\n",
      "Batch 34: loss = 0.7290467023849487\n",
      "Batch 35: loss = 0.691911518573761\n",
      "Batch 36: loss = 0.6213324069976807\n",
      "Batch 37: loss = 0.6889652013778687\n",
      "Batch 38: loss = 0.7278900146484375\n",
      "Batch 39: loss = 0.7169089913368225\n",
      "Batch 40: loss = 0.706235408782959\n",
      "Batch 41: loss = 0.6614792346954346\n",
      "Batch 42: loss = 0.6825822591781616\n",
      "Batch 43: loss = 0.7270504832267761\n",
      "Batch 44: loss = 0.603498101234436\n",
      "Batch 45: loss = 0.5850114822387695\n",
      "Batch 46: loss = 0.6447309255599976\n",
      "Batch 47: loss = 0.6931304931640625\n",
      "Batch 48: loss = 0.6243643760681152\n",
      "Batch 49: loss = 0.5801555514335632\n",
      "Batch 50: loss = 0.6323760747909546\n",
      "Batch 51: loss = 0.642941951751709\n",
      "Batch 52: loss = 0.7026686668395996\n",
      "Batch 53: loss = 0.6982910633087158\n",
      "Batch 54: loss = 0.5997563600540161\n",
      "Batch 55: loss = 0.6168088912963867\n",
      "Batch 56: loss = 0.6816211938858032\n",
      "Batch 57: loss = 0.7472710609436035\n",
      "Batch 58: loss = 0.7191833257675171\n",
      "Batch 59: loss = 0.5356767177581787\n",
      "Batch 60: loss = 0.6818757057189941\n",
      "Batch 61: loss = 0.7003298997879028\n",
      "Batch 62: loss = 0.8241013884544373\n",
      "Batch 63: loss = 0.7296360731124878\n",
      "Batch 64: loss = 0.6214768886566162\n",
      "Batch 65: loss = 0.7345037460327148\n",
      "Batch 66: loss = 0.6798648834228516\n",
      "Batch 67: loss = 0.6549537777900696\n",
      "Batch 68: loss = 0.7113126516342163\n",
      "Batch 69: loss = 0.6775774359703064\n",
      "Batch 70: loss = 0.7631411552429199\n",
      "Batch 71: loss = 0.7266432642936707\n",
      "Batch 72: loss = 0.6299896240234375\n",
      "Batch 73: loss = 0.7456874251365662\n",
      "Batch 74: loss = 0.7813320159912109\n",
      "Batch 75: loss = 0.7922365665435791\n",
      "Batch 76: loss = 0.7396002411842346\n",
      "Batch 77: loss = 0.6869279146194458\n",
      "Batch 78: loss = 0.6991708278656006\n",
      "Batch 79: loss = 0.6207017302513123\n",
      "Batch 80: loss = 0.6611989736557007\n",
      "Batch 81: loss = 0.6562310457229614\n",
      "Batch 82: loss = 0.5947780609130859\n",
      "Batch 83: loss = 0.645098090171814\n",
      "Batch 84: loss = 0.659349799156189\n",
      "Batch 85: loss = 0.7989788055419922\n",
      "Batch 86: loss = 0.6523481607437134\n",
      "Batch 87: loss = 0.6187063455581665\n",
      "Batch 88: loss = 0.8041318655014038\n",
      "Batch 89: loss = 0.6755132675170898\n",
      "Batch 90: loss = 0.7192227840423584\n",
      "Batch 91: loss = 0.7511026859283447\n",
      "Batch 92: loss = 0.7097181081771851\n",
      "Batch 93: loss = 0.5869057178497314\n",
      "Batch 94: loss = 0.6192636489868164\n",
      "Batch 95: loss = 0.6830525994300842\n",
      "Batch 96: loss = 0.725272536277771\n",
      "Batch 97: loss = 0.6443907022476196\n",
      "Batch 98: loss = 0.6767804622650146\n",
      "Batch 99: loss = 0.7350918054580688\n",
      "Batch 100: loss = 0.7017773985862732\n",
      "Batch 101: loss = 0.700992226600647\n",
      "Batch 102: loss = 0.6893182396888733\n",
      "Batch 103: loss = 0.6821801662445068\n",
      "Batch 104: loss = 0.6713582277297974\n",
      "Batch 105: loss = 0.6945366859436035\n",
      "Batch 106: loss = 0.7239173650741577\n",
      "Batch 107: loss = 0.6899051666259766\n",
      "Batch 108: loss = 0.7466607093811035\n",
      "Batch 109: loss = 0.6957286596298218\n",
      "Batch 110: loss = 0.6098624467849731\n",
      "Batch 111: loss = 0.761757493019104\n",
      "Batch 112: loss = 0.680355429649353\n",
      "Batch 113: loss = 0.7143592834472656\n",
      "Batch 114: loss = 0.7586766481399536\n",
      "Batch 115: loss = 0.7633745670318604\n",
      "Batch 116: loss = 0.7760396003723145\n",
      "Batch 117: loss = 0.6330431699752808\n",
      "Batch 118: loss = 0.6178561449050903\n",
      "Batch 119: loss = 0.7327912449836731\n",
      "Batch 120: loss = 0.7178324460983276\n",
      "Batch 121: loss = 0.7011833190917969\n",
      "Batch 122: loss = 0.6358832120895386\n",
      "Batch 123: loss = 0.6921825408935547\n",
      "Batch 124: loss = 0.765512228012085\n",
      "Batch 125: loss = 0.7838881015777588\n",
      "Batch 126: loss = 0.7322697639465332\n",
      "\n",
      "Epoch 25/100\n",
      "Batch 1: loss = 0.7447975873947144\n",
      "Batch 2: loss = 0.761247992515564\n",
      "Batch 3: loss = 0.67989182472229\n",
      "Batch 4: loss = 0.7125250101089478\n",
      "Batch 5: loss = 0.7776939272880554\n",
      "Batch 6: loss = 0.7787622213363647\n",
      "Batch 7: loss = 0.7271981239318848\n",
      "Batch 8: loss = 0.6694630980491638\n",
      "Batch 9: loss = 0.6253066658973694\n",
      "Batch 10: loss = 0.616195559501648\n",
      "Batch 11: loss = 0.7294450998306274\n",
      "Batch 12: loss = 0.7057719230651855\n",
      "Batch 13: loss = 0.677737832069397\n",
      "Batch 14: loss = 0.6607147455215454\n",
      "Batch 15: loss = 0.6343311071395874\n",
      "Batch 16: loss = 0.7510380148887634\n",
      "Batch 17: loss = 0.6899363994598389\n",
      "Batch 18: loss = 0.7311140298843384\n",
      "Batch 19: loss = 0.6487472057342529\n",
      "Batch 20: loss = 0.6488543748855591\n",
      "Batch 21: loss = 0.7095489501953125\n",
      "Batch 22: loss = 0.6213526129722595\n",
      "Batch 23: loss = 0.7082364559173584\n",
      "Batch 24: loss = 0.6432486772537231\n",
      "Batch 25: loss = 0.6164772510528564\n",
      "Batch 26: loss = 0.6291403770446777\n",
      "Batch 27: loss = 0.7789925336837769\n",
      "Batch 28: loss = 0.7137546539306641\n",
      "Batch 29: loss = 0.685913622379303\n",
      "Batch 30: loss = 0.6252505779266357\n",
      "Batch 31: loss = 0.7350277304649353\n",
      "Batch 32: loss = 0.7596232891082764\n",
      "Batch 33: loss = 0.6991608142852783\n",
      "Batch 34: loss = 0.6772018671035767\n",
      "Batch 35: loss = 0.6937698125839233\n",
      "Batch 36: loss = 0.6441130638122559\n",
      "Batch 37: loss = 0.6409292221069336\n",
      "Batch 38: loss = 0.7023004293441772\n",
      "Batch 39: loss = 0.6883727312088013\n",
      "Batch 40: loss = 0.688425600528717\n",
      "Batch 41: loss = 0.6191672682762146\n",
      "Batch 42: loss = 0.6522404551506042\n",
      "Batch 43: loss = 0.7102916240692139\n",
      "Batch 44: loss = 0.5907875299453735\n",
      "Batch 45: loss = 0.5692485570907593\n",
      "Batch 46: loss = 0.6478254199028015\n",
      "Batch 47: loss = 0.6716881394386292\n",
      "Batch 48: loss = 0.6200535297393799\n",
      "Batch 49: loss = 0.5662432312965393\n",
      "Batch 50: loss = 0.6293768882751465\n",
      "Batch 51: loss = 0.6379501819610596\n",
      "Batch 52: loss = 0.6858609318733215\n",
      "Batch 53: loss = 0.6683934926986694\n",
      "Batch 54: loss = 0.5829670429229736\n",
      "Batch 55: loss = 0.580008327960968\n",
      "Batch 56: loss = 0.6810034513473511\n",
      "Batch 57: loss = 0.7350058555603027\n",
      "Batch 58: loss = 0.7084050178527832\n",
      "Batch 59: loss = 0.5482730865478516\n",
      "Batch 60: loss = 0.6668251752853394\n",
      "Batch 61: loss = 0.68648362159729\n",
      "Batch 62: loss = 0.8574162721633911\n",
      "Batch 63: loss = 0.6811009645462036\n",
      "Batch 64: loss = 0.5985393524169922\n",
      "Batch 65: loss = 0.6912829875946045\n",
      "Batch 66: loss = 0.6761036515235901\n",
      "Batch 67: loss = 0.6109868884086609\n",
      "Batch 68: loss = 0.6747238636016846\n",
      "Batch 69: loss = 0.6551452279090881\n",
      "Batch 70: loss = 0.7522661089897156\n",
      "Batch 71: loss = 0.7125207781791687\n",
      "Batch 72: loss = 0.6326454877853394\n",
      "Batch 73: loss = 0.7606768608093262\n",
      "Batch 74: loss = 0.7543574571609497\n",
      "Batch 75: loss = 0.777515172958374\n",
      "Batch 76: loss = 0.722576916217804\n",
      "Batch 77: loss = 0.702960729598999\n",
      "Batch 78: loss = 0.6671855449676514\n",
      "Batch 79: loss = 0.6042672395706177\n",
      "Batch 80: loss = 0.653131365776062\n",
      "Batch 81: loss = 0.665177583694458\n",
      "Batch 82: loss = 0.5888196229934692\n",
      "Batch 83: loss = 0.6321315765380859\n",
      "Batch 84: loss = 0.6395087242126465\n",
      "Batch 85: loss = 0.7790462970733643\n",
      "Batch 86: loss = 0.6551687717437744\n",
      "Batch 87: loss = 0.6411760449409485\n",
      "Batch 88: loss = 0.8202247619628906\n",
      "Batch 89: loss = 0.670673668384552\n",
      "Batch 90: loss = 0.6939185261726379\n",
      "Batch 91: loss = 0.7463292479515076\n",
      "Batch 92: loss = 0.7058277130126953\n",
      "Batch 93: loss = 0.5695940256118774\n",
      "Batch 94: loss = 0.6102768778800964\n",
      "Batch 95: loss = 0.6504977941513062\n",
      "Batch 96: loss = 0.7129755616188049\n",
      "Batch 97: loss = 0.6302157640457153\n",
      "Batch 98: loss = 0.6482644081115723\n",
      "Batch 99: loss = 0.6910001039505005\n",
      "Batch 100: loss = 0.6915813684463501\n",
      "Batch 101: loss = 0.6705170273780823\n",
      "Batch 102: loss = 0.710460901260376\n",
      "Batch 103: loss = 0.6759716868400574\n",
      "Batch 104: loss = 0.6540963649749756\n",
      "Batch 105: loss = 0.6854665279388428\n",
      "Batch 106: loss = 0.681090772151947\n",
      "Batch 107: loss = 0.6692878007888794\n",
      "Batch 108: loss = 0.7149412631988525\n",
      "Batch 109: loss = 0.6776965856552124\n",
      "Batch 110: loss = 0.6120656728744507\n",
      "Batch 111: loss = 0.7353705167770386\n",
      "Batch 112: loss = 0.6761854290962219\n",
      "Batch 113: loss = 0.7242690324783325\n",
      "Batch 114: loss = 0.7239383459091187\n",
      "Batch 115: loss = 0.743328332901001\n",
      "Batch 116: loss = 0.7651938199996948\n",
      "Batch 117: loss = 0.6298593878746033\n",
      "Batch 118: loss = 0.6062665581703186\n",
      "Batch 119: loss = 0.6880093812942505\n",
      "Batch 120: loss = 0.695090651512146\n",
      "Batch 121: loss = 0.6706985831260681\n",
      "Batch 122: loss = 0.6115307807922363\n",
      "Batch 123: loss = 0.697097897529602\n",
      "Batch 124: loss = 0.7506357431411743\n",
      "Batch 125: loss = 0.7663072347640991\n",
      "Batch 126: loss = 0.7131024599075317\n",
      "\n",
      "Epoch 26/100\n",
      "Batch 1: loss = 0.7400569915771484\n",
      "Batch 2: loss = 0.75023353099823\n",
      "Batch 3: loss = 0.7122678756713867\n",
      "Batch 4: loss = 0.6750115156173706\n",
      "Batch 5: loss = 0.7693060636520386\n",
      "Batch 6: loss = 0.7832341194152832\n",
      "Batch 7: loss = 0.7043039798736572\n",
      "Batch 8: loss = 0.6607203483581543\n",
      "Batch 9: loss = 0.6099932789802551\n",
      "Batch 10: loss = 0.6150944232940674\n",
      "Batch 11: loss = 0.6953492164611816\n",
      "Batch 12: loss = 0.6731783151626587\n",
      "Batch 13: loss = 0.649164080619812\n",
      "Batch 14: loss = 0.6541500091552734\n",
      "Batch 15: loss = 0.6547379493713379\n",
      "Batch 16: loss = 0.7119734287261963\n",
      "Batch 17: loss = 0.6724281311035156\n",
      "Batch 18: loss = 0.6796519756317139\n",
      "Batch 19: loss = 0.6113309860229492\n",
      "Batch 20: loss = 0.6626055240631104\n",
      "Batch 21: loss = 0.702191174030304\n",
      "Batch 22: loss = 0.624600887298584\n",
      "Batch 23: loss = 0.7067307829856873\n",
      "Batch 24: loss = 0.6036019325256348\n",
      "Batch 25: loss = 0.6186999082565308\n",
      "Batch 26: loss = 0.6162879467010498\n",
      "Batch 27: loss = 0.7474716901779175\n",
      "Batch 28: loss = 0.6885602474212646\n",
      "Batch 29: loss = 0.693740963935852\n",
      "Batch 30: loss = 0.6127586364746094\n",
      "Batch 31: loss = 0.7330278754234314\n",
      "Batch 32: loss = 0.7709074020385742\n",
      "Batch 33: loss = 0.6915444135665894\n",
      "Batch 34: loss = 0.7012830972671509\n",
      "Batch 35: loss = 0.6618931293487549\n",
      "Batch 36: loss = 0.6154929399490356\n",
      "Batch 37: loss = 0.6288158893585205\n",
      "Batch 38: loss = 0.6939972043037415\n",
      "Batch 39: loss = 0.686614990234375\n",
      "Batch 40: loss = 0.6685479879379272\n",
      "Batch 41: loss = 0.6144548058509827\n",
      "Batch 42: loss = 0.6527745127677917\n",
      "Batch 43: loss = 0.6837095618247986\n",
      "Batch 44: loss = 0.6092447638511658\n",
      "Batch 45: loss = 0.5724685192108154\n",
      "Batch 46: loss = 0.6135313510894775\n",
      "Batch 47: loss = 0.652184009552002\n",
      "Batch 48: loss = 0.6101512312889099\n",
      "Batch 49: loss = 0.5787334442138672\n",
      "Batch 50: loss = 0.5965389013290405\n",
      "Batch 51: loss = 0.6152252554893494\n",
      "Batch 52: loss = 0.6843322515487671\n",
      "Batch 53: loss = 0.6432645320892334\n",
      "Batch 54: loss = 0.567501425743103\n",
      "Batch 55: loss = 0.6065973043441772\n",
      "Batch 56: loss = 0.6852745413780212\n",
      "Batch 57: loss = 0.7276062965393066\n",
      "Batch 58: loss = 0.6748906373977661\n",
      "Batch 59: loss = 0.5468852519989014\n",
      "Batch 60: loss = 0.6616413593292236\n",
      "Batch 61: loss = 0.6644057035446167\n",
      "Batch 62: loss = 0.807615339756012\n",
      "Batch 63: loss = 0.6584473848342896\n",
      "Batch 64: loss = 0.586060106754303\n",
      "Batch 65: loss = 0.6786136031150818\n",
      "Batch 66: loss = 0.6840224862098694\n",
      "Batch 67: loss = 0.6111888885498047\n",
      "Batch 68: loss = 0.6614350080490112\n",
      "Batch 69: loss = 0.6155565977096558\n",
      "Batch 70: loss = 0.756152868270874\n",
      "Batch 71: loss = 0.6986644268035889\n",
      "Batch 72: loss = 0.6099553108215332\n",
      "Batch 73: loss = 0.714038610458374\n",
      "Batch 74: loss = 0.7421274185180664\n",
      "Batch 75: loss = 0.8007723093032837\n",
      "Batch 76: loss = 0.702194094657898\n",
      "Batch 77: loss = 0.6690940260887146\n",
      "Batch 78: loss = 0.656933069229126\n",
      "Batch 79: loss = 0.601219892501831\n",
      "Batch 80: loss = 0.6325527429580688\n",
      "Batch 81: loss = 0.6384042501449585\n",
      "Batch 82: loss = 0.5762615203857422\n",
      "Batch 83: loss = 0.5994423627853394\n",
      "Batch 84: loss = 0.6047003269195557\n",
      "Batch 85: loss = 0.7480194568634033\n",
      "Batch 86: loss = 0.6255161762237549\n",
      "Batch 87: loss = 0.621520459651947\n",
      "Batch 88: loss = 0.7817925810813904\n",
      "Batch 89: loss = 0.6699037551879883\n",
      "Batch 90: loss = 0.6843520998954773\n",
      "Batch 91: loss = 0.7054919600486755\n",
      "Batch 92: loss = 0.7038440704345703\n",
      "Batch 93: loss = 0.5505780577659607\n",
      "Batch 94: loss = 0.5869691371917725\n",
      "Batch 95: loss = 0.6703917980194092\n",
      "Batch 96: loss = 0.7121117115020752\n",
      "Batch 97: loss = 0.6246960163116455\n",
      "Batch 98: loss = 0.6663040518760681\n",
      "Batch 99: loss = 0.688953697681427\n",
      "Batch 100: loss = 0.6860331296920776\n",
      "Batch 101: loss = 0.6426476240158081\n",
      "Batch 102: loss = 0.6773999333381653\n",
      "Batch 103: loss = 0.6704537868499756\n",
      "Batch 104: loss = 0.6245553493499756\n",
      "Batch 105: loss = 0.6647052764892578\n",
      "Batch 106: loss = 0.6731427907943726\n",
      "Batch 107: loss = 0.6243278384208679\n",
      "Batch 108: loss = 0.6686307191848755\n",
      "Batch 109: loss = 0.7121356725692749\n",
      "Batch 110: loss = 0.5815776586532593\n",
      "Batch 111: loss = 0.7226928472518921\n",
      "Batch 112: loss = 0.6864001750946045\n",
      "Batch 113: loss = 0.7159519195556641\n",
      "Batch 114: loss = 0.7045658826828003\n",
      "Batch 115: loss = 0.7129765748977661\n",
      "Batch 116: loss = 0.7453441619873047\n",
      "Batch 117: loss = 0.6287544965744019\n",
      "Batch 118: loss = 0.59676194190979\n",
      "Batch 119: loss = 0.6544582843780518\n",
      "Batch 120: loss = 0.7001501321792603\n",
      "Batch 121: loss = 0.6650735139846802\n",
      "Batch 122: loss = 0.615287184715271\n",
      "Batch 123: loss = 0.6747834086418152\n",
      "Batch 124: loss = 0.7344257831573486\n",
      "Batch 125: loss = 0.7146009206771851\n",
      "Batch 126: loss = 0.6885443925857544\n",
      "\n",
      "Epoch 27/100\n",
      "Batch 1: loss = 0.7231267094612122\n",
      "Batch 2: loss = 0.7440738677978516\n",
      "Batch 3: loss = 0.6816365122795105\n",
      "Batch 4: loss = 0.6978373527526855\n",
      "Batch 5: loss = 0.7311228513717651\n",
      "Batch 6: loss = 0.7567629814147949\n",
      "Batch 7: loss = 0.7034751176834106\n",
      "Batch 8: loss = 0.6634657382965088\n",
      "Batch 9: loss = 0.6382890939712524\n",
      "Batch 10: loss = 0.5926253795623779\n",
      "Batch 11: loss = 0.6717472076416016\n",
      "Batch 12: loss = 0.6950926780700684\n",
      "Batch 13: loss = 0.6369116306304932\n",
      "Batch 14: loss = 0.6443030834197998\n",
      "Batch 15: loss = 0.6339360475540161\n",
      "Batch 16: loss = 0.7130686044692993\n",
      "Batch 17: loss = 0.6540255546569824\n",
      "Batch 18: loss = 0.6950052976608276\n",
      "Batch 19: loss = 0.6299328207969666\n",
      "Batch 20: loss = 0.6380096077919006\n",
      "Batch 21: loss = 0.6745062470436096\n",
      "Batch 22: loss = 0.6444672346115112\n",
      "Batch 23: loss = 0.7072566747665405\n",
      "Batch 24: loss = 0.596453070640564\n",
      "Batch 25: loss = 0.5758661031723022\n",
      "Batch 26: loss = 0.6068675518035889\n",
      "Batch 27: loss = 0.7240279912948608\n",
      "Batch 28: loss = 0.7089442014694214\n",
      "Batch 29: loss = 0.6719145774841309\n",
      "Batch 30: loss = 0.6181130409240723\n",
      "Batch 31: loss = 0.7037758827209473\n",
      "Batch 32: loss = 0.7445831894874573\n",
      "Batch 33: loss = 0.670464277267456\n",
      "Batch 34: loss = 0.6670511960983276\n",
      "Batch 35: loss = 0.6484469175338745\n",
      "Batch 36: loss = 0.5856972336769104\n",
      "Batch 37: loss = 0.6410998702049255\n",
      "Batch 38: loss = 0.6558797359466553\n",
      "Batch 39: loss = 0.6681492328643799\n",
      "Batch 40: loss = 0.6419227123260498\n",
      "Batch 41: loss = 0.607006847858429\n",
      "Batch 42: loss = 0.6277340054512024\n",
      "Batch 43: loss = 0.6530197262763977\n",
      "Batch 44: loss = 0.5664005279541016\n",
      "Batch 45: loss = 0.547799825668335\n",
      "Batch 46: loss = 0.5961244106292725\n",
      "Batch 47: loss = 0.6445232033729553\n",
      "Batch 48: loss = 0.5798208713531494\n",
      "Batch 49: loss = 0.5806912183761597\n",
      "Batch 50: loss = 0.5836668610572815\n",
      "Batch 51: loss = 0.5971438884735107\n",
      "Batch 52: loss = 0.6666995286941528\n",
      "Batch 53: loss = 0.6089098453521729\n",
      "Batch 54: loss = 0.5397309064865112\n",
      "Batch 55: loss = 0.5770136117935181\n",
      "Batch 56: loss = 0.6729416847229004\n",
      "Batch 57: loss = 0.7054691910743713\n",
      "Batch 58: loss = 0.6336226463317871\n",
      "Batch 59: loss = 0.5024867057800293\n",
      "Batch 60: loss = 0.6379438638687134\n",
      "Batch 61: loss = 0.6607885360717773\n",
      "Batch 62: loss = 0.7949178218841553\n",
      "Batch 63: loss = 0.6671846508979797\n",
      "Batch 64: loss = 0.5666695833206177\n",
      "Batch 65: loss = 0.6713721752166748\n",
      "Batch 66: loss = 0.6429316997528076\n",
      "Batch 67: loss = 0.6030546426773071\n",
      "Batch 68: loss = 0.6544390916824341\n",
      "Batch 69: loss = 0.633771538734436\n",
      "Batch 70: loss = 0.7308257818222046\n",
      "Batch 71: loss = 0.6982603073120117\n",
      "Batch 72: loss = 0.6094585657119751\n",
      "Batch 73: loss = 0.7164468765258789\n",
      "Batch 74: loss = 0.7325040698051453\n",
      "Batch 75: loss = 0.7415590286254883\n",
      "Batch 76: loss = 0.6774624586105347\n",
      "Batch 77: loss = 0.6523087024688721\n",
      "Batch 78: loss = 0.6405782699584961\n",
      "Batch 79: loss = 0.5977643728256226\n",
      "Batch 80: loss = 0.6351814270019531\n",
      "Batch 81: loss = 0.6552897691726685\n",
      "Batch 82: loss = 0.5695775747299194\n",
      "Batch 83: loss = 0.613684892654419\n",
      "Batch 84: loss = 0.6182674169540405\n",
      "Batch 85: loss = 0.7495542764663696\n",
      "Batch 86: loss = 0.6080583333969116\n",
      "Batch 87: loss = 0.5887956619262695\n",
      "Batch 88: loss = 0.7700279951095581\n",
      "Batch 89: loss = 0.6042370200157166\n",
      "Batch 90: loss = 0.6855237483978271\n",
      "Batch 91: loss = 0.701256275177002\n",
      "Batch 92: loss = 0.6811543107032776\n",
      "Batch 93: loss = 0.5827829837799072\n",
      "Batch 94: loss = 0.5730695724487305\n",
      "Batch 95: loss = 0.6519405841827393\n",
      "Batch 96: loss = 0.7057016491889954\n",
      "Batch 97: loss = 0.5902355909347534\n",
      "Batch 98: loss = 0.6310610175132751\n",
      "Batch 99: loss = 0.6737393140792847\n",
      "Batch 100: loss = 0.6820973753929138\n",
      "Batch 101: loss = 0.6572267413139343\n",
      "Batch 102: loss = 0.6577931046485901\n",
      "Batch 103: loss = 0.6417050361633301\n",
      "Batch 104: loss = 0.650766134262085\n",
      "Batch 105: loss = 0.6704884767532349\n",
      "Batch 106: loss = 0.6708125472068787\n",
      "Batch 107: loss = 0.6349632740020752\n",
      "Batch 108: loss = 0.6579728126525879\n",
      "Batch 109: loss = 0.6502413749694824\n",
      "Batch 110: loss = 0.564976155757904\n",
      "Batch 111: loss = 0.7272361516952515\n",
      "Batch 112: loss = 0.6648185849189758\n",
      "Batch 113: loss = 0.685467004776001\n",
      "Batch 114: loss = 0.7304484248161316\n",
      "Batch 115: loss = 0.7101290225982666\n",
      "Batch 116: loss = 0.718958854675293\n",
      "Batch 117: loss = 0.5781110525131226\n",
      "Batch 118: loss = 0.5820441246032715\n",
      "Batch 119: loss = 0.6500074863433838\n",
      "Batch 120: loss = 0.6515600681304932\n",
      "Batch 121: loss = 0.6685143113136292\n",
      "Batch 122: loss = 0.5867255330085754\n",
      "Batch 123: loss = 0.6699029803276062\n",
      "Batch 124: loss = 0.7121970653533936\n",
      "Batch 125: loss = 0.7246730327606201\n",
      "Batch 126: loss = 0.681311845779419\n",
      "\n",
      "Epoch 28/100\n",
      "Batch 1: loss = 0.7082622051239014\n",
      "Batch 2: loss = 0.712584376335144\n",
      "Batch 3: loss = 0.6472740769386292\n",
      "Batch 4: loss = 0.6534145474433899\n",
      "Batch 5: loss = 0.7472697496414185\n",
      "Batch 6: loss = 0.7298029661178589\n",
      "Batch 7: loss = 0.6966522336006165\n",
      "Batch 8: loss = 0.6374340057373047\n",
      "Batch 9: loss = 0.613670825958252\n",
      "Batch 10: loss = 0.5987135171890259\n",
      "Batch 11: loss = 0.688561201095581\n",
      "Batch 12: loss = 0.6485421657562256\n",
      "Batch 13: loss = 0.6474635601043701\n",
      "Batch 14: loss = 0.6090824007987976\n",
      "Batch 15: loss = 0.607673168182373\n",
      "Batch 16: loss = 0.7001076936721802\n",
      "Batch 17: loss = 0.6485987901687622\n",
      "Batch 18: loss = 0.677898645401001\n",
      "Batch 19: loss = 0.6036256551742554\n",
      "Batch 20: loss = 0.5991305112838745\n",
      "Batch 21: loss = 0.6632297039031982\n",
      "Batch 22: loss = 0.597481369972229\n",
      "Batch 23: loss = 0.6795811653137207\n",
      "Batch 24: loss = 0.5857954025268555\n",
      "Batch 25: loss = 0.5856038331985474\n",
      "Batch 26: loss = 0.5903214812278748\n",
      "Batch 27: loss = 0.7368820309638977\n",
      "Batch 28: loss = 0.6885808706283569\n",
      "Batch 29: loss = 0.6838520765304565\n",
      "Batch 30: loss = 0.6106852889060974\n",
      "Batch 31: loss = 0.691403865814209\n",
      "Batch 32: loss = 0.7459447979927063\n",
      "Batch 33: loss = 0.6718515753746033\n",
      "Batch 34: loss = 0.6707350015640259\n",
      "Batch 35: loss = 0.6374651193618774\n",
      "Batch 36: loss = 0.5891109108924866\n",
      "Batch 37: loss = 0.6230018138885498\n",
      "Batch 38: loss = 0.6614570617675781\n",
      "Batch 39: loss = 0.6576563119888306\n",
      "Batch 40: loss = 0.6379753351211548\n",
      "Batch 41: loss = 0.613784670829773\n",
      "Batch 42: loss = 0.6251256465911865\n",
      "Batch 43: loss = 0.6654254794120789\n",
      "Batch 44: loss = 0.5513567924499512\n",
      "Batch 45: loss = 0.5648821592330933\n",
      "Batch 46: loss = 0.5940204858779907\n",
      "Batch 47: loss = 0.6112300157546997\n",
      "Batch 48: loss = 0.6044504046440125\n",
      "Batch 49: loss = 0.558857798576355\n",
      "Batch 50: loss = 0.5722144842147827\n",
      "Batch 51: loss = 0.5943742990493774\n",
      "Batch 52: loss = 0.6561290621757507\n",
      "Batch 53: loss = 0.6225063800811768\n",
      "Batch 54: loss = 0.5271257162094116\n",
      "Batch 55: loss = 0.5439707040786743\n",
      "Batch 56: loss = 0.6370459198951721\n",
      "Batch 57: loss = 0.6936695575714111\n",
      "Batch 58: loss = 0.6355718374252319\n",
      "Batch 59: loss = 0.4973721504211426\n",
      "Batch 60: loss = 0.6450150012969971\n",
      "Batch 61: loss = 0.6202555894851685\n",
      "Batch 62: loss = 0.7808089852333069\n",
      "Batch 63: loss = 0.643609881401062\n",
      "Batch 64: loss = 0.5367959141731262\n",
      "Batch 65: loss = 0.671684741973877\n",
      "Batch 66: loss = 0.6289961338043213\n",
      "Batch 67: loss = 0.5837119817733765\n",
      "Batch 68: loss = 0.6101455688476562\n",
      "Batch 69: loss = 0.6102108955383301\n",
      "Batch 70: loss = 0.6993758678436279\n",
      "Batch 71: loss = 0.6525678634643555\n",
      "Batch 72: loss = 0.5855360627174377\n",
      "Batch 73: loss = 0.7067785263061523\n",
      "Batch 74: loss = 0.7046884298324585\n",
      "Batch 75: loss = 0.7286570072174072\n",
      "Batch 76: loss = 0.6850932836532593\n",
      "Batch 77: loss = 0.6455738544464111\n",
      "Batch 78: loss = 0.6353673934936523\n",
      "Batch 79: loss = 0.5671858787536621\n",
      "Batch 80: loss = 0.6184757947921753\n",
      "Batch 81: loss = 0.6278836727142334\n",
      "Batch 82: loss = 0.5530655980110168\n",
      "Batch 83: loss = 0.6024234294891357\n",
      "Batch 84: loss = 0.5913092494010925\n",
      "Batch 85: loss = 0.7228884696960449\n",
      "Batch 86: loss = 0.596825122833252\n",
      "Batch 87: loss = 0.5734574198722839\n",
      "Batch 88: loss = 0.7457126379013062\n",
      "Batch 89: loss = 0.6140257716178894\n",
      "Batch 90: loss = 0.6738271713256836\n",
      "Batch 91: loss = 0.6721147298812866\n",
      "Batch 92: loss = 0.6538959741592407\n",
      "Batch 93: loss = 0.5585466623306274\n",
      "Batch 94: loss = 0.5899130702018738\n",
      "Batch 95: loss = 0.6320059299468994\n",
      "Batch 96: loss = 0.6869240999221802\n",
      "Batch 97: loss = 0.6174342632293701\n",
      "Batch 98: loss = 0.6088916063308716\n",
      "Batch 99: loss = 0.669205904006958\n",
      "Batch 100: loss = 0.6548668146133423\n",
      "Batch 101: loss = 0.6228222250938416\n",
      "Batch 102: loss = 0.6718016266822815\n",
      "Batch 103: loss = 0.6156338453292847\n",
      "Batch 104: loss = 0.6205185651779175\n",
      "Batch 105: loss = 0.6000274419784546\n",
      "Batch 106: loss = 0.644077479839325\n",
      "Batch 107: loss = 0.6086990833282471\n",
      "Batch 108: loss = 0.6482792496681213\n",
      "Batch 109: loss = 0.6435415148735046\n",
      "Batch 110: loss = 0.5418140888214111\n",
      "Batch 111: loss = 0.704483151435852\n",
      "Batch 112: loss = 0.6443894505500793\n",
      "Batch 113: loss = 0.6860034465789795\n",
      "Batch 114: loss = 0.6793946027755737\n",
      "Batch 115: loss = 0.7061350345611572\n",
      "Batch 116: loss = 0.7096182703971863\n",
      "Batch 117: loss = 0.5766431093215942\n",
      "Batch 118: loss = 0.5636518001556396\n",
      "Batch 119: loss = 0.6463607549667358\n",
      "Batch 120: loss = 0.6507313847541809\n",
      "Batch 121: loss = 0.6485558748245239\n",
      "Batch 122: loss = 0.5807392597198486\n",
      "Batch 123: loss = 0.6330186128616333\n",
      "Batch 124: loss = 0.7326087951660156\n",
      "Batch 125: loss = 0.6736960411071777\n",
      "Batch 126: loss = 0.6846301555633545\n",
      "\n",
      "Epoch 29/100\n",
      "Batch 1: loss = 0.6994901299476624\n",
      "Batch 2: loss = 0.7061972618103027\n",
      "Batch 3: loss = 0.6236885786056519\n",
      "Batch 4: loss = 0.614954948425293\n",
      "Batch 5: loss = 0.6974557042121887\n",
      "Batch 6: loss = 0.726093590259552\n",
      "Batch 7: loss = 0.6374396085739136\n",
      "Batch 8: loss = 0.6102997064590454\n",
      "Batch 9: loss = 0.6094536781311035\n",
      "Batch 10: loss = 0.5688742399215698\n",
      "Batch 11: loss = 0.671381413936615\n",
      "Batch 12: loss = 0.6291449666023254\n",
      "Batch 13: loss = 0.6211165189743042\n",
      "Batch 14: loss = 0.6092402935028076\n",
      "Batch 15: loss = 0.5897376537322998\n",
      "Batch 16: loss = 0.691255509853363\n",
      "Batch 17: loss = 0.6284455060958862\n",
      "Batch 18: loss = 0.6491789817810059\n",
      "Batch 19: loss = 0.5630913972854614\n",
      "Batch 20: loss = 0.605907678604126\n",
      "Batch 21: loss = 0.6665878295898438\n",
      "Batch 22: loss = 0.5929737091064453\n",
      "Batch 23: loss = 0.6883890628814697\n",
      "Batch 24: loss = 0.5977784991264343\n",
      "Batch 25: loss = 0.5897740125656128\n",
      "Batch 26: loss = 0.6037193536758423\n",
      "Batch 27: loss = 0.7207808494567871\n",
      "Batch 28: loss = 0.6474401950836182\n",
      "Batch 29: loss = 0.6797122955322266\n",
      "Batch 30: loss = 0.5971959233283997\n",
      "Batch 31: loss = 0.7105796933174133\n",
      "Batch 32: loss = 0.7345348596572876\n",
      "Batch 33: loss = 0.6557597517967224\n",
      "Batch 34: loss = 0.6820257306098938\n",
      "Batch 35: loss = 0.6596572399139404\n",
      "Batch 36: loss = 0.5784934759140015\n",
      "Batch 37: loss = 0.5822728872299194\n",
      "Batch 38: loss = 0.6275836229324341\n",
      "Batch 39: loss = 0.6132979393005371\n",
      "Batch 40: loss = 0.6022416949272156\n",
      "Batch 41: loss = 0.601448655128479\n",
      "Batch 42: loss = 0.616941511631012\n",
      "Batch 43: loss = 0.6739917397499084\n",
      "Batch 44: loss = 0.5366326570510864\n",
      "Batch 45: loss = 0.5558218955993652\n",
      "Batch 46: loss = 0.602035641670227\n",
      "Batch 47: loss = 0.6575450897216797\n",
      "Batch 48: loss = 0.5871131420135498\n",
      "Batch 49: loss = 0.5538075566291809\n",
      "Batch 50: loss = 0.5659146308898926\n",
      "Batch 51: loss = 0.5790586471557617\n",
      "Batch 52: loss = 0.6470203399658203\n",
      "Batch 53: loss = 0.5979669690132141\n",
      "Batch 54: loss = 0.5343271493911743\n",
      "Batch 55: loss = 0.5538949370384216\n",
      "Batch 56: loss = 0.6285182237625122\n",
      "Batch 57: loss = 0.6757329702377319\n",
      "Batch 58: loss = 0.6210861206054688\n",
      "Batch 59: loss = 0.49154162406921387\n",
      "Batch 60: loss = 0.6018612384796143\n",
      "Batch 61: loss = 0.5969484448432922\n",
      "Batch 62: loss = 0.7639108896255493\n",
      "Batch 63: loss = 0.6142557859420776\n",
      "Batch 64: loss = 0.5295246839523315\n",
      "Batch 65: loss = 0.6588459014892578\n",
      "Batch 66: loss = 0.6101773977279663\n",
      "Batch 67: loss = 0.5921918153762817\n",
      "Batch 68: loss = 0.6159659624099731\n",
      "Batch 69: loss = 0.5901225805282593\n",
      "Batch 70: loss = 0.7025985717773438\n",
      "Batch 71: loss = 0.6653814911842346\n",
      "Batch 72: loss = 0.5625323057174683\n",
      "Batch 73: loss = 0.6704790592193604\n",
      "Batch 74: loss = 0.6844538450241089\n",
      "Batch 75: loss = 0.7319106459617615\n",
      "Batch 76: loss = 0.662044882774353\n",
      "Batch 77: loss = 0.6211698651313782\n",
      "Batch 78: loss = 0.6535079479217529\n",
      "Batch 79: loss = 0.5591896772384644\n",
      "Batch 80: loss = 0.6060051321983337\n",
      "Batch 81: loss = 0.6255527138710022\n",
      "Batch 82: loss = 0.5321303009986877\n",
      "Batch 83: loss = 0.6084054708480835\n",
      "Batch 84: loss = 0.5755441188812256\n",
      "Batch 85: loss = 0.7129188179969788\n",
      "Batch 86: loss = 0.5778545141220093\n",
      "Batch 87: loss = 0.5629363059997559\n",
      "Batch 88: loss = 0.7233466506004333\n",
      "Batch 89: loss = 0.6072838306427002\n",
      "Batch 90: loss = 0.6568852663040161\n",
      "Batch 91: loss = 0.6845953464508057\n",
      "Batch 92: loss = 0.638830304145813\n",
      "Batch 93: loss = 0.5346798300743103\n",
      "Batch 94: loss = 0.5660341382026672\n",
      "Batch 95: loss = 0.6302725076675415\n",
      "Batch 96: loss = 0.6741814613342285\n",
      "Batch 97: loss = 0.5978578329086304\n",
      "Batch 98: loss = 0.574791431427002\n",
      "Batch 99: loss = 0.6424344778060913\n",
      "Batch 100: loss = 0.6688399910926819\n",
      "Batch 101: loss = 0.5920912027359009\n",
      "Batch 102: loss = 0.6207483410835266\n",
      "Batch 103: loss = 0.618384063243866\n",
      "Batch 104: loss = 0.5628275871276855\n",
      "Batch 105: loss = 0.6157177686691284\n",
      "Batch 106: loss = 0.6123378276824951\n",
      "Batch 107: loss = 0.6056987643241882\n",
      "Batch 108: loss = 0.6434473991394043\n",
      "Batch 109: loss = 0.6334064602851868\n",
      "Batch 110: loss = 0.5679115653038025\n",
      "Batch 111: loss = 0.6923743486404419\n",
      "Batch 112: loss = 0.660322368144989\n",
      "Batch 113: loss = 0.6533784866333008\n",
      "Batch 114: loss = 0.6593068838119507\n",
      "Batch 115: loss = 0.6731992363929749\n",
      "Batch 116: loss = 0.6821545362472534\n",
      "Batch 117: loss = 0.5601121187210083\n",
      "Batch 118: loss = 0.555587887763977\n",
      "Batch 119: loss = 0.6264586448669434\n",
      "Batch 120: loss = 0.6274434328079224\n",
      "Batch 121: loss = 0.6189336776733398\n",
      "Batch 122: loss = 0.5930607318878174\n",
      "Batch 123: loss = 0.6592166423797607\n",
      "Batch 124: loss = 0.7068401575088501\n",
      "Batch 125: loss = 0.7066140174865723\n",
      "Batch 126: loss = 0.6468440890312195\n",
      "\n",
      "Epoch 30/100\n",
      "Batch 1: loss = 0.6807448863983154\n",
      "Batch 2: loss = 0.680019736289978\n",
      "Batch 3: loss = 0.6064520478248596\n",
      "Batch 4: loss = 0.6320241689682007\n",
      "Batch 5: loss = 0.681201696395874\n",
      "Batch 6: loss = 0.7294756174087524\n",
      "Batch 7: loss = 0.6426351070404053\n",
      "Batch 8: loss = 0.6218410730361938\n",
      "Batch 9: loss = 0.5457628965377808\n",
      "Batch 10: loss = 0.568280816078186\n",
      "Batch 11: loss = 0.635564923286438\n",
      "Batch 12: loss = 0.6270133256912231\n",
      "Batch 13: loss = 0.5976213216781616\n",
      "Batch 14: loss = 0.5955455899238586\n",
      "Batch 15: loss = 0.5883756875991821\n",
      "Batch 16: loss = 0.6436075568199158\n",
      "Batch 17: loss = 0.6238658428192139\n",
      "Batch 18: loss = 0.6119683384895325\n",
      "Batch 19: loss = 0.5848439335823059\n",
      "Batch 20: loss = 0.6008137464523315\n",
      "Batch 21: loss = 0.6416212320327759\n",
      "Batch 22: loss = 0.5860925912857056\n",
      "Batch 23: loss = 0.6333748698234558\n",
      "Batch 24: loss = 0.5431445837020874\n",
      "Batch 25: loss = 0.553097128868103\n",
      "Batch 26: loss = 0.5687974691390991\n",
      "Batch 27: loss = 0.7073241472244263\n",
      "Batch 28: loss = 0.6516157388687134\n",
      "Batch 29: loss = 0.6531068086624146\n",
      "Batch 30: loss = 0.576280951499939\n",
      "Batch 31: loss = 0.6496798992156982\n",
      "Batch 32: loss = 0.6942558288574219\n",
      "Batch 33: loss = 0.6282649040222168\n",
      "Batch 34: loss = 0.6565957069396973\n",
      "Batch 35: loss = 0.6164202690124512\n",
      "Batch 36: loss = 0.5490735769271851\n",
      "Batch 37: loss = 0.5613206624984741\n",
      "Batch 38: loss = 0.6303725838661194\n",
      "Batch 39: loss = 0.6214034557342529\n",
      "Batch 40: loss = 0.6094392538070679\n",
      "Batch 41: loss = 0.5806635618209839\n",
      "Batch 42: loss = 0.6012545824050903\n",
      "Batch 43: loss = 0.6502074003219604\n",
      "Batch 44: loss = 0.5146055221557617\n",
      "Batch 45: loss = 0.5174322128295898\n",
      "Batch 46: loss = 0.5526054501533508\n",
      "Batch 47: loss = 0.6294269561767578\n",
      "Batch 48: loss = 0.5786459445953369\n",
      "Batch 49: loss = 0.5240579843521118\n",
      "Batch 50: loss = 0.5285817384719849\n",
      "Batch 51: loss = 0.5693991780281067\n",
      "Batch 52: loss = 0.6272369623184204\n",
      "Batch 53: loss = 0.5925555229187012\n",
      "Batch 54: loss = 0.518915057182312\n",
      "Batch 55: loss = 0.5251767635345459\n",
      "Batch 56: loss = 0.6113698482513428\n",
      "Batch 57: loss = 0.6867893934249878\n",
      "Batch 58: loss = 0.6164763569831848\n",
      "Batch 59: loss = 0.485818475484848\n",
      "Batch 60: loss = 0.5938538312911987\n",
      "Batch 61: loss = 0.6275300979614258\n",
      "Batch 62: loss = 0.7489559650421143\n",
      "Batch 63: loss = 0.594343364238739\n",
      "Batch 64: loss = 0.5248636603355408\n",
      "Batch 65: loss = 0.6267396807670593\n",
      "Batch 66: loss = 0.6240290999412537\n",
      "Batch 67: loss = 0.6022931337356567\n",
      "Batch 68: loss = 0.5976674556732178\n",
      "Batch 69: loss = 0.5689235925674438\n",
      "Batch 70: loss = 0.6935946941375732\n",
      "Batch 71: loss = 0.6649944186210632\n",
      "Batch 72: loss = 0.545710563659668\n",
      "Batch 73: loss = 0.6473504900932312\n",
      "Batch 74: loss = 0.6937894821166992\n",
      "Batch 75: loss = 0.6914166212081909\n",
      "Batch 76: loss = 0.6480175256729126\n",
      "Batch 77: loss = 0.6322222948074341\n",
      "Batch 78: loss = 0.6035665273666382\n",
      "Batch 79: loss = 0.5403896570205688\n",
      "Batch 80: loss = 0.6004200577735901\n",
      "Batch 81: loss = 0.6063538193702698\n",
      "Batch 82: loss = 0.533515453338623\n",
      "Batch 83: loss = 0.5488531589508057\n",
      "Batch 84: loss = 0.5780129432678223\n",
      "Batch 85: loss = 0.6819759607315063\n",
      "Batch 86: loss = 0.5876917839050293\n",
      "Batch 87: loss = 0.5761206150054932\n",
      "Batch 88: loss = 0.714302659034729\n",
      "Batch 89: loss = 0.6103553771972656\n",
      "Batch 90: loss = 0.6208596229553223\n",
      "Batch 91: loss = 0.6645090579986572\n",
      "Batch 92: loss = 0.6176443099975586\n",
      "Batch 93: loss = 0.5231226682662964\n",
      "Batch 94: loss = 0.5386331081390381\n",
      "Batch 95: loss = 0.5919212102890015\n",
      "Batch 96: loss = 0.6708647012710571\n",
      "Batch 97: loss = 0.5959419012069702\n",
      "Batch 98: loss = 0.589744508266449\n",
      "Batch 99: loss = 0.641058087348938\n",
      "Batch 100: loss = 0.6536493301391602\n",
      "Batch 101: loss = 0.6102770566940308\n",
      "Batch 102: loss = 0.6080867648124695\n",
      "Batch 103: loss = 0.6217882037162781\n",
      "Batch 104: loss = 0.5857133269309998\n",
      "Batch 105: loss = 0.629917323589325\n",
      "Batch 106: loss = 0.6266710758209229\n",
      "Batch 107: loss = 0.6001783013343811\n",
      "Batch 108: loss = 0.6359236240386963\n",
      "Batch 109: loss = 0.6362161636352539\n",
      "Batch 110: loss = 0.5652109384536743\n",
      "Batch 111: loss = 0.6660677194595337\n",
      "Batch 112: loss = 0.6514450311660767\n",
      "Batch 113: loss = 0.6574785709381104\n",
      "Batch 114: loss = 0.6350733041763306\n",
      "Batch 115: loss = 0.6864768266677856\n",
      "Batch 116: loss = 0.6618587970733643\n",
      "Batch 117: loss = 0.5562164783477783\n",
      "Batch 118: loss = 0.5527492761611938\n",
      "Batch 119: loss = 0.6325144171714783\n",
      "Batch 120: loss = 0.6215108633041382\n",
      "Batch 121: loss = 0.6392768621444702\n",
      "Batch 122: loss = 0.5544430017471313\n",
      "Batch 123: loss = 0.627197802066803\n",
      "Batch 124: loss = 0.6993455290794373\n",
      "Batch 125: loss = 0.6909002065658569\n",
      "Batch 126: loss = 0.6292493343353271\n",
      "\n",
      "Epoch 31/100\n",
      "Batch 1: loss = 0.6618577837944031\n",
      "Batch 2: loss = 0.652824878692627\n",
      "Batch 3: loss = 0.6043701767921448\n",
      "Batch 4: loss = 0.6214990019798279\n",
      "Batch 5: loss = 0.6571042537689209\n",
      "Batch 6: loss = 0.6794315576553345\n",
      "Batch 7: loss = 0.6415306925773621\n",
      "Batch 8: loss = 0.6266496181488037\n",
      "Batch 9: loss = 0.5547327995300293\n",
      "Batch 10: loss = 0.5827991366386414\n",
      "Batch 11: loss = 0.6407722234725952\n",
      "Batch 12: loss = 0.6306949853897095\n",
      "Batch 13: loss = 0.5916724801063538\n",
      "Batch 14: loss = 0.6099352240562439\n",
      "Batch 15: loss = 0.5829484462738037\n",
      "Batch 16: loss = 0.6242063045501709\n",
      "Batch 17: loss = 0.6165822744369507\n",
      "Batch 18: loss = 0.6378628611564636\n",
      "Batch 19: loss = 0.564029335975647\n",
      "Batch 20: loss = 0.5679106116294861\n",
      "Batch 21: loss = 0.6203655004501343\n",
      "Batch 22: loss = 0.5480090975761414\n",
      "Batch 23: loss = 0.6269892454147339\n",
      "Batch 24: loss = 0.5627533197402954\n",
      "Batch 25: loss = 0.5543175935745239\n",
      "Batch 26: loss = 0.5673255324363708\n",
      "Batch 27: loss = 0.7138558030128479\n",
      "Batch 28: loss = 0.6331961750984192\n",
      "Batch 29: loss = 0.6248767375946045\n",
      "Batch 30: loss = 0.5607033967971802\n",
      "Batch 31: loss = 0.6395889520645142\n",
      "Batch 32: loss = 0.6592719554901123\n",
      "Batch 33: loss = 0.6218053102493286\n",
      "Batch 34: loss = 0.6412945985794067\n",
      "Batch 35: loss = 0.619682788848877\n",
      "Batch 36: loss = 0.5382534861564636\n",
      "Batch 37: loss = 0.5573218464851379\n",
      "Batch 38: loss = 0.5925197601318359\n",
      "Batch 39: loss = 0.594214677810669\n",
      "Batch 40: loss = 0.6215206384658813\n",
      "Batch 41: loss = 0.5812547206878662\n",
      "Batch 42: loss = 0.5770362615585327\n",
      "Batch 43: loss = 0.6100590229034424\n",
      "Batch 44: loss = 0.525797963142395\n",
      "Batch 45: loss = 0.51410311460495\n",
      "Batch 46: loss = 0.5464334487915039\n",
      "Batch 47: loss = 0.6113582849502563\n",
      "Batch 48: loss = 0.5399842262268066\n",
      "Batch 49: loss = 0.5191777944564819\n",
      "Batch 50: loss = 0.5415259599685669\n",
      "Batch 51: loss = 0.5754004120826721\n",
      "Batch 52: loss = 0.591279923915863\n",
      "Batch 53: loss = 0.5832712650299072\n",
      "Batch 54: loss = 0.48727139830589294\n",
      "Batch 55: loss = 0.5239729881286621\n",
      "Batch 56: loss = 0.5919229388237\n",
      "Batch 57: loss = 0.6686587333679199\n",
      "Batch 58: loss = 0.6086327433586121\n",
      "Batch 59: loss = 0.4855024814605713\n",
      "Batch 60: loss = 0.5770386457443237\n",
      "Batch 61: loss = 0.554448127746582\n",
      "Batch 62: loss = 0.7239458560943604\n",
      "Batch 63: loss = 0.5936957597732544\n",
      "Batch 64: loss = 0.5265716314315796\n",
      "Batch 65: loss = 0.598320722579956\n",
      "Batch 66: loss = 0.6256906986236572\n",
      "Batch 67: loss = 0.5446339249610901\n",
      "Batch 68: loss = 0.5864383578300476\n",
      "Batch 69: loss = 0.5619461536407471\n",
      "Batch 70: loss = 0.6528116464614868\n",
      "Batch 71: loss = 0.6365973949432373\n",
      "Batch 72: loss = 0.5672088861465454\n",
      "Batch 73: loss = 0.6417390704154968\n",
      "Batch 74: loss = 0.6728190183639526\n",
      "Batch 75: loss = 0.6939891576766968\n",
      "Batch 76: loss = 0.6436553001403809\n",
      "Batch 77: loss = 0.6106269359588623\n",
      "Batch 78: loss = 0.6001783609390259\n",
      "Batch 79: loss = 0.5586048364639282\n",
      "Batch 80: loss = 0.595710277557373\n",
      "Batch 81: loss = 0.6032263040542603\n",
      "Batch 82: loss = 0.5179234743118286\n",
      "Batch 83: loss = 0.6001980304718018\n",
      "Batch 84: loss = 0.5826045870780945\n",
      "Batch 85: loss = 0.6932896375656128\n",
      "Batch 86: loss = 0.5650942325592041\n",
      "Batch 87: loss = 0.5525574684143066\n",
      "Batch 88: loss = 0.69840407371521\n",
      "Batch 89: loss = 0.5719563364982605\n",
      "Batch 90: loss = 0.6240959167480469\n",
      "Batch 91: loss = 0.6328846216201782\n",
      "Batch 92: loss = 0.623881459236145\n",
      "Batch 93: loss = 0.5042233467102051\n",
      "Batch 94: loss = 0.5293751358985901\n",
      "Batch 95: loss = 0.5939540863037109\n",
      "Batch 96: loss = 0.6595160961151123\n",
      "Batch 97: loss = 0.566977322101593\n",
      "Batch 98: loss = 0.5742322206497192\n",
      "Batch 99: loss = 0.6412694454193115\n",
      "Batch 100: loss = 0.641571044921875\n",
      "Batch 101: loss = 0.5925809144973755\n",
      "Batch 102: loss = 0.6254396438598633\n",
      "Batch 103: loss = 0.605852484703064\n",
      "Batch 104: loss = 0.5736563205718994\n",
      "Batch 105: loss = 0.586323618888855\n",
      "Batch 106: loss = 0.6156535148620605\n",
      "Batch 107: loss = 0.5592952966690063\n",
      "Batch 108: loss = 0.6086326837539673\n",
      "Batch 109: loss = 0.6386979222297668\n",
      "Batch 110: loss = 0.5608104467391968\n",
      "Batch 111: loss = 0.667281985282898\n",
      "Batch 112: loss = 0.6320285797119141\n",
      "Batch 113: loss = 0.6459835767745972\n",
      "Batch 114: loss = 0.6108667254447937\n",
      "Batch 115: loss = 0.6444677710533142\n",
      "Batch 116: loss = 0.6678605079650879\n",
      "Batch 117: loss = 0.5414761304855347\n",
      "Batch 118: loss = 0.5376009941101074\n",
      "Batch 119: loss = 0.6192240715026855\n",
      "Batch 120: loss = 0.5994528532028198\n",
      "Batch 121: loss = 0.5948675274848938\n",
      "Batch 122: loss = 0.5260465145111084\n",
      "Batch 123: loss = 0.5974382162094116\n",
      "Batch 124: loss = 0.6533255577087402\n",
      "Batch 125: loss = 0.6830025315284729\n",
      "Batch 126: loss = 0.6232540607452393\n",
      "\n",
      "Epoch 32/100\n",
      "Batch 1: loss = 0.6517722010612488\n",
      "Batch 2: loss = 0.6680417060852051\n",
      "Batch 3: loss = 0.5936870574951172\n",
      "Batch 4: loss = 0.5745943784713745\n",
      "Batch 5: loss = 0.6590720415115356\n",
      "Batch 6: loss = 0.6841618418693542\n",
      "Batch 7: loss = 0.6372088193893433\n",
      "Batch 8: loss = 0.6103284955024719\n",
      "Batch 9: loss = 0.5470227003097534\n",
      "Batch 10: loss = 0.5617771148681641\n",
      "Batch 11: loss = 0.5954325795173645\n",
      "Batch 12: loss = 0.5969482064247131\n",
      "Batch 13: loss = 0.5792921781539917\n",
      "Batch 14: loss = 0.6010662913322449\n",
      "Batch 15: loss = 0.5710887908935547\n",
      "Batch 16: loss = 0.6110539436340332\n",
      "Batch 17: loss = 0.5933212637901306\n",
      "Batch 18: loss = 0.6160930395126343\n",
      "Batch 19: loss = 0.5373536348342896\n",
      "Batch 20: loss = 0.5799980163574219\n",
      "Batch 21: loss = 0.603782057762146\n",
      "Batch 22: loss = 0.5684007406234741\n",
      "Batch 23: loss = 0.6327597498893738\n",
      "Batch 24: loss = 0.5169172883033752\n",
      "Batch 25: loss = 0.5703330039978027\n",
      "Batch 26: loss = 0.5594875812530518\n",
      "Batch 27: loss = 0.6621556282043457\n",
      "Batch 28: loss = 0.6119293570518494\n",
      "Batch 29: loss = 0.6278400421142578\n",
      "Batch 30: loss = 0.5721781253814697\n",
      "Batch 31: loss = 0.6360592842102051\n",
      "Batch 32: loss = 0.7153505086898804\n",
      "Batch 33: loss = 0.6254838705062866\n",
      "Batch 34: loss = 0.6449748873710632\n",
      "Batch 35: loss = 0.597980260848999\n",
      "Batch 36: loss = 0.5182985663414001\n",
      "Batch 37: loss = 0.5520875453948975\n",
      "Batch 38: loss = 0.5908613204956055\n",
      "Batch 39: loss = 0.5679145455360413\n",
      "Batch 40: loss = 0.5835258960723877\n",
      "Batch 41: loss = 0.5460085868835449\n",
      "Batch 42: loss = 0.5857550501823425\n",
      "Batch 43: loss = 0.6144140958786011\n",
      "Batch 44: loss = 0.5171982049942017\n",
      "Batch 45: loss = 0.5004509687423706\n",
      "Batch 46: loss = 0.5447914600372314\n",
      "Batch 47: loss = 0.6151701211929321\n",
      "Batch 48: loss = 0.5287463665008545\n",
      "Batch 49: loss = 0.48029467463493347\n",
      "Batch 50: loss = 0.48163050413131714\n",
      "Batch 51: loss = 0.5587451457977295\n",
      "Batch 52: loss = 0.5903425216674805\n",
      "Batch 53: loss = 0.5563379526138306\n",
      "Batch 54: loss = 0.47266125679016113\n",
      "Batch 55: loss = 0.49723076820373535\n",
      "Batch 56: loss = 0.5944472551345825\n",
      "Batch 57: loss = 0.6225695610046387\n",
      "Batch 58: loss = 0.5949890613555908\n",
      "Batch 59: loss = 0.4577842354774475\n",
      "Batch 60: loss = 0.5757070779800415\n",
      "Batch 61: loss = 0.5649815201759338\n",
      "Batch 62: loss = 0.692862331867218\n",
      "Batch 63: loss = 0.579211950302124\n",
      "Batch 64: loss = 0.4832455515861511\n",
      "Batch 65: loss = 0.6275074481964111\n",
      "Batch 66: loss = 0.6087939739227295\n",
      "Batch 67: loss = 0.5522057414054871\n",
      "Batch 68: loss = 0.6103172302246094\n",
      "Batch 69: loss = 0.5646457076072693\n",
      "Batch 70: loss = 0.6744565963745117\n",
      "Batch 71: loss = 0.6441408395767212\n",
      "Batch 72: loss = 0.5411319136619568\n",
      "Batch 73: loss = 0.6580888032913208\n",
      "Batch 74: loss = 0.6509891152381897\n",
      "Batch 75: loss = 0.6826421022415161\n",
      "Batch 76: loss = 0.6225719451904297\n",
      "Batch 77: loss = 0.5756160020828247\n",
      "Batch 78: loss = 0.6137075424194336\n",
      "Batch 79: loss = 0.5433858633041382\n",
      "Batch 80: loss = 0.5896580219268799\n",
      "Batch 81: loss = 0.5962850451469421\n",
      "Batch 82: loss = 0.5235887765884399\n",
      "Batch 83: loss = 0.554751992225647\n",
      "Batch 84: loss = 0.5668220520019531\n",
      "Batch 85: loss = 0.6972424983978271\n",
      "Batch 86: loss = 0.5596943497657776\n",
      "Batch 87: loss = 0.5476323962211609\n",
      "Batch 88: loss = 0.6950905323028564\n",
      "Batch 89: loss = 0.5659990310668945\n",
      "Batch 90: loss = 0.5969007611274719\n",
      "Batch 91: loss = 0.6251511573791504\n",
      "Batch 92: loss = 0.5928090810775757\n",
      "Batch 93: loss = 0.5276410579681396\n",
      "Batch 94: loss = 0.5303958058357239\n",
      "Batch 95: loss = 0.5736876726150513\n",
      "Batch 96: loss = 0.6202517747879028\n",
      "Batch 97: loss = 0.5371672511100769\n",
      "Batch 98: loss = 0.564162015914917\n",
      "Batch 99: loss = 0.6188303232192993\n",
      "Batch 100: loss = 0.6201574802398682\n",
      "Batch 101: loss = 0.5828999280929565\n",
      "Batch 102: loss = 0.564413845539093\n",
      "Batch 103: loss = 0.6117327213287354\n",
      "Batch 104: loss = 0.5660304427146912\n",
      "Batch 105: loss = 0.6195970177650452\n",
      "Batch 106: loss = 0.6111199259757996\n",
      "Batch 107: loss = 0.5606702566146851\n",
      "Batch 108: loss = 0.6091976761817932\n",
      "Batch 109: loss = 0.6188231706619263\n",
      "Batch 110: loss = 0.5285892486572266\n",
      "Batch 111: loss = 0.6306852698326111\n",
      "Batch 112: loss = 0.6192107796669006\n",
      "Batch 113: loss = 0.624456524848938\n",
      "Batch 114: loss = 0.6437141299247742\n",
      "Batch 115: loss = 0.6470307111740112\n",
      "Batch 116: loss = 0.6706335544586182\n",
      "Batch 117: loss = 0.5423191785812378\n",
      "Batch 118: loss = 0.5340151786804199\n",
      "Batch 119: loss = 0.6113367676734924\n",
      "Batch 120: loss = 0.5709793567657471\n",
      "Batch 121: loss = 0.601421594619751\n",
      "Batch 122: loss = 0.5277662873268127\n",
      "Batch 123: loss = 0.608849823474884\n",
      "Batch 124: loss = 0.6608278155326843\n",
      "Batch 125: loss = 0.6624245047569275\n",
      "Batch 126: loss = 0.6077072620391846\n",
      "\n",
      "Epoch 33/100\n",
      "Batch 1: loss = 0.6372042894363403\n",
      "Batch 2: loss = 0.644902229309082\n",
      "Batch 3: loss = 0.5899884700775146\n",
      "Batch 4: loss = 0.5723311901092529\n",
      "Batch 5: loss = 0.6477835774421692\n",
      "Batch 6: loss = 0.6823129653930664\n",
      "Batch 7: loss = 0.5946602821350098\n",
      "Batch 8: loss = 0.5520814657211304\n",
      "Batch 9: loss = 0.520982563495636\n",
      "Batch 10: loss = 0.5348762273788452\n",
      "Batch 11: loss = 0.58678138256073\n",
      "Batch 12: loss = 0.6107640862464905\n",
      "Batch 13: loss = 0.5733472108840942\n",
      "Batch 14: loss = 0.572546124458313\n",
      "Batch 15: loss = 0.5726076364517212\n",
      "Batch 16: loss = 0.5925720930099487\n",
      "Batch 17: loss = 0.6041629910469055\n",
      "Batch 18: loss = 0.5911504030227661\n",
      "Batch 19: loss = 0.5372692346572876\n",
      "Batch 20: loss = 0.5864045023918152\n",
      "Batch 21: loss = 0.5616077184677124\n",
      "Batch 22: loss = 0.542157769203186\n",
      "Batch 23: loss = 0.6190850138664246\n",
      "Batch 24: loss = 0.567839503288269\n",
      "Batch 25: loss = 0.541808545589447\n",
      "Batch 26: loss = 0.5621324777603149\n",
      "Batch 27: loss = 0.6689010858535767\n",
      "Batch 28: loss = 0.631871223449707\n",
      "Batch 29: loss = 0.6214040517807007\n",
      "Batch 30: loss = 0.5338425636291504\n",
      "Batch 31: loss = 0.6349011659622192\n",
      "Batch 32: loss = 0.6313320398330688\n",
      "Batch 33: loss = 0.6111299395561218\n",
      "Batch 34: loss = 0.6066669225692749\n",
      "Batch 35: loss = 0.6074601411819458\n",
      "Batch 36: loss = 0.5269572734832764\n",
      "Batch 37: loss = 0.5584336519241333\n",
      "Batch 38: loss = 0.5829823613166809\n",
      "Batch 39: loss = 0.5802544355392456\n",
      "Batch 40: loss = 0.6053565740585327\n",
      "Batch 41: loss = 0.5555021166801453\n",
      "Batch 42: loss = 0.5528668165206909\n",
      "Batch 43: loss = 0.615365743637085\n",
      "Batch 44: loss = 0.5113101005554199\n",
      "Batch 45: loss = 0.5017694234848022\n",
      "Batch 46: loss = 0.5293035507202148\n",
      "Batch 47: loss = 0.5709809064865112\n",
      "Batch 48: loss = 0.5070383548736572\n",
      "Batch 49: loss = 0.4822876453399658\n",
      "Batch 50: loss = 0.5121221542358398\n",
      "Batch 51: loss = 0.5271201133728027\n",
      "Batch 52: loss = 0.5538605451583862\n",
      "Batch 53: loss = 0.5518523454666138\n",
      "Batch 54: loss = 0.4718841314315796\n",
      "Batch 55: loss = 0.4970092177391052\n",
      "Batch 56: loss = 0.5812362432479858\n",
      "Batch 57: loss = 0.6153470873832703\n",
      "Batch 58: loss = 0.5716986060142517\n",
      "Batch 59: loss = 0.4627247154712677\n",
      "Batch 60: loss = 0.5544542670249939\n",
      "Batch 61: loss = 0.5475244522094727\n",
      "Batch 62: loss = 0.6612107753753662\n",
      "Batch 63: loss = 0.5479012131690979\n",
      "Batch 64: loss = 0.5039430856704712\n",
      "Batch 65: loss = 0.5954886674880981\n",
      "Batch 66: loss = 0.5759608745574951\n",
      "Batch 67: loss = 0.5631572008132935\n",
      "Batch 68: loss = 0.5832774639129639\n",
      "Batch 69: loss = 0.5417169332504272\n",
      "Batch 70: loss = 0.6276541352272034\n",
      "Batch 71: loss = 0.6092144250869751\n",
      "Batch 72: loss = 0.5055005550384521\n",
      "Batch 73: loss = 0.6364153623580933\n",
      "Batch 74: loss = 0.6579221487045288\n",
      "Batch 75: loss = 0.6752758622169495\n",
      "Batch 76: loss = 0.579438328742981\n",
      "Batch 77: loss = 0.5984317064285278\n",
      "Batch 78: loss = 0.6070175170898438\n",
      "Batch 79: loss = 0.5570662021636963\n",
      "Batch 80: loss = 0.575631856918335\n",
      "Batch 81: loss = 0.5770382881164551\n",
      "Batch 82: loss = 0.5081558227539062\n",
      "Batch 83: loss = 0.5708872079849243\n",
      "Batch 84: loss = 0.5862224102020264\n",
      "Batch 85: loss = 0.671676754951477\n",
      "Batch 86: loss = 0.5763432383537292\n",
      "Batch 87: loss = 0.5545171499252319\n",
      "Batch 88: loss = 0.6711519360542297\n",
      "Batch 89: loss = 0.5350346565246582\n",
      "Batch 90: loss = 0.6030747890472412\n",
      "Batch 91: loss = 0.6102663278579712\n",
      "Batch 92: loss = 0.61985182762146\n",
      "Batch 93: loss = 0.4956010580062866\n",
      "Batch 94: loss = 0.5289255976676941\n",
      "Batch 95: loss = 0.5832066535949707\n",
      "Batch 96: loss = 0.6220970153808594\n",
      "Batch 97: loss = 0.5598322749137878\n",
      "Batch 98: loss = 0.5517047047615051\n",
      "Batch 99: loss = 0.6318541765213013\n",
      "Batch 100: loss = 0.6167073249816895\n",
      "Batch 101: loss = 0.5721726417541504\n",
      "Batch 102: loss = 0.5827094316482544\n",
      "Batch 103: loss = 0.5783636569976807\n",
      "Batch 104: loss = 0.5450405478477478\n",
      "Batch 105: loss = 0.5570732355117798\n",
      "Batch 106: loss = 0.5912291407585144\n",
      "Batch 107: loss = 0.5514806509017944\n",
      "Batch 108: loss = 0.5965889096260071\n",
      "Batch 109: loss = 0.6120283007621765\n",
      "Batch 110: loss = 0.51503986120224\n",
      "Batch 111: loss = 0.6342736482620239\n",
      "Batch 112: loss = 0.5935797095298767\n",
      "Batch 113: loss = 0.5967225432395935\n",
      "Batch 114: loss = 0.6155375838279724\n",
      "Batch 115: loss = 0.6472291946411133\n",
      "Batch 116: loss = 0.6361126899719238\n",
      "Batch 117: loss = 0.5293418169021606\n",
      "Batch 118: loss = 0.5220251083374023\n",
      "Batch 119: loss = 0.6000828742980957\n",
      "Batch 120: loss = 0.5809913873672485\n",
      "Batch 121: loss = 0.5932450890541077\n",
      "Batch 122: loss = 0.519697904586792\n",
      "Batch 123: loss = 0.5718865394592285\n",
      "Batch 124: loss = 0.6318482160568237\n",
      "Batch 125: loss = 0.6586598753929138\n",
      "Batch 126: loss = 0.599429726600647\n",
      "\n",
      "Epoch 34/100\n",
      "Batch 1: loss = 0.615453839302063\n",
      "Batch 2: loss = 0.6282907724380493\n",
      "Batch 3: loss = 0.5633584856987\n",
      "Batch 4: loss = 0.6147068738937378\n",
      "Batch 5: loss = 0.6242995262145996\n",
      "Batch 6: loss = 0.6647815108299255\n",
      "Batch 7: loss = 0.5679699182510376\n",
      "Batch 8: loss = 0.5608029961585999\n",
      "Batch 9: loss = 0.5175973176956177\n",
      "Batch 10: loss = 0.528694748878479\n",
      "Batch 11: loss = 0.5912046432495117\n",
      "Batch 12: loss = 0.5870189666748047\n",
      "Batch 13: loss = 0.5665327310562134\n",
      "Batch 14: loss = 0.5895153284072876\n",
      "Batch 15: loss = 0.5326961278915405\n",
      "Batch 16: loss = 0.6281107664108276\n",
      "Batch 17: loss = 0.5849378108978271\n",
      "Batch 18: loss = 0.5968945026397705\n",
      "Batch 19: loss = 0.5277521014213562\n",
      "Batch 20: loss = 0.573536217212677\n",
      "Batch 21: loss = 0.5610140562057495\n",
      "Batch 22: loss = 0.5536426305770874\n",
      "Batch 23: loss = 0.6234596967697144\n",
      "Batch 24: loss = 0.5254919528961182\n",
      "Batch 25: loss = 0.5087651610374451\n",
      "Batch 26: loss = 0.5300270915031433\n",
      "Batch 27: loss = 0.6629945039749146\n",
      "Batch 28: loss = 0.6121805906295776\n",
      "Batch 29: loss = 0.6134103536605835\n",
      "Batch 30: loss = 0.5115981698036194\n",
      "Batch 31: loss = 0.6356642842292786\n",
      "Batch 32: loss = 0.6632267236709595\n",
      "Batch 33: loss = 0.5781381130218506\n",
      "Batch 34: loss = 0.6093539595603943\n",
      "Batch 35: loss = 0.5967567563056946\n",
      "Batch 36: loss = 0.4948713481426239\n",
      "Batch 37: loss = 0.5252076387405396\n",
      "Batch 38: loss = 0.5687159895896912\n",
      "Batch 39: loss = 0.5573453307151794\n",
      "Batch 40: loss = 0.5578820705413818\n",
      "Batch 41: loss = 0.5230109691619873\n",
      "Batch 42: loss = 0.5602316856384277\n",
      "Batch 43: loss = 0.5789713859558105\n",
      "Batch 44: loss = 0.4710952639579773\n",
      "Batch 45: loss = 0.470569908618927\n",
      "Batch 46: loss = 0.5301830768585205\n",
      "Batch 47: loss = 0.5729341506958008\n",
      "Batch 48: loss = 0.5298033952713013\n",
      "Batch 49: loss = 0.4921891987323761\n",
      "Batch 50: loss = 0.5062939524650574\n",
      "Batch 51: loss = 0.556360125541687\n",
      "Batch 52: loss = 0.5787820219993591\n",
      "Batch 53: loss = 0.5392451286315918\n",
      "Batch 54: loss = 0.44796615839004517\n",
      "Batch 55: loss = 0.49267494678497314\n",
      "Batch 56: loss = 0.5787040591239929\n",
      "Batch 57: loss = 0.6128408908843994\n",
      "Batch 58: loss = 0.603479266166687\n",
      "Batch 59: loss = 0.4400371015071869\n",
      "Batch 60: loss = 0.5756639242172241\n",
      "Batch 61: loss = 0.5215621590614319\n",
      "Batch 62: loss = 0.6719521284103394\n",
      "Batch 63: loss = 0.5359675288200378\n",
      "Batch 64: loss = 0.48547857999801636\n",
      "Batch 65: loss = 0.5692891478538513\n",
      "Batch 66: loss = 0.5747008323669434\n",
      "Batch 67: loss = 0.5108863711357117\n",
      "Batch 68: loss = 0.567010223865509\n",
      "Batch 69: loss = 0.5494613647460938\n",
      "Batch 70: loss = 0.6405848860740662\n",
      "Batch 71: loss = 0.6101104617118835\n",
      "Batch 72: loss = 0.4937784969806671\n",
      "Batch 73: loss = 0.6205015182495117\n",
      "Batch 74: loss = 0.6265280246734619\n",
      "Batch 75: loss = 0.6259840726852417\n",
      "Batch 76: loss = 0.6121160387992859\n",
      "Batch 77: loss = 0.5763863921165466\n",
      "Batch 78: loss = 0.5756908059120178\n",
      "Batch 79: loss = 0.5343010425567627\n",
      "Batch 80: loss = 0.5684889554977417\n",
      "Batch 81: loss = 0.5286898612976074\n",
      "Batch 82: loss = 0.4880622923374176\n",
      "Batch 83: loss = 0.5205872654914856\n",
      "Batch 84: loss = 0.5484124422073364\n",
      "Batch 85: loss = 0.6533626317977905\n",
      "Batch 86: loss = 0.5771201848983765\n",
      "Batch 87: loss = 0.5161422491073608\n",
      "Batch 88: loss = 0.6490035057067871\n",
      "Batch 89: loss = 0.5315942168235779\n",
      "Batch 90: loss = 0.5762467384338379\n",
      "Batch 91: loss = 0.6010329723358154\n",
      "Batch 92: loss = 0.5926766395568848\n",
      "Batch 93: loss = 0.47742488980293274\n",
      "Batch 94: loss = 0.5256243348121643\n",
      "Batch 95: loss = 0.5619701147079468\n",
      "Batch 96: loss = 0.6050183773040771\n",
      "Batch 97: loss = 0.5304678082466125\n",
      "Batch 98: loss = 0.555448055267334\n",
      "Batch 99: loss = 0.6141115427017212\n",
      "Batch 100: loss = 0.6018477082252502\n",
      "Batch 101: loss = 0.558449387550354\n",
      "Batch 102: loss = 0.5605682730674744\n",
      "Batch 103: loss = 0.5776625871658325\n",
      "Batch 104: loss = 0.5489230155944824\n",
      "Batch 105: loss = 0.5748677253723145\n",
      "Batch 106: loss = 0.5540913343429565\n",
      "Batch 107: loss = 0.5655179023742676\n",
      "Batch 108: loss = 0.5711389780044556\n",
      "Batch 109: loss = 0.5799561142921448\n",
      "Batch 110: loss = 0.5193942189216614\n",
      "Batch 111: loss = 0.6465579271316528\n",
      "Batch 112: loss = 0.5923181772232056\n",
      "Batch 113: loss = 0.5901215672492981\n",
      "Batch 114: loss = 0.5949357748031616\n",
      "Batch 115: loss = 0.6066515445709229\n",
      "Batch 116: loss = 0.628663957118988\n",
      "Batch 117: loss = 0.5122843980789185\n",
      "Batch 118: loss = 0.49707406759262085\n",
      "Batch 119: loss = 0.5789772272109985\n",
      "Batch 120: loss = 0.5490306615829468\n",
      "Batch 121: loss = 0.5711730718612671\n",
      "Batch 122: loss = 0.5554183721542358\n",
      "Batch 123: loss = 0.5644512176513672\n",
      "Batch 124: loss = 0.6312389373779297\n",
      "Batch 125: loss = 0.6423537731170654\n",
      "Batch 126: loss = 0.5733921527862549\n",
      "\n",
      "Epoch 35/100\n",
      "Batch 1: loss = 0.6224092245101929\n",
      "Batch 2: loss = 0.6069900989532471\n",
      "Batch 3: loss = 0.5572551488876343\n",
      "Batch 4: loss = 0.5891854166984558\n",
      "Batch 5: loss = 0.6442082524299622\n",
      "Batch 6: loss = 0.622066855430603\n",
      "Batch 7: loss = 0.5732205510139465\n",
      "Batch 8: loss = 0.5494438409805298\n",
      "Batch 9: loss = 0.4948329031467438\n",
      "Batch 10: loss = 0.5257652401924133\n",
      "Batch 11: loss = 0.5871467590332031\n",
      "Batch 12: loss = 0.5763996243476868\n",
      "Batch 13: loss = 0.557664692401886\n",
      "Batch 14: loss = 0.5635625123977661\n",
      "Batch 15: loss = 0.5470661520957947\n",
      "Batch 16: loss = 0.5793819427490234\n",
      "Batch 17: loss = 0.5575628876686096\n",
      "Batch 18: loss = 0.5791208744049072\n",
      "Batch 19: loss = 0.4978424310684204\n",
      "Batch 20: loss = 0.5296847224235535\n",
      "Batch 21: loss = 0.5549173355102539\n",
      "Batch 22: loss = 0.5039275884628296\n",
      "Batch 23: loss = 0.6162772178649902\n",
      "Batch 24: loss = 0.49496304988861084\n",
      "Batch 25: loss = 0.4852847456932068\n",
      "Batch 26: loss = 0.5282632112503052\n",
      "Batch 27: loss = 0.6552301645278931\n",
      "Batch 28: loss = 0.6111583709716797\n",
      "Batch 29: loss = 0.5728559494018555\n",
      "Batch 30: loss = 0.5216072797775269\n",
      "Batch 31: loss = 0.6052380204200745\n",
      "Batch 32: loss = 0.6323791742324829\n",
      "Batch 33: loss = 0.5348080396652222\n",
      "Batch 34: loss = 0.596143364906311\n",
      "Batch 35: loss = 0.5802376866340637\n",
      "Batch 36: loss = 0.507487416267395\n",
      "Batch 37: loss = 0.5093600749969482\n",
      "Batch 38: loss = 0.5741978883743286\n",
      "Batch 39: loss = 0.5382418036460876\n",
      "Batch 40: loss = 0.5501394271850586\n",
      "Batch 41: loss = 0.5151956677436829\n",
      "Batch 42: loss = 0.5558372735977173\n",
      "Batch 43: loss = 0.5943727493286133\n",
      "Batch 44: loss = 0.46146494150161743\n",
      "Batch 45: loss = 0.4610590636730194\n",
      "Batch 46: loss = 0.4938541650772095\n",
      "Batch 47: loss = 0.5520317554473877\n",
      "Batch 48: loss = 0.4928871989250183\n",
      "Batch 49: loss = 0.47224533557891846\n",
      "Batch 50: loss = 0.497219443321228\n",
      "Batch 51: loss = 0.484280526638031\n",
      "Batch 52: loss = 0.562874436378479\n",
      "Batch 53: loss = 0.5589520931243896\n",
      "Batch 54: loss = 0.4423190951347351\n",
      "Batch 55: loss = 0.5042499303817749\n",
      "Batch 56: loss = 0.566124677658081\n",
      "Batch 57: loss = 0.591854453086853\n",
      "Batch 58: loss = 0.5792667865753174\n",
      "Batch 59: loss = 0.4314191937446594\n",
      "Batch 60: loss = 0.5279152393341064\n",
      "Batch 61: loss = 0.5443531274795532\n",
      "Batch 62: loss = 0.6122831702232361\n",
      "Batch 63: loss = 0.5373856425285339\n",
      "Batch 64: loss = 0.4746416211128235\n",
      "Batch 65: loss = 0.5452903509140015\n",
      "Batch 66: loss = 0.5711910724639893\n",
      "Batch 67: loss = 0.5302153825759888\n",
      "Batch 68: loss = 0.5527915954589844\n",
      "Batch 69: loss = 0.5082833766937256\n",
      "Batch 70: loss = 0.6274232864379883\n",
      "Batch 71: loss = 0.6237442493438721\n",
      "Batch 72: loss = 0.5135376453399658\n",
      "Batch 73: loss = 0.603865385055542\n",
      "Batch 74: loss = 0.6296164393424988\n",
      "Batch 75: loss = 0.6707055568695068\n",
      "Batch 76: loss = 0.5689833164215088\n",
      "Batch 77: loss = 0.5606553554534912\n",
      "Batch 78: loss = 0.5638946294784546\n",
      "Batch 79: loss = 0.4964020550251007\n",
      "Batch 80: loss = 0.5398546457290649\n",
      "Batch 81: loss = 0.5775774717330933\n",
      "Batch 82: loss = 0.48723074793815613\n",
      "Batch 83: loss = 0.5209676027297974\n",
      "Batch 84: loss = 0.5304967164993286\n",
      "Batch 85: loss = 0.6562972664833069\n",
      "Batch 86: loss = 0.49311012029647827\n",
      "Batch 87: loss = 0.5075271725654602\n",
      "Batch 88: loss = 0.6503914594650269\n",
      "Batch 89: loss = 0.5203763842582703\n",
      "Batch 90: loss = 0.5809270143508911\n",
      "Batch 91: loss = 0.614629864692688\n",
      "Batch 92: loss = 0.5913902521133423\n",
      "Batch 93: loss = 0.4875223636627197\n",
      "Batch 94: loss = 0.5285871028900146\n",
      "Batch 95: loss = 0.5634771585464478\n",
      "Batch 96: loss = 0.5793994665145874\n",
      "Batch 97: loss = 0.5193350911140442\n",
      "Batch 98: loss = 0.5032919645309448\n",
      "Batch 99: loss = 0.6097763776779175\n",
      "Batch 100: loss = 0.5923028588294983\n",
      "Batch 101: loss = 0.5532205104827881\n",
      "Batch 102: loss = 0.5944122076034546\n",
      "Batch 103: loss = 0.5822547078132629\n",
      "Batch 104: loss = 0.5265194177627563\n",
      "Batch 105: loss = 0.5569457411766052\n",
      "Batch 106: loss = 0.5398573875427246\n",
      "Batch 107: loss = 0.5266829133033752\n",
      "Batch 108: loss = 0.5809341073036194\n",
      "Batch 109: loss = 0.5935785174369812\n",
      "Batch 110: loss = 0.4984472692012787\n",
      "Batch 111: loss = 0.6244620680809021\n",
      "Batch 112: loss = 0.578488826751709\n",
      "Batch 113: loss = 0.5891855955123901\n",
      "Batch 114: loss = 0.5654047727584839\n",
      "Batch 115: loss = 0.6045892238616943\n",
      "Batch 116: loss = 0.629709780216217\n",
      "Batch 117: loss = 0.5091878175735474\n",
      "Batch 118: loss = 0.503279447555542\n",
      "Batch 119: loss = 0.5862159132957458\n",
      "Batch 120: loss = 0.5630733966827393\n",
      "Batch 121: loss = 0.5460430979728699\n",
      "Batch 122: loss = 0.505519449710846\n",
      "Batch 123: loss = 0.5608117580413818\n",
      "Batch 124: loss = 0.5899218320846558\n",
      "Batch 125: loss = 0.601948618888855\n",
      "Batch 126: loss = 0.5748387575149536\n",
      "\n",
      "Epoch 36/100\n",
      "Batch 1: loss = 0.6109591126441956\n",
      "Batch 2: loss = 0.6194730997085571\n",
      "Batch 3: loss = 0.5539045333862305\n",
      "Batch 4: loss = 0.5562710165977478\n",
      "Batch 5: loss = 0.6037445068359375\n",
      "Batch 6: loss = 0.6161800026893616\n",
      "Batch 7: loss = 0.5777132511138916\n",
      "Batch 8: loss = 0.5538089275360107\n",
      "Batch 9: loss = 0.5072646737098694\n",
      "Batch 10: loss = 0.4936724305152893\n",
      "Batch 11: loss = 0.5542377233505249\n",
      "Batch 12: loss = 0.5596673488616943\n",
      "Batch 13: loss = 0.5486931800842285\n",
      "Batch 14: loss = 0.5512152314186096\n",
      "Batch 15: loss = 0.5084757804870605\n",
      "Batch 16: loss = 0.6180226802825928\n",
      "Batch 17: loss = 0.5595009326934814\n",
      "Batch 18: loss = 0.5699789524078369\n",
      "Batch 19: loss = 0.5256346464157104\n",
      "Batch 20: loss = 0.533778190612793\n",
      "Batch 21: loss = 0.55854332447052\n",
      "Batch 22: loss = 0.5048959255218506\n",
      "Batch 23: loss = 0.6052971482276917\n",
      "Batch 24: loss = 0.5047280788421631\n",
      "Batch 25: loss = 0.5339404940605164\n",
      "Batch 26: loss = 0.5359082221984863\n",
      "Batch 27: loss = 0.635002613067627\n",
      "Batch 28: loss = 0.5907378196716309\n",
      "Batch 29: loss = 0.5745701789855957\n",
      "Batch 30: loss = 0.5227989554405212\n",
      "Batch 31: loss = 0.6092724204063416\n",
      "Batch 32: loss = 0.6290795803070068\n",
      "Batch 33: loss = 0.5624903440475464\n",
      "Batch 34: loss = 0.5865098237991333\n",
      "Batch 35: loss = 0.5527476072311401\n",
      "Batch 36: loss = 0.49092981219291687\n",
      "Batch 37: loss = 0.5147266387939453\n",
      "Batch 38: loss = 0.5423807501792908\n",
      "Batch 39: loss = 0.5369096994400024\n",
      "Batch 40: loss = 0.5472816228866577\n",
      "Batch 41: loss = 0.5210345387458801\n",
      "Batch 42: loss = 0.5551506280899048\n",
      "Batch 43: loss = 0.5692203044891357\n",
      "Batch 44: loss = 0.46126818656921387\n",
      "Batch 45: loss = 0.45219916105270386\n",
      "Batch 46: loss = 0.48716866970062256\n",
      "Batch 47: loss = 0.5512747764587402\n",
      "Batch 48: loss = 0.5111199617385864\n",
      "Batch 49: loss = 0.4474724531173706\n",
      "Batch 50: loss = 0.48057347536087036\n",
      "Batch 51: loss = 0.5037115812301636\n",
      "Batch 52: loss = 0.5321381092071533\n",
      "Batch 53: loss = 0.5285520553588867\n",
      "Batch 54: loss = 0.44155290722846985\n",
      "Batch 55: loss = 0.47727832198143005\n",
      "Batch 56: loss = 0.5626654028892517\n",
      "Batch 57: loss = 0.5927200317382812\n",
      "Batch 58: loss = 0.5476905107498169\n",
      "Batch 59: loss = 0.4340195953845978\n",
      "Batch 60: loss = 0.49861952662467957\n",
      "Batch 61: loss = 0.5343867540359497\n",
      "Batch 62: loss = 0.6502560377120972\n",
      "Batch 63: loss = 0.5022763013839722\n",
      "Batch 64: loss = 0.47061899304389954\n",
      "Batch 65: loss = 0.5479386448860168\n",
      "Batch 66: loss = 0.5531184077262878\n",
      "Batch 67: loss = 0.5051777958869934\n",
      "Batch 68: loss = 0.5561184287071228\n",
      "Batch 69: loss = 0.5035446882247925\n",
      "Batch 70: loss = 0.6244019269943237\n",
      "Batch 71: loss = 0.5732646584510803\n",
      "Batch 72: loss = 0.5043929815292358\n",
      "Batch 73: loss = 0.5835522413253784\n",
      "Batch 74: loss = 0.6225267648696899\n",
      "Batch 75: loss = 0.6395492553710938\n",
      "Batch 76: loss = 0.5680307149887085\n",
      "Batch 77: loss = 0.5353695750236511\n",
      "Batch 78: loss = 0.5399922132492065\n",
      "Batch 79: loss = 0.5213735103607178\n",
      "Batch 80: loss = 0.556915283203125\n",
      "Batch 81: loss = 0.5296398997306824\n",
      "Batch 82: loss = 0.47555816173553467\n",
      "Batch 83: loss = 0.510461688041687\n",
      "Batch 84: loss = 0.5473644137382507\n",
      "Batch 85: loss = 0.666975200176239\n",
      "Batch 86: loss = 0.49871963262557983\n",
      "Batch 87: loss = 0.5100200772285461\n",
      "Batch 88: loss = 0.6501350402832031\n",
      "Batch 89: loss = 0.5317357778549194\n",
      "Batch 90: loss = 0.5514252185821533\n",
      "Batch 91: loss = 0.5901200771331787\n",
      "Batch 92: loss = 0.5806035995483398\n",
      "Batch 93: loss = 0.44930773973464966\n",
      "Batch 94: loss = 0.4907846450805664\n",
      "Batch 95: loss = 0.5337627530097961\n",
      "Batch 96: loss = 0.585415244102478\n",
      "Batch 97: loss = 0.5206448435783386\n",
      "Batch 98: loss = 0.5163233280181885\n",
      "Batch 99: loss = 0.5741126537322998\n",
      "Batch 100: loss = 0.6057668924331665\n",
      "Batch 101: loss = 0.5348144769668579\n",
      "Batch 102: loss = 0.5577729344367981\n",
      "Batch 103: loss = 0.5482553839683533\n",
      "Batch 104: loss = 0.5302705764770508\n",
      "Batch 105: loss = 0.5216895341873169\n",
      "Batch 106: loss = 0.5607251524925232\n",
      "Batch 107: loss = 0.5363303422927856\n",
      "Batch 108: loss = 0.584682285785675\n",
      "Batch 109: loss = 0.5709809064865112\n",
      "Batch 110: loss = 0.4744897186756134\n",
      "Batch 111: loss = 0.5902847051620483\n",
      "Batch 112: loss = 0.5978299975395203\n",
      "Batch 113: loss = 0.578312873840332\n",
      "Batch 114: loss = 0.583866536617279\n",
      "Batch 115: loss = 0.5912142395973206\n",
      "Batch 116: loss = 0.5966848134994507\n",
      "Batch 117: loss = 0.49501997232437134\n",
      "Batch 118: loss = 0.4886709451675415\n",
      "Batch 119: loss = 0.5465480089187622\n",
      "Batch 120: loss = 0.5492994785308838\n",
      "Batch 121: loss = 0.5593926906585693\n",
      "Batch 122: loss = 0.5030315518379211\n",
      "Batch 123: loss = 0.5506254434585571\n",
      "Batch 124: loss = 0.6166795492172241\n",
      "Batch 125: loss = 0.6142631769180298\n",
      "Batch 126: loss = 0.5336560010910034\n",
      "\n",
      "Epoch 37/100\n",
      "Batch 1: loss = 0.6000626087188721\n",
      "Batch 2: loss = 0.5450570583343506\n",
      "Batch 3: loss = 0.5184820890426636\n",
      "Batch 4: loss = 0.5329889059066772\n",
      "Batch 5: loss = 0.6022347211837769\n",
      "Batch 6: loss = 0.603542685508728\n",
      "Batch 7: loss = 0.5184608697891235\n",
      "Batch 8: loss = 0.5229331254959106\n",
      "Batch 9: loss = 0.4904593527317047\n",
      "Batch 10: loss = 0.46422332525253296\n",
      "Batch 11: loss = 0.5507558584213257\n",
      "Batch 12: loss = 0.5587254762649536\n",
      "Batch 13: loss = 0.519563615322113\n",
      "Batch 14: loss = 0.5292487144470215\n",
      "Batch 15: loss = 0.5192943811416626\n",
      "Batch 16: loss = 0.5730852484703064\n",
      "Batch 17: loss = 0.5439915060997009\n",
      "Batch 18: loss = 0.5564264059066772\n",
      "Batch 19: loss = 0.5016555190086365\n",
      "Batch 20: loss = 0.5508168935775757\n",
      "Batch 21: loss = 0.5383553504943848\n",
      "Batch 22: loss = 0.48419883847236633\n",
      "Batch 23: loss = 0.5852765440940857\n",
      "Batch 24: loss = 0.4953080415725708\n",
      "Batch 25: loss = 0.5083474516868591\n",
      "Batch 26: loss = 0.5159662961959839\n",
      "Batch 27: loss = 0.6296478509902954\n",
      "Batch 28: loss = 0.5840721130371094\n",
      "Batch 29: loss = 0.5636501312255859\n",
      "Batch 30: loss = 0.5172061920166016\n",
      "Batch 31: loss = 0.5946075916290283\n",
      "Batch 32: loss = 0.6115099191665649\n",
      "Batch 33: loss = 0.5405036211013794\n",
      "Batch 34: loss = 0.5362732410430908\n",
      "Batch 35: loss = 0.5311811566352844\n",
      "Batch 36: loss = 0.48842960596084595\n",
      "Batch 37: loss = 0.5225135087966919\n",
      "Batch 38: loss = 0.5528528690338135\n",
      "Batch 39: loss = 0.5101226568222046\n",
      "Batch 40: loss = 0.5387090444564819\n",
      "Batch 41: loss = 0.5232466459274292\n",
      "Batch 42: loss = 0.5463967323303223\n",
      "Batch 43: loss = 0.5498631000518799\n",
      "Batch 44: loss = 0.44189316034317017\n",
      "Batch 45: loss = 0.45221012830734253\n",
      "Batch 46: loss = 0.5070180892944336\n",
      "Batch 47: loss = 0.520527720451355\n",
      "Batch 48: loss = 0.4991643726825714\n",
      "Batch 49: loss = 0.42362356185913086\n",
      "Batch 50: loss = 0.46632635593414307\n",
      "Batch 51: loss = 0.5103044509887695\n",
      "Batch 52: loss = 0.5253946781158447\n",
      "Batch 53: loss = 0.49038755893707275\n",
      "Batch 54: loss = 0.44391876459121704\n",
      "Batch 55: loss = 0.45532551407814026\n",
      "Batch 56: loss = 0.5263657569885254\n",
      "Batch 57: loss = 0.6040614247322083\n",
      "Batch 58: loss = 0.5521498918533325\n",
      "Batch 59: loss = 0.41710972785949707\n",
      "Batch 60: loss = 0.5361304879188538\n",
      "Batch 61: loss = 0.5009291172027588\n",
      "Batch 62: loss = 0.6475263833999634\n",
      "Batch 63: loss = 0.49152129888534546\n",
      "Batch 64: loss = 0.45456504821777344\n",
      "Batch 65: loss = 0.5831440687179565\n",
      "Batch 66: loss = 0.5462859869003296\n",
      "Batch 67: loss = 0.5092910528182983\n",
      "Batch 68: loss = 0.5032598972320557\n",
      "Batch 69: loss = 0.5000318288803101\n",
      "Batch 70: loss = 0.6137450337409973\n",
      "Batch 71: loss = 0.583095908164978\n",
      "Batch 72: loss = 0.5071045756340027\n",
      "Batch 73: loss = 0.597620964050293\n",
      "Batch 74: loss = 0.6081798076629639\n",
      "Batch 75: loss = 0.6235915422439575\n",
      "Batch 76: loss = 0.5564995408058167\n",
      "Batch 77: loss = 0.5515000224113464\n",
      "Batch 78: loss = 0.5597522258758545\n",
      "Batch 79: loss = 0.501314640045166\n",
      "Batch 80: loss = 0.5399172902107239\n",
      "Batch 81: loss = 0.5139143466949463\n",
      "Batch 82: loss = 0.46814221143722534\n",
      "Batch 83: loss = 0.5076503753662109\n",
      "Batch 84: loss = 0.5315021276473999\n",
      "Batch 85: loss = 0.6270825266838074\n",
      "Batch 86: loss = 0.5187876224517822\n",
      "Batch 87: loss = 0.5125572681427002\n",
      "Batch 88: loss = 0.6556767225265503\n",
      "Batch 89: loss = 0.5229554176330566\n",
      "Batch 90: loss = 0.5466419458389282\n",
      "Batch 91: loss = 0.5690662264823914\n",
      "Batch 92: loss = 0.5555052757263184\n",
      "Batch 93: loss = 0.469144344329834\n",
      "Batch 94: loss = 0.498646080493927\n",
      "Batch 95: loss = 0.5091218948364258\n",
      "Batch 96: loss = 0.5814048051834106\n",
      "Batch 97: loss = 0.5133176445960999\n",
      "Batch 98: loss = 0.49836260080337524\n",
      "Batch 99: loss = 0.5579749345779419\n",
      "Batch 100: loss = 0.5819135308265686\n",
      "Batch 101: loss = 0.5090255737304688\n",
      "Batch 102: loss = 0.5581552386283875\n",
      "Batch 103: loss = 0.5153405666351318\n",
      "Batch 104: loss = 0.5026548504829407\n",
      "Batch 105: loss = 0.5097670555114746\n",
      "Batch 106: loss = 0.5390382409095764\n",
      "Batch 107: loss = 0.5325568914413452\n",
      "Batch 108: loss = 0.5500960350036621\n",
      "Batch 109: loss = 0.565300464630127\n",
      "Batch 110: loss = 0.47918519377708435\n",
      "Batch 111: loss = 0.5948296785354614\n",
      "Batch 112: loss = 0.5623911619186401\n",
      "Batch 113: loss = 0.554654061794281\n",
      "Batch 114: loss = 0.5670680999755859\n",
      "Batch 115: loss = 0.5736803412437439\n",
      "Batch 116: loss = 0.5682277679443359\n",
      "Batch 117: loss = 0.4826609194278717\n",
      "Batch 118: loss = 0.4708248972892761\n",
      "Batch 119: loss = 0.5343529582023621\n",
      "Batch 120: loss = 0.5441656112670898\n",
      "Batch 121: loss = 0.5439820289611816\n",
      "Batch 122: loss = 0.4891018271446228\n",
      "Batch 123: loss = 0.5283079147338867\n",
      "Batch 124: loss = 0.5691728591918945\n",
      "Batch 125: loss = 0.6090184450149536\n",
      "Batch 126: loss = 0.5492246150970459\n",
      "\n",
      "Epoch 38/100\n",
      "Batch 1: loss = 0.5586291551589966\n",
      "Batch 2: loss = 0.5625720620155334\n",
      "Batch 3: loss = 0.5047152042388916\n",
      "Batch 4: loss = 0.5285831689834595\n",
      "Batch 5: loss = 0.5725666284561157\n",
      "Batch 6: loss = 0.5847357511520386\n",
      "Batch 7: loss = 0.5299268960952759\n",
      "Batch 8: loss = 0.5549719333648682\n",
      "Batch 9: loss = 0.48360446095466614\n",
      "Batch 10: loss = 0.4775939881801605\n",
      "Batch 11: loss = 0.5286750793457031\n",
      "Batch 12: loss = 0.5348761081695557\n",
      "Batch 13: loss = 0.5117275714874268\n",
      "Batch 14: loss = 0.5374943017959595\n",
      "Batch 15: loss = 0.5134291648864746\n",
      "Batch 16: loss = 0.5488945245742798\n",
      "Batch 17: loss = 0.5143253803253174\n",
      "Batch 18: loss = 0.5699229836463928\n",
      "Batch 19: loss = 0.4911342263221741\n",
      "Batch 20: loss = 0.5184715390205383\n",
      "Batch 21: loss = 0.5300629138946533\n",
      "Batch 22: loss = 0.48607903718948364\n",
      "Batch 23: loss = 0.5569549798965454\n",
      "Batch 24: loss = 0.5000782608985901\n",
      "Batch 25: loss = 0.5163599848747253\n",
      "Batch 26: loss = 0.4785609245300293\n",
      "Batch 27: loss = 0.5968691110610962\n",
      "Batch 28: loss = 0.582461953163147\n",
      "Batch 29: loss = 0.5375820994377136\n",
      "Batch 30: loss = 0.49837666749954224\n",
      "Batch 31: loss = 0.5552235245704651\n",
      "Batch 32: loss = 0.6016241312026978\n",
      "Batch 33: loss = 0.5430052280426025\n",
      "Batch 34: loss = 0.5573403239250183\n",
      "Batch 35: loss = 0.5371887683868408\n",
      "Batch 36: loss = 0.4823017120361328\n",
      "Batch 37: loss = 0.4838277995586395\n",
      "Batch 38: loss = 0.5190590023994446\n",
      "Batch 39: loss = 0.5272926092147827\n",
      "Batch 40: loss = 0.5458903908729553\n",
      "Batch 41: loss = 0.525188148021698\n",
      "Batch 42: loss = 0.5000303387641907\n",
      "Batch 43: loss = 0.5644979476928711\n",
      "Batch 44: loss = 0.4713842272758484\n",
      "Batch 45: loss = 0.4267273545265198\n",
      "Batch 46: loss = 0.47247710824012756\n",
      "Batch 47: loss = 0.5300819873809814\n",
      "Batch 48: loss = 0.49878454208374023\n",
      "Batch 49: loss = 0.44298893213272095\n",
      "Batch 50: loss = 0.4704819321632385\n",
      "Batch 51: loss = 0.514954149723053\n",
      "Batch 52: loss = 0.5350940823554993\n",
      "Batch 53: loss = 0.48841649293899536\n",
      "Batch 54: loss = 0.43022850155830383\n",
      "Batch 55: loss = 0.43984806537628174\n",
      "Batch 56: loss = 0.514003336429596\n",
      "Batch 57: loss = 0.5433814525604248\n",
      "Batch 58: loss = 0.5547111630439758\n",
      "Batch 59: loss = 0.3963749408721924\n",
      "Batch 60: loss = 0.47782599925994873\n",
      "Batch 61: loss = 0.4660159945487976\n",
      "Batch 62: loss = 0.5783938765525818\n",
      "Batch 63: loss = 0.49103808403015137\n",
      "Batch 64: loss = 0.4609813690185547\n",
      "Batch 65: loss = 0.5306302905082703\n",
      "Batch 66: loss = 0.5578957796096802\n",
      "Batch 67: loss = 0.49703463912010193\n",
      "Batch 68: loss = 0.5514626502990723\n",
      "Batch 69: loss = 0.4722633361816406\n",
      "Batch 70: loss = 0.605414867401123\n",
      "Batch 71: loss = 0.5480334758758545\n",
      "Batch 72: loss = 0.44525814056396484\n",
      "Batch 73: loss = 0.557303786277771\n",
      "Batch 74: loss = 0.568488597869873\n",
      "Batch 75: loss = 0.6365712285041809\n",
      "Batch 76: loss = 0.5527545213699341\n",
      "Batch 77: loss = 0.5294461846351624\n",
      "Batch 78: loss = 0.5629323720932007\n",
      "Batch 79: loss = 0.4864281415939331\n",
      "Batch 80: loss = 0.5122241377830505\n",
      "Batch 81: loss = 0.5353875756263733\n",
      "Batch 82: loss = 0.4511689245700836\n",
      "Batch 83: loss = 0.4740248918533325\n",
      "Batch 84: loss = 0.5442999601364136\n",
      "Batch 85: loss = 0.6461774110794067\n",
      "Batch 86: loss = 0.5145772695541382\n",
      "Batch 87: loss = 0.5030878782272339\n",
      "Batch 88: loss = 0.6357572078704834\n",
      "Batch 89: loss = 0.4787641763687134\n",
      "Batch 90: loss = 0.52295982837677\n",
      "Batch 91: loss = 0.5661154985427856\n",
      "Batch 92: loss = 0.5494834184646606\n",
      "Batch 93: loss = 0.452504962682724\n",
      "Batch 94: loss = 0.48685452342033386\n",
      "Batch 95: loss = 0.5404325723648071\n",
      "Batch 96: loss = 0.5774773955345154\n",
      "Batch 97: loss = 0.4850541949272156\n",
      "Batch 98: loss = 0.5250481367111206\n",
      "Batch 99: loss = 0.5703125\n",
      "Batch 100: loss = 0.5634157061576843\n",
      "Batch 101: loss = 0.5208433866500854\n",
      "Batch 102: loss = 0.5271494388580322\n",
      "Batch 103: loss = 0.5365417003631592\n",
      "Batch 104: loss = 0.500608503818512\n",
      "Batch 105: loss = 0.5077345371246338\n",
      "Batch 106: loss = 0.4997066855430603\n",
      "Batch 107: loss = 0.5123752355575562\n",
      "Batch 108: loss = 0.5153405070304871\n",
      "Batch 109: loss = 0.5357418060302734\n",
      "Batch 110: loss = 0.457778662443161\n",
      "Batch 111: loss = 0.5679341554641724\n",
      "Batch 112: loss = 0.5377932190895081\n",
      "Batch 113: loss = 0.5623039603233337\n",
      "Batch 114: loss = 0.5653545260429382\n",
      "Batch 115: loss = 0.5408552885055542\n",
      "Batch 116: loss = 0.5698228478431702\n",
      "Batch 117: loss = 0.4873168468475342\n",
      "Batch 118: loss = 0.4735345244407654\n",
      "Batch 119: loss = 0.5277602672576904\n",
      "Batch 120: loss = 0.5207445621490479\n",
      "Batch 121: loss = 0.5142557621002197\n",
      "Batch 122: loss = 0.48561009764671326\n",
      "Batch 123: loss = 0.5648773908615112\n",
      "Batch 124: loss = 0.5806220173835754\n",
      "Batch 125: loss = 0.564267635345459\n",
      "Batch 126: loss = 0.5465707778930664\n",
      "\n",
      "Epoch 39/100\n",
      "Batch 1: loss = 0.5576913952827454\n",
      "Batch 2: loss = 0.5654494762420654\n",
      "Batch 3: loss = 0.528118908405304\n",
      "Batch 4: loss = 0.5069414377212524\n",
      "Batch 5: loss = 0.5636917948722839\n",
      "Batch 6: loss = 0.5791385173797607\n",
      "Batch 7: loss = 0.5219181776046753\n",
      "Batch 8: loss = 0.5000230669975281\n",
      "Batch 9: loss = 0.49244534969329834\n",
      "Batch 10: loss = 0.4608103632926941\n",
      "Batch 11: loss = 0.5387674570083618\n",
      "Batch 12: loss = 0.5210292935371399\n",
      "Batch 13: loss = 0.49922534823417664\n",
      "Batch 14: loss = 0.5097518563270569\n",
      "Batch 15: loss = 0.4844052791595459\n",
      "Batch 16: loss = 0.5610560774803162\n",
      "Batch 17: loss = 0.5163593292236328\n",
      "Batch 18: loss = 0.5409829616546631\n",
      "Batch 19: loss = 0.49897968769073486\n",
      "Batch 20: loss = 0.5474987626075745\n",
      "Batch 21: loss = 0.5252339839935303\n",
      "Batch 22: loss = 0.4882170557975769\n",
      "Batch 23: loss = 0.5480916500091553\n",
      "Batch 24: loss = 0.4942353367805481\n",
      "Batch 25: loss = 0.4700632691383362\n",
      "Batch 26: loss = 0.4651554822921753\n",
      "Batch 27: loss = 0.6052652597427368\n",
      "Batch 28: loss = 0.551793098449707\n",
      "Batch 29: loss = 0.5327169895172119\n",
      "Batch 30: loss = 0.47860032320022583\n",
      "Batch 31: loss = 0.574347972869873\n",
      "Batch 32: loss = 0.6069468259811401\n",
      "Batch 33: loss = 0.518120288848877\n",
      "Batch 34: loss = 0.5678516626358032\n",
      "Batch 35: loss = 0.5361746549606323\n",
      "Batch 36: loss = 0.4402743875980377\n",
      "Batch 37: loss = 0.4530540704727173\n",
      "Batch 38: loss = 0.5211775302886963\n",
      "Batch 39: loss = 0.5007535815238953\n",
      "Batch 40: loss = 0.5091965794563293\n",
      "Batch 41: loss = 0.4993954002857208\n",
      "Batch 42: loss = 0.4987757205963135\n",
      "Batch 43: loss = 0.5493840575218201\n",
      "Batch 44: loss = 0.4664095342159271\n",
      "Batch 45: loss = 0.44151586294174194\n",
      "Batch 46: loss = 0.46183323860168457\n",
      "Batch 47: loss = 0.5127010345458984\n",
      "Batch 48: loss = 0.5066364407539368\n",
      "Batch 49: loss = 0.4432229995727539\n",
      "Batch 50: loss = 0.4814465045928955\n",
      "Batch 51: loss = 0.4806555509567261\n",
      "Batch 52: loss = 0.5233614444732666\n",
      "Batch 53: loss = 0.495305597782135\n",
      "Batch 54: loss = 0.3966878056526184\n",
      "Batch 55: loss = 0.43879586458206177\n",
      "Batch 56: loss = 0.5282303690910339\n",
      "Batch 57: loss = 0.5440039038658142\n",
      "Batch 58: loss = 0.5292255878448486\n",
      "Batch 59: loss = 0.3932974636554718\n",
      "Batch 60: loss = 0.4952758550643921\n",
      "Batch 61: loss = 0.5069568157196045\n",
      "Batch 62: loss = 0.5865660905838013\n",
      "Batch 63: loss = 0.5118630528450012\n",
      "Batch 64: loss = 0.4448130130767822\n",
      "Batch 65: loss = 0.5186669230461121\n",
      "Batch 66: loss = 0.5202311277389526\n",
      "Batch 67: loss = 0.5058145523071289\n",
      "Batch 68: loss = 0.5007578134536743\n",
      "Batch 69: loss = 0.466339111328125\n",
      "Batch 70: loss = 0.5530745983123779\n",
      "Batch 71: loss = 0.5543394684791565\n",
      "Batch 72: loss = 0.4761660397052765\n",
      "Batch 73: loss = 0.5430607795715332\n",
      "Batch 74: loss = 0.5611943006515503\n",
      "Batch 75: loss = 0.5894602537155151\n",
      "Batch 76: loss = 0.5401001572608948\n",
      "Batch 77: loss = 0.48505455255508423\n",
      "Batch 78: loss = 0.5388820767402649\n",
      "Batch 79: loss = 0.4785369336605072\n",
      "Batch 80: loss = 0.5036446452140808\n",
      "Batch 81: loss = 0.5129956603050232\n",
      "Batch 82: loss = 0.4543599486351013\n",
      "Batch 83: loss = 0.48560845851898193\n",
      "Batch 84: loss = 0.5196751952171326\n",
      "Batch 85: loss = 0.6192710399627686\n",
      "Batch 86: loss = 0.48823508620262146\n",
      "Batch 87: loss = 0.4640512466430664\n",
      "Batch 88: loss = 0.6215991377830505\n",
      "Batch 89: loss = 0.4757798910140991\n",
      "Batch 90: loss = 0.524402379989624\n",
      "Batch 91: loss = 0.5486047863960266\n",
      "Batch 92: loss = 0.5167824029922485\n",
      "Batch 93: loss = 0.45554640889167786\n",
      "Batch 94: loss = 0.4961124062538147\n",
      "Batch 95: loss = 0.519747257232666\n",
      "Batch 96: loss = 0.5480051040649414\n",
      "Batch 97: loss = 0.48469632863998413\n",
      "Batch 98: loss = 0.4867660105228424\n",
      "Batch 99: loss = 0.5712277293205261\n",
      "Batch 100: loss = 0.5529769659042358\n",
      "Batch 101: loss = 0.517849862575531\n",
      "Batch 102: loss = 0.5150753855705261\n",
      "Batch 103: loss = 0.5257788896560669\n",
      "Batch 104: loss = 0.48705679178237915\n",
      "Batch 105: loss = 0.5223479270935059\n",
      "Batch 106: loss = 0.50722736120224\n",
      "Batch 107: loss = 0.495288223028183\n",
      "Batch 108: loss = 0.5085514783859253\n",
      "Batch 109: loss = 0.534749448299408\n",
      "Batch 110: loss = 0.4800925850868225\n",
      "Batch 111: loss = 0.5610744953155518\n",
      "Batch 112: loss = 0.5561894178390503\n",
      "Batch 113: loss = 0.5273308157920837\n",
      "Batch 114: loss = 0.5407493114471436\n",
      "Batch 115: loss = 0.5382096767425537\n",
      "Batch 116: loss = 0.5420619249343872\n",
      "Batch 117: loss = 0.46320563554763794\n",
      "Batch 118: loss = 0.49688297510147095\n",
      "Batch 119: loss = 0.5115829110145569\n",
      "Batch 120: loss = 0.5133552551269531\n",
      "Batch 121: loss = 0.49935758113861084\n",
      "Batch 122: loss = 0.47675633430480957\n",
      "Batch 123: loss = 0.4979044198989868\n",
      "Batch 124: loss = 0.546898603439331\n",
      "Batch 125: loss = 0.5673980116844177\n",
      "Batch 126: loss = 0.5484167337417603\n",
      "\n",
      "Epoch 40/100\n",
      "Batch 1: loss = 0.5517237186431885\n",
      "Batch 2: loss = 0.5453476905822754\n",
      "Batch 3: loss = 0.5090308785438538\n",
      "Batch 4: loss = 0.4850926399230957\n",
      "Batch 5: loss = 0.5494982004165649\n",
      "Batch 6: loss = 0.5890868902206421\n",
      "Batch 7: loss = 0.524486780166626\n",
      "Batch 8: loss = 0.4964388608932495\n",
      "Batch 9: loss = 0.4735260605812073\n",
      "Batch 10: loss = 0.4636862277984619\n",
      "Batch 11: loss = 0.5126875638961792\n",
      "Batch 12: loss = 0.5231192708015442\n",
      "Batch 13: loss = 0.49442344903945923\n",
      "Batch 14: loss = 0.4969290494918823\n",
      "Batch 15: loss = 0.505595862865448\n",
      "Batch 16: loss = 0.5424549579620361\n",
      "Batch 17: loss = 0.49682873487472534\n",
      "Batch 18: loss = 0.5381594896316528\n",
      "Batch 19: loss = 0.5027370452880859\n",
      "Batch 20: loss = 0.5256077647209167\n",
      "Batch 21: loss = 0.5378190279006958\n",
      "Batch 22: loss = 0.43805819749832153\n",
      "Batch 23: loss = 0.5412949919700623\n",
      "Batch 24: loss = 0.45101550221443176\n",
      "Batch 25: loss = 0.467667818069458\n",
      "Batch 26: loss = 0.47690993547439575\n",
      "Batch 27: loss = 0.5983480215072632\n",
      "Batch 28: loss = 0.556304931640625\n",
      "Batch 29: loss = 0.5420836210250854\n",
      "Batch 30: loss = 0.49087095260620117\n",
      "Batch 31: loss = 0.5141838192939758\n",
      "Batch 32: loss = 0.5690494775772095\n",
      "Batch 33: loss = 0.5144145488739014\n",
      "Batch 34: loss = 0.5359245538711548\n",
      "Batch 35: loss = 0.520508885383606\n",
      "Batch 36: loss = 0.4473688006401062\n",
      "Batch 37: loss = 0.44528689980506897\n",
      "Batch 38: loss = 0.5065368413925171\n",
      "Batch 39: loss = 0.4638376235961914\n",
      "Batch 40: loss = 0.4913959503173828\n",
      "Batch 41: loss = 0.507556676864624\n",
      "Batch 42: loss = 0.515406608581543\n",
      "Batch 43: loss = 0.5695885419845581\n",
      "Batch 44: loss = 0.44974565505981445\n",
      "Batch 45: loss = 0.4336016774177551\n",
      "Batch 46: loss = 0.4493257999420166\n",
      "Batch 47: loss = 0.4870959520339966\n",
      "Batch 48: loss = 0.46909356117248535\n",
      "Batch 49: loss = 0.43555232882499695\n",
      "Batch 50: loss = 0.4661422073841095\n",
      "Batch 51: loss = 0.46224653720855713\n",
      "Batch 52: loss = 0.4814290404319763\n",
      "Batch 53: loss = 0.4931524097919464\n",
      "Batch 54: loss = 0.4268728494644165\n",
      "Batch 55: loss = 0.4360051155090332\n",
      "Batch 56: loss = 0.5204573273658752\n",
      "Batch 57: loss = 0.5520346164703369\n",
      "Batch 58: loss = 0.5359308123588562\n",
      "Batch 59: loss = 0.4085288643836975\n",
      "Batch 60: loss = 0.48478132486343384\n",
      "Batch 61: loss = 0.4829760491847992\n",
      "Batch 62: loss = 0.5617435574531555\n",
      "Batch 63: loss = 0.4683069884777069\n",
      "Batch 64: loss = 0.4507511258125305\n",
      "Batch 65: loss = 0.5022410154342651\n",
      "Batch 66: loss = 0.4740281105041504\n",
      "Batch 67: loss = 0.5010241270065308\n",
      "Batch 68: loss = 0.5194646120071411\n",
      "Batch 69: loss = 0.48038530349731445\n",
      "Batch 70: loss = 0.5653121471405029\n",
      "Batch 71: loss = 0.525908887386322\n",
      "Batch 72: loss = 0.4808683395385742\n",
      "Batch 73: loss = 0.5516459941864014\n",
      "Batch 74: loss = 0.5379985570907593\n",
      "Batch 75: loss = 0.5905996561050415\n",
      "Batch 76: loss = 0.5314056873321533\n",
      "Batch 77: loss = 0.5131797790527344\n",
      "Batch 78: loss = 0.516629159450531\n",
      "Batch 79: loss = 0.47892385721206665\n",
      "Batch 80: loss = 0.48933690786361694\n",
      "Batch 81: loss = 0.5077679753303528\n",
      "Batch 82: loss = 0.4607458710670471\n",
      "Batch 83: loss = 0.4788210988044739\n",
      "Batch 84: loss = 0.5235295295715332\n",
      "Batch 85: loss = 0.5876505374908447\n",
      "Batch 86: loss = 0.4671404957771301\n",
      "Batch 87: loss = 0.486741304397583\n",
      "Batch 88: loss = 0.587202787399292\n",
      "Batch 89: loss = 0.4844929277896881\n",
      "Batch 90: loss = 0.5321757793426514\n",
      "Batch 91: loss = 0.5467578768730164\n",
      "Batch 92: loss = 0.5354991555213928\n",
      "Batch 93: loss = 0.4283227026462555\n",
      "Batch 94: loss = 0.4634425640106201\n",
      "Batch 95: loss = 0.5156539678573608\n",
      "Batch 96: loss = 0.550631582736969\n",
      "Batch 97: loss = 0.4883153438568115\n",
      "Batch 98: loss = 0.48578956723213196\n",
      "Batch 99: loss = 0.5522795915603638\n",
      "Batch 100: loss = 0.5517270565032959\n",
      "Batch 101: loss = 0.528407633304596\n",
      "Batch 102: loss = 0.531229555606842\n",
      "Batch 103: loss = 0.5086443424224854\n",
      "Batch 104: loss = 0.48494666814804077\n",
      "Batch 105: loss = 0.49206095933914185\n",
      "Batch 106: loss = 0.5138391256332397\n",
      "Batch 107: loss = 0.45379137992858887\n",
      "Batch 108: loss = 0.5279591083526611\n",
      "Batch 109: loss = 0.5364983081817627\n",
      "Batch 110: loss = 0.4198032021522522\n",
      "Batch 111: loss = 0.5447475910186768\n",
      "Batch 112: loss = 0.5147209167480469\n",
      "Batch 113: loss = 0.5558409690856934\n",
      "Batch 114: loss = 0.5465952157974243\n",
      "Batch 115: loss = 0.5863003730773926\n",
      "Batch 116: loss = 0.5477995872497559\n",
      "Batch 117: loss = 0.48764359951019287\n",
      "Batch 118: loss = 0.47152405977249146\n",
      "Batch 119: loss = 0.4922603964805603\n",
      "Batch 120: loss = 0.5115596055984497\n",
      "Batch 121: loss = 0.5213229656219482\n",
      "Batch 122: loss = 0.46007615327835083\n",
      "Batch 123: loss = 0.515647828578949\n",
      "Batch 124: loss = 0.5637685060501099\n",
      "Batch 125: loss = 0.5353326797485352\n",
      "Batch 126: loss = 0.5238063335418701\n",
      "Saved checkpoint to weights.40.pt\n",
      "\n",
      "Epoch 41/100\n",
      "Batch 1: loss = 0.5539443492889404\n",
      "Batch 2: loss = 0.5312632918357849\n",
      "Batch 3: loss = 0.49017333984375\n",
      "Batch 4: loss = 0.471895694732666\n",
      "Batch 5: loss = 0.5589514374732971\n",
      "Batch 6: loss = 0.549323558807373\n",
      "Batch 7: loss = 0.46070852875709534\n",
      "Batch 8: loss = 0.49696648120880127\n",
      "Batch 9: loss = 0.49516189098358154\n",
      "Batch 10: loss = 0.454274982213974\n",
      "Batch 11: loss = 0.49932682514190674\n",
      "Batch 12: loss = 0.519095778465271\n",
      "Batch 13: loss = 0.5130223035812378\n",
      "Batch 14: loss = 0.49207448959350586\n",
      "Batch 15: loss = 0.48138660192489624\n",
      "Batch 16: loss = 0.5476765632629395\n",
      "Batch 17: loss = 0.48501306772232056\n",
      "Batch 18: loss = 0.5250941514968872\n",
      "Batch 19: loss = 0.4757010340690613\n",
      "Batch 20: loss = 0.518436074256897\n",
      "Batch 21: loss = 0.49308958649635315\n",
      "Batch 22: loss = 0.48195356130599976\n",
      "Batch 23: loss = 0.5478200316429138\n",
      "Batch 24: loss = 0.45522642135620117\n",
      "Batch 25: loss = 0.4753792881965637\n",
      "Batch 26: loss = 0.4470614194869995\n",
      "Batch 27: loss = 0.5788085460662842\n",
      "Batch 28: loss = 0.525835394859314\n",
      "Batch 29: loss = 0.5024131536483765\n",
      "Batch 30: loss = 0.48066872358322144\n",
      "Batch 31: loss = 0.5363284349441528\n",
      "Batch 32: loss = 0.564780592918396\n",
      "Batch 33: loss = 0.49068644642829895\n",
      "Batch 34: loss = 0.5220566987991333\n",
      "Batch 35: loss = 0.5042357444763184\n",
      "Batch 36: loss = 0.43031546473503113\n",
      "Batch 37: loss = 0.46288836002349854\n",
      "Batch 38: loss = 0.4666765630245209\n",
      "Batch 39: loss = 0.4880262017250061\n",
      "Batch 40: loss = 0.501331090927124\n",
      "Batch 41: loss = 0.5055233240127563\n",
      "Batch 42: loss = 0.5345126390457153\n",
      "Batch 43: loss = 0.5351929664611816\n",
      "Batch 44: loss = 0.434824138879776\n",
      "Batch 45: loss = 0.44857722520828247\n",
      "Batch 46: loss = 0.4340980052947998\n",
      "Batch 47: loss = 0.49875956773757935\n",
      "Batch 48: loss = 0.4476434588432312\n",
      "Batch 49: loss = 0.3973686099052429\n",
      "Batch 50: loss = 0.4456310570240021\n",
      "Batch 51: loss = 0.4376949667930603\n",
      "Batch 52: loss = 0.4818202257156372\n",
      "Batch 53: loss = 0.4945107698440552\n",
      "Batch 54: loss = 0.41901811957359314\n",
      "Batch 55: loss = 0.4375787377357483\n",
      "Batch 56: loss = 0.5336145162582397\n",
      "Batch 57: loss = 0.5422120094299316\n",
      "Batch 58: loss = 0.5176361799240112\n",
      "Batch 59: loss = 0.36846381425857544\n",
      "Batch 60: loss = 0.47588977217674255\n",
      "Batch 61: loss = 0.4688869118690491\n",
      "Batch 62: loss = 0.5438560843467712\n",
      "Batch 63: loss = 0.48616328835487366\n",
      "Batch 64: loss = 0.4276336431503296\n",
      "Batch 65: loss = 0.5056754350662231\n",
      "Batch 66: loss = 0.5149469971656799\n",
      "Batch 67: loss = 0.461208313703537\n",
      "Batch 68: loss = 0.5102623701095581\n",
      "Batch 69: loss = 0.4834446310997009\n",
      "Batch 70: loss = 0.5460968017578125\n",
      "Batch 71: loss = 0.5428804755210876\n",
      "Batch 72: loss = 0.46593567728996277\n",
      "Batch 73: loss = 0.5034853219985962\n",
      "Batch 74: loss = 0.5329935550689697\n",
      "Batch 75: loss = 0.582042396068573\n",
      "Batch 76: loss = 0.5297120213508606\n",
      "Batch 77: loss = 0.503413736820221\n",
      "Batch 78: loss = 0.5178245306015015\n",
      "Batch 79: loss = 0.47698748111724854\n",
      "Batch 80: loss = 0.4897218346595764\n",
      "Batch 81: loss = 0.5169253349304199\n",
      "Batch 82: loss = 0.4452701807022095\n",
      "Batch 83: loss = 0.48681825399398804\n",
      "Batch 84: loss = 0.5028815269470215\n",
      "Batch 85: loss = 0.5618797540664673\n",
      "Batch 86: loss = 0.49836766719818115\n",
      "Batch 87: loss = 0.4657280445098877\n",
      "Batch 88: loss = 0.5633034706115723\n",
      "Batch 89: loss = 0.46288228034973145\n",
      "Batch 90: loss = 0.5280763506889343\n",
      "Batch 91: loss = 0.5287383198738098\n",
      "Batch 92: loss = 0.519293487071991\n",
      "Batch 93: loss = 0.430466890335083\n",
      "Batch 94: loss = 0.47739219665527344\n",
      "Batch 95: loss = 0.4902145266532898\n",
      "Batch 96: loss = 0.5448449850082397\n",
      "Batch 97: loss = 0.46780550479888916\n",
      "Batch 98: loss = 0.48619863390922546\n",
      "Batch 99: loss = 0.5470542907714844\n",
      "Batch 100: loss = 0.5141150951385498\n",
      "Batch 101: loss = 0.4934091866016388\n",
      "Batch 102: loss = 0.4800988435745239\n",
      "Batch 103: loss = 0.5068575143814087\n",
      "Batch 104: loss = 0.47201722860336304\n",
      "Batch 105: loss = 0.49396002292633057\n",
      "Batch 106: loss = 0.4828782081604004\n",
      "Batch 107: loss = 0.47125011682510376\n",
      "Batch 108: loss = 0.5058817863464355\n",
      "Batch 109: loss = 0.5113344192504883\n",
      "Batch 110: loss = 0.44213953614234924\n",
      "Batch 111: loss = 0.5238229632377625\n",
      "Batch 112: loss = 0.5483656525611877\n",
      "Batch 113: loss = 0.540273904800415\n",
      "Batch 114: loss = 0.5200521349906921\n",
      "Batch 115: loss = 0.5149824619293213\n",
      "Batch 116: loss = 0.5385081768035889\n",
      "Batch 117: loss = 0.46141231060028076\n",
      "Batch 118: loss = 0.45020121335983276\n",
      "Batch 119: loss = 0.5016611814498901\n",
      "Batch 120: loss = 0.5020947456359863\n",
      "Batch 121: loss = 0.5272597074508667\n",
      "Batch 122: loss = 0.47155770659446716\n",
      "Batch 123: loss = 0.5193721652030945\n",
      "Batch 124: loss = 0.5359205007553101\n",
      "Batch 125: loss = 0.5447214841842651\n",
      "Batch 126: loss = 0.4830261468887329\n",
      "\n",
      "Epoch 42/100\n",
      "Batch 1: loss = 0.5331524014472961\n",
      "Batch 2: loss = 0.5069394111633301\n",
      "Batch 3: loss = 0.48292702436447144\n",
      "Batch 4: loss = 0.48353204131126404\n",
      "Batch 5: loss = 0.5466932058334351\n",
      "Batch 6: loss = 0.5302857160568237\n",
      "Batch 7: loss = 0.49030378460884094\n",
      "Batch 8: loss = 0.48653364181518555\n",
      "Batch 9: loss = 0.4755459427833557\n",
      "Batch 10: loss = 0.4600260555744171\n",
      "Batch 11: loss = 0.5111774206161499\n",
      "Batch 12: loss = 0.4804598093032837\n",
      "Batch 13: loss = 0.4631487727165222\n",
      "Batch 14: loss = 0.49180829524993896\n",
      "Batch 15: loss = 0.44314470887184143\n",
      "Batch 16: loss = 0.5227081775665283\n",
      "Batch 17: loss = 0.4685359597206116\n",
      "Batch 18: loss = 0.5093624591827393\n",
      "Batch 19: loss = 0.4602271318435669\n",
      "Batch 20: loss = 0.4682837724685669\n",
      "Batch 21: loss = 0.5118988752365112\n",
      "Batch 22: loss = 0.4847659468650818\n",
      "Batch 23: loss = 0.5767115354537964\n",
      "Batch 24: loss = 0.4358484745025635\n",
      "Batch 25: loss = 0.46012547612190247\n",
      "Batch 26: loss = 0.46294254064559937\n",
      "Batch 27: loss = 0.6033159494400024\n",
      "Batch 28: loss = 0.5308363437652588\n",
      "Batch 29: loss = 0.5191669464111328\n",
      "Batch 30: loss = 0.4566851854324341\n",
      "Batch 31: loss = 0.5383864641189575\n",
      "Batch 32: loss = 0.5637781023979187\n",
      "Batch 33: loss = 0.47396811842918396\n",
      "Batch 34: loss = 0.5183680653572083\n",
      "Batch 35: loss = 0.524738073348999\n",
      "Batch 36: loss = 0.448631227016449\n",
      "Batch 37: loss = 0.4514254927635193\n",
      "Batch 38: loss = 0.4836721420288086\n",
      "Batch 39: loss = 0.4780772924423218\n",
      "Batch 40: loss = 0.4676569104194641\n",
      "Batch 41: loss = 0.45252490043640137\n",
      "Batch 42: loss = 0.49461451172828674\n",
      "Batch 43: loss = 0.5065371990203857\n",
      "Batch 44: loss = 0.42415595054626465\n",
      "Batch 45: loss = 0.4003949761390686\n",
      "Batch 46: loss = 0.434453547000885\n",
      "Batch 47: loss = 0.48600074648857117\n",
      "Batch 48: loss = 0.47085991501808167\n",
      "Batch 49: loss = 0.42264384031295776\n",
      "Batch 50: loss = 0.4229322671890259\n",
      "Batch 51: loss = 0.4643148183822632\n",
      "Batch 52: loss = 0.5162025094032288\n",
      "Batch 53: loss = 0.436050146818161\n",
      "Batch 54: loss = 0.3905610144138336\n",
      "Batch 55: loss = 0.44479992985725403\n",
      "Batch 56: loss = 0.48854702711105347\n",
      "Batch 57: loss = 0.5387527942657471\n",
      "Batch 58: loss = 0.5081831812858582\n",
      "Batch 59: loss = 0.3834366798400879\n",
      "Batch 60: loss = 0.45480605959892273\n",
      "Batch 61: loss = 0.48550450801849365\n",
      "Batch 62: loss = 0.594628632068634\n",
      "Batch 63: loss = 0.4553054869174957\n",
      "Batch 64: loss = 0.39072728157043457\n",
      "Batch 65: loss = 0.4610576629638672\n",
      "Batch 66: loss = 0.4803239703178406\n",
      "Batch 67: loss = 0.46434247493743896\n",
      "Batch 68: loss = 0.5320001840591431\n",
      "Batch 69: loss = 0.45231133699417114\n",
      "Batch 70: loss = 0.5321698188781738\n",
      "Batch 71: loss = 0.5493649840354919\n",
      "Batch 72: loss = 0.46430039405822754\n",
      "Batch 73: loss = 0.5574109554290771\n",
      "Batch 74: loss = 0.5399516820907593\n",
      "Batch 75: loss = 0.6060878038406372\n",
      "Batch 76: loss = 0.5213844776153564\n",
      "Batch 77: loss = 0.4758921265602112\n",
      "Batch 78: loss = 0.5042847394943237\n",
      "Batch 79: loss = 0.48690783977508545\n",
      "Batch 80: loss = 0.49810460209846497\n",
      "Batch 81: loss = 0.4703901410102844\n",
      "Batch 82: loss = 0.4409753084182739\n",
      "Batch 83: loss = 0.47204673290252686\n",
      "Batch 84: loss = 0.478096067905426\n",
      "Batch 85: loss = 0.5394032001495361\n",
      "Batch 86: loss = 0.4511678218841553\n",
      "Batch 87: loss = 0.46931779384613037\n",
      "Batch 88: loss = 0.5710572004318237\n",
      "Batch 89: loss = 0.4661887586116791\n",
      "Batch 90: loss = 0.5005484819412231\n",
      "Batch 91: loss = 0.5582137703895569\n",
      "Batch 92: loss = 0.5301413536071777\n",
      "Batch 93: loss = 0.40529727935791016\n",
      "Batch 94: loss = 0.4296661913394928\n",
      "Batch 95: loss = 0.48589494824409485\n",
      "Batch 96: loss = 0.5687536001205444\n",
      "Batch 97: loss = 0.46218544244766235\n",
      "Batch 98: loss = 0.4613543748855591\n",
      "Batch 99: loss = 0.5386515855789185\n",
      "Batch 100: loss = 0.516774594783783\n",
      "Batch 101: loss = 0.4749325215816498\n",
      "Batch 102: loss = 0.48185646533966064\n",
      "Batch 103: loss = 0.508965253829956\n",
      "Batch 104: loss = 0.46362173557281494\n",
      "Batch 105: loss = 0.44980424642562866\n",
      "Batch 106: loss = 0.47263163328170776\n",
      "Batch 107: loss = 0.46654996275901794\n",
      "Batch 108: loss = 0.5029890537261963\n",
      "Batch 109: loss = 0.5300620794296265\n",
      "Batch 110: loss = 0.41985172033309937\n",
      "Batch 111: loss = 0.5548778176307678\n",
      "Batch 112: loss = 0.5266368389129639\n",
      "Batch 113: loss = 0.4980178475379944\n",
      "Batch 114: loss = 0.5156401991844177\n",
      "Batch 115: loss = 0.5186384916305542\n",
      "Batch 116: loss = 0.5136489868164062\n",
      "Batch 117: loss = 0.4666619598865509\n",
      "Batch 118: loss = 0.42178842425346375\n",
      "Batch 119: loss = 0.4834173619747162\n",
      "Batch 120: loss = 0.48665809631347656\n",
      "Batch 121: loss = 0.4868776798248291\n",
      "Batch 122: loss = 0.44095808267593384\n",
      "Batch 123: loss = 0.5109708905220032\n",
      "Batch 124: loss = 0.5413594245910645\n",
      "Batch 125: loss = 0.513500452041626\n",
      "Batch 126: loss = 0.5155251026153564\n",
      "\n",
      "Epoch 43/100\n",
      "Batch 1: loss = 0.5079833269119263\n",
      "Batch 2: loss = 0.5217126607894897\n",
      "Batch 3: loss = 0.45606115460395813\n",
      "Batch 4: loss = 0.47112083435058594\n",
      "Batch 5: loss = 0.5370085835456848\n",
      "Batch 6: loss = 0.5342010855674744\n",
      "Batch 7: loss = 0.4765377640724182\n",
      "Batch 8: loss = 0.48017606139183044\n",
      "Batch 9: loss = 0.45438843965530396\n",
      "Batch 10: loss = 0.4341176748275757\n",
      "Batch 11: loss = 0.49266910552978516\n",
      "Batch 12: loss = 0.5035874247550964\n",
      "Batch 13: loss = 0.4561791718006134\n",
      "Batch 14: loss = 0.48037663102149963\n",
      "Batch 15: loss = 0.42850926518440247\n",
      "Batch 16: loss = 0.507568895816803\n",
      "Batch 17: loss = 0.4453987181186676\n",
      "Batch 18: loss = 0.507190465927124\n",
      "Batch 19: loss = 0.48530375957489014\n",
      "Batch 20: loss = 0.48509877920150757\n",
      "Batch 21: loss = 0.48968687653541565\n",
      "Batch 22: loss = 0.44159311056137085\n",
      "Batch 23: loss = 0.5270942449569702\n",
      "Batch 24: loss = 0.45629262924194336\n",
      "Batch 25: loss = 0.47491657733917236\n",
      "Batch 26: loss = 0.4402383863925934\n",
      "Batch 27: loss = 0.5563628077507019\n",
      "Batch 28: loss = 0.5080221891403198\n",
      "Batch 29: loss = 0.5449427366256714\n",
      "Batch 30: loss = 0.44630932807922363\n",
      "Batch 31: loss = 0.5200695395469666\n",
      "Batch 32: loss = 0.568202793598175\n",
      "Batch 33: loss = 0.47067487239837646\n",
      "Batch 34: loss = 0.5140642523765564\n",
      "Batch 35: loss = 0.49245962500572205\n",
      "Batch 36: loss = 0.4112512469291687\n",
      "Batch 37: loss = 0.4265587627887726\n",
      "Batch 38: loss = 0.48944908380508423\n",
      "Batch 39: loss = 0.4711395502090454\n",
      "Batch 40: loss = 0.4903237223625183\n",
      "Batch 41: loss = 0.4908123016357422\n",
      "Batch 42: loss = 0.5074040293693542\n",
      "Batch 43: loss = 0.5303730368614197\n",
      "Batch 44: loss = 0.41432029008865356\n",
      "Batch 45: loss = 0.40851831436157227\n",
      "Batch 46: loss = 0.42350146174430847\n",
      "Batch 47: loss = 0.489801287651062\n",
      "Batch 48: loss = 0.4393475353717804\n",
      "Batch 49: loss = 0.4086444079875946\n",
      "Batch 50: loss = 0.42405152320861816\n",
      "Batch 51: loss = 0.4503909945487976\n",
      "Batch 52: loss = 0.49425071477890015\n",
      "Batch 53: loss = 0.4388231635093689\n",
      "Batch 54: loss = 0.3917485475540161\n",
      "Batch 55: loss = 0.3926897644996643\n",
      "Batch 56: loss = 0.46032023429870605\n",
      "Batch 57: loss = 0.5028707981109619\n",
      "Batch 58: loss = 0.47904911637306213\n",
      "Batch 59: loss = 0.35661834478378296\n",
      "Batch 60: loss = 0.44385987520217896\n",
      "Batch 61: loss = 0.4281458556652069\n",
      "Batch 62: loss = 0.5280544757843018\n",
      "Batch 63: loss = 0.46888023614883423\n",
      "Batch 64: loss = 0.4207441806793213\n",
      "Batch 65: loss = 0.463420033454895\n",
      "Batch 66: loss = 0.48058754205703735\n",
      "Batch 67: loss = 0.4543381631374359\n",
      "Batch 68: loss = 0.4635234475135803\n",
      "Batch 69: loss = 0.45772701501846313\n",
      "Batch 70: loss = 0.5665707588195801\n",
      "Batch 71: loss = 0.5193687081336975\n",
      "Batch 72: loss = 0.43289780616760254\n",
      "Batch 73: loss = 0.5476677417755127\n",
      "Batch 74: loss = 0.5316996574401855\n",
      "Batch 75: loss = 0.593437671661377\n",
      "Batch 76: loss = 0.49766969680786133\n",
      "Batch 77: loss = 0.4878699779510498\n",
      "Batch 78: loss = 0.4989584684371948\n",
      "Batch 79: loss = 0.44752830266952515\n",
      "Batch 80: loss = 0.48043036460876465\n",
      "Batch 81: loss = 0.4837988018989563\n",
      "Batch 82: loss = 0.41540801525115967\n",
      "Batch 83: loss = 0.42827171087265015\n",
      "Batch 84: loss = 0.46881383657455444\n",
      "Batch 85: loss = 0.5631380677223206\n",
      "Batch 86: loss = 0.493031769990921\n",
      "Batch 87: loss = 0.46656617522239685\n",
      "Batch 88: loss = 0.5862662196159363\n",
      "Batch 89: loss = 0.47316494584083557\n",
      "Batch 90: loss = 0.485586017370224\n",
      "Batch 91: loss = 0.5104178786277771\n",
      "Batch 92: loss = 0.49005502462387085\n",
      "Batch 93: loss = 0.43439048528671265\n",
      "Batch 94: loss = 0.4427241384983063\n",
      "Batch 95: loss = 0.505300760269165\n",
      "Batch 96: loss = 0.5421895980834961\n",
      "Batch 97: loss = 0.48391684889793396\n",
      "Batch 98: loss = 0.4558763802051544\n",
      "Batch 99: loss = 0.5060924291610718\n",
      "Batch 100: loss = 0.5533532500267029\n",
      "Batch 101: loss = 0.4728602170944214\n",
      "Batch 102: loss = 0.4700871407985687\n",
      "Batch 103: loss = 0.46901261806488037\n",
      "Batch 104: loss = 0.4533367455005646\n",
      "Batch 105: loss = 0.4644837975502014\n",
      "Batch 106: loss = 0.4862082600593567\n",
      "Batch 107: loss = 0.44960319995880127\n",
      "Batch 108: loss = 0.47364407777786255\n",
      "Batch 109: loss = 0.45861393213272095\n",
      "Batch 110: loss = 0.40987563133239746\n",
      "Batch 111: loss = 0.5042787194252014\n",
      "Batch 112: loss = 0.5136009454727173\n",
      "Batch 113: loss = 0.5074620842933655\n",
      "Batch 114: loss = 0.5310841798782349\n",
      "Batch 115: loss = 0.5369958281517029\n",
      "Batch 116: loss = 0.534661591053009\n",
      "Batch 117: loss = 0.4345483183860779\n",
      "Batch 118: loss = 0.4242689311504364\n",
      "Batch 119: loss = 0.47670435905456543\n",
      "Batch 120: loss = 0.47308075428009033\n",
      "Batch 121: loss = 0.4740297794342041\n",
      "Batch 122: loss = 0.451717734336853\n",
      "Batch 123: loss = 0.4946579933166504\n",
      "Batch 124: loss = 0.5230882167816162\n",
      "Batch 125: loss = 0.5198454856872559\n",
      "Batch 126: loss = 0.5028899312019348\n",
      "\n",
      "Epoch 44/100\n",
      "Batch 1: loss = 0.5115397572517395\n",
      "Batch 2: loss = 0.4967358708381653\n",
      "Batch 3: loss = 0.459458589553833\n",
      "Batch 4: loss = 0.48138105869293213\n",
      "Batch 5: loss = 0.5283839702606201\n",
      "Batch 6: loss = 0.5675128698348999\n",
      "Batch 7: loss = 0.45595693588256836\n",
      "Batch 8: loss = 0.4661121964454651\n",
      "Batch 9: loss = 0.446248859167099\n",
      "Batch 10: loss = 0.4040067195892334\n",
      "Batch 11: loss = 0.489546537399292\n",
      "Batch 12: loss = 0.5002620220184326\n",
      "Batch 13: loss = 0.45864859223365784\n",
      "Batch 14: loss = 0.47616326808929443\n",
      "Batch 15: loss = 0.4488295316696167\n",
      "Batch 16: loss = 0.5116609930992126\n",
      "Batch 17: loss = 0.4641276001930237\n",
      "Batch 18: loss = 0.5146435499191284\n",
      "Batch 19: loss = 0.453271746635437\n",
      "Batch 20: loss = 0.47870349884033203\n",
      "Batch 21: loss = 0.4883105158805847\n",
      "Batch 22: loss = 0.47488802671432495\n",
      "Batch 23: loss = 0.5071191191673279\n",
      "Batch 24: loss = 0.4453534185886383\n",
      "Batch 25: loss = 0.4715930223464966\n",
      "Batch 26: loss = 0.43883147835731506\n",
      "Batch 27: loss = 0.5497848987579346\n",
      "Batch 28: loss = 0.5153505802154541\n",
      "Batch 29: loss = 0.517420768737793\n",
      "Batch 30: loss = 0.4796915650367737\n",
      "Batch 31: loss = 0.5293486714363098\n",
      "Batch 32: loss = 0.5342420935630798\n",
      "Batch 33: loss = 0.45158064365386963\n",
      "Batch 34: loss = 0.4957921504974365\n",
      "Batch 35: loss = 0.47995656728744507\n",
      "Batch 36: loss = 0.4221130907535553\n",
      "Batch 37: loss = 0.4288613498210907\n",
      "Batch 38: loss = 0.4640650153160095\n",
      "Batch 39: loss = 0.46651822328567505\n",
      "Batch 40: loss = 0.45355817675590515\n",
      "Batch 41: loss = 0.4333035349845886\n",
      "Batch 42: loss = 0.47380536794662476\n",
      "Batch 43: loss = 0.5212836265563965\n",
      "Batch 44: loss = 0.4373781681060791\n",
      "Batch 45: loss = 0.4040642976760864\n",
      "Batch 46: loss = 0.40626060962677\n",
      "Batch 47: loss = 0.4795277714729309\n",
      "Batch 48: loss = 0.4799325168132782\n",
      "Batch 49: loss = 0.41087502241134644\n",
      "Batch 50: loss = 0.42242687940597534\n",
      "Batch 51: loss = 0.4341612756252289\n",
      "Batch 52: loss = 0.4882752597332001\n",
      "Batch 53: loss = 0.4687156677246094\n",
      "Batch 54: loss = 0.3732866644859314\n",
      "Batch 55: loss = 0.40118467807769775\n",
      "Batch 56: loss = 0.47527995705604553\n",
      "Batch 57: loss = 0.5037719011306763\n",
      "Batch 58: loss = 0.4833819568157196\n",
      "Batch 59: loss = 0.3595788776874542\n",
      "Batch 60: loss = 0.4282119870185852\n",
      "Batch 61: loss = 0.4419049620628357\n",
      "Batch 62: loss = 0.5097531676292419\n",
      "Batch 63: loss = 0.44225090742111206\n",
      "Batch 64: loss = 0.39495179057121277\n",
      "Batch 65: loss = 0.45800766348838806\n",
      "Batch 66: loss = 0.48349863290786743\n",
      "Batch 67: loss = 0.4473898410797119\n",
      "Batch 68: loss = 0.4562322497367859\n",
      "Batch 69: loss = 0.4549438953399658\n",
      "Batch 70: loss = 0.5442391633987427\n",
      "Batch 71: loss = 0.5039351582527161\n",
      "Batch 72: loss = 0.430653840303421\n",
      "Batch 73: loss = 0.4922837018966675\n",
      "Batch 74: loss = 0.520038366317749\n",
      "Batch 75: loss = 0.5744755268096924\n",
      "Batch 76: loss = 0.5165907144546509\n",
      "Batch 77: loss = 0.45879822969436646\n",
      "Batch 78: loss = 0.4855049252510071\n",
      "Batch 79: loss = 0.46115797758102417\n",
      "Batch 80: loss = 0.45737379789352417\n",
      "Batch 81: loss = 0.48440709710121155\n",
      "Batch 82: loss = 0.4273507595062256\n",
      "Batch 83: loss = 0.4602937698364258\n",
      "Batch 84: loss = 0.44390714168548584\n",
      "Batch 85: loss = 0.5689239501953125\n",
      "Batch 86: loss = 0.45025408267974854\n",
      "Batch 87: loss = 0.4519810080528259\n",
      "Batch 88: loss = 0.539898693561554\n",
      "Batch 89: loss = 0.4508020579814911\n",
      "Batch 90: loss = 0.4856862425804138\n",
      "Batch 91: loss = 0.5327945947647095\n",
      "Batch 92: loss = 0.5288072228431702\n",
      "Batch 93: loss = 0.4179772734642029\n",
      "Batch 94: loss = 0.44463181495666504\n",
      "Batch 95: loss = 0.46217358112335205\n",
      "Batch 96: loss = 0.5336807370185852\n",
      "Batch 97: loss = 0.4480580687522888\n",
      "Batch 98: loss = 0.4445512294769287\n",
      "Batch 99: loss = 0.5216387510299683\n",
      "Batch 100: loss = 0.512978732585907\n",
      "Batch 101: loss = 0.4514998495578766\n",
      "Batch 102: loss = 0.47897428274154663\n",
      "Batch 103: loss = 0.4784938395023346\n",
      "Batch 104: loss = 0.4330804944038391\n",
      "Batch 105: loss = 0.4683050215244293\n",
      "Batch 106: loss = 0.4622974991798401\n",
      "Batch 107: loss = 0.457141637802124\n",
      "Batch 108: loss = 0.48687517642974854\n",
      "Batch 109: loss = 0.5004875659942627\n",
      "Batch 110: loss = 0.40657031536102295\n",
      "Batch 111: loss = 0.5340397357940674\n",
      "Batch 112: loss = 0.4818311333656311\n",
      "Batch 113: loss = 0.5017499327659607\n",
      "Batch 114: loss = 0.5041366815567017\n",
      "Batch 115: loss = 0.5218291878700256\n",
      "Batch 116: loss = 0.5126667618751526\n",
      "Batch 117: loss = 0.4316123127937317\n",
      "Batch 118: loss = 0.4237115979194641\n",
      "Batch 119: loss = 0.47173213958740234\n",
      "Batch 120: loss = 0.45628732442855835\n",
      "Batch 121: loss = 0.4822229743003845\n",
      "Batch 122: loss = 0.4311532974243164\n",
      "Batch 123: loss = 0.49303707480430603\n",
      "Batch 124: loss = 0.5293201208114624\n",
      "Batch 125: loss = 0.5455867052078247\n",
      "Batch 126: loss = 0.48114874958992004\n",
      "\n",
      "Epoch 45/100\n",
      "Batch 1: loss = 0.5188869833946228\n",
      "Batch 2: loss = 0.48996007442474365\n",
      "Batch 3: loss = 0.46509701013565063\n",
      "Batch 4: loss = 0.4340074360370636\n",
      "Batch 5: loss = 0.5113372802734375\n",
      "Batch 6: loss = 0.5134800672531128\n",
      "Batch 7: loss = 0.45631173253059387\n",
      "Batch 8: loss = 0.46918153762817383\n",
      "Batch 9: loss = 0.43830424547195435\n",
      "Batch 10: loss = 0.4244123697280884\n",
      "Batch 11: loss = 0.5004523396492004\n",
      "Batch 12: loss = 0.48519617319107056\n",
      "Batch 13: loss = 0.42252951860427856\n",
      "Batch 14: loss = 0.4457775056362152\n",
      "Batch 15: loss = 0.435397207736969\n",
      "Batch 16: loss = 0.49892592430114746\n",
      "Batch 17: loss = 0.4320666193962097\n",
      "Batch 18: loss = 0.5046055316925049\n",
      "Batch 19: loss = 0.45477747917175293\n",
      "Batch 20: loss = 0.4652937650680542\n",
      "Batch 21: loss = 0.46008336544036865\n",
      "Batch 22: loss = 0.4351944923400879\n",
      "Batch 23: loss = 0.5138977766036987\n",
      "Batch 24: loss = 0.42926299571990967\n",
      "Batch 25: loss = 0.4608056843280792\n",
      "Batch 26: loss = 0.4082658588886261\n",
      "Batch 27: loss = 0.5286842584609985\n",
      "Batch 28: loss = 0.5269729495048523\n",
      "Batch 29: loss = 0.49620866775512695\n",
      "Batch 30: loss = 0.4506914019584656\n",
      "Batch 31: loss = 0.4940716624259949\n",
      "Batch 32: loss = 0.5642911195755005\n",
      "Batch 33: loss = 0.4660704731941223\n",
      "Batch 34: loss = 0.4889870882034302\n",
      "Batch 35: loss = 0.46505478024482727\n",
      "Batch 36: loss = 0.3943307399749756\n",
      "Batch 37: loss = 0.4024243652820587\n",
      "Batch 38: loss = 0.44405439496040344\n",
      "Batch 39: loss = 0.47199419140815735\n",
      "Batch 40: loss = 0.4402616024017334\n",
      "Batch 41: loss = 0.43389636278152466\n",
      "Batch 42: loss = 0.47269758582115173\n",
      "Batch 43: loss = 0.49378591775894165\n",
      "Batch 44: loss = 0.4016900360584259\n",
      "Batch 45: loss = 0.3946240544319153\n",
      "Batch 46: loss = 0.3926863372325897\n",
      "Batch 47: loss = 0.45046693086624146\n",
      "Batch 48: loss = 0.433108925819397\n",
      "Batch 49: loss = 0.40859702229499817\n",
      "Batch 50: loss = 0.3942164182662964\n",
      "Batch 51: loss = 0.4456874132156372\n",
      "Batch 52: loss = 0.4428905248641968\n",
      "Batch 53: loss = 0.44426947832107544\n",
      "Batch 54: loss = 0.368117094039917\n",
      "Batch 55: loss = 0.3765355944633484\n",
      "Batch 56: loss = 0.4591400921344757\n",
      "Batch 57: loss = 0.49448883533477783\n",
      "Batch 58: loss = 0.5080253481864929\n",
      "Batch 59: loss = 0.3431120216846466\n",
      "Batch 60: loss = 0.42064690589904785\n",
      "Batch 61: loss = 0.404438316822052\n",
      "Batch 62: loss = 0.5415439605712891\n",
      "Batch 63: loss = 0.42330819368362427\n",
      "Batch 64: loss = 0.3894416093826294\n",
      "Batch 65: loss = 0.4615686535835266\n",
      "Batch 66: loss = 0.4405956268310547\n",
      "Batch 67: loss = 0.4000215232372284\n",
      "Batch 68: loss = 0.47563838958740234\n",
      "Batch 69: loss = 0.4097103476524353\n",
      "Batch 70: loss = 0.5165563225746155\n",
      "Batch 71: loss = 0.4981350302696228\n",
      "Batch 72: loss = 0.40892529487609863\n",
      "Batch 73: loss = 0.5104657411575317\n",
      "Batch 74: loss = 0.5084367990493774\n",
      "Batch 75: loss = 0.5566055774688721\n",
      "Batch 76: loss = 0.481685072183609\n",
      "Batch 77: loss = 0.4550989270210266\n",
      "Batch 78: loss = 0.474967360496521\n",
      "Batch 79: loss = 0.4306068420410156\n",
      "Batch 80: loss = 0.45817863941192627\n",
      "Batch 81: loss = 0.47334837913513184\n",
      "Batch 82: loss = 0.42883020639419556\n",
      "Batch 83: loss = 0.43723589181900024\n",
      "Batch 84: loss = 0.47195616364479065\n",
      "Batch 85: loss = 0.5537373423576355\n",
      "Batch 86: loss = 0.43994513154029846\n",
      "Batch 87: loss = 0.4070664048194885\n",
      "Batch 88: loss = 0.522386908531189\n",
      "Batch 89: loss = 0.4331227242946625\n",
      "Batch 90: loss = 0.4795503616333008\n",
      "Batch 91: loss = 0.5116064548492432\n",
      "Batch 92: loss = 0.4988681674003601\n",
      "Batch 93: loss = 0.40742620825767517\n",
      "Batch 94: loss = 0.4381380081176758\n",
      "Batch 95: loss = 0.46342602372169495\n",
      "Batch 96: loss = 0.5035147666931152\n",
      "Batch 97: loss = 0.4307647943496704\n",
      "Batch 98: loss = 0.43840980529785156\n",
      "Batch 99: loss = 0.50078284740448\n",
      "Batch 100: loss = 0.5066814422607422\n",
      "Batch 101: loss = 0.45200708508491516\n",
      "Batch 102: loss = 0.4576634466648102\n",
      "Batch 103: loss = 0.4613321125507355\n",
      "Batch 104: loss = 0.4455406367778778\n",
      "Batch 105: loss = 0.4578022062778473\n",
      "Batch 106: loss = 0.46942996978759766\n",
      "Batch 107: loss = 0.43360161781311035\n",
      "Batch 108: loss = 0.4484936594963074\n",
      "Batch 109: loss = 0.478361040353775\n",
      "Batch 110: loss = 0.39902350306510925\n",
      "Batch 111: loss = 0.4817025065422058\n",
      "Batch 112: loss = 0.511839747428894\n",
      "Batch 113: loss = 0.5046787858009338\n",
      "Batch 114: loss = 0.4835793972015381\n",
      "Batch 115: loss = 0.4665921926498413\n",
      "Batch 116: loss = 0.5015385150909424\n",
      "Batch 117: loss = 0.44728466868400574\n",
      "Batch 118: loss = 0.42811405658721924\n",
      "Batch 119: loss = 0.4659688472747803\n",
      "Batch 120: loss = 0.4406203329563141\n",
      "Batch 121: loss = 0.48269277811050415\n",
      "Batch 122: loss = 0.4402117133140564\n",
      "Batch 123: loss = 0.44111210107803345\n",
      "Batch 124: loss = 0.5262835025787354\n",
      "Batch 125: loss = 0.4855539798736572\n",
      "Batch 126: loss = 0.4888859689235687\n",
      "\n",
      "Epoch 46/100\n",
      "Batch 1: loss = 0.47399064898490906\n",
      "Batch 2: loss = 0.4965570271015167\n",
      "Batch 3: loss = 0.4755901098251343\n",
      "Batch 4: loss = 0.42038050293922424\n",
      "Batch 5: loss = 0.4997025728225708\n",
      "Batch 6: loss = 0.4986652731895447\n",
      "Batch 7: loss = 0.4359080195426941\n",
      "Batch 8: loss = 0.4866598844528198\n",
      "Batch 9: loss = 0.431418776512146\n",
      "Batch 10: loss = 0.4158785045146942\n",
      "Batch 11: loss = 0.4633026719093323\n",
      "Batch 12: loss = 0.4832267463207245\n",
      "Batch 13: loss = 0.4350004494190216\n",
      "Batch 14: loss = 0.4526975750923157\n",
      "Batch 15: loss = 0.40766608715057373\n",
      "Batch 16: loss = 0.48909613490104675\n",
      "Batch 17: loss = 0.4404294490814209\n",
      "Batch 18: loss = 0.4973243772983551\n",
      "Batch 19: loss = 0.4588915705680847\n",
      "Batch 20: loss = 0.4364303648471832\n",
      "Batch 21: loss = 0.43887633085250854\n",
      "Batch 22: loss = 0.42194050550460815\n",
      "Batch 23: loss = 0.5205966234207153\n",
      "Batch 24: loss = 0.4191243648529053\n",
      "Batch 25: loss = 0.434373140335083\n",
      "Batch 26: loss = 0.4247814416885376\n",
      "Batch 27: loss = 0.5288331508636475\n",
      "Batch 28: loss = 0.4962558150291443\n",
      "Batch 29: loss = 0.5122690200805664\n",
      "Batch 30: loss = 0.48129308223724365\n",
      "Batch 31: loss = 0.5140348076820374\n",
      "Batch 32: loss = 0.5087642073631287\n",
      "Batch 33: loss = 0.45743557810783386\n",
      "Batch 34: loss = 0.5073866844177246\n",
      "Batch 35: loss = 0.49187731742858887\n",
      "Batch 36: loss = 0.3970726728439331\n",
      "Batch 37: loss = 0.4130173921585083\n",
      "Batch 38: loss = 0.44055408239364624\n",
      "Batch 39: loss = 0.4537447392940521\n",
      "Batch 40: loss = 0.47724950313568115\n",
      "Batch 41: loss = 0.43874162435531616\n",
      "Batch 42: loss = 0.46591588854789734\n",
      "Batch 43: loss = 0.48186594247817993\n",
      "Batch 44: loss = 0.4004003703594208\n",
      "Batch 45: loss = 0.3985542953014374\n",
      "Batch 46: loss = 0.41826027631759644\n",
      "Batch 47: loss = 0.4318038821220398\n",
      "Batch 48: loss = 0.4084090292453766\n",
      "Batch 49: loss = 0.3878689706325531\n",
      "Batch 50: loss = 0.4378849267959595\n",
      "Batch 51: loss = 0.4529901146888733\n",
      "Batch 52: loss = 0.4669176936149597\n",
      "Batch 53: loss = 0.42664119601249695\n",
      "Batch 54: loss = 0.37378329038619995\n",
      "Batch 55: loss = 0.38090360164642334\n",
      "Batch 56: loss = 0.46251851320266724\n",
      "Batch 57: loss = 0.4917702376842499\n",
      "Batch 58: loss = 0.4733823239803314\n",
      "Batch 59: loss = 0.3715088367462158\n",
      "Batch 60: loss = 0.44957274198532104\n",
      "Batch 61: loss = 0.39018651843070984\n",
      "Batch 62: loss = 0.4967970550060272\n",
      "Batch 63: loss = 0.4328717589378357\n",
      "Batch 64: loss = 0.37928909063339233\n",
      "Batch 65: loss = 0.46788546442985535\n",
      "Batch 66: loss = 0.43572747707366943\n",
      "Batch 67: loss = 0.4243263006210327\n",
      "Batch 68: loss = 0.4619036316871643\n",
      "Batch 69: loss = 0.43961188197135925\n",
      "Batch 70: loss = 0.5516840219497681\n",
      "Batch 71: loss = 0.5012503862380981\n",
      "Batch 72: loss = 0.41568636894226074\n",
      "Batch 73: loss = 0.49918580055236816\n",
      "Batch 74: loss = 0.4987972676753998\n",
      "Batch 75: loss = 0.5448428392410278\n",
      "Batch 76: loss = 0.4777131676673889\n",
      "Batch 77: loss = 0.469197154045105\n",
      "Batch 78: loss = 0.4744069278240204\n",
      "Batch 79: loss = 0.44919025897979736\n",
      "Batch 80: loss = 0.45208939909935\n",
      "Batch 81: loss = 0.44439461827278137\n",
      "Batch 82: loss = 0.40653175115585327\n",
      "Batch 83: loss = 0.4035570025444031\n",
      "Batch 84: loss = 0.471641480922699\n",
      "Batch 85: loss = 0.5368711948394775\n",
      "Batch 86: loss = 0.4510076642036438\n",
      "Batch 87: loss = 0.42627185583114624\n",
      "Batch 88: loss = 0.5242624282836914\n",
      "Batch 89: loss = 0.4575731158256531\n",
      "Batch 90: loss = 0.4845433831214905\n",
      "Batch 91: loss = 0.526356041431427\n",
      "Batch 92: loss = 0.49639108777046204\n",
      "Batch 93: loss = 0.3957534432411194\n",
      "Batch 94: loss = 0.42702069878578186\n",
      "Batch 95: loss = 0.4348576068878174\n",
      "Batch 96: loss = 0.5308929681777954\n",
      "Batch 97: loss = 0.44444215297698975\n",
      "Batch 98: loss = 0.4357840418815613\n",
      "Batch 99: loss = 0.5223002433776855\n",
      "Batch 100: loss = 0.5111405849456787\n",
      "Batch 101: loss = 0.44281917810440063\n",
      "Batch 102: loss = 0.4588981866836548\n",
      "Batch 103: loss = 0.4550962448120117\n",
      "Batch 104: loss = 0.442096471786499\n",
      "Batch 105: loss = 0.45380863547325134\n",
      "Batch 106: loss = 0.43591567873954773\n",
      "Batch 107: loss = 0.45393526554107666\n",
      "Batch 108: loss = 0.47588181495666504\n",
      "Batch 109: loss = 0.49162375926971436\n",
      "Batch 110: loss = 0.4145503044128418\n",
      "Batch 111: loss = 0.49316781759262085\n",
      "Batch 112: loss = 0.48552757501602173\n",
      "Batch 113: loss = 0.4856940507888794\n",
      "Batch 114: loss = 0.48155874013900757\n",
      "Batch 115: loss = 0.5250952243804932\n",
      "Batch 116: loss = 0.519967257976532\n",
      "Batch 117: loss = 0.4068681597709656\n",
      "Batch 118: loss = 0.3986159563064575\n",
      "Batch 119: loss = 0.47797366976737976\n",
      "Batch 120: loss = 0.4339103102684021\n",
      "Batch 121: loss = 0.4630018472671509\n",
      "Batch 122: loss = 0.43556296825408936\n",
      "Batch 123: loss = 0.46940627694129944\n",
      "Batch 124: loss = 0.5015814304351807\n",
      "Batch 125: loss = 0.4856176972389221\n",
      "Batch 126: loss = 0.47009384632110596\n",
      "\n",
      "Epoch 47/100\n",
      "Batch 1: loss = 0.4850580394268036\n",
      "Batch 2: loss = 0.45367431640625\n",
      "Batch 3: loss = 0.4377640187740326\n",
      "Batch 4: loss = 0.437977135181427\n",
      "Batch 5: loss = 0.47600722312927246\n",
      "Batch 6: loss = 0.5345821380615234\n",
      "Batch 7: loss = 0.44318515062332153\n",
      "Batch 8: loss = 0.43981969356536865\n",
      "Batch 9: loss = 0.43629032373428345\n",
      "Batch 10: loss = 0.3919001817703247\n",
      "Batch 11: loss = 0.4374205768108368\n",
      "Batch 12: loss = 0.4352388381958008\n",
      "Batch 13: loss = 0.43428975343704224\n",
      "Batch 14: loss = 0.4455105662345886\n",
      "Batch 15: loss = 0.4205153286457062\n",
      "Batch 16: loss = 0.45997941493988037\n",
      "Batch 17: loss = 0.4429817795753479\n",
      "Batch 18: loss = 0.49018609523773193\n",
      "Batch 19: loss = 0.41445544362068176\n",
      "Batch 20: loss = 0.45586729049682617\n",
      "Batch 21: loss = 0.4514020085334778\n",
      "Batch 22: loss = 0.4410554766654968\n",
      "Batch 23: loss = 0.5073179006576538\n",
      "Batch 24: loss = 0.43515801429748535\n",
      "Batch 25: loss = 0.42320024967193604\n",
      "Batch 26: loss = 0.4483451247215271\n",
      "Batch 27: loss = 0.5176072120666504\n",
      "Batch 28: loss = 0.49329543113708496\n",
      "Batch 29: loss = 0.453840434551239\n",
      "Batch 30: loss = 0.43245452642440796\n",
      "Batch 31: loss = 0.4646289348602295\n",
      "Batch 32: loss = 0.5151293873786926\n",
      "Batch 33: loss = 0.43739521503448486\n",
      "Batch 34: loss = 0.48109421133995056\n",
      "Batch 35: loss = 0.45715540647506714\n",
      "Batch 36: loss = 0.4050590395927429\n",
      "Batch 37: loss = 0.40231359004974365\n",
      "Batch 38: loss = 0.4217781126499176\n",
      "Batch 39: loss = 0.43625837564468384\n",
      "Batch 40: loss = 0.4406231641769409\n",
      "Batch 41: loss = 0.42617762088775635\n",
      "Batch 42: loss = 0.45943331718444824\n",
      "Batch 43: loss = 0.4581887125968933\n",
      "Batch 44: loss = 0.3743443489074707\n",
      "Batch 45: loss = 0.38173043727874756\n",
      "Batch 46: loss = 0.3907848298549652\n",
      "Batch 47: loss = 0.4728814363479614\n",
      "Batch 48: loss = 0.4208630323410034\n",
      "Batch 49: loss = 0.40324103832244873\n",
      "Batch 50: loss = 0.38170701265335083\n",
      "Batch 51: loss = 0.4355921149253845\n",
      "Batch 52: loss = 0.46078068017959595\n",
      "Batch 53: loss = 0.4261928200721741\n",
      "Batch 54: loss = 0.3591594696044922\n",
      "Batch 55: loss = 0.3666653037071228\n",
      "Batch 56: loss = 0.46372196078300476\n",
      "Batch 57: loss = 0.48910191655158997\n",
      "Batch 58: loss = 0.4708288311958313\n",
      "Batch 59: loss = 0.3590778708457947\n",
      "Batch 60: loss = 0.4211336076259613\n",
      "Batch 61: loss = 0.43175601959228516\n",
      "Batch 62: loss = 0.4857443571090698\n",
      "Batch 63: loss = 0.3998405635356903\n",
      "Batch 64: loss = 0.3731482923030853\n",
      "Batch 65: loss = 0.4802475571632385\n",
      "Batch 66: loss = 0.4377281963825226\n",
      "Batch 67: loss = 0.41840660572052\n",
      "Batch 68: loss = 0.4573966860771179\n",
      "Batch 69: loss = 0.40725600719451904\n",
      "Batch 70: loss = 0.4994528293609619\n",
      "Batch 71: loss = 0.4694971740245819\n",
      "Batch 72: loss = 0.40342873334884644\n",
      "Batch 73: loss = 0.4919620454311371\n",
      "Batch 74: loss = 0.49462661147117615\n",
      "Batch 75: loss = 0.5091139078140259\n",
      "Batch 76: loss = 0.47210127115249634\n",
      "Batch 77: loss = 0.4447322487831116\n",
      "Batch 78: loss = 0.44258275628089905\n",
      "Batch 79: loss = 0.449086457490921\n",
      "Batch 80: loss = 0.42732518911361694\n",
      "Batch 81: loss = 0.44971734285354614\n",
      "Batch 82: loss = 0.40976226329803467\n",
      "Batch 83: loss = 0.42964524030685425\n",
      "Batch 84: loss = 0.4759654402732849\n",
      "Batch 85: loss = 0.505142331123352\n",
      "Batch 86: loss = 0.4436195194721222\n",
      "Batch 87: loss = 0.4042324423789978\n",
      "Batch 88: loss = 0.5602260231971741\n",
      "Batch 89: loss = 0.44539308547973633\n",
      "Batch 90: loss = 0.4974382519721985\n",
      "Batch 91: loss = 0.506441593170166\n",
      "Batch 92: loss = 0.48319733142852783\n",
      "Batch 93: loss = 0.4243678152561188\n",
      "Batch 94: loss = 0.4498857259750366\n",
      "Batch 95: loss = 0.43207287788391113\n",
      "Batch 96: loss = 0.5082637071609497\n",
      "Batch 97: loss = 0.4252917766571045\n",
      "Batch 98: loss = 0.3830435276031494\n",
      "Batch 99: loss = 0.47507965564727783\n",
      "Batch 100: loss = 0.48783913254737854\n",
      "Batch 101: loss = 0.46292218565940857\n",
      "Batch 102: loss = 0.4287083148956299\n",
      "Batch 103: loss = 0.4197879731655121\n",
      "Batch 104: loss = 0.41321253776550293\n",
      "Batch 105: loss = 0.45133376121520996\n",
      "Batch 106: loss = 0.4326780438423157\n",
      "Batch 107: loss = 0.44368165731430054\n",
      "Batch 108: loss = 0.4491178095340729\n",
      "Batch 109: loss = 0.4537251591682434\n",
      "Batch 110: loss = 0.40003228187561035\n",
      "Batch 111: loss = 0.4718409776687622\n",
      "Batch 112: loss = 0.4867951273918152\n",
      "Batch 113: loss = 0.4832577705383301\n",
      "Batch 114: loss = 0.47435104846954346\n",
      "Batch 115: loss = 0.4629618227481842\n",
      "Batch 116: loss = 0.4622159004211426\n",
      "Batch 117: loss = 0.4221484065055847\n",
      "Batch 118: loss = 0.39246535301208496\n",
      "Batch 119: loss = 0.450953871011734\n",
      "Batch 120: loss = 0.42587199807167053\n",
      "Batch 121: loss = 0.4483213722705841\n",
      "Batch 122: loss = 0.41207313537597656\n",
      "Batch 123: loss = 0.4546715319156647\n",
      "Batch 124: loss = 0.485984206199646\n",
      "Batch 125: loss = 0.4756040573120117\n",
      "Batch 126: loss = 0.4451352059841156\n",
      "\n",
      "Epoch 48/100\n",
      "Batch 1: loss = 0.4609379768371582\n",
      "Batch 2: loss = 0.431248277425766\n",
      "Batch 3: loss = 0.4341934621334076\n",
      "Batch 4: loss = 0.4386288523674011\n",
      "Batch 5: loss = 0.5056972503662109\n",
      "Batch 6: loss = 0.4925427734851837\n",
      "Batch 7: loss = 0.4382665157318115\n",
      "Batch 8: loss = 0.4445342719554901\n",
      "Batch 9: loss = 0.413105845451355\n",
      "Batch 10: loss = 0.4072785973548889\n",
      "Batch 11: loss = 0.45836514234542847\n",
      "Batch 12: loss = 0.4510461091995239\n",
      "Batch 13: loss = 0.4609230160713196\n",
      "Batch 14: loss = 0.4342687129974365\n",
      "Batch 15: loss = 0.4212847948074341\n",
      "Batch 16: loss = 0.4549188017845154\n",
      "Batch 17: loss = 0.4181414246559143\n",
      "Batch 18: loss = 0.4657396078109741\n",
      "Batch 19: loss = 0.43185529112815857\n",
      "Batch 20: loss = 0.4484768509864807\n",
      "Batch 21: loss = 0.45052051544189453\n",
      "Batch 22: loss = 0.43766140937805176\n",
      "Batch 23: loss = 0.4929160475730896\n",
      "Batch 24: loss = 0.40499669313430786\n",
      "Batch 25: loss = 0.45443829894065857\n",
      "Batch 26: loss = 0.395291805267334\n",
      "Batch 27: loss = 0.5386232733726501\n",
      "Batch 28: loss = 0.4976065754890442\n",
      "Batch 29: loss = 0.5171493887901306\n",
      "Batch 30: loss = 0.42682021856307983\n",
      "Batch 31: loss = 0.45848020911216736\n",
      "Batch 32: loss = 0.5013875365257263\n",
      "Batch 33: loss = 0.44662588834762573\n",
      "Batch 34: loss = 0.45890915393829346\n",
      "Batch 35: loss = 0.43972861766815186\n",
      "Batch 36: loss = 0.3841549754142761\n",
      "Batch 37: loss = 0.3716690242290497\n",
      "Batch 38: loss = 0.43901559710502625\n",
      "Batch 39: loss = 0.46717196702957153\n",
      "Batch 40: loss = 0.4392935037612915\n",
      "Batch 41: loss = 0.4250314235687256\n",
      "Batch 42: loss = 0.4570803642272949\n",
      "Batch 43: loss = 0.5084388256072998\n",
      "Batch 44: loss = 0.4086496829986572\n",
      "Batch 45: loss = 0.39418646693229675\n",
      "Batch 46: loss = 0.3835242986679077\n",
      "Batch 47: loss = 0.43320366740226746\n",
      "Batch 48: loss = 0.4216301441192627\n",
      "Batch 49: loss = 0.3908354341983795\n",
      "Batch 50: loss = 0.4015529155731201\n",
      "Batch 51: loss = 0.41898295283317566\n",
      "Batch 52: loss = 0.43637901544570923\n",
      "Batch 53: loss = 0.4188369810581207\n",
      "Batch 54: loss = 0.33399802446365356\n",
      "Batch 55: loss = 0.4007907211780548\n",
      "Batch 56: loss = 0.44380587339401245\n",
      "Batch 57: loss = 0.4557895064353943\n",
      "Batch 58: loss = 0.46461862325668335\n",
      "Batch 59: loss = 0.35528564453125\n",
      "Batch 60: loss = 0.4235028922557831\n",
      "Batch 61: loss = 0.37491375207901\n",
      "Batch 62: loss = 0.49662405252456665\n",
      "Batch 63: loss = 0.39670634269714355\n",
      "Batch 64: loss = 0.3808603286743164\n",
      "Batch 65: loss = 0.45313531160354614\n",
      "Batch 66: loss = 0.4428099989891052\n",
      "Batch 67: loss = 0.41199445724487305\n",
      "Batch 68: loss = 0.4498063921928406\n",
      "Batch 69: loss = 0.4280725121498108\n",
      "Batch 70: loss = 0.5004315376281738\n",
      "Batch 71: loss = 0.4895647466182709\n",
      "Batch 72: loss = 0.3950147032737732\n",
      "Batch 73: loss = 0.46870607137680054\n",
      "Batch 74: loss = 0.49490416049957275\n",
      "Batch 75: loss = 0.524983286857605\n",
      "Batch 76: loss = 0.44355887174606323\n",
      "Batch 77: loss = 0.4120353162288666\n",
      "Batch 78: loss = 0.4636745750904083\n",
      "Batch 79: loss = 0.4521391987800598\n",
      "Batch 80: loss = 0.4266622066497803\n",
      "Batch 81: loss = 0.4412616789340973\n",
      "Batch 82: loss = 0.3756358027458191\n",
      "Batch 83: loss = 0.4166196584701538\n",
      "Batch 84: loss = 0.43656444549560547\n",
      "Batch 85: loss = 0.5218531489372253\n",
      "Batch 86: loss = 0.4384036064147949\n",
      "Batch 87: loss = 0.3970654010772705\n",
      "Batch 88: loss = 0.5205186605453491\n",
      "Batch 89: loss = 0.43891042470932007\n",
      "Batch 90: loss = 0.4564797282218933\n",
      "Batch 91: loss = 0.4765926003456116\n",
      "Batch 92: loss = 0.47098392248153687\n",
      "Batch 93: loss = 0.3885642886161804\n",
      "Batch 94: loss = 0.4197717308998108\n",
      "Batch 95: loss = 0.42007380723953247\n",
      "Batch 96: loss = 0.4849265217781067\n",
      "Batch 97: loss = 0.4167872667312622\n",
      "Batch 98: loss = 0.4251459538936615\n",
      "Batch 99: loss = 0.5072951316833496\n",
      "Batch 100: loss = 0.48285070061683655\n",
      "Batch 101: loss = 0.4683985114097595\n",
      "Batch 102: loss = 0.45432767271995544\n",
      "Batch 103: loss = 0.4267091155052185\n",
      "Batch 104: loss = 0.41365426778793335\n",
      "Batch 105: loss = 0.44657376408576965\n",
      "Batch 106: loss = 0.4201117753982544\n",
      "Batch 107: loss = 0.42718425393104553\n",
      "Batch 108: loss = 0.41695189476013184\n",
      "Batch 109: loss = 0.4660850167274475\n",
      "Batch 110: loss = 0.4080844521522522\n",
      "Batch 111: loss = 0.45228010416030884\n",
      "Batch 112: loss = 0.46596407890319824\n",
      "Batch 113: loss = 0.443290114402771\n",
      "Batch 114: loss = 0.4729679226875305\n",
      "Batch 115: loss = 0.4894765019416809\n",
      "Batch 116: loss = 0.49070197343826294\n",
      "Batch 117: loss = 0.4275236427783966\n",
      "Batch 118: loss = 0.3852593004703522\n",
      "Batch 119: loss = 0.45085516571998596\n",
      "Batch 120: loss = 0.4088096618652344\n",
      "Batch 121: loss = 0.42148399353027344\n",
      "Batch 122: loss = 0.43061530590057373\n",
      "Batch 123: loss = 0.43803149461746216\n",
      "Batch 124: loss = 0.5160990953445435\n",
      "Batch 125: loss = 0.48599666357040405\n",
      "Batch 126: loss = 0.45992034673690796\n",
      "\n",
      "Epoch 49/100\n",
      "Batch 1: loss = 0.4458875060081482\n",
      "Batch 2: loss = 0.4533891975879669\n",
      "Batch 3: loss = 0.41623222827911377\n",
      "Batch 4: loss = 0.4598511755466461\n",
      "Batch 5: loss = 0.4896944761276245\n",
      "Batch 6: loss = 0.456493079662323\n",
      "Batch 7: loss = 0.4245763421058655\n",
      "Batch 8: loss = 0.45200401544570923\n",
      "Batch 9: loss = 0.41445696353912354\n",
      "Batch 10: loss = 0.40320146083831787\n",
      "Batch 11: loss = 0.4463016986846924\n",
      "Batch 12: loss = 0.43021249771118164\n",
      "Batch 13: loss = 0.4114070534706116\n",
      "Batch 14: loss = 0.4074295461177826\n",
      "Batch 15: loss = 0.3926563262939453\n",
      "Batch 16: loss = 0.4932728409767151\n",
      "Batch 17: loss = 0.4342333972454071\n",
      "Batch 18: loss = 0.4415853023529053\n",
      "Batch 19: loss = 0.44504213333129883\n",
      "Batch 20: loss = 0.4176208972930908\n",
      "Batch 21: loss = 0.42162784934043884\n",
      "Batch 22: loss = 0.3884991407394409\n",
      "Batch 23: loss = 0.4696950912475586\n",
      "Batch 24: loss = 0.3846483826637268\n",
      "Batch 25: loss = 0.4239072799682617\n",
      "Batch 26: loss = 0.38844215869903564\n",
      "Batch 27: loss = 0.4950726628303528\n",
      "Batch 28: loss = 0.47011420130729675\n",
      "Batch 29: loss = 0.47689297795295715\n",
      "Batch 30: loss = 0.41222426295280457\n",
      "Batch 31: loss = 0.45697221159935\n",
      "Batch 32: loss = 0.49885913729667664\n",
      "Batch 33: loss = 0.445521742105484\n",
      "Batch 34: loss = 0.44854503870010376\n",
      "Batch 35: loss = 0.4250243306159973\n",
      "Batch 36: loss = 0.39082467555999756\n",
      "Batch 37: loss = 0.39384350180625916\n",
      "Batch 38: loss = 0.40982747077941895\n",
      "Batch 39: loss = 0.4330967962741852\n",
      "Batch 40: loss = 0.4355015754699707\n",
      "Batch 41: loss = 0.40728795528411865\n",
      "Batch 42: loss = 0.42408114671707153\n",
      "Batch 43: loss = 0.46892160177230835\n",
      "Batch 44: loss = 0.3921823501586914\n",
      "Batch 45: loss = 0.3699764609336853\n",
      "Batch 46: loss = 0.39148736000061035\n",
      "Batch 47: loss = 0.40016788244247437\n",
      "Batch 48: loss = 0.4042728543281555\n",
      "Batch 49: loss = 0.39811715483665466\n",
      "Batch 50: loss = 0.3926851153373718\n",
      "Batch 51: loss = 0.38818463683128357\n",
      "Batch 52: loss = 0.44266024231910706\n",
      "Batch 53: loss = 0.4064742922782898\n",
      "Batch 54: loss = 0.3579762578010559\n",
      "Batch 55: loss = 0.36532819271087646\n",
      "Batch 56: loss = 0.439694881439209\n",
      "Batch 57: loss = 0.4456559419631958\n",
      "Batch 58: loss = 0.47899460792541504\n",
      "Batch 59: loss = 0.3357102870941162\n",
      "Batch 60: loss = 0.42223888635635376\n",
      "Batch 61: loss = 0.4444495439529419\n",
      "Batch 62: loss = 0.5209289193153381\n",
      "Batch 63: loss = 0.3850169777870178\n",
      "Batch 64: loss = 0.33307981491088867\n",
      "Batch 65: loss = 0.4244588017463684\n",
      "Batch 66: loss = 0.42213600873947144\n",
      "Batch 67: loss = 0.42478621006011963\n",
      "Batch 68: loss = 0.459078311920166\n",
      "Batch 69: loss = 0.4536212384700775\n",
      "Batch 70: loss = 0.5006582140922546\n",
      "Batch 71: loss = 0.4653763175010681\n",
      "Batch 72: loss = 0.3999367356300354\n",
      "Batch 73: loss = 0.45166370272636414\n",
      "Batch 74: loss = 0.4763796329498291\n",
      "Batch 75: loss = 0.5237557888031006\n",
      "Batch 76: loss = 0.4566165804862976\n",
      "Batch 77: loss = 0.438366174697876\n",
      "Batch 78: loss = 0.46314454078674316\n",
      "Batch 79: loss = 0.42499637603759766\n",
      "Batch 80: loss = 0.4439287781715393\n",
      "Batch 81: loss = 0.4310705065727234\n",
      "Batch 82: loss = 0.38642948865890503\n",
      "Batch 83: loss = 0.391743004322052\n",
      "Batch 84: loss = 0.45816928148269653\n",
      "Batch 85: loss = 0.5144581198692322\n",
      "Batch 86: loss = 0.43544483184814453\n",
      "Batch 87: loss = 0.38676369190216064\n",
      "Batch 88: loss = 0.48081961274147034\n",
      "Batch 89: loss = 0.40000277757644653\n",
      "Batch 90: loss = 0.46002405881881714\n",
      "Batch 91: loss = 0.4879027009010315\n",
      "Batch 92: loss = 0.4399210810661316\n",
      "Batch 93: loss = 0.39108356833457947\n",
      "Batch 94: loss = 0.4101550579071045\n",
      "Batch 95: loss = 0.4547070860862732\n",
      "Batch 96: loss = 0.47924497723579407\n",
      "Batch 97: loss = 0.4103245437145233\n",
      "Batch 98: loss = 0.38390833139419556\n",
      "Batch 99: loss = 0.48879730701446533\n",
      "Batch 100: loss = 0.4801177382469177\n",
      "Batch 101: loss = 0.4548690617084503\n",
      "Batch 102: loss = 0.4431568384170532\n",
      "Batch 103: loss = 0.42565038800239563\n",
      "Batch 104: loss = 0.4255676865577698\n",
      "Batch 105: loss = 0.41178417205810547\n",
      "Batch 106: loss = 0.44494926929473877\n",
      "Batch 107: loss = 0.43552839756011963\n",
      "Batch 108: loss = 0.4280052185058594\n",
      "Batch 109: loss = 0.4428163170814514\n",
      "Batch 110: loss = 0.37810465693473816\n",
      "Batch 111: loss = 0.44682562351226807\n",
      "Batch 112: loss = 0.4578310549259186\n",
      "Batch 113: loss = 0.4274420142173767\n",
      "Batch 114: loss = 0.45592060685157776\n",
      "Batch 115: loss = 0.4783616364002228\n",
      "Batch 116: loss = 0.46562767028808594\n",
      "Batch 117: loss = 0.4015641212463379\n",
      "Batch 118: loss = 0.4178004264831543\n",
      "Batch 119: loss = 0.4392319321632385\n",
      "Batch 120: loss = 0.41334035992622375\n",
      "Batch 121: loss = 0.48829007148742676\n",
      "Batch 122: loss = 0.4162098467350006\n",
      "Batch 123: loss = 0.4490585923194885\n",
      "Batch 124: loss = 0.44782933592796326\n",
      "Batch 125: loss = 0.49444934725761414\n",
      "Batch 126: loss = 0.42522335052490234\n",
      "\n",
      "Epoch 50/100\n",
      "Batch 1: loss = 0.44267380237579346\n",
      "Batch 2: loss = 0.44972550868988037\n",
      "Batch 3: loss = 0.43233925104141235\n",
      "Batch 4: loss = 0.4690210819244385\n",
      "Batch 5: loss = 0.476673424243927\n",
      "Batch 6: loss = 0.4404296278953552\n",
      "Batch 7: loss = 0.4183112680912018\n",
      "Batch 8: loss = 0.44281071424484253\n",
      "Batch 9: loss = 0.4117014408111572\n",
      "Batch 10: loss = 0.38604092597961426\n",
      "Batch 11: loss = 0.4301689863204956\n",
      "Batch 12: loss = 0.4246246814727783\n",
      "Batch 13: loss = 0.40113934874534607\n",
      "Batch 14: loss = 0.40164533257484436\n",
      "Batch 15: loss = 0.3888965845108032\n",
      "Batch 16: loss = 0.4214482307434082\n",
      "Batch 17: loss = 0.4287796914577484\n",
      "Batch 18: loss = 0.4261477291584015\n",
      "Batch 19: loss = 0.44021734595298767\n",
      "Batch 20: loss = 0.4454863667488098\n",
      "Batch 21: loss = 0.4402247667312622\n",
      "Batch 22: loss = 0.40298163890838623\n",
      "Batch 23: loss = 0.47344261407852173\n",
      "Batch 24: loss = 0.404354453086853\n",
      "Batch 25: loss = 0.41810327768325806\n",
      "Batch 26: loss = 0.3816906809806824\n",
      "Batch 27: loss = 0.48440441489219666\n",
      "Batch 28: loss = 0.46933695673942566\n",
      "Batch 29: loss = 0.4444655776023865\n",
      "Batch 30: loss = 0.4238666594028473\n",
      "Batch 31: loss = 0.4755862355232239\n",
      "Batch 32: loss = 0.45156389474868774\n",
      "Batch 33: loss = 0.42733561992645264\n",
      "Batch 34: loss = 0.4633771777153015\n",
      "Batch 35: loss = 0.4288022816181183\n",
      "Batch 36: loss = 0.3638937771320343\n",
      "Batch 37: loss = 0.40997403860092163\n",
      "Batch 38: loss = 0.40689682960510254\n",
      "Batch 39: loss = 0.411508709192276\n",
      "Batch 40: loss = 0.4064415395259857\n",
      "Batch 41: loss = 0.4162176847457886\n",
      "Batch 42: loss = 0.40519702434539795\n",
      "Batch 43: loss = 0.4479990005493164\n",
      "Batch 44: loss = 0.3912433385848999\n",
      "Batch 45: loss = 0.4059322774410248\n",
      "Batch 46: loss = 0.37957054376602173\n",
      "Batch 47: loss = 0.4004588723182678\n",
      "Batch 48: loss = 0.4086790084838867\n",
      "Batch 49: loss = 0.3697940707206726\n",
      "Batch 50: loss = 0.39563673734664917\n",
      "Batch 51: loss = 0.400579571723938\n",
      "Batch 52: loss = 0.47456085681915283\n",
      "Batch 53: loss = 0.4343699514865875\n",
      "Batch 54: loss = 0.3591335415840149\n",
      "Batch 55: loss = 0.35939884185791016\n",
      "Batch 56: loss = 0.4223400354385376\n",
      "Batch 57: loss = 0.48560813069343567\n",
      "Batch 58: loss = 0.4145420491695404\n",
      "Batch 59: loss = 0.33117926120758057\n",
      "Batch 60: loss = 0.3919892907142639\n",
      "Batch 61: loss = 0.3881060481071472\n",
      "Batch 62: loss = 0.4324926733970642\n",
      "Batch 63: loss = 0.3926708996295929\n",
      "Batch 64: loss = 0.3443155884742737\n",
      "Batch 65: loss = 0.44712430238723755\n",
      "Batch 66: loss = 0.4370267987251282\n",
      "Batch 67: loss = 0.4215244650840759\n",
      "Batch 68: loss = 0.41330385208129883\n",
      "Batch 69: loss = 0.3968553841114044\n",
      "Batch 70: loss = 0.4511142671108246\n",
      "Batch 71: loss = 0.47448980808258057\n",
      "Batch 72: loss = 0.38488155603408813\n",
      "Batch 73: loss = 0.4909431040287018\n",
      "Batch 74: loss = 0.476715087890625\n",
      "Batch 75: loss = 0.5120412111282349\n",
      "Batch 76: loss = 0.4585737884044647\n",
      "Batch 77: loss = 0.41251420974731445\n",
      "Batch 78: loss = 0.45347121357917786\n",
      "Batch 79: loss = 0.4126865863800049\n",
      "Batch 80: loss = 0.4339236915111542\n",
      "Batch 81: loss = 0.4160476326942444\n",
      "Batch 82: loss = 0.4046187996864319\n",
      "Batch 83: loss = 0.40188565850257874\n",
      "Batch 84: loss = 0.4874791204929352\n",
      "Batch 85: loss = 0.5007089972496033\n",
      "Batch 86: loss = 0.4251025319099426\n",
      "Batch 87: loss = 0.4181779623031616\n",
      "Batch 88: loss = 0.4942343533039093\n",
      "Batch 89: loss = 0.45336419343948364\n",
      "Batch 90: loss = 0.453914999961853\n",
      "Batch 91: loss = 0.4572242796421051\n",
      "Batch 92: loss = 0.4808051288127899\n",
      "Batch 93: loss = 0.40853559970855713\n",
      "Batch 94: loss = 0.379042387008667\n",
      "Batch 95: loss = 0.40412864089012146\n",
      "Batch 96: loss = 0.5114545226097107\n",
      "Batch 97: loss = 0.4113689661026001\n",
      "Batch 98: loss = 0.42056331038475037\n",
      "Batch 99: loss = 0.48611897230148315\n",
      "Batch 100: loss = 0.4990665316581726\n",
      "Batch 101: loss = 0.41530096530914307\n",
      "Batch 102: loss = 0.44604095816612244\n",
      "Batch 103: loss = 0.42884159088134766\n",
      "Batch 104: loss = 0.3900284469127655\n",
      "Batch 105: loss = 0.39242759346961975\n",
      "Batch 106: loss = 0.43069449067115784\n",
      "Batch 107: loss = 0.38803690671920776\n",
      "Batch 108: loss = 0.43579769134521484\n",
      "Batch 109: loss = 0.4464595913887024\n",
      "Batch 110: loss = 0.35387182235717773\n",
      "Batch 111: loss = 0.4498906135559082\n",
      "Batch 112: loss = 0.46218574047088623\n",
      "Batch 113: loss = 0.43196234107017517\n",
      "Batch 114: loss = 0.45591098070144653\n",
      "Batch 115: loss = 0.4694609045982361\n",
      "Batch 116: loss = 0.45734041929244995\n",
      "Batch 117: loss = 0.387305349111557\n",
      "Batch 118: loss = 0.3701134920120239\n",
      "Batch 119: loss = 0.45096859335899353\n",
      "Batch 120: loss = 0.41672372817993164\n",
      "Batch 121: loss = 0.4377482533454895\n",
      "Batch 122: loss = 0.3892248868942261\n",
      "Batch 123: loss = 0.43527868390083313\n",
      "Batch 124: loss = 0.47168970108032227\n",
      "Batch 125: loss = 0.4734235405921936\n",
      "Batch 126: loss = 0.42435118556022644\n",
      "\n",
      "Epoch 51/100\n",
      "Batch 1: loss = 0.43203967809677124\n",
      "Batch 2: loss = 0.4883902668952942\n",
      "Batch 3: loss = 0.4497588872909546\n",
      "Batch 4: loss = 0.41147708892822266\n",
      "Batch 5: loss = 0.44769901037216187\n",
      "Batch 6: loss = 0.44872865080833435\n",
      "Batch 7: loss = 0.40652671456336975\n",
      "Batch 8: loss = 0.4313916563987732\n",
      "Batch 9: loss = 0.4059069752693176\n",
      "Batch 10: loss = 0.3733263611793518\n",
      "Batch 11: loss = 0.4666309058666229\n",
      "Batch 12: loss = 0.453652024269104\n",
      "Batch 13: loss = 0.3975646495819092\n",
      "Batch 14: loss = 0.4159255623817444\n",
      "Batch 15: loss = 0.39765357971191406\n",
      "Batch 16: loss = 0.4323413372039795\n",
      "Batch 17: loss = 0.39987632632255554\n",
      "Batch 18: loss = 0.4408235549926758\n",
      "Batch 19: loss = 0.4491363763809204\n",
      "Batch 20: loss = 0.40886175632476807\n",
      "Batch 21: loss = 0.4326065182685852\n",
      "Batch 22: loss = 0.3986234664916992\n",
      "Batch 23: loss = 0.4537818133831024\n",
      "Batch 24: loss = 0.39797282218933105\n",
      "Batch 25: loss = 0.4345206618309021\n",
      "Batch 26: loss = 0.3852330446243286\n",
      "Batch 27: loss = 0.49831539392471313\n",
      "Batch 28: loss = 0.47345736622810364\n",
      "Batch 29: loss = 0.4460294842720032\n",
      "Batch 30: loss = 0.4082111120223999\n",
      "Batch 31: loss = 0.4422728419303894\n",
      "Batch 32: loss = 0.4616885781288147\n",
      "Batch 33: loss = 0.410981684923172\n",
      "Batch 34: loss = 0.4743579030036926\n",
      "Batch 35: loss = 0.4024178981781006\n",
      "Batch 36: loss = 0.3533512353897095\n",
      "Batch 37: loss = 0.3701228201389313\n",
      "Batch 38: loss = 0.3975948691368103\n",
      "Batch 39: loss = 0.40781307220458984\n",
      "Batch 40: loss = 0.4317523241043091\n",
      "Batch 41: loss = 0.3847697377204895\n",
      "Batch 42: loss = 0.4340778589248657\n",
      "Batch 43: loss = 0.45439010858535767\n",
      "Batch 44: loss = 0.4044991731643677\n",
      "Batch 45: loss = 0.3812521696090698\n",
      "Batch 46: loss = 0.36843910813331604\n",
      "Batch 47: loss = 0.4052981734275818\n",
      "Batch 48: loss = 0.41036859154701233\n",
      "Batch 49: loss = 0.36313533782958984\n",
      "Batch 50: loss = 0.3890959620475769\n",
      "Batch 51: loss = 0.41824769973754883\n",
      "Batch 52: loss = 0.4225870668888092\n",
      "Batch 53: loss = 0.39293405413627625\n",
      "Batch 54: loss = 0.3298580050468445\n",
      "Batch 55: loss = 0.341711163520813\n",
      "Batch 56: loss = 0.4308274984359741\n",
      "Batch 57: loss = 0.44361114501953125\n",
      "Batch 58: loss = 0.45842084288597107\n",
      "Batch 59: loss = 0.3432968556880951\n",
      "Batch 60: loss = 0.39551955461502075\n",
      "Batch 61: loss = 0.4120319187641144\n",
      "Batch 62: loss = 0.4780089259147644\n",
      "Batch 63: loss = 0.4012245535850525\n",
      "Batch 64: loss = 0.34387803077697754\n",
      "Batch 65: loss = 0.40721800923347473\n",
      "Batch 66: loss = 0.4296259880065918\n",
      "Batch 67: loss = 0.4149104952812195\n",
      "Batch 68: loss = 0.4411507844924927\n",
      "Batch 69: loss = 0.3954586386680603\n",
      "Batch 70: loss = 0.48705101013183594\n",
      "Batch 71: loss = 0.44386720657348633\n",
      "Batch 72: loss = 0.41701340675354004\n",
      "Batch 73: loss = 0.4634087085723877\n",
      "Batch 74: loss = 0.4358917772769928\n",
      "Batch 75: loss = 0.48817598819732666\n",
      "Batch 76: loss = 0.4383888840675354\n",
      "Batch 77: loss = 0.4247971475124359\n",
      "Batch 78: loss = 0.4262540340423584\n",
      "Batch 79: loss = 0.41398316621780396\n",
      "Batch 80: loss = 0.3923534154891968\n",
      "Batch 81: loss = 0.41457927227020264\n",
      "Batch 82: loss = 0.4040270447731018\n",
      "Batch 83: loss = 0.40038931369781494\n",
      "Batch 84: loss = 0.4392462968826294\n",
      "Batch 85: loss = 0.5083301067352295\n",
      "Batch 86: loss = 0.41885629296302795\n",
      "Batch 87: loss = 0.3751876950263977\n",
      "Batch 88: loss = 0.4832766652107239\n",
      "Batch 89: loss = 0.40448176860809326\n",
      "Batch 90: loss = 0.43251052498817444\n",
      "Batch 91: loss = 0.4975621700286865\n",
      "Batch 92: loss = 0.4616730511188507\n",
      "Batch 93: loss = 0.37027227878570557\n",
      "Batch 94: loss = 0.405159592628479\n",
      "Batch 95: loss = 0.4277971386909485\n",
      "Batch 96: loss = 0.46689289808273315\n",
      "Batch 97: loss = 0.4014904499053955\n",
      "Batch 98: loss = 0.412836492061615\n",
      "Batch 99: loss = 0.4822760820388794\n",
      "Batch 100: loss = 0.4690253436565399\n",
      "Batch 101: loss = 0.4259971082210541\n",
      "Batch 102: loss = 0.4320223927497864\n",
      "Batch 103: loss = 0.4283466935157776\n",
      "Batch 104: loss = 0.41716766357421875\n",
      "Batch 105: loss = 0.3955312967300415\n",
      "Batch 106: loss = 0.40217268466949463\n",
      "Batch 107: loss = 0.42384904623031616\n",
      "Batch 108: loss = 0.4382908344268799\n",
      "Batch 109: loss = 0.4482190012931824\n",
      "Batch 110: loss = 0.34897467494010925\n",
      "Batch 111: loss = 0.45464658737182617\n",
      "Batch 112: loss = 0.4843779504299164\n",
      "Batch 113: loss = 0.4385409355163574\n",
      "Batch 114: loss = 0.45003652572631836\n",
      "Batch 115: loss = 0.4530029296875\n",
      "Batch 116: loss = 0.46616262197494507\n",
      "Batch 117: loss = 0.3831406235694885\n",
      "Batch 118: loss = 0.40948498249053955\n",
      "Batch 119: loss = 0.42379680275917053\n",
      "Batch 120: loss = 0.4101846218109131\n",
      "Batch 121: loss = 0.42469510436058044\n",
      "Batch 122: loss = 0.38277357816696167\n",
      "Batch 123: loss = 0.4328024983406067\n",
      "Batch 124: loss = 0.4869600832462311\n",
      "Batch 125: loss = 0.439348042011261\n",
      "Batch 126: loss = 0.4044950604438782\n",
      "\n",
      "Epoch 52/100\n",
      "Batch 1: loss = 0.42914915084838867\n",
      "Batch 2: loss = 0.454389363527298\n",
      "Batch 3: loss = 0.42405423521995544\n",
      "Batch 4: loss = 0.42497456073760986\n",
      "Batch 5: loss = 0.4192218780517578\n",
      "Batch 6: loss = 0.45853477716445923\n",
      "Batch 7: loss = 0.39564821124076843\n",
      "Batch 8: loss = 0.41925713419914246\n",
      "Batch 9: loss = 0.4208388328552246\n",
      "Batch 10: loss = 0.38605058193206787\n",
      "Batch 11: loss = 0.4238491654396057\n",
      "Batch 12: loss = 0.40829014778137207\n",
      "Batch 13: loss = 0.4134633541107178\n",
      "Batch 14: loss = 0.39301466941833496\n",
      "Batch 15: loss = 0.40348711609840393\n",
      "Batch 16: loss = 0.4185432195663452\n",
      "Batch 17: loss = 0.38132625818252563\n",
      "Batch 18: loss = 0.44265392422676086\n",
      "Batch 19: loss = 0.40684306621551514\n",
      "Batch 20: loss = 0.42439553141593933\n",
      "Batch 21: loss = 0.38836929202079773\n",
      "Batch 22: loss = 0.40416139364242554\n",
      "Batch 23: loss = 0.48345836997032166\n",
      "Batch 24: loss = 0.4254549443721771\n",
      "Batch 25: loss = 0.4133148789405823\n",
      "Batch 26: loss = 0.3834106922149658\n",
      "Batch 27: loss = 0.4926148056983948\n",
      "Batch 28: loss = 0.4686663746833801\n",
      "Batch 29: loss = 0.43901363015174866\n",
      "Batch 30: loss = 0.39237433671951294\n",
      "Batch 31: loss = 0.4568493366241455\n",
      "Batch 32: loss = 0.45544421672821045\n",
      "Batch 33: loss = 0.40986669063568115\n",
      "Batch 34: loss = 0.45214974880218506\n",
      "Batch 35: loss = 0.416272908449173\n",
      "Batch 36: loss = 0.36312416195869446\n",
      "Batch 37: loss = 0.3713788092136383\n",
      "Batch 38: loss = 0.4063096344470978\n",
      "Batch 39: loss = 0.37052807211875916\n",
      "Batch 40: loss = 0.4176960587501526\n",
      "Batch 41: loss = 0.4105134606361389\n",
      "Batch 42: loss = 0.4144270718097687\n",
      "Batch 43: loss = 0.45596548914909363\n",
      "Batch 44: loss = 0.36853212118148804\n",
      "Batch 45: loss = 0.3513115644454956\n",
      "Batch 46: loss = 0.3392416834831238\n",
      "Batch 47: loss = 0.38536393642425537\n",
      "Batch 48: loss = 0.3754923939704895\n",
      "Batch 49: loss = 0.36497873067855835\n",
      "Batch 50: loss = 0.3656456768512726\n",
      "Batch 51: loss = 0.3934857249259949\n",
      "Batch 52: loss = 0.41893109679222107\n",
      "Batch 53: loss = 0.42404353618621826\n",
      "Batch 54: loss = 0.3140396475791931\n",
      "Batch 55: loss = 0.36627164483070374\n",
      "Batch 56: loss = 0.4382253885269165\n",
      "Batch 57: loss = 0.4625858664512634\n",
      "Batch 58: loss = 0.4546492099761963\n",
      "Batch 59: loss = 0.3383645713329315\n",
      "Batch 60: loss = 0.3920353651046753\n",
      "Batch 61: loss = 0.3628654181957245\n",
      "Batch 62: loss = 0.5023994445800781\n",
      "Batch 63: loss = 0.3392646610736847\n",
      "Batch 64: loss = 0.3319290280342102\n",
      "Batch 65: loss = 0.4247305989265442\n",
      "Batch 66: loss = 0.41258475184440613\n",
      "Batch 67: loss = 0.43307891488075256\n",
      "Batch 68: loss = 0.41700756549835205\n",
      "Batch 69: loss = 0.3932836651802063\n",
      "Batch 70: loss = 0.47756341099739075\n",
      "Batch 71: loss = 0.46700596809387207\n",
      "Batch 72: loss = 0.412065327167511\n",
      "Batch 73: loss = 0.47583359479904175\n",
      "Batch 74: loss = 0.46999046206474304\n",
      "Batch 75: loss = 0.506014883518219\n",
      "Batch 76: loss = 0.4327930212020874\n",
      "Batch 77: loss = 0.4183294177055359\n",
      "Batch 78: loss = 0.4630679488182068\n",
      "Batch 79: loss = 0.40357598662376404\n",
      "Batch 80: loss = 0.4415571093559265\n",
      "Batch 81: loss = 0.432034969329834\n",
      "Batch 82: loss = 0.3650836944580078\n",
      "Batch 83: loss = 0.38905033469200134\n",
      "Batch 84: loss = 0.3939805030822754\n",
      "Batch 85: loss = 0.4898567795753479\n",
      "Batch 86: loss = 0.4281947910785675\n",
      "Batch 87: loss = 0.4005078971385956\n",
      "Batch 88: loss = 0.4759427011013031\n",
      "Batch 89: loss = 0.41750216484069824\n",
      "Batch 90: loss = 0.4473715126514435\n",
      "Batch 91: loss = 0.48903605341911316\n",
      "Batch 92: loss = 0.450481116771698\n",
      "Batch 93: loss = 0.4011008143424988\n",
      "Batch 94: loss = 0.4138760268688202\n",
      "Batch 95: loss = 0.40904563665390015\n",
      "Batch 96: loss = 0.4823233485221863\n",
      "Batch 97: loss = 0.37604546546936035\n",
      "Batch 98: loss = 0.3996489644050598\n",
      "Batch 99: loss = 0.4651644825935364\n",
      "Batch 100: loss = 0.46241509914398193\n",
      "Batch 101: loss = 0.43331509828567505\n",
      "Batch 102: loss = 0.41478776931762695\n",
      "Batch 103: loss = 0.42700451612472534\n",
      "Batch 104: loss = 0.38843458890914917\n",
      "Batch 105: loss = 0.39906492829322815\n",
      "Batch 106: loss = 0.40587669610977173\n",
      "Batch 107: loss = 0.397036075592041\n",
      "Batch 108: loss = 0.3993755578994751\n",
      "Batch 109: loss = 0.41889360547065735\n",
      "Batch 110: loss = 0.38086020946502686\n",
      "Batch 111: loss = 0.4462336301803589\n",
      "Batch 112: loss = 0.4460899233818054\n",
      "Batch 113: loss = 0.40685296058654785\n",
      "Batch 114: loss = 0.43283987045288086\n",
      "Batch 115: loss = 0.46177977323532104\n",
      "Batch 116: loss = 0.47422945499420166\n",
      "Batch 117: loss = 0.38592612743377686\n",
      "Batch 118: loss = 0.4069441556930542\n",
      "Batch 119: loss = 0.4318395256996155\n",
      "Batch 120: loss = 0.38741520047187805\n",
      "Batch 121: loss = 0.4171147644519806\n",
      "Batch 122: loss = 0.3929770588874817\n",
      "Batch 123: loss = 0.42924901843070984\n",
      "Batch 124: loss = 0.4364114999771118\n",
      "Batch 125: loss = 0.448167085647583\n",
      "Batch 126: loss = 0.42060214281082153\n",
      "\n",
      "Epoch 53/100\n",
      "Batch 1: loss = 0.41346415877342224\n",
      "Batch 2: loss = 0.4448032081127167\n",
      "Batch 3: loss = 0.3827459216117859\n",
      "Batch 4: loss = 0.40401262044906616\n",
      "Batch 5: loss = 0.4657548666000366\n",
      "Batch 6: loss = 0.47287219762802124\n",
      "Batch 7: loss = 0.38535329699516296\n",
      "Batch 8: loss = 0.4433952867984772\n",
      "Batch 9: loss = 0.38993507623672485\n",
      "Batch 10: loss = 0.34008556604385376\n",
      "Batch 11: loss = 0.4039788544178009\n",
      "Batch 12: loss = 0.45351552963256836\n",
      "Batch 13: loss = 0.3853780925273895\n",
      "Batch 14: loss = 0.38181406259536743\n",
      "Batch 15: loss = 0.3570430278778076\n",
      "Batch 16: loss = 0.42877790331840515\n",
      "Batch 17: loss = 0.386127233505249\n",
      "Batch 18: loss = 0.4400752782821655\n",
      "Batch 19: loss = 0.4389750361442566\n",
      "Batch 20: loss = 0.42935580015182495\n",
      "Batch 21: loss = 0.40764516592025757\n",
      "Batch 22: loss = 0.3703690767288208\n",
      "Batch 23: loss = 0.4449392557144165\n",
      "Batch 24: loss = 0.3994699716567993\n",
      "Batch 25: loss = 0.38947027921676636\n",
      "Batch 26: loss = 0.3809102177619934\n",
      "Batch 27: loss = 0.46620452404022217\n",
      "Batch 28: loss = 0.45601338148117065\n",
      "Batch 29: loss = 0.4416547119617462\n",
      "Batch 30: loss = 0.3855065107345581\n",
      "Batch 31: loss = 0.4591609239578247\n",
      "Batch 32: loss = 0.499772846698761\n",
      "Batch 33: loss = 0.40292632579803467\n",
      "Batch 34: loss = 0.4166470170021057\n",
      "Batch 35: loss = 0.41229626536369324\n",
      "Batch 36: loss = 0.34539908170700073\n",
      "Batch 37: loss = 0.36152568459510803\n",
      "Batch 38: loss = 0.3978821635246277\n",
      "Batch 39: loss = 0.36786195635795593\n",
      "Batch 40: loss = 0.40258708596229553\n",
      "Batch 41: loss = 0.3812188506126404\n",
      "Batch 42: loss = 0.4196532368659973\n",
      "Batch 43: loss = 0.43220391869544983\n",
      "Batch 44: loss = 0.39151033759117126\n",
      "Batch 45: loss = 0.32414472103118896\n",
      "Batch 46: loss = 0.37222546339035034\n",
      "Batch 47: loss = 0.4188622832298279\n",
      "Batch 48: loss = 0.38903602957725525\n",
      "Batch 49: loss = 0.37662187218666077\n",
      "Batch 50: loss = 0.3772476613521576\n",
      "Batch 51: loss = 0.422520250082016\n",
      "Batch 52: loss = 0.382156640291214\n",
      "Batch 53: loss = 0.4099085330963135\n",
      "Batch 54: loss = 0.33066326379776\n",
      "Batch 55: loss = 0.3608071804046631\n",
      "Batch 56: loss = 0.41440171003341675\n",
      "Batch 57: loss = 0.39655646681785583\n",
      "Batch 58: loss = 0.4254693388938904\n",
      "Batch 59: loss = 0.348217248916626\n",
      "Batch 60: loss = 0.3744446635246277\n",
      "Batch 61: loss = 0.37560662627220154\n",
      "Batch 62: loss = 0.4670170247554779\n",
      "Batch 63: loss = 0.37781596183776855\n",
      "Batch 64: loss = 0.31986770033836365\n",
      "Batch 65: loss = 0.38740217685699463\n",
      "Batch 66: loss = 0.39689889550209045\n",
      "Batch 67: loss = 0.39001405239105225\n",
      "Batch 68: loss = 0.39742353558540344\n",
      "Batch 69: loss = 0.3832509517669678\n",
      "Batch 70: loss = 0.4590691328048706\n",
      "Batch 71: loss = 0.4793304204940796\n",
      "Batch 72: loss = 0.38570767641067505\n",
      "Batch 73: loss = 0.44975215196609497\n",
      "Batch 74: loss = 0.42047470808029175\n",
      "Batch 75: loss = 0.47306397557258606\n",
      "Batch 76: loss = 0.3999745845794678\n",
      "Batch 77: loss = 0.4137395918369293\n",
      "Batch 78: loss = 0.4663501977920532\n",
      "Batch 79: loss = 0.3857993483543396\n",
      "Batch 80: loss = 0.42216062545776367\n",
      "Batch 81: loss = 0.41427478194236755\n",
      "Batch 82: loss = 0.375905841588974\n",
      "Batch 83: loss = 0.3881891071796417\n",
      "Batch 84: loss = 0.410426527261734\n",
      "Batch 85: loss = 0.48017552495002747\n",
      "Batch 86: loss = 0.4158400893211365\n",
      "Batch 87: loss = 0.41398414969444275\n",
      "Batch 88: loss = 0.5120598673820496\n",
      "Batch 89: loss = 0.35681748390197754\n",
      "Batch 90: loss = 0.45838552713394165\n",
      "Batch 91: loss = 0.45926550030708313\n",
      "Batch 92: loss = 0.41920047998428345\n",
      "Batch 93: loss = 0.3804038166999817\n",
      "Batch 94: loss = 0.38693955540657043\n",
      "Batch 95: loss = 0.4212798476219177\n",
      "Batch 96: loss = 0.4491342306137085\n",
      "Batch 97: loss = 0.3818613290786743\n",
      "Batch 98: loss = 0.4091654121875763\n",
      "Batch 99: loss = 0.45837169885635376\n",
      "Batch 100: loss = 0.4646107852458954\n",
      "Batch 101: loss = 0.39248910546302795\n",
      "Batch 102: loss = 0.4172334671020508\n",
      "Batch 103: loss = 0.3986468017101288\n",
      "Batch 104: loss = 0.34775668382644653\n",
      "Batch 105: loss = 0.4044860899448395\n",
      "Batch 106: loss = 0.41857415437698364\n",
      "Batch 107: loss = 0.40672576427459717\n",
      "Batch 108: loss = 0.4163209795951843\n",
      "Batch 109: loss = 0.4062424898147583\n",
      "Batch 110: loss = 0.3674163818359375\n",
      "Batch 111: loss = 0.46486300230026245\n",
      "Batch 112: loss = 0.445645272731781\n",
      "Batch 113: loss = 0.38155001401901245\n",
      "Batch 114: loss = 0.4316366910934448\n",
      "Batch 115: loss = 0.43666958808898926\n",
      "Batch 116: loss = 0.4816170334815979\n",
      "Batch 117: loss = 0.38756346702575684\n",
      "Batch 118: loss = 0.36201584339141846\n",
      "Batch 119: loss = 0.43988192081451416\n",
      "Batch 120: loss = 0.3952830135822296\n",
      "Batch 121: loss = 0.42826005816459656\n",
      "Batch 122: loss = 0.3788805603981018\n",
      "Batch 123: loss = 0.40794873237609863\n",
      "Batch 124: loss = 0.4330061078071594\n",
      "Batch 125: loss = 0.456360787153244\n",
      "Batch 126: loss = 0.4087623953819275\n",
      "\n",
      "Epoch 54/100\n",
      "Batch 1: loss = 0.39389580488204956\n",
      "Batch 2: loss = 0.42038166522979736\n",
      "Batch 3: loss = 0.4021320343017578\n",
      "Batch 4: loss = 0.4035399556159973\n",
      "Batch 5: loss = 0.45043981075286865\n",
      "Batch 6: loss = 0.4490300118923187\n",
      "Batch 7: loss = 0.3939005434513092\n",
      "Batch 8: loss = 0.4186720848083496\n",
      "Batch 9: loss = 0.4001404941082001\n",
      "Batch 10: loss = 0.3680509030818939\n",
      "Batch 11: loss = 0.3906194567680359\n",
      "Batch 12: loss = 0.4300163984298706\n",
      "Batch 13: loss = 0.4090258479118347\n",
      "Batch 14: loss = 0.39172908663749695\n",
      "Batch 15: loss = 0.3565419614315033\n",
      "Batch 16: loss = 0.41242608428001404\n",
      "Batch 17: loss = 0.4193649888038635\n",
      "Batch 18: loss = 0.4319879114627838\n",
      "Batch 19: loss = 0.38894444704055786\n",
      "Batch 20: loss = 0.39419201016426086\n",
      "Batch 21: loss = 0.4181823134422302\n",
      "Batch 22: loss = 0.3764786720275879\n",
      "Batch 23: loss = 0.43515267968177795\n",
      "Batch 24: loss = 0.3948274254798889\n",
      "Batch 25: loss = 0.41019219160079956\n",
      "Batch 26: loss = 0.39770299196243286\n",
      "Batch 27: loss = 0.48696184158325195\n",
      "Batch 28: loss = 0.4539085030555725\n",
      "Batch 29: loss = 0.4426473081111908\n",
      "Batch 30: loss = 0.3939879536628723\n",
      "Batch 31: loss = 0.42363041639328003\n",
      "Batch 32: loss = 0.4320305585861206\n",
      "Batch 33: loss = 0.3918015956878662\n",
      "Batch 34: loss = 0.416045606136322\n",
      "Batch 35: loss = 0.4030120372772217\n",
      "Batch 36: loss = 0.36406946182250977\n",
      "Batch 37: loss = 0.36383265256881714\n",
      "Batch 38: loss = 0.39391064643859863\n",
      "Batch 39: loss = 0.39369910955429077\n",
      "Batch 40: loss = 0.42447152733802795\n",
      "Batch 41: loss = 0.4043903946876526\n",
      "Batch 42: loss = 0.41003596782684326\n",
      "Batch 43: loss = 0.4382544755935669\n",
      "Batch 44: loss = 0.37960243225097656\n",
      "Batch 45: loss = 0.34753912687301636\n",
      "Batch 46: loss = 0.35616064071655273\n",
      "Batch 47: loss = 0.3807142972946167\n",
      "Batch 48: loss = 0.3652909994125366\n",
      "Batch 49: loss = 0.3458031117916107\n",
      "Batch 50: loss = 0.35745489597320557\n",
      "Batch 51: loss = 0.3781545162200928\n",
      "Batch 52: loss = 0.39702489972114563\n",
      "Batch 53: loss = 0.3922739624977112\n",
      "Batch 54: loss = 0.3299139738082886\n",
      "Batch 55: loss = 0.35857489705085754\n",
      "Batch 56: loss = 0.40528059005737305\n",
      "Batch 57: loss = 0.43064242601394653\n",
      "Batch 58: loss = 0.41805756092071533\n",
      "Batch 59: loss = 0.3070511817932129\n",
      "Batch 60: loss = 0.3819706439971924\n",
      "Batch 61: loss = 0.37995481491088867\n",
      "Batch 62: loss = 0.45315295457839966\n",
      "Batch 63: loss = 0.36939018964767456\n",
      "Batch 64: loss = 0.3345968425273895\n",
      "Batch 65: loss = 0.39023101329803467\n",
      "Batch 66: loss = 0.4088403582572937\n",
      "Batch 67: loss = 0.40391045808792114\n",
      "Batch 68: loss = 0.4247640371322632\n",
      "Batch 69: loss = 0.3940093517303467\n",
      "Batch 70: loss = 0.4608370065689087\n",
      "Batch 71: loss = 0.4468787908554077\n",
      "Batch 72: loss = 0.3620585799217224\n",
      "Batch 73: loss = 0.45685356855392456\n",
      "Batch 74: loss = 0.4303075969219208\n",
      "Batch 75: loss = 0.4657242000102997\n",
      "Batch 76: loss = 0.4474198818206787\n",
      "Batch 77: loss = 0.38727837800979614\n",
      "Batch 78: loss = 0.4252619743347168\n",
      "Batch 79: loss = 0.3992350697517395\n",
      "Batch 80: loss = 0.419695645570755\n",
      "Batch 81: loss = 0.41149652004241943\n",
      "Batch 82: loss = 0.38803187012672424\n",
      "Batch 83: loss = 0.3742026090621948\n",
      "Batch 84: loss = 0.392463743686676\n",
      "Batch 85: loss = 0.4570099711418152\n",
      "Batch 86: loss = 0.38985583186149597\n",
      "Batch 87: loss = 0.3827698230743408\n",
      "Batch 88: loss = 0.46125805377960205\n",
      "Batch 89: loss = 0.3745349645614624\n",
      "Batch 90: loss = 0.43227535486221313\n",
      "Batch 91: loss = 0.4421708583831787\n",
      "Batch 92: loss = 0.4583362340927124\n",
      "Batch 93: loss = 0.35755592584609985\n",
      "Batch 94: loss = 0.3724638521671295\n",
      "Batch 95: loss = 0.38885876536369324\n",
      "Batch 96: loss = 0.4584282636642456\n",
      "Batch 97: loss = 0.4019429385662079\n",
      "Batch 98: loss = 0.37982994318008423\n",
      "Batch 99: loss = 0.4424937069416046\n",
      "Batch 100: loss = 0.48059549927711487\n",
      "Batch 101: loss = 0.4125910997390747\n",
      "Batch 102: loss = 0.40475934743881226\n",
      "Batch 103: loss = 0.38768303394317627\n",
      "Batch 104: loss = 0.3900721073150635\n",
      "Batch 105: loss = 0.39187055826187134\n",
      "Batch 106: loss = 0.3819613456726074\n",
      "Batch 107: loss = 0.3773614764213562\n",
      "Batch 108: loss = 0.3975616991519928\n",
      "Batch 109: loss = 0.43183812499046326\n",
      "Batch 110: loss = 0.375827431678772\n",
      "Batch 111: loss = 0.44144827127456665\n",
      "Batch 112: loss = 0.4560798406600952\n",
      "Batch 113: loss = 0.4251013994216919\n",
      "Batch 114: loss = 0.42382535338401794\n",
      "Batch 115: loss = 0.42028793692588806\n",
      "Batch 116: loss = 0.4197050631046295\n",
      "Batch 117: loss = 0.3765537142753601\n",
      "Batch 118: loss = 0.38309240341186523\n",
      "Batch 119: loss = 0.40485942363739014\n",
      "Batch 120: loss = 0.38870739936828613\n",
      "Batch 121: loss = 0.41146302223205566\n",
      "Batch 122: loss = 0.35115230083465576\n",
      "Batch 123: loss = 0.4061529040336609\n",
      "Batch 124: loss = 0.4659142792224884\n",
      "Batch 125: loss = 0.45129165053367615\n",
      "Batch 126: loss = 0.4223366975784302\n",
      "\n",
      "Epoch 55/100\n",
      "Batch 1: loss = 0.39593058824539185\n",
      "Batch 2: loss = 0.4230528473854065\n",
      "Batch 3: loss = 0.3669252097606659\n",
      "Batch 4: loss = 0.3922831416130066\n",
      "Batch 5: loss = 0.4294567406177521\n",
      "Batch 6: loss = 0.4425649642944336\n",
      "Batch 7: loss = 0.39462801814079285\n",
      "Batch 8: loss = 0.37934428453445435\n",
      "Batch 9: loss = 0.40121734142303467\n",
      "Batch 10: loss = 0.3806259036064148\n",
      "Batch 11: loss = 0.3946613073348999\n",
      "Batch 12: loss = 0.40218544006347656\n",
      "Batch 13: loss = 0.3859281539916992\n",
      "Batch 14: loss = 0.4161410331726074\n",
      "Batch 15: loss = 0.34302568435668945\n",
      "Batch 16: loss = 0.4024120569229126\n",
      "Batch 17: loss = 0.38292431831359863\n",
      "Batch 18: loss = 0.39970898628234863\n",
      "Batch 19: loss = 0.3699207007884979\n",
      "Batch 20: loss = 0.38680070638656616\n",
      "Batch 21: loss = 0.3851585388183594\n",
      "Batch 22: loss = 0.4112933576107025\n",
      "Batch 23: loss = 0.41064006090164185\n",
      "Batch 24: loss = 0.39189374446868896\n",
      "Batch 25: loss = 0.3939298987388611\n",
      "Batch 26: loss = 0.3702349066734314\n",
      "Batch 27: loss = 0.4762380123138428\n",
      "Batch 28: loss = 0.4503772556781769\n",
      "Batch 29: loss = 0.44012048840522766\n",
      "Batch 30: loss = 0.3998737335205078\n",
      "Batch 31: loss = 0.413705974817276\n",
      "Batch 32: loss = 0.43052539229393005\n",
      "Batch 33: loss = 0.3995772898197174\n",
      "Batch 34: loss = 0.4423578381538391\n",
      "Batch 35: loss = 0.3965420424938202\n",
      "Batch 36: loss = 0.31749725341796875\n",
      "Batch 37: loss = 0.3381446599960327\n",
      "Batch 38: loss = 0.39493969082832336\n",
      "Batch 39: loss = 0.3664221465587616\n",
      "Batch 40: loss = 0.370796263217926\n",
      "Batch 41: loss = 0.38071104884147644\n",
      "Batch 42: loss = 0.4007188677787781\n",
      "Batch 43: loss = 0.4601355195045471\n",
      "Batch 44: loss = 0.3239469826221466\n",
      "Batch 45: loss = 0.3408690094947815\n",
      "Batch 46: loss = 0.35553309321403503\n",
      "Batch 47: loss = 0.3742079734802246\n",
      "Batch 48: loss = 0.4052767753601074\n",
      "Batch 49: loss = 0.33026230335235596\n",
      "Batch 50: loss = 0.3390907049179077\n",
      "Batch 51: loss = 0.3730602264404297\n",
      "Batch 52: loss = 0.40365344285964966\n",
      "Batch 53: loss = 0.36567068099975586\n",
      "Batch 54: loss = 0.31088078022003174\n",
      "Batch 55: loss = 0.3535560965538025\n",
      "Batch 56: loss = 0.38572436571121216\n",
      "Batch 57: loss = 0.39608848094940186\n",
      "Batch 58: loss = 0.4292656183242798\n",
      "Batch 59: loss = 0.31939733028411865\n",
      "Batch 60: loss = 0.36507448554039\n",
      "Batch 61: loss = 0.382405161857605\n",
      "Batch 62: loss = 0.46213528513908386\n",
      "Batch 63: loss = 0.3645256757736206\n",
      "Batch 64: loss = 0.3337504267692566\n",
      "Batch 65: loss = 0.38297268748283386\n",
      "Batch 66: loss = 0.39942508935928345\n",
      "Batch 67: loss = 0.3986906409263611\n",
      "Batch 68: loss = 0.3909090757369995\n",
      "Batch 69: loss = 0.36733531951904297\n",
      "Batch 70: loss = 0.44636809825897217\n",
      "Batch 71: loss = 0.4399200677871704\n",
      "Batch 72: loss = 0.35924217104911804\n",
      "Batch 73: loss = 0.42444512248039246\n",
      "Batch 74: loss = 0.4423474967479706\n",
      "Batch 75: loss = 0.4709767997264862\n",
      "Batch 76: loss = 0.41927000880241394\n",
      "Batch 77: loss = 0.4075067639350891\n",
      "Batch 78: loss = 0.3998781442642212\n",
      "Batch 79: loss = 0.3661969304084778\n",
      "Batch 80: loss = 0.40127187967300415\n",
      "Batch 81: loss = 0.3903672695159912\n",
      "Batch 82: loss = 0.3698621988296509\n",
      "Batch 83: loss = 0.39991921186447144\n",
      "Batch 84: loss = 0.3934895992279053\n",
      "Batch 85: loss = 0.4407983422279358\n",
      "Batch 86: loss = 0.4035801589488983\n",
      "Batch 87: loss = 0.3549554646015167\n",
      "Batch 88: loss = 0.4707188010215759\n",
      "Batch 89: loss = 0.3625161647796631\n",
      "Batch 90: loss = 0.41623789072036743\n",
      "Batch 91: loss = 0.44654184579849243\n",
      "Batch 92: loss = 0.41697007417678833\n",
      "Batch 93: loss = 0.37145429849624634\n",
      "Batch 94: loss = 0.393592894077301\n",
      "Batch 95: loss = 0.37562739849090576\n",
      "Batch 96: loss = 0.44394922256469727\n",
      "Batch 97: loss = 0.36873161792755127\n",
      "Batch 98: loss = 0.37994611263275146\n",
      "Batch 99: loss = 0.43449437618255615\n",
      "Batch 100: loss = 0.4509410262107849\n",
      "Batch 101: loss = 0.3778352439403534\n",
      "Batch 102: loss = 0.39778685569763184\n",
      "Batch 103: loss = 0.3998432755470276\n",
      "Batch 104: loss = 0.38712888956069946\n",
      "Batch 105: loss = 0.3787386119365692\n",
      "Batch 106: loss = 0.370716392993927\n",
      "Batch 107: loss = 0.3842164874076843\n",
      "Batch 108: loss = 0.3837023079395294\n",
      "Batch 109: loss = 0.4310373365879059\n",
      "Batch 110: loss = 0.35540398955345154\n",
      "Batch 111: loss = 0.4335780739784241\n",
      "Batch 112: loss = 0.4321640431880951\n",
      "Batch 113: loss = 0.4077887535095215\n",
      "Batch 114: loss = 0.4403408169746399\n",
      "Batch 115: loss = 0.4084118604660034\n",
      "Batch 116: loss = 0.45002055168151855\n",
      "Batch 117: loss = 0.37673425674438477\n",
      "Batch 118: loss = 0.36206182837486267\n",
      "Batch 119: loss = 0.4207639694213867\n",
      "Batch 120: loss = 0.40644389390945435\n",
      "Batch 121: loss = 0.4050842523574829\n",
      "Batch 122: loss = 0.3597547709941864\n",
      "Batch 123: loss = 0.41037243604660034\n",
      "Batch 124: loss = 0.4462778568267822\n",
      "Batch 125: loss = 0.3930915594100952\n",
      "Batch 126: loss = 0.424972802400589\n",
      "\n",
      "Epoch 56/100\n",
      "Batch 1: loss = 0.405556857585907\n",
      "Batch 2: loss = 0.42399275302886963\n",
      "Batch 3: loss = 0.37900233268737793\n",
      "Batch 4: loss = 0.38407444953918457\n",
      "Batch 5: loss = 0.4109348654747009\n",
      "Batch 6: loss = 0.4337586760520935\n",
      "Batch 7: loss = 0.37375468015670776\n",
      "Batch 8: loss = 0.41790062189102173\n",
      "Batch 9: loss = 0.39835768938064575\n",
      "Batch 10: loss = 0.3611867427825928\n",
      "Batch 11: loss = 0.39973175525665283\n",
      "Batch 12: loss = 0.4001728296279907\n",
      "Batch 13: loss = 0.39061158895492554\n",
      "Batch 14: loss = 0.4033769369125366\n",
      "Batch 15: loss = 0.36284884810447693\n",
      "Batch 16: loss = 0.4090976119041443\n",
      "Batch 17: loss = 0.3691753149032593\n",
      "Batch 18: loss = 0.4242163896560669\n",
      "Batch 19: loss = 0.4181663990020752\n",
      "Batch 20: loss = 0.4146949052810669\n",
      "Batch 21: loss = 0.39737147092819214\n",
      "Batch 22: loss = 0.3788348436355591\n",
      "Batch 23: loss = 0.42870384454727173\n",
      "Batch 24: loss = 0.3813698887825012\n",
      "Batch 25: loss = 0.3981049656867981\n",
      "Batch 26: loss = 0.3720000386238098\n",
      "Batch 27: loss = 0.45847705006599426\n",
      "Batch 28: loss = 0.4161699414253235\n",
      "Batch 29: loss = 0.4375458359718323\n",
      "Batch 30: loss = 0.39097142219543457\n",
      "Batch 31: loss = 0.41940581798553467\n",
      "Batch 32: loss = 0.45225095748901367\n",
      "Batch 33: loss = 0.37978804111480713\n",
      "Batch 34: loss = 0.41986775398254395\n",
      "Batch 35: loss = 0.3934488892555237\n",
      "Batch 36: loss = 0.3490027189254761\n",
      "Batch 37: loss = 0.3278312683105469\n",
      "Batch 38: loss = 0.4251399040222168\n",
      "Batch 39: loss = 0.38060635328292847\n",
      "Batch 40: loss = 0.37716835737228394\n",
      "Batch 41: loss = 0.3746100664138794\n",
      "Batch 42: loss = 0.40617889165878296\n",
      "Batch 43: loss = 0.4230507016181946\n",
      "Batch 44: loss = 0.37451171875\n",
      "Batch 45: loss = 0.34774643182754517\n",
      "Batch 46: loss = 0.35336774587631226\n",
      "Batch 47: loss = 0.3794093430042267\n",
      "Batch 48: loss = 0.37238606810569763\n",
      "Batch 49: loss = 0.3366023302078247\n",
      "Batch 50: loss = 0.3412511944770813\n",
      "Batch 51: loss = 0.39139845967292786\n",
      "Batch 52: loss = 0.4258374571800232\n",
      "Batch 53: loss = 0.3717016577720642\n",
      "Batch 54: loss = 0.32800042629241943\n",
      "Batch 55: loss = 0.3468667268753052\n",
      "Batch 56: loss = 0.38216662406921387\n",
      "Batch 57: loss = 0.4001333713531494\n",
      "Batch 58: loss = 0.4332689642906189\n",
      "Batch 59: loss = 0.31516286730766296\n",
      "Batch 60: loss = 0.3731098771095276\n",
      "Batch 61: loss = 0.3692651689052582\n",
      "Batch 62: loss = 0.406647652387619\n",
      "Batch 63: loss = 0.3612736463546753\n",
      "Batch 64: loss = 0.3157103657722473\n",
      "Batch 65: loss = 0.3731309175491333\n",
      "Batch 66: loss = 0.3593646287918091\n",
      "Batch 67: loss = 0.38652586936950684\n",
      "Batch 68: loss = 0.39396965503692627\n",
      "Batch 69: loss = 0.37670576572418213\n",
      "Batch 70: loss = 0.4328928589820862\n",
      "Batch 71: loss = 0.4179231822490692\n",
      "Batch 72: loss = 0.3851543664932251\n",
      "Batch 73: loss = 0.43690794706344604\n",
      "Batch 74: loss = 0.4279783070087433\n",
      "Batch 75: loss = 0.4683825373649597\n",
      "Batch 76: loss = 0.38107115030288696\n",
      "Batch 77: loss = 0.3720458447933197\n",
      "Batch 78: loss = 0.41470867395401\n",
      "Batch 79: loss = 0.3875833749771118\n",
      "Batch 80: loss = 0.39512568712234497\n",
      "Batch 81: loss = 0.3955722153186798\n",
      "Batch 82: loss = 0.36338549852371216\n",
      "Batch 83: loss = 0.351662814617157\n",
      "Batch 84: loss = 0.4061397314071655\n",
      "Batch 85: loss = 0.46123266220092773\n",
      "Batch 86: loss = 0.3649109899997711\n",
      "Batch 87: loss = 0.35341984033584595\n",
      "Batch 88: loss = 0.4880690276622772\n",
      "Batch 89: loss = 0.363370418548584\n",
      "Batch 90: loss = 0.40973949432373047\n",
      "Batch 91: loss = 0.4265739321708679\n",
      "Batch 92: loss = 0.4185117483139038\n",
      "Batch 93: loss = 0.3561667799949646\n",
      "Batch 94: loss = 0.3834742307662964\n",
      "Batch 95: loss = 0.3971198797225952\n",
      "Batch 96: loss = 0.44014105200767517\n",
      "Batch 97: loss = 0.3793528079986572\n",
      "Batch 98: loss = 0.38189077377319336\n",
      "Batch 99: loss = 0.44134360551834106\n",
      "Batch 100: loss = 0.4291050434112549\n",
      "Batch 101: loss = 0.40857332944869995\n",
      "Batch 102: loss = 0.4308202862739563\n",
      "Batch 103: loss = 0.3939115107059479\n",
      "Batch 104: loss = 0.37360572814941406\n",
      "Batch 105: loss = 0.37047064304351807\n",
      "Batch 106: loss = 0.4064275920391083\n",
      "Batch 107: loss = 0.40092265605926514\n",
      "Batch 108: loss = 0.3905562162399292\n",
      "Batch 109: loss = 0.4166986346244812\n",
      "Batch 110: loss = 0.35582196712493896\n",
      "Batch 111: loss = 0.4228283166885376\n",
      "Batch 112: loss = 0.4256255626678467\n",
      "Batch 113: loss = 0.3904029130935669\n",
      "Batch 114: loss = 0.4343169629573822\n",
      "Batch 115: loss = 0.42075902223587036\n",
      "Batch 116: loss = 0.4028235673904419\n",
      "Batch 117: loss = 0.3832668662071228\n",
      "Batch 118: loss = 0.3609124422073364\n",
      "Batch 119: loss = 0.40300291776657104\n",
      "Batch 120: loss = 0.4103061556816101\n",
      "Batch 121: loss = 0.40146806836128235\n",
      "Batch 122: loss = 0.3768733739852905\n",
      "Batch 123: loss = 0.3985818922519684\n",
      "Batch 124: loss = 0.43952763080596924\n",
      "Batch 125: loss = 0.42317265272140503\n",
      "Batch 126: loss = 0.4071165919303894\n",
      "\n",
      "Epoch 57/100\n",
      "Batch 1: loss = 0.4103285074234009\n",
      "Batch 2: loss = 0.4145207107067108\n",
      "Batch 3: loss = 0.3659340441226959\n",
      "Batch 4: loss = 0.4002794623374939\n",
      "Batch 5: loss = 0.3956209719181061\n",
      "Batch 6: loss = 0.4074151813983917\n",
      "Batch 7: loss = 0.3757479786872864\n",
      "Batch 8: loss = 0.3784503936767578\n",
      "Batch 9: loss = 0.3825751543045044\n",
      "Batch 10: loss = 0.3543327748775482\n",
      "Batch 11: loss = 0.40355056524276733\n",
      "Batch 12: loss = 0.4040505290031433\n",
      "Batch 13: loss = 0.39574146270751953\n",
      "Batch 14: loss = 0.38989460468292236\n",
      "Batch 15: loss = 0.3488309383392334\n",
      "Batch 16: loss = 0.4176585078239441\n",
      "Batch 17: loss = 0.36781787872314453\n",
      "Batch 18: loss = 0.40796875953674316\n",
      "Batch 19: loss = 0.35902929306030273\n",
      "Batch 20: loss = 0.3631460666656494\n",
      "Batch 21: loss = 0.3832002878189087\n",
      "Batch 22: loss = 0.3849431872367859\n",
      "Batch 23: loss = 0.4457438588142395\n",
      "Batch 24: loss = 0.36608433723449707\n",
      "Batch 25: loss = 0.36128559708595276\n",
      "Batch 26: loss = 0.354117751121521\n",
      "Batch 27: loss = 0.46022993326187134\n",
      "Batch 28: loss = 0.4249842166900635\n",
      "Batch 29: loss = 0.44448453187942505\n",
      "Batch 30: loss = 0.3902035355567932\n",
      "Batch 31: loss = 0.4235292375087738\n",
      "Batch 32: loss = 0.41536617279052734\n",
      "Batch 33: loss = 0.4071964621543884\n",
      "Batch 34: loss = 0.40608739852905273\n",
      "Batch 35: loss = 0.3928394317626953\n",
      "Batch 36: loss = 0.36009451746940613\n",
      "Batch 37: loss = 0.3314164876937866\n",
      "Batch 38: loss = 0.3791483938694\n",
      "Batch 39: loss = 0.3938330411911011\n",
      "Batch 40: loss = 0.3894418478012085\n",
      "Batch 41: loss = 0.36189842224121094\n",
      "Batch 42: loss = 0.3934454917907715\n",
      "Batch 43: loss = 0.41374504566192627\n",
      "Batch 44: loss = 0.35263848304748535\n",
      "Batch 45: loss = 0.33609163761138916\n",
      "Batch 46: loss = 0.35741540789604187\n",
      "Batch 47: loss = 0.35783565044403076\n",
      "Batch 48: loss = 0.36880427598953247\n",
      "Batch 49: loss = 0.34900325536727905\n",
      "Batch 50: loss = 0.35233527421951294\n",
      "Batch 51: loss = 0.3668155074119568\n",
      "Batch 52: loss = 0.40799593925476074\n",
      "Batch 53: loss = 0.3631038963794708\n",
      "Batch 54: loss = 0.3120476007461548\n",
      "Batch 55: loss = 0.30772435665130615\n",
      "Batch 56: loss = 0.39651817083358765\n",
      "Batch 57: loss = 0.4065037965774536\n",
      "Batch 58: loss = 0.42100852727890015\n",
      "Batch 59: loss = 0.27135369181632996\n",
      "Batch 60: loss = 0.3450278639793396\n",
      "Batch 61: loss = 0.38300392031669617\n",
      "Batch 62: loss = 0.4291796088218689\n",
      "Batch 63: loss = 0.331581711769104\n",
      "Batch 64: loss = 0.33448997139930725\n",
      "Batch 65: loss = 0.354667067527771\n",
      "Batch 66: loss = 0.38149023056030273\n",
      "Batch 67: loss = 0.36729779839515686\n",
      "Batch 68: loss = 0.3955550491809845\n",
      "Batch 69: loss = 0.3872474431991577\n",
      "Batch 70: loss = 0.4665541648864746\n",
      "Batch 71: loss = 0.43145179748535156\n",
      "Batch 72: loss = 0.3723362684249878\n",
      "Batch 73: loss = 0.4327463209629059\n",
      "Batch 74: loss = 0.4273855984210968\n",
      "Batch 75: loss = 0.47168073058128357\n",
      "Batch 76: loss = 0.38304418325424194\n",
      "Batch 77: loss = 0.3724045753479004\n",
      "Batch 78: loss = 0.4019758701324463\n",
      "Batch 79: loss = 0.3621761202812195\n",
      "Batch 80: loss = 0.3978695869445801\n",
      "Batch 81: loss = 0.39818713068962097\n",
      "Batch 82: loss = 0.3802293539047241\n",
      "Batch 83: loss = 0.3762667775154114\n",
      "Batch 84: loss = 0.40714481472969055\n",
      "Batch 85: loss = 0.4781588315963745\n",
      "Batch 86: loss = 0.3938252925872803\n",
      "Batch 87: loss = 0.3527623414993286\n",
      "Batch 88: loss = 0.45574480295181274\n",
      "Batch 89: loss = 0.4103468358516693\n",
      "Batch 90: loss = 0.42360353469848633\n",
      "Batch 91: loss = 0.4321141541004181\n",
      "Batch 92: loss = 0.41006234288215637\n",
      "Batch 93: loss = 0.3697100281715393\n",
      "Batch 94: loss = 0.3455999493598938\n",
      "Batch 95: loss = 0.3653562664985657\n",
      "Batch 96: loss = 0.4526416063308716\n",
      "Batch 97: loss = 0.3743865489959717\n",
      "Batch 98: loss = 0.360573947429657\n",
      "Batch 99: loss = 0.44680166244506836\n",
      "Batch 100: loss = 0.4470919072628021\n",
      "Batch 101: loss = 0.383821964263916\n",
      "Batch 102: loss = 0.41620635986328125\n",
      "Batch 103: loss = 0.37768498063087463\n",
      "Batch 104: loss = 0.376286119222641\n",
      "Batch 105: loss = 0.3648800849914551\n",
      "Batch 106: loss = 0.3846609592437744\n",
      "Batch 107: loss = 0.3741454780101776\n",
      "Batch 108: loss = 0.39626234769821167\n",
      "Batch 109: loss = 0.41788655519485474\n",
      "Batch 110: loss = 0.33053094148635864\n",
      "Batch 111: loss = 0.43204596638679504\n",
      "Batch 112: loss = 0.44078710675239563\n",
      "Batch 113: loss = 0.3971709609031677\n",
      "Batch 114: loss = 0.40638062357902527\n",
      "Batch 115: loss = 0.4048428535461426\n",
      "Batch 116: loss = 0.3765300512313843\n",
      "Batch 117: loss = 0.4020508825778961\n",
      "Batch 118: loss = 0.36705857515335083\n",
      "Batch 119: loss = 0.40066707134246826\n",
      "Batch 120: loss = 0.3700440227985382\n",
      "Batch 121: loss = 0.3706779181957245\n",
      "Batch 122: loss = 0.347553551197052\n",
      "Batch 123: loss = 0.3822345733642578\n",
      "Batch 124: loss = 0.4222886562347412\n",
      "Batch 125: loss = 0.3947868347167969\n",
      "Batch 126: loss = 0.39024895429611206\n",
      "\n",
      "Epoch 58/100\n",
      "Batch 1: loss = 0.39559638500213623\n",
      "Batch 2: loss = 0.38751983642578125\n",
      "Batch 3: loss = 0.37647682428359985\n",
      "Batch 4: loss = 0.4172728657722473\n",
      "Batch 5: loss = 0.39564603567123413\n",
      "Batch 6: loss = 0.40527868270874023\n",
      "Batch 7: loss = 0.3460097312927246\n",
      "Batch 8: loss = 0.3960931897163391\n",
      "Batch 9: loss = 0.3996342122554779\n",
      "Batch 10: loss = 0.3493051826953888\n",
      "Batch 11: loss = 0.41663435101509094\n",
      "Batch 12: loss = 0.37436801195144653\n",
      "Batch 13: loss = 0.35837703943252563\n",
      "Batch 14: loss = 0.37792885303497314\n",
      "Batch 15: loss = 0.3334842920303345\n",
      "Batch 16: loss = 0.39084553718566895\n",
      "Batch 17: loss = 0.36926954984664917\n",
      "Batch 18: loss = 0.3885612189769745\n",
      "Batch 19: loss = 0.42614126205444336\n",
      "Batch 20: loss = 0.384814977645874\n",
      "Batch 21: loss = 0.3915097117424011\n",
      "Batch 22: loss = 0.37551674246788025\n",
      "Batch 23: loss = 0.44599002599716187\n",
      "Batch 24: loss = 0.3627702593803406\n",
      "Batch 25: loss = 0.36267322301864624\n",
      "Batch 26: loss = 0.3891107439994812\n",
      "Batch 27: loss = 0.4882003962993622\n",
      "Batch 28: loss = 0.4168546497821808\n",
      "Batch 29: loss = 0.4320276975631714\n",
      "Batch 30: loss = 0.3931804299354553\n",
      "Batch 31: loss = 0.4139435589313507\n",
      "Batch 32: loss = 0.4005178213119507\n",
      "Batch 33: loss = 0.3869591951370239\n",
      "Batch 34: loss = 0.38940179347991943\n",
      "Batch 35: loss = 0.3829249143600464\n",
      "Batch 36: loss = 0.3309112787246704\n",
      "Batch 37: loss = 0.33345839381217957\n",
      "Batch 38: loss = 0.36212873458862305\n",
      "Batch 39: loss = 0.3711979389190674\n",
      "Batch 40: loss = 0.3507920503616333\n",
      "Batch 41: loss = 0.3701571226119995\n",
      "Batch 42: loss = 0.39696237444877625\n",
      "Batch 43: loss = 0.41128140687942505\n",
      "Batch 44: loss = 0.35173261165618896\n",
      "Batch 45: loss = 0.3317660689353943\n",
      "Batch 46: loss = 0.3398992717266083\n",
      "Batch 47: loss = 0.37908047437667847\n",
      "Batch 48: loss = 0.3325040936470032\n",
      "Batch 49: loss = 0.32761475443840027\n",
      "Batch 50: loss = 0.35914021730422974\n",
      "Batch 51: loss = 0.3793463706970215\n",
      "Batch 52: loss = 0.38271358609199524\n",
      "Batch 53: loss = 0.3652111291885376\n",
      "Batch 54: loss = 0.32386887073516846\n",
      "Batch 55: loss = 0.32726436853408813\n",
      "Batch 56: loss = 0.37059295177459717\n",
      "Batch 57: loss = 0.4250091314315796\n",
      "Batch 58: loss = 0.36242806911468506\n",
      "Batch 59: loss = 0.3199307322502136\n",
      "Batch 60: loss = 0.34427571296691895\n",
      "Batch 61: loss = 0.3433174192905426\n",
      "Batch 62: loss = 0.4282582998275757\n",
      "Batch 63: loss = 0.3395373225212097\n",
      "Batch 64: loss = 0.32477110624313354\n",
      "Batch 65: loss = 0.40916669368743896\n",
      "Batch 66: loss = 0.40560007095336914\n",
      "Batch 67: loss = 0.3645443618297577\n",
      "Batch 68: loss = 0.35336410999298096\n",
      "Batch 69: loss = 0.36026978492736816\n",
      "Batch 70: loss = 0.41741523146629333\n",
      "Batch 71: loss = 0.43465864658355713\n",
      "Batch 72: loss = 0.3639991879463196\n",
      "Batch 73: loss = 0.4105982184410095\n",
      "Batch 74: loss = 0.43194204568862915\n",
      "Batch 75: loss = 0.44383400678634644\n",
      "Batch 76: loss = 0.3761499524116516\n",
      "Batch 77: loss = 0.37097686529159546\n",
      "Batch 78: loss = 0.3841729164123535\n",
      "Batch 79: loss = 0.38634154200553894\n",
      "Batch 80: loss = 0.38592901825904846\n",
      "Batch 81: loss = 0.395418643951416\n",
      "Batch 82: loss = 0.35275501012802124\n",
      "Batch 83: loss = 0.3708011209964752\n",
      "Batch 84: loss = 0.3999149799346924\n",
      "Batch 85: loss = 0.4470265805721283\n",
      "Batch 86: loss = 0.3754562735557556\n",
      "Batch 87: loss = 0.37821775674819946\n",
      "Batch 88: loss = 0.42030245065689087\n",
      "Batch 89: loss = 0.3689667284488678\n",
      "Batch 90: loss = 0.41423875093460083\n",
      "Batch 91: loss = 0.4186564087867737\n",
      "Batch 92: loss = 0.44637367129325867\n",
      "Batch 93: loss = 0.3370044231414795\n",
      "Batch 94: loss = 0.36090677976608276\n",
      "Batch 95: loss = 0.3633759617805481\n",
      "Batch 96: loss = 0.46128755807876587\n",
      "Batch 97: loss = 0.40303200483322144\n",
      "Batch 98: loss = 0.3489525616168976\n",
      "Batch 99: loss = 0.4386681020259857\n",
      "Batch 100: loss = 0.39727649092674255\n",
      "Batch 101: loss = 0.37132400274276733\n",
      "Batch 102: loss = 0.39117035269737244\n",
      "Batch 103: loss = 0.3795280158519745\n",
      "Batch 104: loss = 0.3845062851905823\n",
      "Batch 105: loss = 0.38239461183547974\n",
      "Batch 106: loss = 0.3964189887046814\n",
      "Batch 107: loss = 0.3640410602092743\n",
      "Batch 108: loss = 0.3982608914375305\n",
      "Batch 109: loss = 0.3798485994338989\n",
      "Batch 110: loss = 0.3603518009185791\n",
      "Batch 111: loss = 0.42390763759613037\n",
      "Batch 112: loss = 0.40233877301216125\n",
      "Batch 113: loss = 0.3963010311126709\n",
      "Batch 114: loss = 0.43381208181381226\n",
      "Batch 115: loss = 0.43091273307800293\n",
      "Batch 116: loss = 0.40011656284332275\n",
      "Batch 117: loss = 0.35983455181121826\n",
      "Batch 118: loss = 0.34180691838264465\n",
      "Batch 119: loss = 0.3834278881549835\n",
      "Batch 120: loss = 0.33399564027786255\n",
      "Batch 121: loss = 0.3749392032623291\n",
      "Batch 122: loss = 0.347708523273468\n",
      "Batch 123: loss = 0.3797292113304138\n",
      "Batch 124: loss = 0.38218289613723755\n",
      "Batch 125: loss = 0.41329890489578247\n",
      "Batch 126: loss = 0.3935779929161072\n",
      "\n",
      "Epoch 59/100\n",
      "Batch 1: loss = 0.39735329151153564\n",
      "Batch 2: loss = 0.38757437467575073\n",
      "Batch 3: loss = 0.37781673669815063\n",
      "Batch 4: loss = 0.3644254505634308\n",
      "Batch 5: loss = 0.3955734968185425\n",
      "Batch 6: loss = 0.4044848084449768\n",
      "Batch 7: loss = 0.35153335332870483\n",
      "Batch 8: loss = 0.3762054741382599\n",
      "Batch 9: loss = 0.37833333015441895\n",
      "Batch 10: loss = 0.3427858352661133\n",
      "Batch 11: loss = 0.39371156692504883\n",
      "Batch 12: loss = 0.3836681544780731\n",
      "Batch 13: loss = 0.3403710126876831\n",
      "Batch 14: loss = 0.3841514587402344\n",
      "Batch 15: loss = 0.3309900760650635\n",
      "Batch 16: loss = 0.3760772943496704\n",
      "Batch 17: loss = 0.37814009189605713\n",
      "Batch 18: loss = 0.4022088646888733\n",
      "Batch 19: loss = 0.3786737322807312\n",
      "Batch 20: loss = 0.36913424730300903\n",
      "Batch 21: loss = 0.40170055627822876\n",
      "Batch 22: loss = 0.39869803190231323\n",
      "Batch 23: loss = 0.4222354292869568\n",
      "Batch 24: loss = 0.3737804889678955\n",
      "Batch 25: loss = 0.3679230213165283\n",
      "Batch 26: loss = 0.3401794135570526\n",
      "Batch 27: loss = 0.4323551654815674\n",
      "Batch 28: loss = 0.38811153173446655\n",
      "Batch 29: loss = 0.4270815849304199\n",
      "Batch 30: loss = 0.3852829039096832\n",
      "Batch 31: loss = 0.3746562600135803\n",
      "Batch 32: loss = 0.3684064745903015\n",
      "Batch 33: loss = 0.359569251537323\n",
      "Batch 34: loss = 0.3768431544303894\n",
      "Batch 35: loss = 0.350375771522522\n",
      "Batch 36: loss = 0.3364849090576172\n",
      "Batch 37: loss = 0.33623212575912476\n",
      "Batch 38: loss = 0.3668879270553589\n",
      "Batch 39: loss = 0.3573956787586212\n",
      "Batch 40: loss = 0.3665617108345032\n",
      "Batch 41: loss = 0.37828683853149414\n",
      "Batch 42: loss = 0.38569390773773193\n",
      "Batch 43: loss = 0.4056438207626343\n",
      "Batch 44: loss = 0.3816545009613037\n",
      "Batch 45: loss = 0.31180769205093384\n",
      "Batch 46: loss = 0.36200910806655884\n",
      "Batch 47: loss = 0.3566032648086548\n",
      "Batch 48: loss = 0.3756045401096344\n",
      "Batch 49: loss = 0.31450939178466797\n",
      "Batch 50: loss = 0.35456645488739014\n",
      "Batch 51: loss = 0.35711419582366943\n",
      "Batch 52: loss = 0.4036988615989685\n",
      "Batch 53: loss = 0.3441198468208313\n",
      "Batch 54: loss = 0.3067254424095154\n",
      "Batch 55: loss = 0.3432675004005432\n",
      "Batch 56: loss = 0.37408721446990967\n",
      "Batch 57: loss = 0.3816149830818176\n",
      "Batch 58: loss = 0.4007072150707245\n",
      "Batch 59: loss = 0.28937268257141113\n",
      "Batch 60: loss = 0.36722931265830994\n",
      "Batch 61: loss = 0.3844751715660095\n",
      "Batch 62: loss = 0.41119956970214844\n",
      "Batch 63: loss = 0.3304096460342407\n",
      "Batch 64: loss = 0.306904137134552\n",
      "Batch 65: loss = 0.37033140659332275\n",
      "Batch 66: loss = 0.38897037506103516\n",
      "Batch 67: loss = 0.3701856732368469\n",
      "Batch 68: loss = 0.398252010345459\n",
      "Batch 69: loss = 0.3597663342952728\n",
      "Batch 70: loss = 0.42226123809814453\n",
      "Batch 71: loss = 0.4264170527458191\n",
      "Batch 72: loss = 0.35048428177833557\n",
      "Batch 73: loss = 0.404590368270874\n",
      "Batch 74: loss = 0.4276081919670105\n",
      "Batch 75: loss = 0.4660014510154724\n",
      "Batch 76: loss = 0.3750377297401428\n",
      "Batch 77: loss = 0.3865126967430115\n",
      "Batch 78: loss = 0.42701956629753113\n",
      "Batch 79: loss = 0.366560697555542\n",
      "Batch 80: loss = 0.36783120036125183\n",
      "Batch 81: loss = 0.40532177686691284\n",
      "Batch 82: loss = 0.33647117018699646\n",
      "Batch 83: loss = 0.38063400983810425\n",
      "Batch 84: loss = 0.3903989791870117\n",
      "Batch 85: loss = 0.4948359727859497\n",
      "Batch 86: loss = 0.38873744010925293\n",
      "Batch 87: loss = 0.36439603567123413\n",
      "Batch 88: loss = 0.45524099469184875\n",
      "Batch 89: loss = 0.34099122881889343\n",
      "Batch 90: loss = 0.3895798921585083\n",
      "Batch 91: loss = 0.4360727071762085\n",
      "Batch 92: loss = 0.4195922017097473\n",
      "Batch 93: loss = 0.3874667286872864\n",
      "Batch 94: loss = 0.3587382435798645\n",
      "Batch 95: loss = 0.3413766324520111\n",
      "Batch 96: loss = 0.41336286067962646\n",
      "Batch 97: loss = 0.36766529083251953\n",
      "Batch 98: loss = 0.37314191460609436\n",
      "Batch 99: loss = 0.41597771644592285\n",
      "Batch 100: loss = 0.4366849660873413\n",
      "Batch 101: loss = 0.38193202018737793\n",
      "Batch 102: loss = 0.3791723847389221\n",
      "Batch 103: loss = 0.38330960273742676\n",
      "Batch 104: loss = 0.33078664541244507\n",
      "Batch 105: loss = 0.34131306409835815\n",
      "Batch 106: loss = 0.36810117959976196\n",
      "Batch 107: loss = 0.35808199644088745\n",
      "Batch 108: loss = 0.3917570114135742\n",
      "Batch 109: loss = 0.3679797649383545\n",
      "Batch 110: loss = 0.3467685878276825\n",
      "Batch 111: loss = 0.426736056804657\n",
      "Batch 112: loss = 0.4279159903526306\n",
      "Batch 113: loss = 0.4029385447502136\n",
      "Batch 114: loss = 0.3842430114746094\n",
      "Batch 115: loss = 0.3565685749053955\n",
      "Batch 116: loss = 0.37350374460220337\n",
      "Batch 117: loss = 0.3690806031227112\n",
      "Batch 118: loss = 0.3258231282234192\n",
      "Batch 119: loss = 0.39492225646972656\n",
      "Batch 120: loss = 0.3653630018234253\n",
      "Batch 121: loss = 0.35558879375457764\n",
      "Batch 122: loss = 0.33912962675094604\n",
      "Batch 123: loss = 0.3923647105693817\n",
      "Batch 124: loss = 0.4071611762046814\n",
      "Batch 125: loss = 0.4091431796550751\n",
      "Batch 126: loss = 0.38507190346717834\n",
      "\n",
      "Epoch 60/100\n",
      "Batch 1: loss = 0.3775726556777954\n",
      "Batch 2: loss = 0.37353694438934326\n",
      "Batch 3: loss = 0.377216637134552\n",
      "Batch 4: loss = 0.34996795654296875\n",
      "Batch 5: loss = 0.39852792024612427\n",
      "Batch 6: loss = 0.40499377250671387\n",
      "Batch 7: loss = 0.3739593029022217\n",
      "Batch 8: loss = 0.3877614736557007\n",
      "Batch 9: loss = 0.37035879492759705\n",
      "Batch 10: loss = 0.34503796696662903\n",
      "Batch 11: loss = 0.4008616805076599\n",
      "Batch 12: loss = 0.3757464289665222\n",
      "Batch 13: loss = 0.33602508902549744\n",
      "Batch 14: loss = 0.382296085357666\n",
      "Batch 15: loss = 0.32438790798187256\n",
      "Batch 16: loss = 0.36354100704193115\n",
      "Batch 17: loss = 0.3622797727584839\n",
      "Batch 18: loss = 0.3704643249511719\n",
      "Batch 19: loss = 0.3972012996673584\n",
      "Batch 20: loss = 0.3452867269515991\n",
      "Batch 21: loss = 0.3774619698524475\n",
      "Batch 22: loss = 0.3686523735523224\n",
      "Batch 23: loss = 0.40693098306655884\n",
      "Batch 24: loss = 0.36012619733810425\n",
      "Batch 25: loss = 0.3934485912322998\n",
      "Batch 26: loss = 0.3523435592651367\n",
      "Batch 27: loss = 0.43490755558013916\n",
      "Batch 28: loss = 0.3961695730686188\n",
      "Batch 29: loss = 0.39884984493255615\n",
      "Batch 30: loss = 0.389342725276947\n",
      "Batch 31: loss = 0.41195929050445557\n",
      "Batch 32: loss = 0.42509394884109497\n",
      "Batch 33: loss = 0.3780108690261841\n",
      "Batch 34: loss = 0.3869509994983673\n",
      "Batch 35: loss = 0.3843243718147278\n",
      "Batch 36: loss = 0.293535977602005\n",
      "Batch 37: loss = 0.3495282530784607\n",
      "Batch 38: loss = 0.33550795912742615\n",
      "Batch 39: loss = 0.33769822120666504\n",
      "Batch 40: loss = 0.34664711356163025\n",
      "Batch 41: loss = 0.3598141074180603\n",
      "Batch 42: loss = 0.3504179120063782\n",
      "Batch 43: loss = 0.4068247377872467\n",
      "Batch 44: loss = 0.3493803143501282\n",
      "Batch 45: loss = 0.350003182888031\n",
      "Batch 46: loss = 0.2928335666656494\n",
      "Batch 47: loss = 0.36190667748451233\n",
      "Batch 48: loss = 0.31759417057037354\n",
      "Batch 49: loss = 0.3139701187610626\n",
      "Batch 50: loss = 0.3194582164287567\n",
      "Batch 51: loss = 0.36257603764533997\n",
      "Batch 52: loss = 0.38037121295928955\n",
      "Batch 53: loss = 0.3231801986694336\n",
      "Batch 54: loss = 0.29436051845550537\n",
      "Batch 55: loss = 0.2931104898452759\n",
      "Batch 56: loss = 0.36530667543411255\n",
      "Batch 57: loss = 0.4028872847557068\n",
      "Batch 58: loss = 0.38091978430747986\n",
      "Batch 59: loss = 0.27449291944503784\n",
      "Batch 60: loss = 0.3328120708465576\n",
      "Batch 61: loss = 0.33060693740844727\n",
      "Batch 62: loss = 0.4213743805885315\n",
      "Batch 63: loss = 0.3213587701320648\n",
      "Batch 64: loss = 0.3185294270515442\n",
      "Batch 65: loss = 0.35760825872421265\n",
      "Batch 66: loss = 0.3555595278739929\n",
      "Batch 67: loss = 0.3359839916229248\n",
      "Batch 68: loss = 0.3925652503967285\n",
      "Batch 69: loss = 0.3555452227592468\n",
      "Batch 70: loss = 0.40442001819610596\n",
      "Batch 71: loss = 0.41026726365089417\n",
      "Batch 72: loss = 0.34034866094589233\n",
      "Batch 73: loss = 0.39807265996932983\n",
      "Batch 74: loss = 0.37937653064727783\n",
      "Batch 75: loss = 0.4276857376098633\n",
      "Batch 76: loss = 0.388217031955719\n",
      "Batch 77: loss = 0.3572254776954651\n",
      "Batch 78: loss = 0.3828824460506439\n",
      "Batch 79: loss = 0.3713628053665161\n",
      "Batch 80: loss = 0.3793261647224426\n",
      "Batch 81: loss = 0.3769710063934326\n",
      "Batch 82: loss = 0.3643209934234619\n",
      "Batch 83: loss = 0.362251341342926\n",
      "Batch 84: loss = 0.3785246014595032\n",
      "Batch 85: loss = 0.40930837392807007\n",
      "Batch 86: loss = 0.36885908246040344\n",
      "Batch 87: loss = 0.3343795835971832\n",
      "Batch 88: loss = 0.4236690104007721\n",
      "Batch 89: loss = 0.36238014698028564\n",
      "Batch 90: loss = 0.3708096146583557\n",
      "Batch 91: loss = 0.42994940280914307\n",
      "Batch 92: loss = 0.4143771529197693\n",
      "Batch 93: loss = 0.33441588282585144\n",
      "Batch 94: loss = 0.3731303811073303\n",
      "Batch 95: loss = 0.37103790044784546\n",
      "Batch 96: loss = 0.4079446494579315\n",
      "Batch 97: loss = 0.352112352848053\n",
      "Batch 98: loss = 0.372028112411499\n",
      "Batch 99: loss = 0.4328366816043854\n",
      "Batch 100: loss = 0.44382983446121216\n",
      "Batch 101: loss = 0.3837464451789856\n",
      "Batch 102: loss = 0.37639424204826355\n",
      "Batch 103: loss = 0.3724907636642456\n",
      "Batch 104: loss = 0.3388023376464844\n",
      "Batch 105: loss = 0.3420965075492859\n",
      "Batch 106: loss = 0.38958626985549927\n",
      "Batch 107: loss = 0.3386562466621399\n",
      "Batch 108: loss = 0.4006563127040863\n",
      "Batch 109: loss = 0.4015563726425171\n",
      "Batch 110: loss = 0.3443088233470917\n",
      "Batch 111: loss = 0.39794665575027466\n",
      "Batch 112: loss = 0.40923425555229187\n",
      "Batch 113: loss = 0.3819478750228882\n",
      "Batch 114: loss = 0.38144415616989136\n",
      "Batch 115: loss = 0.3984508812427521\n",
      "Batch 116: loss = 0.36446747183799744\n",
      "Batch 117: loss = 0.3766738772392273\n",
      "Batch 118: loss = 0.35781002044677734\n",
      "Batch 119: loss = 0.3914393186569214\n",
      "Batch 120: loss = 0.34094539284706116\n",
      "Batch 121: loss = 0.36580610275268555\n",
      "Batch 122: loss = 0.33397549390792847\n",
      "Batch 123: loss = 0.3491964340209961\n",
      "Batch 124: loss = 0.4318079352378845\n",
      "Batch 125: loss = 0.40642446279525757\n",
      "Batch 126: loss = 0.3616200089454651\n",
      "Saved checkpoint to weights.60.pt\n",
      "\n",
      "Epoch 61/100\n",
      "Batch 1: loss = 0.3460766077041626\n",
      "Batch 2: loss = 0.4228988289833069\n",
      "Batch 3: loss = 0.3746446371078491\n",
      "Batch 4: loss = 0.3577495217323303\n",
      "Batch 5: loss = 0.37786656618118286\n",
      "Batch 6: loss = 0.41726261377334595\n",
      "Batch 7: loss = 0.3566070795059204\n",
      "Batch 8: loss = 0.39007437229156494\n",
      "Batch 9: loss = 0.3776891529560089\n",
      "Batch 10: loss = 0.34636157751083374\n",
      "Batch 11: loss = 0.3673044443130493\n",
      "Batch 12: loss = 0.38471755385398865\n",
      "Batch 13: loss = 0.33123189210891724\n",
      "Batch 14: loss = 0.3502848446369171\n",
      "Batch 15: loss = 0.3054167926311493\n",
      "Batch 16: loss = 0.3889670968055725\n",
      "Batch 17: loss = 0.3868713080883026\n",
      "Batch 18: loss = 0.3959219455718994\n",
      "Batch 19: loss = 0.36896222829818726\n",
      "Batch 20: loss = 0.35760697722435\n",
      "Batch 21: loss = 0.33970940113067627\n",
      "Batch 22: loss = 0.3449116349220276\n",
      "Batch 23: loss = 0.4074912965297699\n",
      "Batch 24: loss = 0.36781060695648193\n",
      "Batch 25: loss = 0.36884379386901855\n",
      "Batch 26: loss = 0.34609413146972656\n",
      "Batch 27: loss = 0.42902064323425293\n",
      "Batch 28: loss = 0.38404661417007446\n",
      "Batch 29: loss = 0.41847532987594604\n",
      "Batch 30: loss = 0.374562531709671\n",
      "Batch 31: loss = 0.3796044588088989\n",
      "Batch 32: loss = 0.3821554183959961\n",
      "Batch 33: loss = 0.3471524715423584\n",
      "Batch 34: loss = 0.3674432039260864\n",
      "Batch 35: loss = 0.3756658434867859\n",
      "Batch 36: loss = 0.3041386604309082\n",
      "Batch 37: loss = 0.31853580474853516\n",
      "Batch 38: loss = 0.36104699969291687\n",
      "Batch 39: loss = 0.3703961968421936\n",
      "Batch 40: loss = 0.3716253638267517\n",
      "Batch 41: loss = 0.37645772099494934\n",
      "Batch 42: loss = 0.3796202838420868\n",
      "Batch 43: loss = 0.38713955879211426\n",
      "Batch 44: loss = 0.3609319031238556\n",
      "Batch 45: loss = 0.3394649028778076\n",
      "Batch 46: loss = 0.33909332752227783\n",
      "Batch 47: loss = 0.3631363809108734\n",
      "Batch 48: loss = 0.35392946004867554\n",
      "Batch 49: loss = 0.32270365953445435\n",
      "Batch 50: loss = 0.32332009077072144\n",
      "Batch 51: loss = 0.35472846031188965\n",
      "Batch 52: loss = 0.36597901582717896\n",
      "Batch 53: loss = 0.34628555178642273\n",
      "Batch 54: loss = 0.2885211706161499\n",
      "Batch 55: loss = 0.29938578605651855\n",
      "Batch 56: loss = 0.36542749404907227\n",
      "Batch 57: loss = 0.39189469814300537\n",
      "Batch 58: loss = 0.409950315952301\n",
      "Batch 59: loss = 0.31793534755706787\n",
      "Batch 60: loss = 0.3465614318847656\n",
      "Batch 61: loss = 0.33761823177337646\n",
      "Batch 62: loss = 0.42197883129119873\n",
      "Batch 63: loss = 0.3328835070133209\n",
      "Batch 64: loss = 0.29540717601776123\n",
      "Batch 65: loss = 0.3649674654006958\n",
      "Batch 66: loss = 0.37464824318885803\n",
      "Batch 67: loss = 0.33863452076911926\n",
      "Batch 68: loss = 0.3765614926815033\n",
      "Batch 69: loss = 0.35115838050842285\n",
      "Batch 70: loss = 0.4144420027732849\n",
      "Batch 71: loss = 0.4232632517814636\n",
      "Batch 72: loss = 0.35214030742645264\n",
      "Batch 73: loss = 0.4158082604408264\n",
      "Batch 74: loss = 0.3968287706375122\n",
      "Batch 75: loss = 0.4576248824596405\n",
      "Batch 76: loss = 0.40752094984054565\n",
      "Batch 77: loss = 0.3566378355026245\n",
      "Batch 78: loss = 0.4010156989097595\n",
      "Batch 79: loss = 0.36173224449157715\n",
      "Batch 80: loss = 0.3795667290687561\n",
      "Batch 81: loss = 0.4106099605560303\n",
      "Batch 82: loss = 0.3445444703102112\n",
      "Batch 83: loss = 0.34464287757873535\n",
      "Batch 84: loss = 0.3891068398952484\n",
      "Batch 85: loss = 0.43277597427368164\n",
      "Batch 86: loss = 0.38246798515319824\n",
      "Batch 87: loss = 0.3389562666416168\n",
      "Batch 88: loss = 0.44956016540527344\n",
      "Batch 89: loss = 0.38142919540405273\n",
      "Batch 90: loss = 0.3931703567504883\n",
      "Batch 91: loss = 0.4372263252735138\n",
      "Batch 92: loss = 0.4073459804058075\n",
      "Batch 93: loss = 0.3499267101287842\n",
      "Batch 94: loss = 0.3433513641357422\n",
      "Batch 95: loss = 0.3554403781890869\n",
      "Batch 96: loss = 0.41386860609054565\n",
      "Batch 97: loss = 0.37662822008132935\n",
      "Batch 98: loss = 0.3438373804092407\n",
      "Batch 99: loss = 0.46039530634880066\n",
      "Batch 100: loss = 0.42896246910095215\n",
      "Batch 101: loss = 0.3470616638660431\n",
      "Batch 102: loss = 0.39563095569610596\n",
      "Batch 103: loss = 0.38662514090538025\n",
      "Batch 104: loss = 0.34296947717666626\n",
      "Batch 105: loss = 0.3638681173324585\n",
      "Batch 106: loss = 0.41110914945602417\n",
      "Batch 107: loss = 0.38637757301330566\n",
      "Batch 108: loss = 0.36704421043395996\n",
      "Batch 109: loss = 0.39157211780548096\n",
      "Batch 110: loss = 0.31435978412628174\n",
      "Batch 111: loss = 0.4164440929889679\n",
      "Batch 112: loss = 0.3929453194141388\n",
      "Batch 113: loss = 0.39263439178466797\n",
      "Batch 114: loss = 0.37643206119537354\n",
      "Batch 115: loss = 0.41243982315063477\n",
      "Batch 116: loss = 0.37085169553756714\n",
      "Batch 117: loss = 0.3734147846698761\n",
      "Batch 118: loss = 0.36773115396499634\n",
      "Batch 119: loss = 0.36782538890838623\n",
      "Batch 120: loss = 0.333479106426239\n",
      "Batch 121: loss = 0.3780808448791504\n",
      "Batch 122: loss = 0.3367723822593689\n",
      "Batch 123: loss = 0.37376344203948975\n",
      "Batch 124: loss = 0.4138762354850769\n",
      "Batch 125: loss = 0.40000057220458984\n",
      "Batch 126: loss = 0.3576394319534302\n",
      "\n",
      "Epoch 62/100\n",
      "Batch 1: loss = 0.3881824314594269\n",
      "Batch 2: loss = 0.3847986161708832\n",
      "Batch 3: loss = 0.379228413105011\n",
      "Batch 4: loss = 0.34528928995132446\n",
      "Batch 5: loss = 0.38264620304107666\n",
      "Batch 6: loss = 0.37299519777297974\n",
      "Batch 7: loss = 0.3562411963939667\n",
      "Batch 8: loss = 0.3778921365737915\n",
      "Batch 9: loss = 0.36774319410324097\n",
      "Batch 10: loss = 0.3369961977005005\n",
      "Batch 11: loss = 0.3488987982273102\n",
      "Batch 12: loss = 0.35954713821411133\n",
      "Batch 13: loss = 0.39012500643730164\n",
      "Batch 14: loss = 0.3602876365184784\n",
      "Batch 15: loss = 0.3399044871330261\n",
      "Batch 16: loss = 0.363279789686203\n",
      "Batch 17: loss = 0.34506532549858093\n",
      "Batch 18: loss = 0.4046790599822998\n",
      "Batch 19: loss = 0.365506649017334\n",
      "Batch 20: loss = 0.37211063504219055\n",
      "Batch 21: loss = 0.3842710256576538\n",
      "Batch 22: loss = 0.36022910475730896\n",
      "Batch 23: loss = 0.3885607421398163\n",
      "Batch 24: loss = 0.39636021852493286\n",
      "Batch 25: loss = 0.37844932079315186\n",
      "Batch 26: loss = 0.32792526483535767\n",
      "Batch 27: loss = 0.425859272480011\n",
      "Batch 28: loss = 0.3991353511810303\n",
      "Batch 29: loss = 0.3770174980163574\n",
      "Batch 30: loss = 0.3729420602321625\n",
      "Batch 31: loss = 0.39451757073402405\n",
      "Batch 32: loss = 0.389718621969223\n",
      "Batch 33: loss = 0.36086687445640564\n",
      "Batch 34: loss = 0.39484238624572754\n",
      "Batch 35: loss = 0.3714006841182709\n",
      "Batch 36: loss = 0.31253716349601746\n",
      "Batch 37: loss = 0.30209171772003174\n",
      "Batch 38: loss = 0.354172945022583\n",
      "Batch 39: loss = 0.3376883268356323\n",
      "Batch 40: loss = 0.3555181622505188\n",
      "Batch 41: loss = 0.36144113540649414\n",
      "Batch 42: loss = 0.355628103017807\n",
      "Batch 43: loss = 0.3842672109603882\n",
      "Batch 44: loss = 0.3502022922039032\n",
      "Batch 45: loss = 0.33024072647094727\n",
      "Batch 46: loss = 0.3321431875228882\n",
      "Batch 47: loss = 0.3424328565597534\n",
      "Batch 48: loss = 0.32096004486083984\n",
      "Batch 49: loss = 0.31434351205825806\n",
      "Batch 50: loss = 0.3612828552722931\n",
      "Batch 51: loss = 0.36340799927711487\n",
      "Batch 52: loss = 0.3930484652519226\n",
      "Batch 53: loss = 0.3414950966835022\n",
      "Batch 54: loss = 0.28625744581222534\n",
      "Batch 55: loss = 0.3420904278755188\n",
      "Batch 56: loss = 0.3774068355560303\n",
      "Batch 57: loss = 0.38741981983184814\n",
      "Batch 58: loss = 0.4061170220375061\n",
      "Batch 59: loss = 0.2846013307571411\n",
      "Batch 60: loss = 0.32932960987091064\n",
      "Batch 61: loss = 0.3282970190048218\n",
      "Batch 62: loss = 0.4071640968322754\n",
      "Batch 63: loss = 0.3231245279312134\n",
      "Batch 64: loss = 0.28049352765083313\n",
      "Batch 65: loss = 0.3565596640110016\n",
      "Batch 66: loss = 0.35827890038490295\n",
      "Batch 67: loss = 0.36150795221328735\n",
      "Batch 68: loss = 0.38083726167678833\n",
      "Batch 69: loss = 0.31262996792793274\n",
      "Batch 70: loss = 0.40904420614242554\n",
      "Batch 71: loss = 0.38480350375175476\n",
      "Batch 72: loss = 0.31508687138557434\n",
      "Batch 73: loss = 0.37427952885627747\n",
      "Batch 74: loss = 0.40088266134262085\n",
      "Batch 75: loss = 0.4245935082435608\n",
      "Batch 76: loss = 0.38512349128723145\n",
      "Batch 77: loss = 0.3550291657447815\n",
      "Batch 78: loss = 0.4155782163143158\n",
      "Batch 79: loss = 0.3495957851409912\n",
      "Batch 80: loss = 0.36669331789016724\n",
      "Batch 81: loss = 0.3806341290473938\n",
      "Batch 82: loss = 0.34141039848327637\n",
      "Batch 83: loss = 0.3435341715812683\n",
      "Batch 84: loss = 0.3394670784473419\n",
      "Batch 85: loss = 0.4183690547943115\n",
      "Batch 86: loss = 0.3468255400657654\n",
      "Batch 87: loss = 0.3280826508998871\n",
      "Batch 88: loss = 0.41705262660980225\n",
      "Batch 89: loss = 0.3257390260696411\n",
      "Batch 90: loss = 0.39077091217041016\n",
      "Batch 91: loss = 0.42539092898368835\n",
      "Batch 92: loss = 0.40080469846725464\n",
      "Batch 93: loss = 0.3464716672897339\n",
      "Batch 94: loss = 0.3577570617198944\n",
      "Batch 95: loss = 0.35251593589782715\n",
      "Batch 96: loss = 0.4060380458831787\n",
      "Batch 97: loss = 0.34547460079193115\n",
      "Batch 98: loss = 0.330437034368515\n",
      "Batch 99: loss = 0.42885786294937134\n",
      "Batch 100: loss = 0.41891416907310486\n",
      "Batch 101: loss = 0.372562050819397\n",
      "Batch 102: loss = 0.3543855547904968\n",
      "Batch 103: loss = 0.37658169865608215\n",
      "Batch 104: loss = 0.354556679725647\n",
      "Batch 105: loss = 0.32909584045410156\n",
      "Batch 106: loss = 0.35163918137550354\n",
      "Batch 107: loss = 0.3811136782169342\n",
      "Batch 108: loss = 0.3786037564277649\n",
      "Batch 109: loss = 0.41135314106941223\n",
      "Batch 110: loss = 0.3262122869491577\n",
      "Batch 111: loss = 0.3879510164260864\n",
      "Batch 112: loss = 0.37457025051116943\n",
      "Batch 113: loss = 0.37834930419921875\n",
      "Batch 114: loss = 0.38947924971580505\n",
      "Batch 115: loss = 0.3594762086868286\n",
      "Batch 116: loss = 0.374996542930603\n",
      "Batch 117: loss = 0.36748331785202026\n",
      "Batch 118: loss = 0.3576326370239258\n",
      "Batch 119: loss = 0.3624719977378845\n",
      "Batch 120: loss = 0.34352579712867737\n",
      "Batch 121: loss = 0.36463654041290283\n",
      "Batch 122: loss = 0.3187463879585266\n",
      "Batch 123: loss = 0.33577239513397217\n",
      "Batch 124: loss = 0.3900660276412964\n",
      "Batch 125: loss = 0.3732544779777527\n",
      "Batch 126: loss = 0.3614397644996643\n",
      "\n",
      "Epoch 63/100\n",
      "Batch 1: loss = 0.3567729592323303\n",
      "Batch 2: loss = 0.38331374526023865\n",
      "Batch 3: loss = 0.35173511505126953\n",
      "Batch 4: loss = 0.38876646757125854\n",
      "Batch 5: loss = 0.3723398745059967\n",
      "Batch 6: loss = 0.3807157278060913\n",
      "Batch 7: loss = 0.30201593041419983\n",
      "Batch 8: loss = 0.3432629704475403\n",
      "Batch 9: loss = 0.38045528531074524\n",
      "Batch 10: loss = 0.31955686211586\n",
      "Batch 11: loss = 0.3391628861427307\n",
      "Batch 12: loss = 0.33955109119415283\n",
      "Batch 13: loss = 0.3609845042228699\n",
      "Batch 14: loss = 0.3421586751937866\n",
      "Batch 15: loss = 0.3237937092781067\n",
      "Batch 16: loss = 0.3505439758300781\n",
      "Batch 17: loss = 0.34378713369369507\n",
      "Batch 18: loss = 0.3806004524230957\n",
      "Batch 19: loss = 0.3328700661659241\n",
      "Batch 20: loss = 0.3652600646018982\n",
      "Batch 21: loss = 0.34042227268218994\n",
      "Batch 22: loss = 0.35849902033805847\n",
      "Batch 23: loss = 0.4166940450668335\n",
      "Batch 24: loss = 0.3635389804840088\n",
      "Batch 25: loss = 0.3605455756187439\n",
      "Batch 26: loss = 0.32659703493118286\n",
      "Batch 27: loss = 0.42105886340141296\n",
      "Batch 28: loss = 0.37950414419174194\n",
      "Batch 29: loss = 0.38997983932495117\n",
      "Batch 30: loss = 0.3583330810070038\n",
      "Batch 31: loss = 0.39479395747184753\n",
      "Batch 32: loss = 0.4068666100502014\n",
      "Batch 33: loss = 0.3306177854537964\n",
      "Batch 34: loss = 0.4003256559371948\n",
      "Batch 35: loss = 0.3796001374721527\n",
      "Batch 36: loss = 0.32638800144195557\n",
      "Batch 37: loss = 0.33255040645599365\n",
      "Batch 38: loss = 0.3482712507247925\n",
      "Batch 39: loss = 0.32872122526168823\n",
      "Batch 40: loss = 0.33962273597717285\n",
      "Batch 41: loss = 0.3453657627105713\n",
      "Batch 42: loss = 0.37651288509368896\n",
      "Batch 43: loss = 0.38323184847831726\n",
      "Batch 44: loss = 0.33652636408805847\n",
      "Batch 45: loss = 0.31331777572631836\n",
      "Batch 46: loss = 0.32515400648117065\n",
      "Batch 47: loss = 0.35706430673599243\n",
      "Batch 48: loss = 0.3112868070602417\n",
      "Batch 49: loss = 0.3219609558582306\n",
      "Batch 50: loss = 0.32518842816352844\n",
      "Batch 51: loss = 0.35504406690597534\n",
      "Batch 52: loss = 0.36213991045951843\n",
      "Batch 53: loss = 0.37160351872444153\n",
      "Batch 54: loss = 0.26319044828414917\n",
      "Batch 55: loss = 0.29849720001220703\n",
      "Batch 56: loss = 0.36879825592041016\n",
      "Batch 57: loss = 0.3932081460952759\n",
      "Batch 58: loss = 0.3427651524543762\n",
      "Batch 59: loss = 0.2948418855667114\n",
      "Batch 60: loss = 0.33714932203292847\n",
      "Batch 61: loss = 0.32464373111724854\n",
      "Batch 62: loss = 0.37424588203430176\n",
      "Batch 63: loss = 0.33226609230041504\n",
      "Batch 64: loss = 0.30395129323005676\n",
      "Batch 65: loss = 0.37378203868865967\n",
      "Batch 66: loss = 0.37616413831710815\n",
      "Batch 67: loss = 0.3484219014644623\n",
      "Batch 68: loss = 0.36894094944000244\n",
      "Batch 69: loss = 0.3462302088737488\n",
      "Batch 70: loss = 0.3978307843208313\n",
      "Batch 71: loss = 0.37888818979263306\n",
      "Batch 72: loss = 0.31654489040374756\n",
      "Batch 73: loss = 0.4070117473602295\n",
      "Batch 74: loss = 0.3545190095901489\n",
      "Batch 75: loss = 0.390966534614563\n",
      "Batch 76: loss = 0.34593212604522705\n",
      "Batch 77: loss = 0.33497893810272217\n",
      "Batch 78: loss = 0.37306544184684753\n",
      "Batch 79: loss = 0.34146204590797424\n",
      "Batch 80: loss = 0.3405132293701172\n",
      "Batch 81: loss = 0.37742435932159424\n",
      "Batch 82: loss = 0.34026265144348145\n",
      "Batch 83: loss = 0.34093523025512695\n",
      "Batch 84: loss = 0.35948264598846436\n",
      "Batch 85: loss = 0.39852970838546753\n",
      "Batch 86: loss = 0.3516830503940582\n",
      "Batch 87: loss = 0.32919713854789734\n",
      "Batch 88: loss = 0.4272933602333069\n",
      "Batch 89: loss = 0.32765311002731323\n",
      "Batch 90: loss = 0.3533999025821686\n",
      "Batch 91: loss = 0.4057490825653076\n",
      "Batch 92: loss = 0.42019784450531006\n",
      "Batch 93: loss = 0.32958492636680603\n",
      "Batch 94: loss = 0.3649192154407501\n",
      "Batch 95: loss = 0.33644580841064453\n",
      "Batch 96: loss = 0.4385007619857788\n",
      "Batch 97: loss = 0.33419105410575867\n",
      "Batch 98: loss = 0.33990222215652466\n",
      "Batch 99: loss = 0.42288047075271606\n",
      "Batch 100: loss = 0.44791465997695923\n",
      "Batch 101: loss = 0.3912203907966614\n",
      "Batch 102: loss = 0.38023942708969116\n",
      "Batch 103: loss = 0.35822999477386475\n",
      "Batch 104: loss = 0.3423458933830261\n",
      "Batch 105: loss = 0.32816290855407715\n",
      "Batch 106: loss = 0.3167530298233032\n",
      "Batch 107: loss = 0.35183143615722656\n",
      "Batch 108: loss = 0.35418373346328735\n",
      "Batch 109: loss = 0.3766113817691803\n",
      "Batch 110: loss = 0.3339301645755768\n",
      "Batch 111: loss = 0.3636813461780548\n",
      "Batch 112: loss = 0.37931185960769653\n",
      "Batch 113: loss = 0.37166643142700195\n",
      "Batch 114: loss = 0.3902459442615509\n",
      "Batch 115: loss = 0.3645009398460388\n",
      "Batch 116: loss = 0.40420445799827576\n",
      "Batch 117: loss = 0.3530247211456299\n",
      "Batch 118: loss = 0.34901684522628784\n",
      "Batch 119: loss = 0.3617382049560547\n",
      "Batch 120: loss = 0.3239626884460449\n",
      "Batch 121: loss = 0.35471415519714355\n",
      "Batch 122: loss = 0.32898423075675964\n",
      "Batch 123: loss = 0.3620220422744751\n",
      "Batch 124: loss = 0.3885762095451355\n",
      "Batch 125: loss = 0.3782753348350525\n",
      "Batch 126: loss = 0.35960638523101807\n",
      "\n",
      "Epoch 64/100\n",
      "Batch 1: loss = 0.3290753662586212\n",
      "Batch 2: loss = 0.36181098222732544\n",
      "Batch 3: loss = 0.3307865262031555\n",
      "Batch 4: loss = 0.330472469329834\n",
      "Batch 5: loss = 0.37487807869911194\n",
      "Batch 6: loss = 0.3944730758666992\n",
      "Batch 7: loss = 0.34190234541893005\n",
      "Batch 8: loss = 0.3555532693862915\n",
      "Batch 9: loss = 0.3745885491371155\n",
      "Batch 10: loss = 0.2974012494087219\n",
      "Batch 11: loss = 0.34424781799316406\n",
      "Batch 12: loss = 0.35564714670181274\n",
      "Batch 13: loss = 0.35074806213378906\n",
      "Batch 14: loss = 0.34387487173080444\n",
      "Batch 15: loss = 0.32029157876968384\n",
      "Batch 16: loss = 0.3743261694908142\n",
      "Batch 17: loss = 0.33918824791908264\n",
      "Batch 18: loss = 0.36937642097473145\n",
      "Batch 19: loss = 0.3656079173088074\n",
      "Batch 20: loss = 0.3419491946697235\n",
      "Batch 21: loss = 0.34319889545440674\n",
      "Batch 22: loss = 0.3407086730003357\n",
      "Batch 23: loss = 0.3956720232963562\n",
      "Batch 24: loss = 0.35418960452079773\n",
      "Batch 25: loss = 0.3848845958709717\n",
      "Batch 26: loss = 0.31475841999053955\n",
      "Batch 27: loss = 0.43970584869384766\n",
      "Batch 28: loss = 0.4112889766693115\n",
      "Batch 29: loss = 0.4241098463535309\n",
      "Batch 30: loss = 0.3415125608444214\n",
      "Batch 31: loss = 0.375980406999588\n",
      "Batch 32: loss = 0.38617682456970215\n",
      "Batch 33: loss = 0.3344227969646454\n",
      "Batch 34: loss = 0.36292392015457153\n",
      "Batch 35: loss = 0.3403503894805908\n",
      "Batch 36: loss = 0.32018405199050903\n",
      "Batch 37: loss = 0.30871737003326416\n",
      "Batch 38: loss = 0.34495651721954346\n",
      "Batch 39: loss = 0.32940196990966797\n",
      "Batch 40: loss = 0.35257816314697266\n",
      "Batch 41: loss = 0.34792324900627136\n",
      "Batch 42: loss = 0.35414832830429077\n",
      "Batch 43: loss = 0.3943970799446106\n",
      "Batch 44: loss = 0.3126750588417053\n",
      "Batch 45: loss = 0.29421091079711914\n",
      "Batch 46: loss = 0.32609057426452637\n",
      "Batch 47: loss = 0.3218276798725128\n",
      "Batch 48: loss = 0.30746424198150635\n",
      "Batch 49: loss = 0.311087042093277\n",
      "Batch 50: loss = 0.30623263120651245\n",
      "Batch 51: loss = 0.3514626622200012\n",
      "Batch 52: loss = 0.3541724681854248\n",
      "Batch 53: loss = 0.3168964982032776\n",
      "Batch 54: loss = 0.27990031242370605\n",
      "Batch 55: loss = 0.2968871593475342\n",
      "Batch 56: loss = 0.3255292773246765\n",
      "Batch 57: loss = 0.3626382350921631\n",
      "Batch 58: loss = 0.3917728066444397\n",
      "Batch 59: loss = 0.2793009579181671\n",
      "Batch 60: loss = 0.3266618847846985\n",
      "Batch 61: loss = 0.30974024534225464\n",
      "Batch 62: loss = 0.366983026266098\n",
      "Batch 63: loss = 0.30992090702056885\n",
      "Batch 64: loss = 0.29916834831237793\n",
      "Batch 65: loss = 0.33454933762550354\n",
      "Batch 66: loss = 0.3444003462791443\n",
      "Batch 67: loss = 0.3274197578430176\n",
      "Batch 68: loss = 0.3520142436027527\n",
      "Batch 69: loss = 0.3494488298892975\n",
      "Batch 70: loss = 0.40790051221847534\n",
      "Batch 71: loss = 0.36895543336868286\n",
      "Batch 72: loss = 0.32008862495422363\n",
      "Batch 73: loss = 0.3956599831581116\n",
      "Batch 74: loss = 0.36920166015625\n",
      "Batch 75: loss = 0.4122581481933594\n",
      "Batch 76: loss = 0.35284972190856934\n",
      "Batch 77: loss = 0.354562908411026\n",
      "Batch 78: loss = 0.3891262412071228\n",
      "Batch 79: loss = 0.33988869190216064\n",
      "Batch 80: loss = 0.33497267961502075\n",
      "Batch 81: loss = 0.36118367314338684\n",
      "Batch 82: loss = 0.32661110162734985\n",
      "Batch 83: loss = 0.340013325214386\n",
      "Batch 84: loss = 0.3693504333496094\n",
      "Batch 85: loss = 0.3833153247833252\n",
      "Batch 86: loss = 0.3702920377254486\n",
      "Batch 87: loss = 0.3476144075393677\n",
      "Batch 88: loss = 0.38371363282203674\n",
      "Batch 89: loss = 0.3165181279182434\n",
      "Batch 90: loss = 0.3873141407966614\n",
      "Batch 91: loss = 0.4267015755176544\n",
      "Batch 92: loss = 0.38512343168258667\n",
      "Batch 93: loss = 0.3156293034553528\n",
      "Batch 94: loss = 0.3336673378944397\n",
      "Batch 95: loss = 0.3633425235748291\n",
      "Batch 96: loss = 0.4439964294433594\n",
      "Batch 97: loss = 0.3512459993362427\n",
      "Batch 98: loss = 0.3239949941635132\n",
      "Batch 99: loss = 0.40303725004196167\n",
      "Batch 100: loss = 0.38088130950927734\n",
      "Batch 101: loss = 0.36144304275512695\n",
      "Batch 102: loss = 0.3921305537223816\n",
      "Batch 103: loss = 0.3582405745983124\n",
      "Batch 104: loss = 0.3414718508720398\n",
      "Batch 105: loss = 0.31898200511932373\n",
      "Batch 106: loss = 0.3469282388687134\n",
      "Batch 107: loss = 0.32980871200561523\n",
      "Batch 108: loss = 0.3752117156982422\n",
      "Batch 109: loss = 0.3516188859939575\n",
      "Batch 110: loss = 0.3497484624385834\n",
      "Batch 111: loss = 0.37506550550460815\n",
      "Batch 112: loss = 0.40394389629364014\n",
      "Batch 113: loss = 0.33328843116760254\n",
      "Batch 114: loss = 0.3695858120918274\n",
      "Batch 115: loss = 0.3825773596763611\n",
      "Batch 116: loss = 0.38194406032562256\n",
      "Batch 117: loss = 0.348580539226532\n",
      "Batch 118: loss = 0.32944977283477783\n",
      "Batch 119: loss = 0.38507533073425293\n",
      "Batch 120: loss = 0.33193904161453247\n",
      "Batch 121: loss = 0.36117976903915405\n",
      "Batch 122: loss = 0.33170440793037415\n",
      "Batch 123: loss = 0.3648730516433716\n",
      "Batch 124: loss = 0.39780330657958984\n",
      "Batch 125: loss = 0.3814423084259033\n",
      "Batch 126: loss = 0.36325109004974365\n",
      "\n",
      "Epoch 65/100\n",
      "Batch 1: loss = 0.34285467863082886\n",
      "Batch 2: loss = 0.36203181743621826\n",
      "Batch 3: loss = 0.32931289076805115\n",
      "Batch 4: loss = 0.3680647611618042\n",
      "Batch 5: loss = 0.36581844091415405\n",
      "Batch 6: loss = 0.3682934045791626\n",
      "Batch 7: loss = 0.3421381711959839\n",
      "Batch 8: loss = 0.3598390817642212\n",
      "Batch 9: loss = 0.326601505279541\n",
      "Batch 10: loss = 0.33777695894241333\n",
      "Batch 11: loss = 0.3359152674674988\n",
      "Batch 12: loss = 0.3564939796924591\n",
      "Batch 13: loss = 0.32817786931991577\n",
      "Batch 14: loss = 0.3237296938896179\n",
      "Batch 15: loss = 0.32232701778411865\n",
      "Batch 16: loss = 0.3774758577346802\n",
      "Batch 17: loss = 0.32743099331855774\n",
      "Batch 18: loss = 0.3862011432647705\n",
      "Batch 19: loss = 0.3776029646396637\n",
      "Batch 20: loss = 0.3546350598335266\n",
      "Batch 21: loss = 0.4006277918815613\n",
      "Batch 22: loss = 0.34642618894577026\n",
      "Batch 23: loss = 0.3673062324523926\n",
      "Batch 24: loss = 0.35055726766586304\n",
      "Batch 25: loss = 0.3524095416069031\n",
      "Batch 26: loss = 0.3113133907318115\n",
      "Batch 27: loss = 0.4060240089893341\n",
      "Batch 28: loss = 0.3697057366371155\n",
      "Batch 29: loss = 0.39577627182006836\n",
      "Batch 30: loss = 0.37746942043304443\n",
      "Batch 31: loss = 0.36198690533638\n",
      "Batch 32: loss = 0.39308008551597595\n",
      "Batch 33: loss = 0.3503357172012329\n",
      "Batch 34: loss = 0.35636815428733826\n",
      "Batch 35: loss = 0.3748225271701813\n",
      "Batch 36: loss = 0.2934136390686035\n",
      "Batch 37: loss = 0.27377158403396606\n",
      "Batch 38: loss = 0.3186221122741699\n",
      "Batch 39: loss = 0.34565359354019165\n",
      "Batch 40: loss = 0.35240963101387024\n",
      "Batch 41: loss = 0.33884185552597046\n",
      "Batch 42: loss = 0.35378867387771606\n",
      "Batch 43: loss = 0.37531542778015137\n",
      "Batch 44: loss = 0.3258228302001953\n",
      "Batch 45: loss = 0.2997334599494934\n",
      "Batch 46: loss = 0.3228096663951874\n",
      "Batch 47: loss = 0.3709339201450348\n",
      "Batch 48: loss = 0.32195931673049927\n",
      "Batch 49: loss = 0.3304483890533447\n",
      "Batch 50: loss = 0.32631534337997437\n",
      "Batch 51: loss = 0.346299409866333\n",
      "Batch 52: loss = 0.364371657371521\n",
      "Batch 53: loss = 0.3198004364967346\n",
      "Batch 54: loss = 0.2592712342739105\n",
      "Batch 55: loss = 0.29985901713371277\n",
      "Batch 56: loss = 0.36775726079940796\n",
      "Batch 57: loss = 0.3778679370880127\n",
      "Batch 58: loss = 0.4026340842247009\n",
      "Batch 59: loss = 0.27425888180732727\n",
      "Batch 60: loss = 0.3553673028945923\n",
      "Batch 61: loss = 0.3300507664680481\n",
      "Batch 62: loss = 0.4177320897579193\n",
      "Batch 63: loss = 0.34875890612602234\n",
      "Batch 64: loss = 0.2924511134624481\n",
      "Batch 65: loss = 0.31900519132614136\n",
      "Batch 66: loss = 0.35517120361328125\n",
      "Batch 67: loss = 0.3193158805370331\n",
      "Batch 68: loss = 0.3604397177696228\n",
      "Batch 69: loss = 0.31219369173049927\n",
      "Batch 70: loss = 0.37226995825767517\n",
      "Batch 71: loss = 0.3627711534500122\n",
      "Batch 72: loss = 0.3129541575908661\n",
      "Batch 73: loss = 0.3832920789718628\n",
      "Batch 74: loss = 0.3563266694545746\n",
      "Batch 75: loss = 0.40729230642318726\n",
      "Batch 76: loss = 0.384223997592926\n",
      "Batch 77: loss = 0.32612115144729614\n",
      "Batch 78: loss = 0.35463303327560425\n",
      "Batch 79: loss = 0.3600000739097595\n",
      "Batch 80: loss = 0.34281104803085327\n",
      "Batch 81: loss = 0.3358532190322876\n",
      "Batch 82: loss = 0.3081762194633484\n",
      "Batch 83: loss = 0.33879518508911133\n",
      "Batch 84: loss = 0.37962502241134644\n",
      "Batch 85: loss = 0.40031158924102783\n",
      "Batch 86: loss = 0.3336966335773468\n",
      "Batch 87: loss = 0.33506110310554504\n",
      "Batch 88: loss = 0.40386343002319336\n",
      "Batch 89: loss = 0.302234947681427\n",
      "Batch 90: loss = 0.349213182926178\n",
      "Batch 91: loss = 0.38669154047966003\n",
      "Batch 92: loss = 0.36912471055984497\n",
      "Batch 93: loss = 0.31398463249206543\n",
      "Batch 94: loss = 0.36864009499549866\n",
      "Batch 95: loss = 0.3241020143032074\n",
      "Batch 96: loss = 0.40568870306015015\n",
      "Batch 97: loss = 0.3381494879722595\n",
      "Batch 98: loss = 0.3241986632347107\n",
      "Batch 99: loss = 0.4118891656398773\n",
      "Batch 100: loss = 0.37691301107406616\n",
      "Batch 101: loss = 0.35052284598350525\n",
      "Batch 102: loss = 0.36377912759780884\n",
      "Batch 103: loss = 0.34335464239120483\n",
      "Batch 104: loss = 0.33587706089019775\n",
      "Batch 105: loss = 0.3411933183670044\n",
      "Batch 106: loss = 0.3497503399848938\n",
      "Batch 107: loss = 0.3564522862434387\n",
      "Batch 108: loss = 0.3386836051940918\n",
      "Batch 109: loss = 0.3541186451911926\n",
      "Batch 110: loss = 0.3383943438529968\n",
      "Batch 111: loss = 0.38369226455688477\n",
      "Batch 112: loss = 0.3861677944660187\n",
      "Batch 113: loss = 0.3728925585746765\n",
      "Batch 114: loss = 0.3558841347694397\n",
      "Batch 115: loss = 0.36333346366882324\n",
      "Batch 116: loss = 0.38586777448654175\n",
      "Batch 117: loss = 0.3395051956176758\n",
      "Batch 118: loss = 0.33377084136009216\n",
      "Batch 119: loss = 0.3384731113910675\n",
      "Batch 120: loss = 0.3588973581790924\n",
      "Batch 121: loss = 0.3529922366142273\n",
      "Batch 122: loss = 0.3424273133277893\n",
      "Batch 123: loss = 0.36580368876457214\n",
      "Batch 124: loss = 0.3898547887802124\n",
      "Batch 125: loss = 0.37840306758880615\n",
      "Batch 126: loss = 0.3469368815422058\n",
      "\n",
      "Epoch 66/100\n",
      "Batch 1: loss = 0.36630773544311523\n",
      "Batch 2: loss = 0.3666772246360779\n",
      "Batch 3: loss = 0.3241037130355835\n",
      "Batch 4: loss = 0.33978933095932007\n",
      "Batch 5: loss = 0.377372145652771\n",
      "Batch 6: loss = 0.35992616415023804\n",
      "Batch 7: loss = 0.3521246314048767\n",
      "Batch 8: loss = 0.34583956003189087\n",
      "Batch 9: loss = 0.3479768633842468\n",
      "Batch 10: loss = 0.3486728072166443\n",
      "Batch 11: loss = 0.36025646328926086\n",
      "Batch 12: loss = 0.3544495105743408\n",
      "Batch 13: loss = 0.33728063106536865\n",
      "Batch 14: loss = 0.3335627317428589\n",
      "Batch 15: loss = 0.3320852816104889\n",
      "Batch 16: loss = 0.3619113862514496\n",
      "Batch 17: loss = 0.2947651147842407\n",
      "Batch 18: loss = 0.3525136113166809\n",
      "Batch 19: loss = 0.3671010732650757\n",
      "Batch 20: loss = 0.35426855087280273\n",
      "Batch 21: loss = 0.3574298024177551\n",
      "Batch 22: loss = 0.34391123056411743\n",
      "Batch 23: loss = 0.3673861622810364\n",
      "Batch 24: loss = 0.32141101360321045\n",
      "Batch 25: loss = 0.3400876522064209\n",
      "Batch 26: loss = 0.320403516292572\n",
      "Batch 27: loss = 0.3871234655380249\n",
      "Batch 28: loss = 0.37071964144706726\n",
      "Batch 29: loss = 0.38060590624809265\n",
      "Batch 30: loss = 0.3668787479400635\n",
      "Batch 31: loss = 0.37069928646087646\n",
      "Batch 32: loss = 0.38178199529647827\n",
      "Batch 33: loss = 0.3096657991409302\n",
      "Batch 34: loss = 0.3470765948295593\n",
      "Batch 35: loss = 0.36962056159973145\n",
      "Batch 36: loss = 0.29621022939682007\n",
      "Batch 37: loss = 0.28825297951698303\n",
      "Batch 38: loss = 0.3282623291015625\n",
      "Batch 39: loss = 0.3199302554130554\n",
      "Batch 40: loss = 0.35481274127960205\n",
      "Batch 41: loss = 0.309853196144104\n",
      "Batch 42: loss = 0.3404526114463806\n",
      "Batch 43: loss = 0.3750181198120117\n",
      "Batch 44: loss = 0.3045942187309265\n",
      "Batch 45: loss = 0.3120374381542206\n",
      "Batch 46: loss = 0.3094678819179535\n",
      "Batch 47: loss = 0.3450171947479248\n",
      "Batch 48: loss = 0.31795984506607056\n",
      "Batch 49: loss = 0.28901511430740356\n",
      "Batch 50: loss = 0.32780954241752625\n",
      "Batch 51: loss = 0.3406239449977875\n",
      "Batch 52: loss = 0.3583434224128723\n",
      "Batch 53: loss = 0.30825334787368774\n",
      "Batch 54: loss = 0.26765263080596924\n",
      "Batch 55: loss = 0.2962099611759186\n",
      "Batch 56: loss = 0.3633221983909607\n",
      "Batch 57: loss = 0.37518730759620667\n",
      "Batch 58: loss = 0.33421361446380615\n",
      "Batch 59: loss = 0.2864435911178589\n",
      "Batch 60: loss = 0.314544677734375\n",
      "Batch 61: loss = 0.29094362258911133\n",
      "Batch 62: loss = 0.38991987705230713\n",
      "Batch 63: loss = 0.332689493894577\n",
      "Batch 64: loss = 0.2934287190437317\n",
      "Batch 65: loss = 0.3440038561820984\n",
      "Batch 66: loss = 0.336823046207428\n",
      "Batch 67: loss = 0.3222888112068176\n",
      "Batch 68: loss = 0.347231924533844\n",
      "Batch 69: loss = 0.31276148557662964\n",
      "Batch 70: loss = 0.38948386907577515\n",
      "Batch 71: loss = 0.36690735816955566\n",
      "Batch 72: loss = 0.3055388927459717\n",
      "Batch 73: loss = 0.37586116790771484\n",
      "Batch 74: loss = 0.3415365219116211\n",
      "Batch 75: loss = 0.4215332269668579\n",
      "Batch 76: loss = 0.349201500415802\n",
      "Batch 77: loss = 0.3193635940551758\n",
      "Batch 78: loss = 0.3524828255176544\n",
      "Batch 79: loss = 0.3263905644416809\n",
      "Batch 80: loss = 0.3112606406211853\n",
      "Batch 81: loss = 0.3597296476364136\n",
      "Batch 82: loss = 0.31721043586730957\n",
      "Batch 83: loss = 0.3268152177333832\n",
      "Batch 84: loss = 0.36009925603866577\n",
      "Batch 85: loss = 0.4084606170654297\n",
      "Batch 86: loss = 0.3568548858165741\n",
      "Batch 87: loss = 0.3167446255683899\n",
      "Batch 88: loss = 0.3664816617965698\n",
      "Batch 89: loss = 0.3311673402786255\n",
      "Batch 90: loss = 0.3792954683303833\n",
      "Batch 91: loss = 0.39276036620140076\n",
      "Batch 92: loss = 0.38386011123657227\n",
      "Batch 93: loss = 0.33647316694259644\n",
      "Batch 94: loss = 0.35271406173706055\n",
      "Batch 95: loss = 0.35760682821273804\n",
      "Batch 96: loss = 0.3846561014652252\n",
      "Batch 97: loss = 0.33687490224838257\n",
      "Batch 98: loss = 0.3326147794723511\n",
      "Batch 99: loss = 0.4049919843673706\n",
      "Batch 100: loss = 0.3832235634326935\n",
      "Batch 101: loss = 0.3398909568786621\n",
      "Batch 102: loss = 0.34646597504615784\n",
      "Batch 103: loss = 0.3480710983276367\n",
      "Batch 104: loss = 0.3093874454498291\n",
      "Batch 105: loss = 0.32620948553085327\n",
      "Batch 106: loss = 0.32984691858291626\n",
      "Batch 107: loss = 0.3416493833065033\n",
      "Batch 108: loss = 0.3294726014137268\n",
      "Batch 109: loss = 0.3717724680900574\n",
      "Batch 110: loss = 0.31091755628585815\n",
      "Batch 111: loss = 0.3439834415912628\n",
      "Batch 112: loss = 0.3774038553237915\n",
      "Batch 113: loss = 0.3661884069442749\n",
      "Batch 114: loss = 0.3695352077484131\n",
      "Batch 115: loss = 0.3376353979110718\n",
      "Batch 116: loss = 0.36436957120895386\n",
      "Batch 117: loss = 0.3089878559112549\n",
      "Batch 118: loss = 0.3037993311882019\n",
      "Batch 119: loss = 0.36638420820236206\n",
      "Batch 120: loss = 0.32013392448425293\n",
      "Batch 121: loss = 0.3453419804573059\n",
      "Batch 122: loss = 0.3206689953804016\n",
      "Batch 123: loss = 0.34678399562835693\n",
      "Batch 124: loss = 0.3589833974838257\n",
      "Batch 125: loss = 0.3476100564002991\n",
      "Batch 126: loss = 0.3227989971637726\n",
      "\n",
      "Epoch 67/100\n",
      "Batch 1: loss = 0.3373214602470398\n",
      "Batch 2: loss = 0.36134499311447144\n",
      "Batch 3: loss = 0.340985506772995\n",
      "Batch 4: loss = 0.32308724522590637\n",
      "Batch 5: loss = 0.35289275646209717\n",
      "Batch 6: loss = 0.3632027804851532\n",
      "Batch 7: loss = 0.3140653967857361\n",
      "Batch 8: loss = 0.3295500576496124\n",
      "Batch 9: loss = 0.3405689597129822\n",
      "Batch 10: loss = 0.30597954988479614\n",
      "Batch 11: loss = 0.36969125270843506\n",
      "Batch 12: loss = 0.34977978467941284\n",
      "Batch 13: loss = 0.341021329164505\n",
      "Batch 14: loss = 0.3346180319786072\n",
      "Batch 15: loss = 0.301021546125412\n",
      "Batch 16: loss = 0.3553112745285034\n",
      "Batch 17: loss = 0.32627689838409424\n",
      "Batch 18: loss = 0.3565205931663513\n",
      "Batch 19: loss = 0.35013535618782043\n",
      "Batch 20: loss = 0.3376123011112213\n",
      "Batch 21: loss = 0.3240824043750763\n",
      "Batch 22: loss = 0.3107762634754181\n",
      "Batch 23: loss = 0.41063785552978516\n",
      "Batch 24: loss = 0.34544065594673157\n",
      "Batch 25: loss = 0.32868367433547974\n",
      "Batch 26: loss = 0.3469281792640686\n",
      "Batch 27: loss = 0.435282438993454\n",
      "Batch 28: loss = 0.39158114790916443\n",
      "Batch 29: loss = 0.3798045516014099\n",
      "Batch 30: loss = 0.3528743088245392\n",
      "Batch 31: loss = 0.35679545998573303\n",
      "Batch 32: loss = 0.3524608910083771\n",
      "Batch 33: loss = 0.3395656943321228\n",
      "Batch 34: loss = 0.3930317759513855\n",
      "Batch 35: loss = 0.36856505274772644\n",
      "Batch 36: loss = 0.3022401034832001\n",
      "Batch 37: loss = 0.28710806369781494\n",
      "Batch 38: loss = 0.3245474696159363\n",
      "Batch 39: loss = 0.31723299622535706\n",
      "Batch 40: loss = 0.3086293339729309\n",
      "Batch 41: loss = 0.3362885117530823\n",
      "Batch 42: loss = 0.37864333391189575\n",
      "Batch 43: loss = 0.39327168464660645\n",
      "Batch 44: loss = 0.3098234534263611\n",
      "Batch 45: loss = 0.316744863986969\n",
      "Batch 46: loss = 0.29344940185546875\n",
      "Batch 47: loss = 0.2919834852218628\n",
      "Batch 48: loss = 0.32281380891799927\n",
      "Batch 49: loss = 0.3005281388759613\n",
      "Batch 50: loss = 0.3197847604751587\n",
      "Batch 51: loss = 0.3593302369117737\n",
      "Batch 52: loss = 0.32317885756492615\n",
      "Batch 53: loss = 0.3342394232749939\n",
      "Batch 54: loss = 0.27498847246170044\n",
      "Batch 55: loss = 0.2696800231933594\n",
      "Batch 56: loss = 0.35430270433425903\n",
      "Batch 57: loss = 0.3283434510231018\n",
      "Batch 58: loss = 0.3773152828216553\n",
      "Batch 59: loss = 0.28708478808403015\n",
      "Batch 60: loss = 0.32110875844955444\n",
      "Batch 61: loss = 0.2893995940685272\n",
      "Batch 62: loss = 0.3713209331035614\n",
      "Batch 63: loss = 0.2896246910095215\n",
      "Batch 64: loss = 0.2785903215408325\n",
      "Batch 65: loss = 0.3417590856552124\n",
      "Batch 66: loss = 0.3622264564037323\n",
      "Batch 67: loss = 0.34039631485939026\n",
      "Batch 68: loss = 0.3481796979904175\n",
      "Batch 69: loss = 0.320476770401001\n",
      "Batch 70: loss = 0.37168464064598083\n",
      "Batch 71: loss = 0.3320254683494568\n",
      "Batch 72: loss = 0.31115302443504333\n",
      "Batch 73: loss = 0.36394184827804565\n",
      "Batch 74: loss = 0.36061394214630127\n",
      "Batch 75: loss = 0.4005236029624939\n",
      "Batch 76: loss = 0.3469621539115906\n",
      "Batch 77: loss = 0.32728707790374756\n",
      "Batch 78: loss = 0.3580385744571686\n",
      "Batch 79: loss = 0.3416421413421631\n",
      "Batch 80: loss = 0.3292897045612335\n",
      "Batch 81: loss = 0.35180002450942993\n",
      "Batch 82: loss = 0.2910950779914856\n",
      "Batch 83: loss = 0.31016668677330017\n",
      "Batch 84: loss = 0.3737683594226837\n",
      "Batch 85: loss = 0.3884952962398529\n",
      "Batch 86: loss = 0.31549787521362305\n",
      "Batch 87: loss = 0.34550946950912476\n",
      "Batch 88: loss = 0.3968914747238159\n",
      "Batch 89: loss = 0.33082568645477295\n",
      "Batch 90: loss = 0.37062275409698486\n",
      "Batch 91: loss = 0.3702748119831085\n",
      "Batch 92: loss = 0.39487338066101074\n",
      "Batch 93: loss = 0.3265444040298462\n",
      "Batch 94: loss = 0.3300245404243469\n",
      "Batch 95: loss = 0.3197609484195709\n",
      "Batch 96: loss = 0.3870694041252136\n",
      "Batch 97: loss = 0.3254411816596985\n",
      "Batch 98: loss = 0.3240498900413513\n",
      "Batch 99: loss = 0.3634478747844696\n",
      "Batch 100: loss = 0.359427809715271\n",
      "Batch 101: loss = 0.3479388654232025\n",
      "Batch 102: loss = 0.3697770833969116\n",
      "Batch 103: loss = 0.33496004343032837\n",
      "Batch 104: loss = 0.3175206184387207\n",
      "Batch 105: loss = 0.3405129313468933\n",
      "Batch 106: loss = 0.32671552896499634\n",
      "Batch 107: loss = 0.32801270484924316\n",
      "Batch 108: loss = 0.3264434337615967\n",
      "Batch 109: loss = 0.34840548038482666\n",
      "Batch 110: loss = 0.3141230344772339\n",
      "Batch 111: loss = 0.37127208709716797\n",
      "Batch 112: loss = 0.3616711497306824\n",
      "Batch 113: loss = 0.3595229387283325\n",
      "Batch 114: loss = 0.375008225440979\n",
      "Batch 115: loss = 0.3672841489315033\n",
      "Batch 116: loss = 0.3589603006839752\n",
      "Batch 117: loss = 0.34387630224227905\n",
      "Batch 118: loss = 0.3354511857032776\n",
      "Batch 119: loss = 0.3493764400482178\n",
      "Batch 120: loss = 0.3035533130168915\n",
      "Batch 121: loss = 0.3602542281150818\n",
      "Batch 122: loss = 0.32030442357063293\n",
      "Batch 123: loss = 0.3372204005718231\n",
      "Batch 124: loss = 0.3690757751464844\n",
      "Batch 125: loss = 0.35638201236724854\n",
      "Batch 126: loss = 0.36825329065322876\n",
      "\n",
      "Epoch 68/100\n",
      "Batch 1: loss = 0.3720524311065674\n",
      "Batch 2: loss = 0.3568761944770813\n",
      "Batch 3: loss = 0.32733428478240967\n",
      "Batch 4: loss = 0.3213047981262207\n",
      "Batch 5: loss = 0.3144378662109375\n",
      "Batch 6: loss = 0.3470824658870697\n",
      "Batch 7: loss = 0.3198815584182739\n",
      "Batch 8: loss = 0.350358247756958\n",
      "Batch 9: loss = 0.33812785148620605\n",
      "Batch 10: loss = 0.32457059621810913\n",
      "Batch 11: loss = 0.3318254351615906\n",
      "Batch 12: loss = 0.3438882827758789\n",
      "Batch 13: loss = 0.2964266538619995\n",
      "Batch 14: loss = 0.33473044633865356\n",
      "Batch 15: loss = 0.29892659187316895\n",
      "Batch 16: loss = 0.3596549928188324\n",
      "Batch 17: loss = 0.30356210470199585\n",
      "Batch 18: loss = 0.35533854365348816\n",
      "Batch 19: loss = 0.33804962038993835\n",
      "Batch 20: loss = 0.3398544490337372\n",
      "Batch 21: loss = 0.334520548582077\n",
      "Batch 22: loss = 0.31784695386886597\n",
      "Batch 23: loss = 0.38483884930610657\n",
      "Batch 24: loss = 0.33184343576431274\n",
      "Batch 25: loss = 0.34997284412384033\n",
      "Batch 26: loss = 0.31286486983299255\n",
      "Batch 27: loss = 0.39354580640792847\n",
      "Batch 28: loss = 0.3687441051006317\n",
      "Batch 29: loss = 0.36363327503204346\n",
      "Batch 30: loss = 0.3754561245441437\n",
      "Batch 31: loss = 0.3566220998764038\n",
      "Batch 32: loss = 0.3402881920337677\n",
      "Batch 33: loss = 0.3297637701034546\n",
      "Batch 34: loss = 0.34777823090553284\n",
      "Batch 35: loss = 0.3304206132888794\n",
      "Batch 36: loss = 0.2951682209968567\n",
      "Batch 37: loss = 0.3055221736431122\n",
      "Batch 38: loss = 0.34635430574417114\n",
      "Batch 39: loss = 0.3216363191604614\n",
      "Batch 40: loss = 0.3253605365753174\n",
      "Batch 41: loss = 0.3277069330215454\n",
      "Batch 42: loss = 0.33605438470840454\n",
      "Batch 43: loss = 0.3651670217514038\n",
      "Batch 44: loss = 0.30881038308143616\n",
      "Batch 45: loss = 0.2980896830558777\n",
      "Batch 46: loss = 0.29670026898384094\n",
      "Batch 47: loss = 0.29007601737976074\n",
      "Batch 48: loss = 0.30354082584381104\n",
      "Batch 49: loss = 0.2866630554199219\n",
      "Batch 50: loss = 0.29719188809394836\n",
      "Batch 51: loss = 0.3042164146900177\n",
      "Batch 52: loss = 0.372201144695282\n",
      "Batch 53: loss = 0.3222370743751526\n",
      "Batch 54: loss = 0.26879215240478516\n",
      "Batch 55: loss = 0.306190550327301\n",
      "Batch 56: loss = 0.35456764698028564\n",
      "Batch 57: loss = 0.3700738549232483\n",
      "Batch 58: loss = 0.3628509044647217\n",
      "Batch 59: loss = 0.26603567600250244\n",
      "Batch 60: loss = 0.29054832458496094\n",
      "Batch 61: loss = 0.30783453583717346\n",
      "Batch 62: loss = 0.3967565596103668\n",
      "Batch 63: loss = 0.289995402097702\n",
      "Batch 64: loss = 0.2843239903450012\n",
      "Batch 65: loss = 0.34368497133255005\n",
      "Batch 66: loss = 0.3754255175590515\n",
      "Batch 67: loss = 0.35270610451698303\n",
      "Batch 68: loss = 0.3295533061027527\n",
      "Batch 69: loss = 0.3047459125518799\n",
      "Batch 70: loss = 0.3651905059814453\n",
      "Batch 71: loss = 0.3472350537776947\n",
      "Batch 72: loss = 0.31283333897590637\n",
      "Batch 73: loss = 0.39233216643333435\n",
      "Batch 74: loss = 0.35448014736175537\n",
      "Batch 75: loss = 0.3950806260108948\n",
      "Batch 76: loss = 0.36023858189582825\n",
      "Batch 77: loss = 0.314425528049469\n",
      "Batch 78: loss = 0.3606499433517456\n",
      "Batch 79: loss = 0.3194980025291443\n",
      "Batch 80: loss = 0.3284786343574524\n",
      "Batch 81: loss = 0.34611260890960693\n",
      "Batch 82: loss = 0.3026297688484192\n",
      "Batch 83: loss = 0.32399827241897583\n",
      "Batch 84: loss = 0.33140069246292114\n",
      "Batch 85: loss = 0.38870474696159363\n",
      "Batch 86: loss = 0.34599632024765015\n",
      "Batch 87: loss = 0.3335850238800049\n",
      "Batch 88: loss = 0.39706850051879883\n",
      "Batch 89: loss = 0.3269679546356201\n",
      "Batch 90: loss = 0.351045161485672\n",
      "Batch 91: loss = 0.42311710119247437\n",
      "Batch 92: loss = 0.36758583784103394\n",
      "Batch 93: loss = 0.3425775468349457\n",
      "Batch 94: loss = 0.34085437655448914\n",
      "Batch 95: loss = 0.35161978006362915\n",
      "Batch 96: loss = 0.35616201162338257\n",
      "Batch 97: loss = 0.32665860652923584\n",
      "Batch 98: loss = 0.33474135398864746\n",
      "Batch 99: loss = 0.4034678339958191\n",
      "Batch 100: loss = 0.39114731550216675\n",
      "Batch 101: loss = 0.34124138951301575\n",
      "Batch 102: loss = 0.3431243896484375\n",
      "Batch 103: loss = 0.3435848355293274\n",
      "Batch 104: loss = 0.32591962814331055\n",
      "Batch 105: loss = 0.31184810400009155\n",
      "Batch 106: loss = 0.31498047709465027\n",
      "Batch 107: loss = 0.34362220764160156\n",
      "Batch 108: loss = 0.36019080877304077\n",
      "Batch 109: loss = 0.34276053309440613\n",
      "Batch 110: loss = 0.31157994270324707\n",
      "Batch 111: loss = 0.3697437644004822\n",
      "Batch 112: loss = 0.3741854429244995\n",
      "Batch 113: loss = 0.32162633538246155\n",
      "Batch 114: loss = 0.3634713292121887\n",
      "Batch 115: loss = 0.35260009765625\n",
      "Batch 116: loss = 0.35923710465431213\n",
      "Batch 117: loss = 0.3722432255744934\n",
      "Batch 118: loss = 0.3195886015892029\n",
      "Batch 119: loss = 0.362341970205307\n",
      "Batch 120: loss = 0.30583199858665466\n",
      "Batch 121: loss = 0.3874961733818054\n",
      "Batch 122: loss = 0.28889209032058716\n",
      "Batch 123: loss = 0.3513447940349579\n",
      "Batch 124: loss = 0.33890819549560547\n",
      "Batch 125: loss = 0.3608008325099945\n",
      "Batch 126: loss = 0.3460245728492737\n",
      "\n",
      "Epoch 69/100\n",
      "Batch 1: loss = 0.3330749273300171\n",
      "Batch 2: loss = 0.32401400804519653\n",
      "Batch 3: loss = 0.3272767961025238\n",
      "Batch 4: loss = 0.34148290753364563\n",
      "Batch 5: loss = 0.3477579355239868\n",
      "Batch 6: loss = 0.3518214821815491\n",
      "Batch 7: loss = 0.31531310081481934\n",
      "Batch 8: loss = 0.3383733332157135\n",
      "Batch 9: loss = 0.3535230755805969\n",
      "Batch 10: loss = 0.3038199543952942\n",
      "Batch 11: loss = 0.3775455355644226\n",
      "Batch 12: loss = 0.35368674993515015\n",
      "Batch 13: loss = 0.3534255027770996\n",
      "Batch 14: loss = 0.3203496038913727\n",
      "Batch 15: loss = 0.29621991515159607\n",
      "Batch 16: loss = 0.33292609453201294\n",
      "Batch 17: loss = 0.32395344972610474\n",
      "Batch 18: loss = 0.35690200328826904\n",
      "Batch 19: loss = 0.3309931755065918\n",
      "Batch 20: loss = 0.3260875940322876\n",
      "Batch 21: loss = 0.35407233238220215\n",
      "Batch 22: loss = 0.33559590578079224\n",
      "Batch 23: loss = 0.3716035783290863\n",
      "Batch 24: loss = 0.35836854577064514\n",
      "Batch 25: loss = 0.32752662897109985\n",
      "Batch 26: loss = 0.30756670236587524\n",
      "Batch 27: loss = 0.3917328119277954\n",
      "Batch 28: loss = 0.3818405866622925\n",
      "Batch 29: loss = 0.36397606134414673\n",
      "Batch 30: loss = 0.356461763381958\n",
      "Batch 31: loss = 0.3735496699810028\n",
      "Batch 32: loss = 0.3620834946632385\n",
      "Batch 33: loss = 0.34003210067749023\n",
      "Batch 34: loss = 0.3550707697868347\n",
      "Batch 35: loss = 0.34382086992263794\n",
      "Batch 36: loss = 0.2997119128704071\n",
      "Batch 37: loss = 0.27255719900131226\n",
      "Batch 38: loss = 0.3206108808517456\n",
      "Batch 39: loss = 0.32856783270835876\n",
      "Batch 40: loss = 0.3516327142715454\n",
      "Batch 41: loss = 0.3189069628715515\n",
      "Batch 42: loss = 0.3351537585258484\n",
      "Batch 43: loss = 0.3813474774360657\n",
      "Batch 44: loss = 0.2957359850406647\n",
      "Batch 45: loss = 0.2910107970237732\n",
      "Batch 46: loss = 0.2931978404521942\n",
      "Batch 47: loss = 0.3096391260623932\n",
      "Batch 48: loss = 0.32447612285614014\n",
      "Batch 49: loss = 0.331236332654953\n",
      "Batch 50: loss = 0.34431779384613037\n",
      "Batch 51: loss = 0.3430545926094055\n",
      "Batch 52: loss = 0.3566731810569763\n",
      "Batch 53: loss = 0.3335985541343689\n",
      "Batch 54: loss = 0.29216456413269043\n",
      "Batch 55: loss = 0.27879297733306885\n",
      "Batch 56: loss = 0.3148706555366516\n",
      "Batch 57: loss = 0.3616873621940613\n",
      "Batch 58: loss = 0.36067235469818115\n",
      "Batch 59: loss = 0.23879675567150116\n",
      "Batch 60: loss = 0.29309335350990295\n",
      "Batch 61: loss = 0.29353609681129456\n",
      "Batch 62: loss = 0.37449872493743896\n",
      "Batch 63: loss = 0.3065086305141449\n",
      "Batch 64: loss = 0.2809823751449585\n",
      "Batch 65: loss = 0.3300803601741791\n",
      "Batch 66: loss = 0.3248491883277893\n",
      "Batch 67: loss = 0.33452916145324707\n",
      "Batch 68: loss = 0.3311483860015869\n",
      "Batch 69: loss = 0.33570244908332825\n",
      "Batch 70: loss = 0.3728181719779968\n",
      "Batch 71: loss = 0.34458503127098083\n",
      "Batch 72: loss = 0.2683248817920685\n",
      "Batch 73: loss = 0.34016501903533936\n",
      "Batch 74: loss = 0.3412523567676544\n",
      "Batch 75: loss = 0.38601958751678467\n",
      "Batch 76: loss = 0.35927897691726685\n",
      "Batch 77: loss = 0.29832977056503296\n",
      "Batch 78: loss = 0.32376354932785034\n",
      "Batch 79: loss = 0.3244732618331909\n",
      "Batch 80: loss = 0.33788615465164185\n",
      "Batch 81: loss = 0.3363057076931\n",
      "Batch 82: loss = 0.31415855884552\n",
      "Batch 83: loss = 0.3132248520851135\n",
      "Batch 84: loss = 0.3423832058906555\n",
      "Batch 85: loss = 0.38598161935806274\n",
      "Batch 86: loss = 0.3392183780670166\n",
      "Batch 87: loss = 0.32582786679267883\n",
      "Batch 88: loss = 0.37966012954711914\n",
      "Batch 89: loss = 0.29377830028533936\n",
      "Batch 90: loss = 0.31838667392730713\n",
      "Batch 91: loss = 0.34476542472839355\n",
      "Batch 92: loss = 0.3310757875442505\n",
      "Batch 93: loss = 0.31424957513809204\n",
      "Batch 94: loss = 0.34031933546066284\n",
      "Batch 95: loss = 0.33914661407470703\n",
      "Batch 96: loss = 0.3753008544445038\n",
      "Batch 97: loss = 0.3492215871810913\n",
      "Batch 98: loss = 0.3173704147338867\n",
      "Batch 99: loss = 0.3720783293247223\n",
      "Batch 100: loss = 0.3546253442764282\n",
      "Batch 101: loss = 0.3298342227935791\n",
      "Batch 102: loss = 0.3420897126197815\n",
      "Batch 103: loss = 0.31390759348869324\n",
      "Batch 104: loss = 0.33103859424591064\n",
      "Batch 105: loss = 0.3208862543106079\n",
      "Batch 106: loss = 0.32750701904296875\n",
      "Batch 107: loss = 0.3531744182109833\n",
      "Batch 108: loss = 0.34891998767852783\n",
      "Batch 109: loss = 0.34064292907714844\n",
      "Batch 110: loss = 0.31792017817497253\n",
      "Batch 111: loss = 0.328860342502594\n",
      "Batch 112: loss = 0.39041316509246826\n",
      "Batch 113: loss = 0.34972208738327026\n",
      "Batch 114: loss = 0.354535311460495\n",
      "Batch 115: loss = 0.3557528257369995\n",
      "Batch 116: loss = 0.34397464990615845\n",
      "Batch 117: loss = 0.34423020482063293\n",
      "Batch 118: loss = 0.3134649693965912\n",
      "Batch 119: loss = 0.3433406949043274\n",
      "Batch 120: loss = 0.3109649419784546\n",
      "Batch 121: loss = 0.3093620836734772\n",
      "Batch 122: loss = 0.32077693939208984\n",
      "Batch 123: loss = 0.3452407121658325\n",
      "Batch 124: loss = 0.3524743616580963\n",
      "Batch 125: loss = 0.33798056840896606\n",
      "Batch 126: loss = 0.37676432728767395\n",
      "\n",
      "Epoch 70/100\n",
      "Batch 1: loss = 0.33042559027671814\n",
      "Batch 2: loss = 0.3518660068511963\n",
      "Batch 3: loss = 0.3202088475227356\n",
      "Batch 4: loss = 0.323123574256897\n",
      "Batch 5: loss = 0.3254563808441162\n",
      "Batch 6: loss = 0.34097498655319214\n",
      "Batch 7: loss = 0.31019434332847595\n",
      "Batch 8: loss = 0.33011507987976074\n",
      "Batch 9: loss = 0.33405664563179016\n",
      "Batch 10: loss = 0.30516916513442993\n",
      "Batch 11: loss = 0.3409537374973297\n",
      "Batch 12: loss = 0.3270444869995117\n",
      "Batch 13: loss = 0.29410699009895325\n",
      "Batch 14: loss = 0.32535964250564575\n",
      "Batch 15: loss = 0.30655404925346375\n",
      "Batch 16: loss = 0.33172106742858887\n",
      "Batch 17: loss = 0.2967105507850647\n",
      "Batch 18: loss = 0.33382606506347656\n",
      "Batch 19: loss = 0.3579423129558563\n",
      "Batch 20: loss = 0.3250162601470947\n",
      "Batch 21: loss = 0.3283035159111023\n",
      "Batch 22: loss = 0.31865763664245605\n",
      "Batch 23: loss = 0.355205237865448\n",
      "Batch 24: loss = 0.3196079134941101\n",
      "Batch 25: loss = 0.32856395840644836\n",
      "Batch 26: loss = 0.30382055044174194\n",
      "Batch 27: loss = 0.4007388651371002\n",
      "Batch 28: loss = 0.3598308563232422\n",
      "Batch 29: loss = 0.36422938108444214\n",
      "Batch 30: loss = 0.3598068356513977\n",
      "Batch 31: loss = 0.392864853143692\n",
      "Batch 32: loss = 0.35033172369003296\n",
      "Batch 33: loss = 0.32699429988861084\n",
      "Batch 34: loss = 0.3252972364425659\n",
      "Batch 35: loss = 0.3294804096221924\n",
      "Batch 36: loss = 0.31453222036361694\n",
      "Batch 37: loss = 0.2664608955383301\n",
      "Batch 38: loss = 0.3024680018424988\n",
      "Batch 39: loss = 0.31815043091773987\n",
      "Batch 40: loss = 0.31631773710250854\n",
      "Batch 41: loss = 0.318025141954422\n",
      "Batch 42: loss = 0.3339555263519287\n",
      "Batch 43: loss = 0.3507503569126129\n",
      "Batch 44: loss = 0.308904230594635\n",
      "Batch 45: loss = 0.2848767638206482\n",
      "Batch 46: loss = 0.3077313303947449\n",
      "Batch 47: loss = 0.29031944274902344\n",
      "Batch 48: loss = 0.2821691930294037\n",
      "Batch 49: loss = 0.2780604362487793\n",
      "Batch 50: loss = 0.31375232338905334\n",
      "Batch 51: loss = 0.3017882704734802\n",
      "Batch 52: loss = 0.3474568724632263\n",
      "Batch 53: loss = 0.29599061608314514\n",
      "Batch 54: loss = 0.25898241996765137\n",
      "Batch 55: loss = 0.2947189509868622\n",
      "Batch 56: loss = 0.344547837972641\n",
      "Batch 57: loss = 0.3539491891860962\n",
      "Batch 58: loss = 0.33938854932785034\n",
      "Batch 59: loss = 0.2543240487575531\n",
      "Batch 60: loss = 0.29972541332244873\n",
      "Batch 61: loss = 0.30071723461151123\n",
      "Batch 62: loss = 0.3573569655418396\n",
      "Batch 63: loss = 0.2680450677871704\n",
      "Batch 64: loss = 0.2903021275997162\n",
      "Batch 65: loss = 0.31437575817108154\n",
      "Batch 66: loss = 0.32519426941871643\n",
      "Batch 67: loss = 0.3181052505970001\n",
      "Batch 68: loss = 0.3298930823802948\n",
      "Batch 69: loss = 0.30459529161453247\n",
      "Batch 70: loss = 0.37689998745918274\n",
      "Batch 71: loss = 0.3466009497642517\n",
      "Batch 72: loss = 0.2962636351585388\n",
      "Batch 73: loss = 0.32885628938674927\n",
      "Batch 74: loss = 0.3370344042778015\n",
      "Batch 75: loss = 0.36766326427459717\n",
      "Batch 76: loss = 0.3119053840637207\n",
      "Batch 77: loss = 0.31593576073646545\n",
      "Batch 78: loss = 0.3553568124771118\n",
      "Batch 79: loss = 0.33453720808029175\n",
      "Batch 80: loss = 0.31254857778549194\n",
      "Batch 81: loss = 0.34548479318618774\n",
      "Batch 82: loss = 0.313467800617218\n",
      "Batch 83: loss = 0.3185405135154724\n",
      "Batch 84: loss = 0.3235706686973572\n",
      "Batch 85: loss = 0.39515066146850586\n",
      "Batch 86: loss = 0.33397096395492554\n",
      "Batch 87: loss = 0.31418049335479736\n",
      "Batch 88: loss = 0.371929407119751\n",
      "Batch 89: loss = 0.3004952669143677\n",
      "Batch 90: loss = 0.3496863842010498\n",
      "Batch 91: loss = 0.3927260637283325\n",
      "Batch 92: loss = 0.3491767644882202\n",
      "Batch 93: loss = 0.30636492371559143\n",
      "Batch 94: loss = 0.31119561195373535\n",
      "Batch 95: loss = 0.3013920187950134\n",
      "Batch 96: loss = 0.36123597621917725\n",
      "Batch 97: loss = 0.3066781163215637\n",
      "Batch 98: loss = 0.31126028299331665\n",
      "Batch 99: loss = 0.3564876317977905\n",
      "Batch 100: loss = 0.3782360553741455\n",
      "Batch 101: loss = 0.3394205868244171\n",
      "Batch 102: loss = 0.35558101534843445\n",
      "Batch 103: loss = 0.3036080598831177\n",
      "Batch 104: loss = 0.30851322412490845\n",
      "Batch 105: loss = 0.3042709529399872\n",
      "Batch 106: loss = 0.3360861837863922\n",
      "Batch 107: loss = 0.3115689158439636\n",
      "Batch 108: loss = 0.3424098491668701\n",
      "Batch 109: loss = 0.3266923129558563\n",
      "Batch 110: loss = 0.3323935270309448\n",
      "Batch 111: loss = 0.3620375692844391\n",
      "Batch 112: loss = 0.3488301634788513\n",
      "Batch 113: loss = 0.3571437895298004\n",
      "Batch 114: loss = 0.34504765272140503\n",
      "Batch 115: loss = 0.34119147062301636\n",
      "Batch 116: loss = 0.3448110818862915\n",
      "Batch 117: loss = 0.2798924744129181\n",
      "Batch 118: loss = 0.31443458795547485\n",
      "Batch 119: loss = 0.33526816964149475\n",
      "Batch 120: loss = 0.28173351287841797\n",
      "Batch 121: loss = 0.3198428750038147\n",
      "Batch 122: loss = 0.28994685411453247\n",
      "Batch 123: loss = 0.32097190618515015\n",
      "Batch 124: loss = 0.3346339464187622\n",
      "Batch 125: loss = 0.3593306541442871\n",
      "Batch 126: loss = 0.3264249861240387\n",
      "\n",
      "Epoch 71/100\n",
      "Batch 1: loss = 0.32453715801239014\n",
      "Batch 2: loss = 0.33260565996170044\n",
      "Batch 3: loss = 0.31857064366340637\n",
      "Batch 4: loss = 0.3024026155471802\n",
      "Batch 5: loss = 0.351493775844574\n",
      "Batch 6: loss = 0.34440505504608154\n",
      "Batch 7: loss = 0.29251202940940857\n",
      "Batch 8: loss = 0.36105087399482727\n",
      "Batch 9: loss = 0.3416326344013214\n",
      "Batch 10: loss = 0.29565978050231934\n",
      "Batch 11: loss = 0.31530070304870605\n",
      "Batch 12: loss = 0.31546542048454285\n",
      "Batch 13: loss = 0.28403085470199585\n",
      "Batch 14: loss = 0.32854899764060974\n",
      "Batch 15: loss = 0.29832297563552856\n",
      "Batch 16: loss = 0.35114726424217224\n",
      "Batch 17: loss = 0.32698869705200195\n",
      "Batch 18: loss = 0.33059898018836975\n",
      "Batch 19: loss = 0.3274477422237396\n",
      "Batch 20: loss = 0.32151085138320923\n",
      "Batch 21: loss = 0.31782031059265137\n",
      "Batch 22: loss = 0.29995355010032654\n",
      "Batch 23: loss = 0.3839869499206543\n",
      "Batch 24: loss = 0.3302042484283447\n",
      "Batch 25: loss = 0.3655405640602112\n",
      "Batch 26: loss = 0.30003803968429565\n",
      "Batch 27: loss = 0.38539308309555054\n",
      "Batch 28: loss = 0.35746824741363525\n",
      "Batch 29: loss = 0.35047245025634766\n",
      "Batch 30: loss = 0.3206370174884796\n",
      "Batch 31: loss = 0.34883052110671997\n",
      "Batch 32: loss = 0.35529327392578125\n",
      "Batch 33: loss = 0.333570271730423\n",
      "Batch 34: loss = 0.36005303263664246\n",
      "Batch 35: loss = 0.3339720666408539\n",
      "Batch 36: loss = 0.2797776460647583\n",
      "Batch 37: loss = 0.29620295763015747\n",
      "Batch 38: loss = 0.3103681206703186\n",
      "Batch 39: loss = 0.31267181038856506\n",
      "Batch 40: loss = 0.31636494398117065\n",
      "Batch 41: loss = 0.3171146512031555\n",
      "Batch 42: loss = 0.32236313819885254\n",
      "Batch 43: loss = 0.3458675444126129\n",
      "Batch 44: loss = 0.2926328778266907\n",
      "Batch 45: loss = 0.279158353805542\n",
      "Batch 46: loss = 0.26933348178863525\n",
      "Batch 47: loss = 0.30830734968185425\n",
      "Batch 48: loss = 0.29444167017936707\n",
      "Batch 49: loss = 0.2905319035053253\n",
      "Batch 50: loss = 0.3043619394302368\n",
      "Batch 51: loss = 0.31107833981513977\n",
      "Batch 52: loss = 0.3366032838821411\n",
      "Batch 53: loss = 0.3070499897003174\n",
      "Batch 54: loss = 0.2547934055328369\n",
      "Batch 55: loss = 0.32356691360473633\n",
      "Batch 56: loss = 0.34101223945617676\n",
      "Batch 57: loss = 0.3384220004081726\n",
      "Batch 58: loss = 0.3406897783279419\n",
      "Batch 59: loss = 0.2597699761390686\n",
      "Batch 60: loss = 0.30176836252212524\n",
      "Batch 61: loss = 0.3149558901786804\n",
      "Batch 62: loss = 0.32909053564071655\n",
      "Batch 63: loss = 0.2518013119697571\n",
      "Batch 64: loss = 0.27936917543411255\n",
      "Batch 65: loss = 0.3353348672389984\n",
      "Batch 66: loss = 0.308022141456604\n",
      "Batch 67: loss = 0.3086646795272827\n",
      "Batch 68: loss = 0.32284194231033325\n",
      "Batch 69: loss = 0.32605642080307007\n",
      "Batch 70: loss = 0.3357984125614166\n",
      "Batch 71: loss = 0.3686639964580536\n",
      "Batch 72: loss = 0.2574535608291626\n",
      "Batch 73: loss = 0.3515201508998871\n",
      "Batch 74: loss = 0.34653815627098083\n",
      "Batch 75: loss = 0.35548681020736694\n",
      "Batch 76: loss = 0.33415549993515015\n",
      "Batch 77: loss = 0.3328818082809448\n",
      "Batch 78: loss = 0.3541030287742615\n",
      "Batch 79: loss = 0.3333619236946106\n",
      "Batch 80: loss = 0.30679023265838623\n",
      "Batch 81: loss = 0.32898789644241333\n",
      "Batch 82: loss = 0.3124900460243225\n",
      "Batch 83: loss = 0.29976677894592285\n",
      "Batch 84: loss = 0.3416709899902344\n",
      "Batch 85: loss = 0.3731217384338379\n",
      "Batch 86: loss = 0.3570074737071991\n",
      "Batch 87: loss = 0.3054807782173157\n",
      "Batch 88: loss = 0.3391765356063843\n",
      "Batch 89: loss = 0.3291592001914978\n",
      "Batch 90: loss = 0.3582248091697693\n",
      "Batch 91: loss = 0.37180477380752563\n",
      "Batch 92: loss = 0.33897340297698975\n",
      "Batch 93: loss = 0.325802206993103\n",
      "Batch 94: loss = 0.32246720790863037\n",
      "Batch 95: loss = 0.3404967188835144\n",
      "Batch 96: loss = 0.36328911781311035\n",
      "Batch 97: loss = 0.3348153829574585\n",
      "Batch 98: loss = 0.3109623193740845\n",
      "Batch 99: loss = 0.3375202417373657\n",
      "Batch 100: loss = 0.3537213206291199\n",
      "Batch 101: loss = 0.3199942708015442\n",
      "Batch 102: loss = 0.3246634006500244\n",
      "Batch 103: loss = 0.3142707049846649\n",
      "Batch 104: loss = 0.31103014945983887\n",
      "Batch 105: loss = 0.30593574047088623\n",
      "Batch 106: loss = 0.344444215297699\n",
      "Batch 107: loss = 0.34890538454055786\n",
      "Batch 108: loss = 0.3269962668418884\n",
      "Batch 109: loss = 0.3331051170825958\n",
      "Batch 110: loss = 0.31319659948349\n",
      "Batch 111: loss = 0.355060338973999\n",
      "Batch 112: loss = 0.37426313757896423\n",
      "Batch 113: loss = 0.3110162019729614\n",
      "Batch 114: loss = 0.37145209312438965\n",
      "Batch 115: loss = 0.35976675152778625\n",
      "Batch 116: loss = 0.361510694026947\n",
      "Batch 117: loss = 0.2996426224708557\n",
      "Batch 118: loss = 0.2844923138618469\n",
      "Batch 119: loss = 0.29589006304740906\n",
      "Batch 120: loss = 0.29630494117736816\n",
      "Batch 121: loss = 0.3231648802757263\n",
      "Batch 122: loss = 0.3245082199573517\n",
      "Batch 123: loss = 0.3104645013809204\n",
      "Batch 124: loss = 0.3388991355895996\n",
      "Batch 125: loss = 0.3595799207687378\n",
      "Batch 126: loss = 0.31077152490615845\n",
      "\n",
      "Epoch 72/100\n",
      "Batch 1: loss = 0.3233640193939209\n",
      "Batch 2: loss = 0.3118857145309448\n",
      "Batch 3: loss = 0.34402430057525635\n",
      "Batch 4: loss = 0.301773339509964\n",
      "Batch 5: loss = 0.3321325182914734\n",
      "Batch 6: loss = 0.3673969805240631\n",
      "Batch 7: loss = 0.2983100414276123\n",
      "Batch 8: loss = 0.332403302192688\n",
      "Batch 9: loss = 0.33733636140823364\n",
      "Batch 10: loss = 0.31765568256378174\n",
      "Batch 11: loss = 0.3233344256877899\n",
      "Batch 12: loss = 0.2983931601047516\n",
      "Batch 13: loss = 0.3021589517593384\n",
      "Batch 14: loss = 0.3313094675540924\n",
      "Batch 15: loss = 0.3054620623588562\n",
      "Batch 16: loss = 0.3488885760307312\n",
      "Batch 17: loss = 0.2926751673221588\n",
      "Batch 18: loss = 0.33224883675575256\n",
      "Batch 19: loss = 0.32124224305152893\n",
      "Batch 20: loss = 0.2986041009426117\n",
      "Batch 21: loss = 0.3021061420440674\n",
      "Batch 22: loss = 0.3285514712333679\n",
      "Batch 23: loss = 0.3803725242614746\n",
      "Batch 24: loss = 0.3350036144256592\n",
      "Batch 25: loss = 0.32550156116485596\n",
      "Batch 26: loss = 0.3129500150680542\n",
      "Batch 27: loss = 0.37364351749420166\n",
      "Batch 28: loss = 0.3566698431968689\n",
      "Batch 29: loss = 0.3567272424697876\n",
      "Batch 30: loss = 0.2946256101131439\n",
      "Batch 31: loss = 0.32549357414245605\n",
      "Batch 32: loss = 0.36997050046920776\n",
      "Batch 33: loss = 0.32505202293395996\n",
      "Batch 34: loss = 0.3361167311668396\n",
      "Batch 35: loss = 0.31541699171066284\n",
      "Batch 36: loss = 0.2689308822154999\n",
      "Batch 37: loss = 0.3045825958251953\n",
      "Batch 38: loss = 0.30123254656791687\n",
      "Batch 39: loss = 0.3029024600982666\n",
      "Batch 40: loss = 0.30712199211120605\n",
      "Batch 41: loss = 0.3104391098022461\n",
      "Batch 42: loss = 0.29578304290771484\n",
      "Batch 43: loss = 0.3463648557662964\n",
      "Batch 44: loss = 0.27989810705184937\n",
      "Batch 45: loss = 0.3064669966697693\n",
      "Batch 46: loss = 0.2813197076320648\n",
      "Batch 47: loss = 0.3247044086456299\n",
      "Batch 48: loss = 0.2975655794143677\n",
      "Batch 49: loss = 0.3028097152709961\n",
      "Batch 50: loss = 0.28103095293045044\n",
      "Batch 51: loss = 0.3267112672328949\n",
      "Batch 52: loss = 0.35461485385894775\n",
      "Batch 53: loss = 0.3361913561820984\n",
      "Batch 54: loss = 0.26347407698631287\n",
      "Batch 55: loss = 0.30575817823410034\n",
      "Batch 56: loss = 0.3652864098548889\n",
      "Batch 57: loss = 0.39258652925491333\n",
      "Batch 58: loss = 0.36011117696762085\n",
      "Batch 59: loss = 0.24013318121433258\n",
      "Batch 60: loss = 0.30345991253852844\n",
      "Batch 61: loss = 0.29869407415390015\n",
      "Batch 62: loss = 0.33291614055633545\n",
      "Batch 63: loss = 0.3101091980934143\n",
      "Batch 64: loss = 0.26223742961883545\n",
      "Batch 65: loss = 0.32498788833618164\n",
      "Batch 66: loss = 0.3590158522129059\n",
      "Batch 67: loss = 0.35233569145202637\n",
      "Batch 68: loss = 0.32888472080230713\n",
      "Batch 69: loss = 0.3226078152656555\n",
      "Batch 70: loss = 0.33961260318756104\n",
      "Batch 71: loss = 0.35626524686813354\n",
      "Batch 72: loss = 0.29692065715789795\n",
      "Batch 73: loss = 0.31115958094596863\n",
      "Batch 74: loss = 0.3336120545864105\n",
      "Batch 75: loss = 0.3934124708175659\n",
      "Batch 76: loss = 0.34192049503326416\n",
      "Batch 77: loss = 0.32637524604797363\n",
      "Batch 78: loss = 0.3223625719547272\n",
      "Batch 79: loss = 0.32398736476898193\n",
      "Batch 80: loss = 0.32833603024482727\n",
      "Batch 81: loss = 0.3256329596042633\n",
      "Batch 82: loss = 0.3110722601413727\n",
      "Batch 83: loss = 0.3016541600227356\n",
      "Batch 84: loss = 0.32786136865615845\n",
      "Batch 85: loss = 0.3468412160873413\n",
      "Batch 86: loss = 0.3399711847305298\n",
      "Batch 87: loss = 0.32752346992492676\n",
      "Batch 88: loss = 0.37387701869010925\n",
      "Batch 89: loss = 0.28435224294662476\n",
      "Batch 90: loss = 0.34601494669914246\n",
      "Batch 91: loss = 0.3608990013599396\n",
      "Batch 92: loss = 0.34502577781677246\n",
      "Batch 93: loss = 0.2914312183856964\n",
      "Batch 94: loss = 0.3329232931137085\n",
      "Batch 95: loss = 0.32991138100624084\n",
      "Batch 96: loss = 0.36874014139175415\n",
      "Batch 97: loss = 0.324543833732605\n",
      "Batch 98: loss = 0.30936741828918457\n",
      "Batch 99: loss = 0.374630868434906\n",
      "Batch 100: loss = 0.3771565556526184\n",
      "Batch 101: loss = 0.32510626316070557\n",
      "Batch 102: loss = 0.3285689651966095\n",
      "Batch 103: loss = 0.31220391392707825\n",
      "Batch 104: loss = 0.2942853569984436\n",
      "Batch 105: loss = 0.3007928431034088\n",
      "Batch 106: loss = 0.29848039150238037\n",
      "Batch 107: loss = 0.3279529809951782\n",
      "Batch 108: loss = 0.32741063833236694\n",
      "Batch 109: loss = 0.33490675687789917\n",
      "Batch 110: loss = 0.2977040410041809\n",
      "Batch 111: loss = 0.3647174835205078\n",
      "Batch 112: loss = 0.35992711782455444\n",
      "Batch 113: loss = 0.31386420130729675\n",
      "Batch 114: loss = 0.3529092073440552\n",
      "Batch 115: loss = 0.3481864631175995\n",
      "Batch 116: loss = 0.3363723158836365\n",
      "Batch 117: loss = 0.3031385540962219\n",
      "Batch 118: loss = 0.3349791467189789\n",
      "Batch 119: loss = 0.3104998469352722\n",
      "Batch 120: loss = 0.30466869473457336\n",
      "Batch 121: loss = 0.317371666431427\n",
      "Batch 122: loss = 0.3008558750152588\n",
      "Batch 123: loss = 0.3596634864807129\n",
      "Batch 124: loss = 0.3382454514503479\n",
      "Batch 125: loss = 0.35479581356048584\n",
      "Batch 126: loss = 0.3409683108329773\n",
      "\n",
      "Epoch 73/100\n",
      "Batch 1: loss = 0.31260788440704346\n",
      "Batch 2: loss = 0.3351556062698364\n",
      "Batch 3: loss = 0.3261154294013977\n",
      "Batch 4: loss = 0.31104332208633423\n",
      "Batch 5: loss = 0.33572226762771606\n",
      "Batch 6: loss = 0.3816322088241577\n",
      "Batch 7: loss = 0.31839707493782043\n",
      "Batch 8: loss = 0.3355140686035156\n",
      "Batch 9: loss = 0.34666866064071655\n",
      "Batch 10: loss = 0.30388134717941284\n",
      "Batch 11: loss = 0.2934429943561554\n",
      "Batch 12: loss = 0.3225914239883423\n",
      "Batch 13: loss = 0.281521201133728\n",
      "Batch 14: loss = 0.33227241039276123\n",
      "Batch 15: loss = 0.2855941653251648\n",
      "Batch 16: loss = 0.34038883447647095\n",
      "Batch 17: loss = 0.2966538369655609\n",
      "Batch 18: loss = 0.3415197432041168\n",
      "Batch 19: loss = 0.33153432607650757\n",
      "Batch 20: loss = 0.3030571937561035\n",
      "Batch 21: loss = 0.33947503566741943\n",
      "Batch 22: loss = 0.3347901701927185\n",
      "Batch 23: loss = 0.34107881784439087\n",
      "Batch 24: loss = 0.3106568455696106\n",
      "Batch 25: loss = 0.3259705901145935\n",
      "Batch 26: loss = 0.29737019538879395\n",
      "Batch 27: loss = 0.36797934770584106\n",
      "Batch 28: loss = 0.34069299697875977\n",
      "Batch 29: loss = 0.33235421776771545\n",
      "Batch 30: loss = 0.33527255058288574\n",
      "Batch 31: loss = 0.36515164375305176\n",
      "Batch 32: loss = 0.35105425119400024\n",
      "Batch 33: loss = 0.32896968722343445\n",
      "Batch 34: loss = 0.34460729360580444\n",
      "Batch 35: loss = 0.32882624864578247\n",
      "Batch 36: loss = 0.2850353717803955\n",
      "Batch 37: loss = 0.2858751118183136\n",
      "Batch 38: loss = 0.2710696756839752\n",
      "Batch 39: loss = 0.3384271264076233\n",
      "Batch 40: loss = 0.29102426767349243\n",
      "Batch 41: loss = 0.31237906217575073\n",
      "Batch 42: loss = 0.32563844323158264\n",
      "Batch 43: loss = 0.38476383686065674\n",
      "Batch 44: loss = 0.30007120966911316\n",
      "Batch 45: loss = 0.30889391899108887\n",
      "Batch 46: loss = 0.28765493631362915\n",
      "Batch 47: loss = 0.27858972549438477\n",
      "Batch 48: loss = 0.2825774848461151\n",
      "Batch 49: loss = 0.28257256746292114\n",
      "Batch 50: loss = 0.29497620463371277\n",
      "Batch 51: loss = 0.3087468147277832\n",
      "Batch 52: loss = 0.3270665407180786\n",
      "Batch 53: loss = 0.30027562379837036\n",
      "Batch 54: loss = 0.25189101696014404\n",
      "Batch 55: loss = 0.2716820240020752\n",
      "Batch 56: loss = 0.2981656789779663\n",
      "Batch 57: loss = 0.29935193061828613\n",
      "Batch 58: loss = 0.3351859450340271\n",
      "Batch 59: loss = 0.26161080598831177\n",
      "Batch 60: loss = 0.31461864709854126\n",
      "Batch 61: loss = 0.2789735794067383\n",
      "Batch 62: loss = 0.3360164165496826\n",
      "Batch 63: loss = 0.29334959387779236\n",
      "Batch 64: loss = 0.26663827896118164\n",
      "Batch 65: loss = 0.326602041721344\n",
      "Batch 66: loss = 0.31388431787490845\n",
      "Batch 67: loss = 0.3167724013328552\n",
      "Batch 68: loss = 0.30099907517433167\n",
      "Batch 69: loss = 0.27974599599838257\n",
      "Batch 70: loss = 0.340730220079422\n",
      "Batch 71: loss = 0.34073445200920105\n",
      "Batch 72: loss = 0.287670373916626\n",
      "Batch 73: loss = 0.35853469371795654\n",
      "Batch 74: loss = 0.32286375761032104\n",
      "Batch 75: loss = 0.3394339680671692\n",
      "Batch 76: loss = 0.3490215539932251\n",
      "Batch 77: loss = 0.31477054953575134\n",
      "Batch 78: loss = 0.32296687364578247\n",
      "Batch 79: loss = 0.31507188081741333\n",
      "Batch 80: loss = 0.33738288283348083\n",
      "Batch 81: loss = 0.3766702711582184\n",
      "Batch 82: loss = 0.28925132751464844\n",
      "Batch 83: loss = 0.3006676435470581\n",
      "Batch 84: loss = 0.31886178255081177\n",
      "Batch 85: loss = 0.3939138650894165\n",
      "Batch 86: loss = 0.30262047052383423\n",
      "Batch 87: loss = 0.3009801506996155\n",
      "Batch 88: loss = 0.36400389671325684\n",
      "Batch 89: loss = 0.30799853801727295\n",
      "Batch 90: loss = 0.3467863202095032\n",
      "Batch 91: loss = 0.32755690813064575\n",
      "Batch 92: loss = 0.3210331201553345\n",
      "Batch 93: loss = 0.3040812909603119\n",
      "Batch 94: loss = 0.2950921654701233\n",
      "Batch 95: loss = 0.3047817051410675\n",
      "Batch 96: loss = 0.3667917847633362\n",
      "Batch 97: loss = 0.28547927737236023\n",
      "Batch 98: loss = 0.2953287363052368\n",
      "Batch 99: loss = 0.35341203212738037\n",
      "Batch 100: loss = 0.3380483090877533\n",
      "Batch 101: loss = 0.3152453601360321\n",
      "Batch 102: loss = 0.33019059896469116\n",
      "Batch 103: loss = 0.3002849221229553\n",
      "Batch 104: loss = 0.3056371212005615\n",
      "Batch 105: loss = 0.2685709297657013\n",
      "Batch 106: loss = 0.3294428884983063\n",
      "Batch 107: loss = 0.34604647755622864\n",
      "Batch 108: loss = 0.32818225026130676\n",
      "Batch 109: loss = 0.32920950651168823\n",
      "Batch 110: loss = 0.26622989773750305\n",
      "Batch 111: loss = 0.32283294200897217\n",
      "Batch 112: loss = 0.34340810775756836\n",
      "Batch 113: loss = 0.31710970401763916\n",
      "Batch 114: loss = 0.3236621916294098\n",
      "Batch 115: loss = 0.3107476234436035\n",
      "Batch 116: loss = 0.3160010278224945\n",
      "Batch 117: loss = 0.31777340173721313\n",
      "Batch 118: loss = 0.3147457540035248\n",
      "Batch 119: loss = 0.30130714178085327\n",
      "Batch 120: loss = 0.3003244698047638\n",
      "Batch 121: loss = 0.31070366501808167\n",
      "Batch 122: loss = 0.31320440769195557\n",
      "Batch 123: loss = 0.35011541843414307\n",
      "Batch 124: loss = 0.3576553463935852\n",
      "Batch 125: loss = 0.3484242558479309\n",
      "Batch 126: loss = 0.32299309968948364\n",
      "\n",
      "Epoch 74/100\n",
      "Batch 1: loss = 0.31014540791511536\n",
      "Batch 2: loss = 0.34206151962280273\n",
      "Batch 3: loss = 0.2822329103946686\n",
      "Batch 4: loss = 0.32581889629364014\n",
      "Batch 5: loss = 0.3188493847846985\n",
      "Batch 6: loss = 0.31365469098091125\n",
      "Batch 7: loss = 0.29931023716926575\n",
      "Batch 8: loss = 0.32742932438850403\n",
      "Batch 9: loss = 0.3351738750934601\n",
      "Batch 10: loss = 0.3026547431945801\n",
      "Batch 11: loss = 0.31765371561050415\n",
      "Batch 12: loss = 0.32695460319519043\n",
      "Batch 13: loss = 0.3223578929901123\n",
      "Batch 14: loss = 0.2880988121032715\n",
      "Batch 15: loss = 0.31137171387672424\n",
      "Batch 16: loss = 0.3438490033149719\n",
      "Batch 17: loss = 0.30985724925994873\n",
      "Batch 18: loss = 0.33726897835731506\n",
      "Batch 19: loss = 0.31043922901153564\n",
      "Batch 20: loss = 0.2921849489212036\n",
      "Batch 21: loss = 0.3319162130355835\n",
      "Batch 22: loss = 0.2974650263786316\n",
      "Batch 23: loss = 0.36553242802619934\n",
      "Batch 24: loss = 0.28248167037963867\n",
      "Batch 25: loss = 0.31883132457733154\n",
      "Batch 26: loss = 0.3112404942512512\n",
      "Batch 27: loss = 0.37261998653411865\n",
      "Batch 28: loss = 0.3303295969963074\n",
      "Batch 29: loss = 0.34919577836990356\n",
      "Batch 30: loss = 0.2937256693840027\n",
      "Batch 31: loss = 0.34475457668304443\n",
      "Batch 32: loss = 0.3363695740699768\n",
      "Batch 33: loss = 0.2849172353744507\n",
      "Batch 34: loss = 0.32784923911094666\n",
      "Batch 35: loss = 0.29771482944488525\n",
      "Batch 36: loss = 0.2510296702384949\n",
      "Batch 37: loss = 0.28972819447517395\n",
      "Batch 38: loss = 0.31300246715545654\n",
      "Batch 39: loss = 0.30180633068084717\n",
      "Batch 40: loss = 0.349806547164917\n",
      "Batch 41: loss = 0.32993894815444946\n",
      "Batch 42: loss = 0.3202390670776367\n",
      "Batch 43: loss = 0.33284658193588257\n",
      "Batch 44: loss = 0.3265465497970581\n",
      "Batch 45: loss = 0.2942483127117157\n",
      "Batch 46: loss = 0.2580628991127014\n",
      "Batch 47: loss = 0.29631683230400085\n",
      "Batch 48: loss = 0.2875496745109558\n",
      "Batch 49: loss = 0.2812810242176056\n",
      "Batch 50: loss = 0.28787684440612793\n",
      "Batch 51: loss = 0.35354211926460266\n",
      "Batch 52: loss = 0.3192148804664612\n",
      "Batch 53: loss = 0.3087829053401947\n",
      "Batch 54: loss = 0.26718056201934814\n",
      "Batch 55: loss = 0.2920075058937073\n",
      "Batch 56: loss = 0.3292716145515442\n",
      "Batch 57: loss = 0.3257748484611511\n",
      "Batch 58: loss = 0.34274423122406006\n",
      "Batch 59: loss = 0.2314637303352356\n",
      "Batch 60: loss = 0.3018394410610199\n",
      "Batch 61: loss = 0.2860336899757385\n",
      "Batch 62: loss = 0.32790714502334595\n",
      "Batch 63: loss = 0.2834182679653168\n",
      "Batch 64: loss = 0.2843359112739563\n",
      "Batch 65: loss = 0.3083137273788452\n",
      "Batch 66: loss = 0.30400770902633667\n",
      "Batch 67: loss = 0.323245108127594\n",
      "Batch 68: loss = 0.3394067585468292\n",
      "Batch 69: loss = 0.3187764883041382\n",
      "Batch 70: loss = 0.35256460309028625\n",
      "Batch 71: loss = 0.32610267400741577\n",
      "Batch 72: loss = 0.24517005681991577\n",
      "Batch 73: loss = 0.3786689043045044\n",
      "Batch 74: loss = 0.32757115364074707\n",
      "Batch 75: loss = 0.3478161096572876\n",
      "Batch 76: loss = 0.2979053258895874\n",
      "Batch 77: loss = 0.26680687069892883\n",
      "Batch 78: loss = 0.329461008310318\n",
      "Batch 79: loss = 0.35067057609558105\n",
      "Batch 80: loss = 0.29355281591415405\n",
      "Batch 81: loss = 0.3557596206665039\n",
      "Batch 82: loss = 0.3457027077674866\n",
      "Batch 83: loss = 0.2908688187599182\n",
      "Batch 84: loss = 0.3310156464576721\n",
      "Batch 85: loss = 0.3583824038505554\n",
      "Batch 86: loss = 0.3205476403236389\n",
      "Batch 87: loss = 0.3133365213871002\n",
      "Batch 88: loss = 0.34775733947753906\n",
      "Batch 89: loss = 0.302084743976593\n",
      "Batch 90: loss = 0.341670960187912\n",
      "Batch 91: loss = 0.37900471687316895\n",
      "Batch 92: loss = 0.34858882427215576\n",
      "Batch 93: loss = 0.31222033500671387\n",
      "Batch 94: loss = 0.3025534749031067\n",
      "Batch 95: loss = 0.2949722707271576\n",
      "Batch 96: loss = 0.38063836097717285\n",
      "Batch 97: loss = 0.33015167713165283\n",
      "Batch 98: loss = 0.29632484912872314\n",
      "Batch 99: loss = 0.36196643114089966\n",
      "Batch 100: loss = 0.37495627999305725\n",
      "Batch 101: loss = 0.3365841805934906\n",
      "Batch 102: loss = 0.354065477848053\n",
      "Batch 103: loss = 0.2879430949687958\n",
      "Batch 104: loss = 0.29373374581336975\n",
      "Batch 105: loss = 0.3027888536453247\n",
      "Batch 106: loss = 0.2984963655471802\n",
      "Batch 107: loss = 0.2957395911216736\n",
      "Batch 108: loss = 0.3007487654685974\n",
      "Batch 109: loss = 0.3326832354068756\n",
      "Batch 110: loss = 0.31406646966934204\n",
      "Batch 111: loss = 0.3130244314670563\n",
      "Batch 112: loss = 0.3481394052505493\n",
      "Batch 113: loss = 0.3299974203109741\n",
      "Batch 114: loss = 0.34724950790405273\n",
      "Batch 115: loss = 0.3381158709526062\n",
      "Batch 116: loss = 0.3186326324939728\n",
      "Batch 117: loss = 0.3020801544189453\n",
      "Batch 118: loss = 0.2789844274520874\n",
      "Batch 119: loss = 0.3053012490272522\n",
      "Batch 120: loss = 0.2907593548297882\n",
      "Batch 121: loss = 0.30780431628227234\n",
      "Batch 122: loss = 0.3082347810268402\n",
      "Batch 123: loss = 0.3295648694038391\n",
      "Batch 124: loss = 0.32621264457702637\n",
      "Batch 125: loss = 0.3644009232521057\n",
      "Batch 126: loss = 0.3269367218017578\n",
      "\n",
      "Epoch 75/100\n",
      "Batch 1: loss = 0.29414209723472595\n",
      "Batch 2: loss = 0.3206157088279724\n",
      "Batch 3: loss = 0.32151275873184204\n",
      "Batch 4: loss = 0.3069927990436554\n",
      "Batch 5: loss = 0.297932505607605\n",
      "Batch 6: loss = 0.31466907262802124\n",
      "Batch 7: loss = 0.28503721952438354\n",
      "Batch 8: loss = 0.33967459201812744\n",
      "Batch 9: loss = 0.29756996035575867\n",
      "Batch 10: loss = 0.2846266031265259\n",
      "Batch 11: loss = 0.3032609820365906\n",
      "Batch 12: loss = 0.2945632338523865\n",
      "Batch 13: loss = 0.2843378782272339\n",
      "Batch 14: loss = 0.33194273710250854\n",
      "Batch 15: loss = 0.2942520081996918\n",
      "Batch 16: loss = 0.32946938276290894\n",
      "Batch 17: loss = 0.27437835931777954\n",
      "Batch 18: loss = 0.34442874789237976\n",
      "Batch 19: loss = 0.2924020290374756\n",
      "Batch 20: loss = 0.32829397916793823\n",
      "Batch 21: loss = 0.3206223249435425\n",
      "Batch 22: loss = 0.3115267753601074\n",
      "Batch 23: loss = 0.33023226261138916\n",
      "Batch 24: loss = 0.3337845802307129\n",
      "Batch 25: loss = 0.34155982732772827\n",
      "Batch 26: loss = 0.29235410690307617\n",
      "Batch 27: loss = 0.376383900642395\n",
      "Batch 28: loss = 0.34683161973953247\n",
      "Batch 29: loss = 0.3273942470550537\n",
      "Batch 30: loss = 0.31517747044563293\n",
      "Batch 31: loss = 0.36160337924957275\n",
      "Batch 32: loss = 0.3084079623222351\n",
      "Batch 33: loss = 0.2880168855190277\n",
      "Batch 34: loss = 0.33843475580215454\n",
      "Batch 35: loss = 0.3222905695438385\n",
      "Batch 36: loss = 0.2685336172580719\n",
      "Batch 37: loss = 0.29011374711990356\n",
      "Batch 38: loss = 0.3197551369667053\n",
      "Batch 39: loss = 0.31022676825523376\n",
      "Batch 40: loss = 0.3096676468849182\n",
      "Batch 41: loss = 0.2870270609855652\n",
      "Batch 42: loss = 0.31556791067123413\n",
      "Batch 43: loss = 0.3637283444404602\n",
      "Batch 44: loss = 0.294603168964386\n",
      "Batch 45: loss = 0.2566477060317993\n",
      "Batch 46: loss = 0.2980102300643921\n",
      "Batch 47: loss = 0.3139001131057739\n",
      "Batch 48: loss = 0.2674943208694458\n",
      "Batch 49: loss = 0.27742627263069153\n",
      "Batch 50: loss = 0.27177155017852783\n",
      "Batch 51: loss = 0.2856835722923279\n",
      "Batch 52: loss = 0.3503534197807312\n",
      "Batch 53: loss = 0.30187714099884033\n",
      "Batch 54: loss = 0.2348155975341797\n",
      "Batch 55: loss = 0.2746258080005646\n",
      "Batch 56: loss = 0.30856698751449585\n",
      "Batch 57: loss = 0.3204600214958191\n",
      "Batch 58: loss = 0.32081204652786255\n",
      "Batch 59: loss = 0.2607876658439636\n",
      "Batch 60: loss = 0.28153491020202637\n",
      "Batch 61: loss = 0.27671581506729126\n",
      "Batch 62: loss = 0.3304537534713745\n",
      "Batch 63: loss = 0.2779851257801056\n",
      "Batch 64: loss = 0.26092198491096497\n",
      "Batch 65: loss = 0.30399495363235474\n",
      "Batch 66: loss = 0.33786481618881226\n",
      "Batch 67: loss = 0.30039846897125244\n",
      "Batch 68: loss = 0.30674999952316284\n",
      "Batch 69: loss = 0.29485589265823364\n",
      "Batch 70: loss = 0.34771817922592163\n",
      "Batch 71: loss = 0.2984394431114197\n",
      "Batch 72: loss = 0.2858721613883972\n",
      "Batch 73: loss = 0.31843310594558716\n",
      "Batch 74: loss = 0.31042876839637756\n",
      "Batch 75: loss = 0.3460540771484375\n",
      "Batch 76: loss = 0.31374460458755493\n",
      "Batch 77: loss = 0.2936842143535614\n",
      "Batch 78: loss = 0.2951553463935852\n",
      "Batch 79: loss = 0.3183692395687103\n",
      "Batch 80: loss = 0.31095755100250244\n",
      "Batch 81: loss = 0.3292001485824585\n",
      "Batch 82: loss = 0.28371405601501465\n",
      "Batch 83: loss = 0.32329317927360535\n",
      "Batch 84: loss = 0.3271455764770508\n",
      "Batch 85: loss = 0.33992573618888855\n",
      "Batch 86: loss = 0.312776118516922\n",
      "Batch 87: loss = 0.2942866086959839\n",
      "Batch 88: loss = 0.3799758851528168\n",
      "Batch 89: loss = 0.33793097734451294\n",
      "Batch 90: loss = 0.32679247856140137\n",
      "Batch 91: loss = 0.3338088095188141\n",
      "Batch 92: loss = 0.33329033851623535\n",
      "Batch 93: loss = 0.3096742630004883\n",
      "Batch 94: loss = 0.3145971894264221\n",
      "Batch 95: loss = 0.2996269166469574\n",
      "Batch 96: loss = 0.34829801321029663\n",
      "Batch 97: loss = 0.3132936656475067\n",
      "Batch 98: loss = 0.29389631748199463\n",
      "Batch 99: loss = 0.33573704957962036\n",
      "Batch 100: loss = 0.3459780812263489\n",
      "Batch 101: loss = 0.32872074842453003\n",
      "Batch 102: loss = 0.2997207045555115\n",
      "Batch 103: loss = 0.2943603992462158\n",
      "Batch 104: loss = 0.2972557544708252\n",
      "Batch 105: loss = 0.29673200845718384\n",
      "Batch 106: loss = 0.31999850273132324\n",
      "Batch 107: loss = 0.3218819499015808\n",
      "Batch 108: loss = 0.31260257959365845\n",
      "Batch 109: loss = 0.3138898015022278\n",
      "Batch 110: loss = 0.2936398983001709\n",
      "Batch 111: loss = 0.3036103844642639\n",
      "Batch 112: loss = 0.34222447872161865\n",
      "Batch 113: loss = 0.3423095941543579\n",
      "Batch 114: loss = 0.33166569471359253\n",
      "Batch 115: loss = 0.3461495637893677\n",
      "Batch 116: loss = 0.3113696575164795\n",
      "Batch 117: loss = 0.3027668595314026\n",
      "Batch 118: loss = 0.293209433555603\n",
      "Batch 119: loss = 0.3273710608482361\n",
      "Batch 120: loss = 0.2679048180580139\n",
      "Batch 121: loss = 0.32554715871810913\n",
      "Batch 122: loss = 0.31563758850097656\n",
      "Batch 123: loss = 0.31964579224586487\n",
      "Batch 124: loss = 0.32363954186439514\n",
      "Batch 125: loss = 0.3425324559211731\n",
      "Batch 126: loss = 0.28364133834838867\n",
      "\n",
      "Epoch 76/100\n",
      "Batch 1: loss = 0.3086242079734802\n",
      "Batch 2: loss = 0.3104642629623413\n",
      "Batch 3: loss = 0.3152458667755127\n",
      "Batch 4: loss = 0.3302401304244995\n",
      "Batch 5: loss = 0.3071577847003937\n",
      "Batch 6: loss = 0.3114781975746155\n",
      "Batch 7: loss = 0.27226144075393677\n",
      "Batch 8: loss = 0.32851874828338623\n",
      "Batch 9: loss = 0.3279905915260315\n",
      "Batch 10: loss = 0.281088650226593\n",
      "Batch 11: loss = 0.2972847819328308\n",
      "Batch 12: loss = 0.31091994047164917\n",
      "Batch 13: loss = 0.2910657227039337\n",
      "Batch 14: loss = 0.27787137031555176\n",
      "Batch 15: loss = 0.26730841398239136\n",
      "Batch 16: loss = 0.3311910331249237\n",
      "Batch 17: loss = 0.30090397596359253\n",
      "Batch 18: loss = 0.3403199315071106\n",
      "Batch 19: loss = 0.3033965229988098\n",
      "Batch 20: loss = 0.30551987886428833\n",
      "Batch 21: loss = 0.3071713149547577\n",
      "Batch 22: loss = 0.3380786180496216\n",
      "Batch 23: loss = 0.36365634202957153\n",
      "Batch 24: loss = 0.3151094615459442\n",
      "Batch 25: loss = 0.2950551509857178\n",
      "Batch 26: loss = 0.2851068079471588\n",
      "Batch 27: loss = 0.3722217082977295\n",
      "Batch 28: loss = 0.3340812623500824\n",
      "Batch 29: loss = 0.358661413192749\n",
      "Batch 30: loss = 0.32992368936538696\n",
      "Batch 31: loss = 0.3349055051803589\n",
      "Batch 32: loss = 0.3248714208602905\n",
      "Batch 33: loss = 0.28797245025634766\n",
      "Batch 34: loss = 0.3395686447620392\n",
      "Batch 35: loss = 0.30773285031318665\n",
      "Batch 36: loss = 0.2794153094291687\n",
      "Batch 37: loss = 0.2460356503725052\n",
      "Batch 38: loss = 0.305224746465683\n",
      "Batch 39: loss = 0.29349470138549805\n",
      "Batch 40: loss = 0.28877779841423035\n",
      "Batch 41: loss = 0.2761257290840149\n",
      "Batch 42: loss = 0.2969011068344116\n",
      "Batch 43: loss = 0.3035197854042053\n",
      "Batch 44: loss = 0.2892659902572632\n",
      "Batch 45: loss = 0.30267250537872314\n",
      "Batch 46: loss = 0.2787303924560547\n",
      "Batch 47: loss = 0.30769622325897217\n",
      "Batch 48: loss = 0.2757835388183594\n",
      "Batch 49: loss = 0.25414130091667175\n",
      "Batch 50: loss = 0.2683119773864746\n",
      "Batch 51: loss = 0.3061586022377014\n",
      "Batch 52: loss = 0.31951838731765747\n",
      "Batch 53: loss = 0.2981981039047241\n",
      "Batch 54: loss = 0.23858484625816345\n",
      "Batch 55: loss = 0.24195492267608643\n",
      "Batch 56: loss = 0.3034440875053406\n",
      "Batch 57: loss = 0.35135167837142944\n",
      "Batch 58: loss = 0.32155266404151917\n",
      "Batch 59: loss = 0.264015793800354\n",
      "Batch 60: loss = 0.2976875901222229\n",
      "Batch 61: loss = 0.27945515513420105\n",
      "Batch 62: loss = 0.29875391721725464\n",
      "Batch 63: loss = 0.2868719696998596\n",
      "Batch 64: loss = 0.2508589029312134\n",
      "Batch 65: loss = 0.2959338426589966\n",
      "Batch 66: loss = 0.32917076349258423\n",
      "Batch 67: loss = 0.27875882387161255\n",
      "Batch 68: loss = 0.26198703050613403\n",
      "Batch 69: loss = 0.2859957814216614\n",
      "Batch 70: loss = 0.3272222578525543\n",
      "Batch 71: loss = 0.30777138471603394\n",
      "Batch 72: loss = 0.2501387596130371\n",
      "Batch 73: loss = 0.33313941955566406\n",
      "Batch 74: loss = 0.3305519223213196\n",
      "Batch 75: loss = 0.38146868348121643\n",
      "Batch 76: loss = 0.3225504755973816\n",
      "Batch 77: loss = 0.3014426827430725\n",
      "Batch 78: loss = 0.32125312089920044\n",
      "Batch 79: loss = 0.30978405475616455\n",
      "Batch 80: loss = 0.2766307592391968\n",
      "Batch 81: loss = 0.32963109016418457\n",
      "Batch 82: loss = 0.2616017162799835\n",
      "Batch 83: loss = 0.29012101888656616\n",
      "Batch 84: loss = 0.3219177722930908\n",
      "Batch 85: loss = 0.3314135670661926\n",
      "Batch 86: loss = 0.302856981754303\n",
      "Batch 87: loss = 0.30775463581085205\n",
      "Batch 88: loss = 0.35611817240715027\n",
      "Batch 89: loss = 0.30834639072418213\n",
      "Batch 90: loss = 0.29813337326049805\n",
      "Batch 91: loss = 0.31962698698043823\n",
      "Batch 92: loss = 0.3106469213962555\n",
      "Batch 93: loss = 0.2678329348564148\n",
      "Batch 94: loss = 0.2948734760284424\n",
      "Batch 95: loss = 0.2810875177383423\n",
      "Batch 96: loss = 0.35221171379089355\n",
      "Batch 97: loss = 0.3160278797149658\n",
      "Batch 98: loss = 0.324704110622406\n",
      "Batch 99: loss = 0.3279780447483063\n",
      "Batch 100: loss = 0.34184134006500244\n",
      "Batch 101: loss = 0.32994136214256287\n",
      "Batch 102: loss = 0.32884296774864197\n",
      "Batch 103: loss = 0.2941265106201172\n",
      "Batch 104: loss = 0.29473477602005005\n",
      "Batch 105: loss = 0.27217090129852295\n",
      "Batch 106: loss = 0.30734604597091675\n",
      "Batch 107: loss = 0.29791945219039917\n",
      "Batch 108: loss = 0.30996525287628174\n",
      "Batch 109: loss = 0.3146488070487976\n",
      "Batch 110: loss = 0.2827540934085846\n",
      "Batch 111: loss = 0.3169189691543579\n",
      "Batch 112: loss = 0.3287309408187866\n",
      "Batch 113: loss = 0.2898489832878113\n",
      "Batch 114: loss = 0.3240307569503784\n",
      "Batch 115: loss = 0.3625211715698242\n",
      "Batch 116: loss = 0.3347877860069275\n",
      "Batch 117: loss = 0.32517725229263306\n",
      "Batch 118: loss = 0.27520808577537537\n",
      "Batch 119: loss = 0.3212854862213135\n",
      "Batch 120: loss = 0.2836592197418213\n",
      "Batch 121: loss = 0.30834972858428955\n",
      "Batch 122: loss = 0.3068302273750305\n",
      "Batch 123: loss = 0.28703877329826355\n",
      "Batch 124: loss = 0.3405826687812805\n",
      "Batch 125: loss = 0.3264634609222412\n",
      "Batch 126: loss = 0.3211556673049927\n",
      "\n",
      "Epoch 77/100\n",
      "Batch 1: loss = 0.30367815494537354\n",
      "Batch 2: loss = 0.28948989510536194\n",
      "Batch 3: loss = 0.31159549951553345\n",
      "Batch 4: loss = 0.32441288232803345\n",
      "Batch 5: loss = 0.3240780532360077\n",
      "Batch 6: loss = 0.29347676038742065\n",
      "Batch 7: loss = 0.28375333547592163\n",
      "Batch 8: loss = 0.35155120491981506\n",
      "Batch 9: loss = 0.3299131989479065\n",
      "Batch 10: loss = 0.2739602327346802\n",
      "Batch 11: loss = 0.28755658864974976\n",
      "Batch 12: loss = 0.27793318033218384\n",
      "Batch 13: loss = 0.2676768898963928\n",
      "Batch 14: loss = 0.28949451446533203\n",
      "Batch 15: loss = 0.27048319578170776\n",
      "Batch 16: loss = 0.32841548323631287\n",
      "Batch 17: loss = 0.2855086326599121\n",
      "Batch 18: loss = 0.3354683220386505\n",
      "Batch 19: loss = 0.3122393488883972\n",
      "Batch 20: loss = 0.2998781204223633\n",
      "Batch 21: loss = 0.3097814917564392\n",
      "Batch 22: loss = 0.319846510887146\n",
      "Batch 23: loss = 0.3161599338054657\n",
      "Batch 24: loss = 0.30806100368499756\n",
      "Batch 25: loss = 0.3287961483001709\n",
      "Batch 26: loss = 0.26104384660720825\n",
      "Batch 27: loss = 0.34060561656951904\n",
      "Batch 28: loss = 0.3665490448474884\n",
      "Batch 29: loss = 0.3445168137550354\n",
      "Batch 30: loss = 0.3091265857219696\n",
      "Batch 31: loss = 0.2967415452003479\n",
      "Batch 32: loss = 0.3225466012954712\n",
      "Batch 33: loss = 0.3271230459213257\n",
      "Batch 34: loss = 0.3357153534889221\n",
      "Batch 35: loss = 0.28869858384132385\n",
      "Batch 36: loss = 0.2665258049964905\n",
      "Batch 37: loss = 0.2498171031475067\n",
      "Batch 38: loss = 0.3011980652809143\n",
      "Batch 39: loss = 0.29632318019866943\n",
      "Batch 40: loss = 0.3074444532394409\n",
      "Batch 41: loss = 0.27146974205970764\n",
      "Batch 42: loss = 0.32881003618240356\n",
      "Batch 43: loss = 0.3425295948982239\n",
      "Batch 44: loss = 0.28438976407051086\n",
      "Batch 45: loss = 0.26903843879699707\n",
      "Batch 46: loss = 0.26214173436164856\n",
      "Batch 47: loss = 0.28953367471694946\n",
      "Batch 48: loss = 0.2554837167263031\n",
      "Batch 49: loss = 0.25868287682533264\n",
      "Batch 50: loss = 0.2680128812789917\n",
      "Batch 51: loss = 0.2977968454360962\n",
      "Batch 52: loss = 0.32837194204330444\n",
      "Batch 53: loss = 0.3121893107891083\n",
      "Batch 54: loss = 0.23846101760864258\n",
      "Batch 55: loss = 0.27970460057258606\n",
      "Batch 56: loss = 0.30382949113845825\n",
      "Batch 57: loss = 0.31050992012023926\n",
      "Batch 58: loss = 0.3531295955181122\n",
      "Batch 59: loss = 0.2650526165962219\n",
      "Batch 60: loss = 0.26483428478240967\n",
      "Batch 61: loss = 0.2621835172176361\n",
      "Batch 62: loss = 0.3564208149909973\n",
      "Batch 63: loss = 0.25638994574546814\n",
      "Batch 64: loss = 0.2578578591346741\n",
      "Batch 65: loss = 0.29156237840652466\n",
      "Batch 66: loss = 0.30215492844581604\n",
      "Batch 67: loss = 0.299035906791687\n",
      "Batch 68: loss = 0.3079923987388611\n",
      "Batch 69: loss = 0.2737855315208435\n",
      "Batch 70: loss = 0.3444384038448334\n",
      "Batch 71: loss = 0.33614152669906616\n",
      "Batch 72: loss = 0.26598232984542847\n",
      "Batch 73: loss = 0.3084230422973633\n",
      "Batch 74: loss = 0.3095068335533142\n",
      "Batch 75: loss = 0.3337794542312622\n",
      "Batch 76: loss = 0.3239971399307251\n",
      "Batch 77: loss = 0.2846718430519104\n",
      "Batch 78: loss = 0.3492230474948883\n",
      "Batch 79: loss = 0.2867332994937897\n",
      "Batch 80: loss = 0.31063687801361084\n",
      "Batch 81: loss = 0.32605311274528503\n",
      "Batch 82: loss = 0.29167038202285767\n",
      "Batch 83: loss = 0.3146669268608093\n",
      "Batch 84: loss = 0.32125744223594666\n",
      "Batch 85: loss = 0.355873703956604\n",
      "Batch 86: loss = 0.3196532726287842\n",
      "Batch 87: loss = 0.2887228727340698\n",
      "Batch 88: loss = 0.3652985095977783\n",
      "Batch 89: loss = 0.27597713470458984\n",
      "Batch 90: loss = 0.3288917541503906\n",
      "Batch 91: loss = 0.3284423351287842\n",
      "Batch 92: loss = 0.30655062198638916\n",
      "Batch 93: loss = 0.2769348621368408\n",
      "Batch 94: loss = 0.31270894408226013\n",
      "Batch 95: loss = 0.2900906801223755\n",
      "Batch 96: loss = 0.34634828567504883\n",
      "Batch 97: loss = 0.30728936195373535\n",
      "Batch 98: loss = 0.2831304371356964\n",
      "Batch 99: loss = 0.35469090938568115\n",
      "Batch 100: loss = 0.3391163647174835\n",
      "Batch 101: loss = 0.34102001786231995\n",
      "Batch 102: loss = 0.3387119472026825\n",
      "Batch 103: loss = 0.294966459274292\n",
      "Batch 104: loss = 0.2929255962371826\n",
      "Batch 105: loss = 0.28605711460113525\n",
      "Batch 106: loss = 0.29621443152427673\n",
      "Batch 107: loss = 0.30059289932250977\n",
      "Batch 108: loss = 0.3256373405456543\n",
      "Batch 109: loss = 0.29728496074676514\n",
      "Batch 110: loss = 0.2743000388145447\n",
      "Batch 111: loss = 0.31232041120529175\n",
      "Batch 112: loss = 0.3258970379829407\n",
      "Batch 113: loss = 0.29814842343330383\n",
      "Batch 114: loss = 0.31729835271835327\n",
      "Batch 115: loss = 0.29654985666275024\n",
      "Batch 116: loss = 0.3427654802799225\n",
      "Batch 117: loss = 0.3052132725715637\n",
      "Batch 118: loss = 0.260275661945343\n",
      "Batch 119: loss = 0.3300549387931824\n",
      "Batch 120: loss = 0.28145933151245117\n",
      "Batch 121: loss = 0.2758335471153259\n",
      "Batch 122: loss = 0.2756548523902893\n",
      "Batch 123: loss = 0.29705148935317993\n",
      "Batch 124: loss = 0.3382769823074341\n",
      "Batch 125: loss = 0.3593823313713074\n",
      "Batch 126: loss = 0.3072356581687927\n",
      "\n",
      "Epoch 78/100\n",
      "Batch 1: loss = 0.28995805978775024\n",
      "Batch 2: loss = 0.33267921209335327\n",
      "Batch 3: loss = 0.3109177052974701\n",
      "Batch 4: loss = 0.294101744890213\n",
      "Batch 5: loss = 0.307935893535614\n",
      "Batch 6: loss = 0.31703054904937744\n",
      "Batch 7: loss = 0.27713948488235474\n",
      "Batch 8: loss = 0.3232412338256836\n",
      "Batch 9: loss = 0.3085513114929199\n",
      "Batch 10: loss = 0.28280481696128845\n",
      "Batch 11: loss = 0.2662211060523987\n",
      "Batch 12: loss = 0.30858713388442993\n",
      "Batch 13: loss = 0.3006325364112854\n",
      "Batch 14: loss = 0.2924114465713501\n",
      "Batch 15: loss = 0.2851467430591583\n",
      "Batch 16: loss = 0.27457594871520996\n",
      "Batch 17: loss = 0.29585781693458557\n",
      "Batch 18: loss = 0.3011721968650818\n",
      "Batch 19: loss = 0.30194127559661865\n",
      "Batch 20: loss = 0.31336575746536255\n",
      "Batch 21: loss = 0.31920066475868225\n",
      "Batch 22: loss = 0.2964422404766083\n",
      "Batch 23: loss = 0.3354703187942505\n",
      "Batch 24: loss = 0.2946922183036804\n",
      "Batch 25: loss = 0.32485342025756836\n",
      "Batch 26: loss = 0.28173938393592834\n",
      "Batch 27: loss = 0.34478721022605896\n",
      "Batch 28: loss = 0.3409174680709839\n",
      "Batch 29: loss = 0.35157573223114014\n",
      "Batch 30: loss = 0.3290679454803467\n",
      "Batch 31: loss = 0.3166240453720093\n",
      "Batch 32: loss = 0.3012811541557312\n",
      "Batch 33: loss = 0.2941610813140869\n",
      "Batch 34: loss = 0.2813968062400818\n",
      "Batch 35: loss = 0.31453782320022583\n",
      "Batch 36: loss = 0.2786336839199066\n",
      "Batch 37: loss = 0.27525705099105835\n",
      "Batch 38: loss = 0.3209765553474426\n",
      "Batch 39: loss = 0.2801506817340851\n",
      "Batch 40: loss = 0.30430901050567627\n",
      "Batch 41: loss = 0.2994040250778198\n",
      "Batch 42: loss = 0.2871275842189789\n",
      "Batch 43: loss = 0.3039623498916626\n",
      "Batch 44: loss = 0.2783568501472473\n",
      "Batch 45: loss = 0.2621835470199585\n",
      "Batch 46: loss = 0.2812489867210388\n",
      "Batch 47: loss = 0.26407867670059204\n",
      "Batch 48: loss = 0.2793181240558624\n",
      "Batch 49: loss = 0.26661986112594604\n",
      "Batch 50: loss = 0.26904773712158203\n",
      "Batch 51: loss = 0.26803576946258545\n",
      "Batch 52: loss = 0.3124812841415405\n",
      "Batch 53: loss = 0.2723248600959778\n",
      "Batch 54: loss = 0.23701569437980652\n",
      "Batch 55: loss = 0.2756684124469757\n",
      "Batch 56: loss = 0.3157517910003662\n",
      "Batch 57: loss = 0.31597140431404114\n",
      "Batch 58: loss = 0.31963464617729187\n",
      "Batch 59: loss = 0.2527275085449219\n",
      "Batch 60: loss = 0.2820196747779846\n",
      "Batch 61: loss = 0.2785419821739197\n",
      "Batch 62: loss = 0.3231493830680847\n",
      "Batch 63: loss = 0.2807948589324951\n",
      "Batch 64: loss = 0.22707301378250122\n",
      "Batch 65: loss = 0.30033355951309204\n",
      "Batch 66: loss = 0.3109811842441559\n",
      "Batch 67: loss = 0.28910592198371887\n",
      "Batch 68: loss = 0.29518452286720276\n",
      "Batch 69: loss = 0.28031155467033386\n",
      "Batch 70: loss = 0.30720704793930054\n",
      "Batch 71: loss = 0.3065066635608673\n",
      "Batch 72: loss = 0.24716976284980774\n",
      "Batch 73: loss = 0.3287040591239929\n",
      "Batch 74: loss = 0.2993241250514984\n",
      "Batch 75: loss = 0.3350023031234741\n",
      "Batch 76: loss = 0.33522936701774597\n",
      "Batch 77: loss = 0.27550995349884033\n",
      "Batch 78: loss = 0.3260747790336609\n",
      "Batch 79: loss = 0.26921316981315613\n",
      "Batch 80: loss = 0.2801399230957031\n",
      "Batch 81: loss = 0.30041027069091797\n",
      "Batch 82: loss = 0.2884610891342163\n",
      "Batch 83: loss = 0.282714307308197\n",
      "Batch 84: loss = 0.3407619595527649\n",
      "Batch 85: loss = 0.3299495577812195\n",
      "Batch 86: loss = 0.2785508632659912\n",
      "Batch 87: loss = 0.2647496461868286\n",
      "Batch 88: loss = 0.3448259234428406\n",
      "Batch 89: loss = 0.27662193775177\n",
      "Batch 90: loss = 0.322573184967041\n",
      "Batch 91: loss = 0.31973597407341003\n",
      "Batch 92: loss = 0.33926790952682495\n",
      "Batch 93: loss = 0.27845802903175354\n",
      "Batch 94: loss = 0.29432860016822815\n",
      "Batch 95: loss = 0.31624555587768555\n",
      "Batch 96: loss = 0.3701019287109375\n",
      "Batch 97: loss = 0.3183574676513672\n",
      "Batch 98: loss = 0.29384493827819824\n",
      "Batch 99: loss = 0.34051769971847534\n",
      "Batch 100: loss = 0.34493887424468994\n",
      "Batch 101: loss = 0.3274068534374237\n",
      "Batch 102: loss = 0.3299858868122101\n",
      "Batch 103: loss = 0.2801171839237213\n",
      "Batch 104: loss = 0.29425376653671265\n",
      "Batch 105: loss = 0.23221448063850403\n",
      "Batch 106: loss = 0.30443504452705383\n",
      "Batch 107: loss = 0.28998106718063354\n",
      "Batch 108: loss = 0.296170711517334\n",
      "Batch 109: loss = 0.3118402361869812\n",
      "Batch 110: loss = 0.2679544985294342\n",
      "Batch 111: loss = 0.3531966209411621\n",
      "Batch 112: loss = 0.34585851430892944\n",
      "Batch 113: loss = 0.32753586769104004\n",
      "Batch 114: loss = 0.3224489092826843\n",
      "Batch 115: loss = 0.29909926652908325\n",
      "Batch 116: loss = 0.3163638114929199\n",
      "Batch 117: loss = 0.2801594138145447\n",
      "Batch 118: loss = 0.2716657817363739\n",
      "Batch 119: loss = 0.32581761479377747\n",
      "Batch 120: loss = 0.26679402589797974\n",
      "Batch 121: loss = 0.28785407543182373\n",
      "Batch 122: loss = 0.2801395058631897\n",
      "Batch 123: loss = 0.3034515380859375\n",
      "Batch 124: loss = 0.3237021565437317\n",
      "Batch 125: loss = 0.3275759816169739\n",
      "Batch 126: loss = 0.28767213225364685\n",
      "\n",
      "Epoch 79/100\n",
      "Batch 1: loss = 0.26966238021850586\n",
      "Batch 2: loss = 0.3131095767021179\n",
      "Batch 3: loss = 0.2946597933769226\n",
      "Batch 4: loss = 0.28786322474479675\n",
      "Batch 5: loss = 0.32330122590065\n",
      "Batch 6: loss = 0.295197069644928\n",
      "Batch 7: loss = 0.29469460248947144\n",
      "Batch 8: loss = 0.3011004328727722\n",
      "Batch 9: loss = 0.2786082625389099\n",
      "Batch 10: loss = 0.273985356092453\n",
      "Batch 11: loss = 0.3049952983856201\n",
      "Batch 12: loss = 0.3192210793495178\n",
      "Batch 13: loss = 0.2991827726364136\n",
      "Batch 14: loss = 0.29029375314712524\n",
      "Batch 15: loss = 0.28295573592185974\n",
      "Batch 16: loss = 0.3277952969074249\n",
      "Batch 17: loss = 0.2721927762031555\n",
      "Batch 18: loss = 0.308399498462677\n",
      "Batch 19: loss = 0.2985701560974121\n",
      "Batch 20: loss = 0.30700793862342834\n",
      "Batch 21: loss = 0.3140723705291748\n",
      "Batch 22: loss = 0.2913166284561157\n",
      "Batch 23: loss = 0.3053758144378662\n",
      "Batch 24: loss = 0.3103685975074768\n",
      "Batch 25: loss = 0.31475695967674255\n",
      "Batch 26: loss = 0.28975197672843933\n",
      "Batch 27: loss = 0.3374510407447815\n",
      "Batch 28: loss = 0.3327866792678833\n",
      "Batch 29: loss = 0.30785292387008667\n",
      "Batch 30: loss = 0.30206286907196045\n",
      "Batch 31: loss = 0.3221740424633026\n",
      "Batch 32: loss = 0.31888502836227417\n",
      "Batch 33: loss = 0.297932505607605\n",
      "Batch 34: loss = 0.30886560678482056\n",
      "Batch 35: loss = 0.2719154953956604\n",
      "Batch 36: loss = 0.25493067502975464\n",
      "Batch 37: loss = 0.26372024416923523\n",
      "Batch 38: loss = 0.2840690612792969\n",
      "Batch 39: loss = 0.26601141691207886\n",
      "Batch 40: loss = 0.301288902759552\n",
      "Batch 41: loss = 0.30806517601013184\n",
      "Batch 42: loss = 0.29450348019599915\n",
      "Batch 43: loss = 0.2819770574569702\n",
      "Batch 44: loss = 0.2846258878707886\n",
      "Batch 45: loss = 0.2705422341823578\n",
      "Batch 46: loss = 0.26736384630203247\n",
      "Batch 47: loss = 0.2816658616065979\n",
      "Batch 48: loss = 0.28590136766433716\n",
      "Batch 49: loss = 0.2852349877357483\n",
      "Batch 50: loss = 0.28364667296409607\n",
      "Batch 51: loss = 0.26133203506469727\n",
      "Batch 52: loss = 0.30958789587020874\n",
      "Batch 53: loss = 0.29599493741989136\n",
      "Batch 54: loss = 0.2255268543958664\n",
      "Batch 55: loss = 0.24941930174827576\n",
      "Batch 56: loss = 0.3094969391822815\n",
      "Batch 57: loss = 0.31349265575408936\n",
      "Batch 58: loss = 0.31777772307395935\n",
      "Batch 59: loss = 0.22569885849952698\n",
      "Batch 60: loss = 0.2895081639289856\n",
      "Batch 61: loss = 0.24093538522720337\n",
      "Batch 62: loss = 0.34742796421051025\n",
      "Batch 63: loss = 0.2584558129310608\n",
      "Batch 64: loss = 0.2565368413925171\n",
      "Batch 65: loss = 0.2804795503616333\n",
      "Batch 66: loss = 0.28824877738952637\n",
      "Batch 67: loss = 0.2573433518409729\n",
      "Batch 68: loss = 0.2868719696998596\n",
      "Batch 69: loss = 0.2851104736328125\n",
      "Batch 70: loss = 0.2942900061607361\n",
      "Batch 71: loss = 0.31400173902511597\n",
      "Batch 72: loss = 0.2641114592552185\n",
      "Batch 73: loss = 0.3181582987308502\n",
      "Batch 74: loss = 0.3330455422401428\n",
      "Batch 75: loss = 0.3459007143974304\n",
      "Batch 76: loss = 0.307611346244812\n",
      "Batch 77: loss = 0.2639629542827606\n",
      "Batch 78: loss = 0.307068407535553\n",
      "Batch 79: loss = 0.3049972355365753\n",
      "Batch 80: loss = 0.2903905510902405\n",
      "Batch 81: loss = 0.3161330223083496\n",
      "Batch 82: loss = 0.2587580978870392\n",
      "Batch 83: loss = 0.27205029129981995\n",
      "Batch 84: loss = 0.2879083752632141\n",
      "Batch 85: loss = 0.31046271324157715\n",
      "Batch 86: loss = 0.28178101778030396\n",
      "Batch 87: loss = 0.2823876142501831\n",
      "Batch 88: loss = 0.34049737453460693\n",
      "Batch 89: loss = 0.28185486793518066\n",
      "Batch 90: loss = 0.2860199213027954\n",
      "Batch 91: loss = 0.3254503309726715\n",
      "Batch 92: loss = 0.31598955392837524\n",
      "Batch 93: loss = 0.2834610342979431\n",
      "Batch 94: loss = 0.29783594608306885\n",
      "Batch 95: loss = 0.28667503595352173\n",
      "Batch 96: loss = 0.3499661982059479\n",
      "Batch 97: loss = 0.32923632860183716\n",
      "Batch 98: loss = 0.3198954463005066\n",
      "Batch 99: loss = 0.3424503207206726\n",
      "Batch 100: loss = 0.32552802562713623\n",
      "Batch 101: loss = 0.28439491987228394\n",
      "Batch 102: loss = 0.31076210737228394\n",
      "Batch 103: loss = 0.30355843901634216\n",
      "Batch 104: loss = 0.2600823640823364\n",
      "Batch 105: loss = 0.25938907265663147\n",
      "Batch 106: loss = 0.309989869594574\n",
      "Batch 107: loss = 0.29638904333114624\n",
      "Batch 108: loss = 0.30727314949035645\n",
      "Batch 109: loss = 0.3405206799507141\n",
      "Batch 110: loss = 0.2866070568561554\n",
      "Batch 111: loss = 0.2864095866680145\n",
      "Batch 112: loss = 0.35562676191329956\n",
      "Batch 113: loss = 0.28390851616859436\n",
      "Batch 114: loss = 0.2859877645969391\n",
      "Batch 115: loss = 0.29809361696243286\n",
      "Batch 116: loss = 0.301889032125473\n",
      "Batch 117: loss = 0.27587535977363586\n",
      "Batch 118: loss = 0.27681484818458557\n",
      "Batch 119: loss = 0.31635233759880066\n",
      "Batch 120: loss = 0.2590090036392212\n",
      "Batch 121: loss = 0.30979350209236145\n",
      "Batch 122: loss = 0.28594914078712463\n",
      "Batch 123: loss = 0.26919540762901306\n",
      "Batch 124: loss = 0.32784923911094666\n",
      "Batch 125: loss = 0.3483005166053772\n",
      "Batch 126: loss = 0.27380993962287903\n",
      "\n",
      "Epoch 80/100\n",
      "Batch 1: loss = 0.2974430322647095\n",
      "Batch 2: loss = 0.2901366353034973\n",
      "Batch 3: loss = 0.295254111289978\n",
      "Batch 4: loss = 0.29371875524520874\n",
      "Batch 5: loss = 0.30277466773986816\n",
      "Batch 6: loss = 0.3242553770542145\n",
      "Batch 7: loss = 0.2825215458869934\n",
      "Batch 8: loss = 0.33905673027038574\n",
      "Batch 9: loss = 0.3214390277862549\n",
      "Batch 10: loss = 0.27218079566955566\n",
      "Batch 11: loss = 0.30444347858428955\n",
      "Batch 12: loss = 0.3040789067745209\n",
      "Batch 13: loss = 0.28377336263656616\n",
      "Batch 14: loss = 0.29564347863197327\n",
      "Batch 15: loss = 0.2716241180896759\n",
      "Batch 16: loss = 0.31186509132385254\n",
      "Batch 17: loss = 0.30722999572753906\n",
      "Batch 18: loss = 0.32514816522598267\n",
      "Batch 19: loss = 0.3173098564147949\n",
      "Batch 20: loss = 0.3093898892402649\n",
      "Batch 21: loss = 0.2861310839653015\n",
      "Batch 22: loss = 0.2991313934326172\n",
      "Batch 23: loss = 0.35640084743499756\n",
      "Batch 24: loss = 0.2857004702091217\n",
      "Batch 25: loss = 0.3027288615703583\n",
      "Batch 26: loss = 0.28005853295326233\n",
      "Batch 27: loss = 0.36501049995422363\n",
      "Batch 28: loss = 0.32799720764160156\n",
      "Batch 29: loss = 0.3143681287765503\n",
      "Batch 30: loss = 0.29797059297561646\n",
      "Batch 31: loss = 0.3167562782764435\n",
      "Batch 32: loss = 0.32185861468315125\n",
      "Batch 33: loss = 0.2993233799934387\n",
      "Batch 34: loss = 0.3023664951324463\n",
      "Batch 35: loss = 0.2993619740009308\n",
      "Batch 36: loss = 0.2744806706905365\n",
      "Batch 37: loss = 0.29106205701828003\n",
      "Batch 38: loss = 0.2692810893058777\n",
      "Batch 39: loss = 0.27911198139190674\n",
      "Batch 40: loss = 0.2907053828239441\n",
      "Batch 41: loss = 0.2657802104949951\n",
      "Batch 42: loss = 0.281829297542572\n",
      "Batch 43: loss = 0.3189515173435211\n",
      "Batch 44: loss = 0.2907712459564209\n",
      "Batch 45: loss = 0.251438707113266\n",
      "Batch 46: loss = 0.28507736325263977\n",
      "Batch 47: loss = 0.28030163049697876\n",
      "Batch 48: loss = 0.2724803388118744\n",
      "Batch 49: loss = 0.26035794615745544\n",
      "Batch 50: loss = 0.2751079797744751\n",
      "Batch 51: loss = 0.28785640001296997\n",
      "Batch 52: loss = 0.33219751715660095\n",
      "Batch 53: loss = 0.27864718437194824\n",
      "Batch 54: loss = 0.2630825638771057\n",
      "Batch 55: loss = 0.28924277424812317\n",
      "Batch 56: loss = 0.31130513548851013\n",
      "Batch 57: loss = 0.28861844539642334\n",
      "Batch 58: loss = 0.3206169009208679\n",
      "Batch 59: loss = 0.24944919347763062\n",
      "Batch 60: loss = 0.2751566469669342\n",
      "Batch 61: loss = 0.28119856119155884\n",
      "Batch 62: loss = 0.3207414746284485\n",
      "Batch 63: loss = 0.2622339725494385\n",
      "Batch 64: loss = 0.273073673248291\n",
      "Batch 65: loss = 0.26074203848838806\n",
      "Batch 66: loss = 0.28219401836395264\n",
      "Batch 67: loss = 0.27861565351486206\n",
      "Batch 68: loss = 0.2691647410392761\n",
      "Batch 69: loss = 0.2807592749595642\n",
      "Batch 70: loss = 0.32101184129714966\n",
      "Batch 71: loss = 0.317760169506073\n",
      "Batch 72: loss = 0.2724037766456604\n",
      "Batch 73: loss = 0.29506951570510864\n",
      "Batch 74: loss = 0.33523353934288025\n",
      "Batch 75: loss = 0.3329710066318512\n",
      "Batch 76: loss = 0.3187122344970703\n",
      "Batch 77: loss = 0.29757726192474365\n",
      "Batch 78: loss = 0.31800881028175354\n",
      "Batch 79: loss = 0.2854691445827484\n",
      "Batch 80: loss = 0.2742903232574463\n",
      "Batch 81: loss = 0.31060463190078735\n",
      "Batch 82: loss = 0.2992004156112671\n",
      "Batch 83: loss = 0.30685335397720337\n",
      "Batch 84: loss = 0.3167899250984192\n",
      "Batch 85: loss = 0.31114277243614197\n",
      "Batch 86: loss = 0.3131489157676697\n",
      "Batch 87: loss = 0.2869464159011841\n",
      "Batch 88: loss = 0.285040020942688\n",
      "Batch 89: loss = 0.26079845428466797\n",
      "Batch 90: loss = 0.2916527986526489\n",
      "Batch 91: loss = 0.34947964549064636\n",
      "Batch 92: loss = 0.3284970223903656\n",
      "Batch 93: loss = 0.2817164957523346\n",
      "Batch 94: loss = 0.2886117696762085\n",
      "Batch 95: loss = 0.28061723709106445\n",
      "Batch 96: loss = 0.3537282347679138\n",
      "Batch 97: loss = 0.30749595165252686\n",
      "Batch 98: loss = 0.2750083804130554\n",
      "Batch 99: loss = 0.351678729057312\n",
      "Batch 100: loss = 0.33233100175857544\n",
      "Batch 101: loss = 0.3119415044784546\n",
      "Batch 102: loss = 0.3203328549861908\n",
      "Batch 103: loss = 0.24495750665664673\n",
      "Batch 104: loss = 0.27894508838653564\n",
      "Batch 105: loss = 0.25612473487854004\n",
      "Batch 106: loss = 0.3003699779510498\n",
      "Batch 107: loss = 0.2796567678451538\n",
      "Batch 108: loss = 0.29040318727493286\n",
      "Batch 109: loss = 0.31111761927604675\n",
      "Batch 110: loss = 0.2790641784667969\n",
      "Batch 111: loss = 0.3325628340244293\n",
      "Batch 112: loss = 0.3237191140651703\n",
      "Batch 113: loss = 0.3134559988975525\n",
      "Batch 114: loss = 0.2921620011329651\n",
      "Batch 115: loss = 0.2842395603656769\n",
      "Batch 116: loss = 0.2964550852775574\n",
      "Batch 117: loss = 0.2836158573627472\n",
      "Batch 118: loss = 0.3041918873786926\n",
      "Batch 119: loss = 0.2946351170539856\n",
      "Batch 120: loss = 0.26536911725997925\n",
      "Batch 121: loss = 0.2750191390514374\n",
      "Batch 122: loss = 0.26795899868011475\n",
      "Batch 123: loss = 0.3098679184913635\n",
      "Batch 124: loss = 0.3070642054080963\n",
      "Batch 125: loss = 0.3188861012458801\n",
      "Batch 126: loss = 0.2903275489807129\n",
      "Saved checkpoint to weights.80.pt\n",
      "\n",
      "Epoch 81/100\n",
      "Batch 1: loss = 0.293714702129364\n",
      "Batch 2: loss = 0.2997628152370453\n",
      "Batch 3: loss = 0.2966720759868622\n",
      "Batch 4: loss = 0.29356974363327026\n",
      "Batch 5: loss = 0.29703208804130554\n",
      "Batch 6: loss = 0.2809102535247803\n",
      "Batch 7: loss = 0.2829633355140686\n",
      "Batch 8: loss = 0.2983613908290863\n",
      "Batch 9: loss = 0.3024178147315979\n",
      "Batch 10: loss = 0.2835216522216797\n",
      "Batch 11: loss = 0.2646788954734802\n",
      "Batch 12: loss = 0.28673654794692993\n",
      "Batch 13: loss = 0.2735089063644409\n",
      "Batch 14: loss = 0.2620132565498352\n",
      "Batch 15: loss = 0.2337353527545929\n",
      "Batch 16: loss = 0.3269505202770233\n",
      "Batch 17: loss = 0.2863827347755432\n",
      "Batch 18: loss = 0.30676355957984924\n",
      "Batch 19: loss = 0.32439085841178894\n",
      "Batch 20: loss = 0.28839266300201416\n",
      "Batch 21: loss = 0.3097258508205414\n",
      "Batch 22: loss = 0.29323145747184753\n",
      "Batch 23: loss = 0.343088835477829\n",
      "Batch 24: loss = 0.29190754890441895\n",
      "Batch 25: loss = 0.31212642788887024\n",
      "Batch 26: loss = 0.28159821033477783\n",
      "Batch 27: loss = 0.35083794593811035\n",
      "Batch 28: loss = 0.34036996960639954\n",
      "Batch 29: loss = 0.31006425619125366\n",
      "Batch 30: loss = 0.3288196325302124\n",
      "Batch 31: loss = 0.284892737865448\n",
      "Batch 32: loss = 0.29974037408828735\n",
      "Batch 33: loss = 0.3006588816642761\n",
      "Batch 34: loss = 0.28741344809532166\n",
      "Batch 35: loss = 0.3185616731643677\n",
      "Batch 36: loss = 0.24892652034759521\n",
      "Batch 37: loss = 0.24725735187530518\n",
      "Batch 38: loss = 0.33771026134490967\n",
      "Batch 39: loss = 0.26702865958213806\n",
      "Batch 40: loss = 0.2784428000450134\n",
      "Batch 41: loss = 0.27125635743141174\n",
      "Batch 42: loss = 0.304996132850647\n",
      "Batch 43: loss = 0.3157443404197693\n",
      "Batch 44: loss = 0.27083921432495117\n",
      "Batch 45: loss = 0.29027917981147766\n",
      "Batch 46: loss = 0.24739032983779907\n",
      "Batch 47: loss = 0.26292774081230164\n",
      "Batch 48: loss = 0.2850567102432251\n",
      "Batch 49: loss = 0.2523488402366638\n",
      "Batch 50: loss = 0.22929471731185913\n",
      "Batch 51: loss = 0.27060753107070923\n",
      "Batch 52: loss = 0.32066816091537476\n",
      "Batch 53: loss = 0.29217129945755005\n",
      "Batch 54: loss = 0.23300158977508545\n",
      "Batch 55: loss = 0.24440768361091614\n",
      "Batch 56: loss = 0.2847674489021301\n",
      "Batch 57: loss = 0.302725613117218\n",
      "Batch 58: loss = 0.2929241955280304\n",
      "Batch 59: loss = 0.23289458453655243\n",
      "Batch 60: loss = 0.2879972457885742\n",
      "Batch 61: loss = 0.2653487026691437\n",
      "Batch 62: loss = 0.3301185965538025\n",
      "Batch 63: loss = 0.2725105285644531\n",
      "Batch 64: loss = 0.25266382098197937\n",
      "Batch 65: loss = 0.2801550030708313\n",
      "Batch 66: loss = 0.2678968012332916\n",
      "Batch 67: loss = 0.2934470772743225\n",
      "Batch 68: loss = 0.28505057096481323\n",
      "Batch 69: loss = 0.28890079259872437\n",
      "Batch 70: loss = 0.3051101565361023\n",
      "Batch 71: loss = 0.3154013454914093\n",
      "Batch 72: loss = 0.26146388053894043\n",
      "Batch 73: loss = 0.3055858612060547\n",
      "Batch 74: loss = 0.3428140878677368\n",
      "Batch 75: loss = 0.3501015603542328\n",
      "Batch 76: loss = 0.30577903985977173\n",
      "Batch 77: loss = 0.28476661443710327\n",
      "Batch 78: loss = 0.3062458038330078\n",
      "Batch 79: loss = 0.28398871421813965\n",
      "Batch 80: loss = 0.320203572511673\n",
      "Batch 81: loss = 0.3303355276584625\n",
      "Batch 82: loss = 0.24778905510902405\n",
      "Batch 83: loss = 0.25926411151885986\n",
      "Batch 84: loss = 0.31226298213005066\n",
      "Batch 85: loss = 0.32101213932037354\n",
      "Batch 86: loss = 0.29226067662239075\n",
      "Batch 87: loss = 0.3095815181732178\n",
      "Batch 88: loss = 0.33090052008628845\n",
      "Batch 89: loss = 0.2749113440513611\n",
      "Batch 90: loss = 0.27281326055526733\n",
      "Batch 91: loss = 0.2946448028087616\n",
      "Batch 92: loss = 0.3033028244972229\n",
      "Batch 93: loss = 0.29881709814071655\n",
      "Batch 94: loss = 0.29423007369041443\n",
      "Batch 95: loss = 0.301006942987442\n",
      "Batch 96: loss = 0.32911550998687744\n",
      "Batch 97: loss = 0.3016405701637268\n",
      "Batch 98: loss = 0.2958609163761139\n",
      "Batch 99: loss = 0.3344223201274872\n",
      "Batch 100: loss = 0.32461297512054443\n",
      "Batch 101: loss = 0.29779502749443054\n",
      "Batch 102: loss = 0.33538609743118286\n",
      "Batch 103: loss = 0.28323793411254883\n",
      "Batch 104: loss = 0.2912486791610718\n",
      "Batch 105: loss = 0.29581040143966675\n",
      "Batch 106: loss = 0.29082605242729187\n",
      "Batch 107: loss = 0.29343414306640625\n",
      "Batch 108: loss = 0.31964558362960815\n",
      "Batch 109: loss = 0.31202030181884766\n",
      "Batch 110: loss = 0.2849053144454956\n",
      "Batch 111: loss = 0.3119450509548187\n",
      "Batch 112: loss = 0.3151952028274536\n",
      "Batch 113: loss = 0.30439865589141846\n",
      "Batch 114: loss = 0.3066686987876892\n",
      "Batch 115: loss = 0.31246015429496765\n",
      "Batch 116: loss = 0.32882049679756165\n",
      "Batch 117: loss = 0.2775556445121765\n",
      "Batch 118: loss = 0.2894725799560547\n",
      "Batch 119: loss = 0.3060142993927002\n",
      "Batch 120: loss = 0.2750394344329834\n",
      "Batch 121: loss = 0.28720322251319885\n",
      "Batch 122: loss = 0.2785851061344147\n",
      "Batch 123: loss = 0.2741066515445709\n",
      "Batch 124: loss = 0.3000604808330536\n",
      "Batch 125: loss = 0.3177163600921631\n",
      "Batch 126: loss = 0.28782060742378235\n",
      "\n",
      "Epoch 82/100\n",
      "Batch 1: loss = 0.2821773588657379\n",
      "Batch 2: loss = 0.3066259026527405\n",
      "Batch 3: loss = 0.29331299662590027\n",
      "Batch 4: loss = 0.2791144847869873\n",
      "Batch 5: loss = 0.311940461397171\n",
      "Batch 6: loss = 0.3340338170528412\n",
      "Batch 7: loss = 0.27692246437072754\n",
      "Batch 8: loss = 0.3001707196235657\n",
      "Batch 9: loss = 0.3058507740497589\n",
      "Batch 10: loss = 0.2337430864572525\n",
      "Batch 11: loss = 0.2780495882034302\n",
      "Batch 12: loss = 0.3243251144886017\n",
      "Batch 13: loss = 0.28818559646606445\n",
      "Batch 14: loss = 0.2857748866081238\n",
      "Batch 15: loss = 0.25368547439575195\n",
      "Batch 16: loss = 0.29860877990722656\n",
      "Batch 17: loss = 0.27507641911506653\n",
      "Batch 18: loss = 0.3186837434768677\n",
      "Batch 19: loss = 0.29871201515197754\n",
      "Batch 20: loss = 0.3112332820892334\n",
      "Batch 21: loss = 0.27994242310523987\n",
      "Batch 22: loss = 0.28518521785736084\n",
      "Batch 23: loss = 0.33024969696998596\n",
      "Batch 24: loss = 0.2899588942527771\n",
      "Batch 25: loss = 0.30367809534072876\n",
      "Batch 26: loss = 0.2927378714084625\n",
      "Batch 27: loss = 0.3357292711734772\n",
      "Batch 28: loss = 0.3379066288471222\n",
      "Batch 29: loss = 0.321622371673584\n",
      "Batch 30: loss = 0.30597352981567383\n",
      "Batch 31: loss = 0.3199187219142914\n",
      "Batch 32: loss = 0.278928279876709\n",
      "Batch 33: loss = 0.3264039158821106\n",
      "Batch 34: loss = 0.31444796919822693\n",
      "Batch 35: loss = 0.31399598717689514\n",
      "Batch 36: loss = 0.2713676691055298\n",
      "Batch 37: loss = 0.23558171093463898\n",
      "Batch 38: loss = 0.3021188974380493\n",
      "Batch 39: loss = 0.2960563004016876\n",
      "Batch 40: loss = 0.31042903661727905\n",
      "Batch 41: loss = 0.2692486047744751\n",
      "Batch 42: loss = 0.2854412794113159\n",
      "Batch 43: loss = 0.35527515411376953\n",
      "Batch 44: loss = 0.2967008948326111\n",
      "Batch 45: loss = 0.27373528480529785\n",
      "Batch 46: loss = 0.24748331308364868\n",
      "Batch 47: loss = 0.3106246888637543\n",
      "Batch 48: loss = 0.26943743228912354\n",
      "Batch 49: loss = 0.2516128718852997\n",
      "Batch 50: loss = 0.24320481717586517\n",
      "Batch 51: loss = 0.3202782869338989\n",
      "Batch 52: loss = 0.3034350872039795\n",
      "Batch 53: loss = 0.2920744717121124\n",
      "Batch 54: loss = 0.23661987483501434\n",
      "Batch 55: loss = 0.26641646027565\n",
      "Batch 56: loss = 0.27798980474472046\n",
      "Batch 57: loss = 0.2951739728450775\n",
      "Batch 58: loss = 0.3046197295188904\n",
      "Batch 59: loss = 0.23894354701042175\n",
      "Batch 60: loss = 0.23928846418857574\n",
      "Batch 61: loss = 0.27442288398742676\n",
      "Batch 62: loss = 0.3077958822250366\n",
      "Batch 63: loss = 0.25821366906166077\n",
      "Batch 64: loss = 0.25972607731819153\n",
      "Batch 65: loss = 0.26682257652282715\n",
      "Batch 66: loss = 0.2689279615879059\n",
      "Batch 67: loss = 0.29829221963882446\n",
      "Batch 68: loss = 0.2967543303966522\n",
      "Batch 69: loss = 0.2977362871170044\n",
      "Batch 70: loss = 0.3088062107563019\n",
      "Batch 71: loss = 0.30336254835128784\n",
      "Batch 72: loss = 0.2728901505470276\n",
      "Batch 73: loss = 0.32672369480133057\n",
      "Batch 74: loss = 0.30691200494766235\n",
      "Batch 75: loss = 0.33453547954559326\n",
      "Batch 76: loss = 0.3050233721733093\n",
      "Batch 77: loss = 0.2862587869167328\n",
      "Batch 78: loss = 0.3331509828567505\n",
      "Batch 79: loss = 0.2503644824028015\n",
      "Batch 80: loss = 0.2677451968193054\n",
      "Batch 81: loss = 0.2931133806705475\n",
      "Batch 82: loss = 0.2946512699127197\n",
      "Batch 83: loss = 0.2497909963130951\n",
      "Batch 84: loss = 0.2888469099998474\n",
      "Batch 85: loss = 0.32076871395111084\n",
      "Batch 86: loss = 0.29817521572113037\n",
      "Batch 87: loss = 0.3121270537376404\n",
      "Batch 88: loss = 0.3506365120410919\n",
      "Batch 89: loss = 0.30977144837379456\n",
      "Batch 90: loss = 0.31707465648651123\n",
      "Batch 91: loss = 0.3126704692840576\n",
      "Batch 92: loss = 0.32946062088012695\n",
      "Batch 93: loss = 0.2797367572784424\n",
      "Batch 94: loss = 0.28115856647491455\n",
      "Batch 95: loss = 0.2909863591194153\n",
      "Batch 96: loss = 0.3148806691169739\n",
      "Batch 97: loss = 0.29412585496902466\n",
      "Batch 98: loss = 0.2968462109565735\n",
      "Batch 99: loss = 0.3386607766151428\n",
      "Batch 100: loss = 0.30728209018707275\n",
      "Batch 101: loss = 0.27459943294525146\n",
      "Batch 102: loss = 0.309887170791626\n",
      "Batch 103: loss = 0.28933513164520264\n",
      "Batch 104: loss = 0.2580946683883667\n",
      "Batch 105: loss = 0.24560317397117615\n",
      "Batch 106: loss = 0.2987150549888611\n",
      "Batch 107: loss = 0.30565547943115234\n",
      "Batch 108: loss = 0.3137784004211426\n",
      "Batch 109: loss = 0.2780305743217468\n",
      "Batch 110: loss = 0.2651752829551697\n",
      "Batch 111: loss = 0.31783372163772583\n",
      "Batch 112: loss = 0.3290126919746399\n",
      "Batch 113: loss = 0.29756343364715576\n",
      "Batch 114: loss = 0.324416846036911\n",
      "Batch 115: loss = 0.2962539494037628\n",
      "Batch 116: loss = 0.31715118885040283\n",
      "Batch 117: loss = 0.27894455194473267\n",
      "Batch 118: loss = 0.26722875237464905\n",
      "Batch 119: loss = 0.28055888414382935\n",
      "Batch 120: loss = 0.25398245453834534\n",
      "Batch 121: loss = 0.264051228761673\n",
      "Batch 122: loss = 0.2814655900001526\n",
      "Batch 123: loss = 0.281963050365448\n",
      "Batch 124: loss = 0.3009021580219269\n",
      "Batch 125: loss = 0.29115355014801025\n",
      "Batch 126: loss = 0.28415679931640625\n",
      "\n",
      "Epoch 83/100\n",
      "Batch 1: loss = 0.2894293963909149\n",
      "Batch 2: loss = 0.31273120641708374\n",
      "Batch 3: loss = 0.2805059552192688\n",
      "Batch 4: loss = 0.287090003490448\n",
      "Batch 5: loss = 0.2875552177429199\n",
      "Batch 6: loss = 0.2891632914543152\n",
      "Batch 7: loss = 0.2885611653327942\n",
      "Batch 8: loss = 0.2914161682128906\n",
      "Batch 9: loss = 0.292048841714859\n",
      "Batch 10: loss = 0.25684893131256104\n",
      "Batch 11: loss = 0.27445459365844727\n",
      "Batch 12: loss = 0.28401362895965576\n",
      "Batch 13: loss = 0.2962765395641327\n",
      "Batch 14: loss = 0.2790331244468689\n",
      "Batch 15: loss = 0.26818299293518066\n",
      "Batch 16: loss = 0.2740040421485901\n",
      "Batch 17: loss = 0.28796863555908203\n",
      "Batch 18: loss = 0.31954509019851685\n",
      "Batch 19: loss = 0.29621264338493347\n",
      "Batch 20: loss = 0.2696613371372223\n",
      "Batch 21: loss = 0.2780163884162903\n",
      "Batch 22: loss = 0.3084624707698822\n",
      "Batch 23: loss = 0.35891953110694885\n",
      "Batch 24: loss = 0.2657616138458252\n",
      "Batch 25: loss = 0.2931119203567505\n",
      "Batch 26: loss = 0.31526169180870056\n",
      "Batch 27: loss = 0.3369789719581604\n",
      "Batch 28: loss = 0.32250910997390747\n",
      "Batch 29: loss = 0.3243248164653778\n",
      "Batch 30: loss = 0.30833494663238525\n",
      "Batch 31: loss = 0.3390917181968689\n",
      "Batch 32: loss = 0.31452465057373047\n",
      "Batch 33: loss = 0.2747238874435425\n",
      "Batch 34: loss = 0.3148314952850342\n",
      "Batch 35: loss = 0.30463606119155884\n",
      "Batch 36: loss = 0.24614983797073364\n",
      "Batch 37: loss = 0.24340251088142395\n",
      "Batch 38: loss = 0.2905535399913788\n",
      "Batch 39: loss = 0.2507244050502777\n",
      "Batch 40: loss = 0.28324705362319946\n",
      "Batch 41: loss = 0.28229570388793945\n",
      "Batch 42: loss = 0.30155059695243835\n",
      "Batch 43: loss = 0.31221580505371094\n",
      "Batch 44: loss = 0.28675881028175354\n",
      "Batch 45: loss = 0.23610952496528625\n",
      "Batch 46: loss = 0.2702043652534485\n",
      "Batch 47: loss = 0.2673569321632385\n",
      "Batch 48: loss = 0.29155194759368896\n",
      "Batch 49: loss = 0.26360005140304565\n",
      "Batch 50: loss = 0.28545886278152466\n",
      "Batch 51: loss = 0.2832711338996887\n",
      "Batch 52: loss = 0.30687880516052246\n",
      "Batch 53: loss = 0.28159594535827637\n",
      "Batch 54: loss = 0.23765139281749725\n",
      "Batch 55: loss = 0.24158945679664612\n",
      "Batch 56: loss = 0.287675142288208\n",
      "Batch 57: loss = 0.3262292742729187\n",
      "Batch 58: loss = 0.3000890910625458\n",
      "Batch 59: loss = 0.22351470589637756\n",
      "Batch 60: loss = 0.27529746294021606\n",
      "Batch 61: loss = 0.27665263414382935\n",
      "Batch 62: loss = 0.32584211230278015\n",
      "Batch 63: loss = 0.2581121027469635\n",
      "Batch 64: loss = 0.239205002784729\n",
      "Batch 65: loss = 0.2861972451210022\n",
      "Batch 66: loss = 0.28345987200737\n",
      "Batch 67: loss = 0.27659276127815247\n",
      "Batch 68: loss = 0.2892307937145233\n",
      "Batch 69: loss = 0.27757537364959717\n",
      "Batch 70: loss = 0.27793818712234497\n",
      "Batch 71: loss = 0.31193745136260986\n",
      "Batch 72: loss = 0.24646683037281036\n",
      "Batch 73: loss = 0.29979968070983887\n",
      "Batch 74: loss = 0.2943621873855591\n",
      "Batch 75: loss = 0.35230308771133423\n",
      "Batch 76: loss = 0.3126927614212036\n",
      "Batch 77: loss = 0.30476680397987366\n",
      "Batch 78: loss = 0.2862131893634796\n",
      "Batch 79: loss = 0.31064724922180176\n",
      "Batch 80: loss = 0.2663553059101105\n",
      "Batch 81: loss = 0.29777318239212036\n",
      "Batch 82: loss = 0.28253498673439026\n",
      "Batch 83: loss = 0.28082558512687683\n",
      "Batch 84: loss = 0.2890114188194275\n",
      "Batch 85: loss = 0.32348543405532837\n",
      "Batch 86: loss = 0.30597805976867676\n",
      "Batch 87: loss = 0.2778484523296356\n",
      "Batch 88: loss = 0.36092567443847656\n",
      "Batch 89: loss = 0.27865856885910034\n",
      "Batch 90: loss = 0.2905424237251282\n",
      "Batch 91: loss = 0.3378468155860901\n",
      "Batch 92: loss = 0.29683971405029297\n",
      "Batch 93: loss = 0.2936965823173523\n",
      "Batch 94: loss = 0.27469849586486816\n",
      "Batch 95: loss = 0.3119753301143646\n",
      "Batch 96: loss = 0.34022629261016846\n",
      "Batch 97: loss = 0.29395049810409546\n",
      "Batch 98: loss = 0.2627650499343872\n",
      "Batch 99: loss = 0.3406391739845276\n",
      "Batch 100: loss = 0.313262015581131\n",
      "Batch 101: loss = 0.2830563485622406\n",
      "Batch 102: loss = 0.30156517028808594\n",
      "Batch 103: loss = 0.2732367515563965\n",
      "Batch 104: loss = 0.25978150963783264\n",
      "Batch 105: loss = 0.26320648193359375\n",
      "Batch 106: loss = 0.3165050745010376\n",
      "Batch 107: loss = 0.29892224073410034\n",
      "Batch 108: loss = 0.31059879064559937\n",
      "Batch 109: loss = 0.2999752163887024\n",
      "Batch 110: loss = 0.26707106828689575\n",
      "Batch 111: loss = 0.2848662734031677\n",
      "Batch 112: loss = 0.2812809646129608\n",
      "Batch 113: loss = 0.27797403931617737\n",
      "Batch 114: loss = 0.3050137162208557\n",
      "Batch 115: loss = 0.3045823574066162\n",
      "Batch 116: loss = 0.2893601357936859\n",
      "Batch 117: loss = 0.3007637858390808\n",
      "Batch 118: loss = 0.2678646743297577\n",
      "Batch 119: loss = 0.277346670627594\n",
      "Batch 120: loss = 0.283454954624176\n",
      "Batch 121: loss = 0.2618933320045471\n",
      "Batch 122: loss = 0.265836238861084\n",
      "Batch 123: loss = 0.34061598777770996\n",
      "Batch 124: loss = 0.3066343069076538\n",
      "Batch 125: loss = 0.3451631963253021\n",
      "Batch 126: loss = 0.2417505532503128\n",
      "\n",
      "Epoch 84/100\n",
      "Batch 1: loss = 0.2951263189315796\n",
      "Batch 2: loss = 0.26315099000930786\n",
      "Batch 3: loss = 0.2860998511314392\n",
      "Batch 4: loss = 0.2801414132118225\n",
      "Batch 5: loss = 0.2645002603530884\n",
      "Batch 6: loss = 0.3119094967842102\n",
      "Batch 7: loss = 0.299716055393219\n",
      "Batch 8: loss = 0.3040252923965454\n",
      "Batch 9: loss = 0.28911054134368896\n",
      "Batch 10: loss = 0.27128052711486816\n",
      "Batch 11: loss = 0.2958643436431885\n",
      "Batch 12: loss = 0.2726500928401947\n",
      "Batch 13: loss = 0.250793993473053\n",
      "Batch 14: loss = 0.2716308832168579\n",
      "Batch 15: loss = 0.2606775164604187\n",
      "Batch 16: loss = 0.2901841402053833\n",
      "Batch 17: loss = 0.26140061020851135\n",
      "Batch 18: loss = 0.3040449917316437\n",
      "Batch 19: loss = 0.30964142084121704\n",
      "Batch 20: loss = 0.25820040702819824\n",
      "Batch 21: loss = 0.2664499282836914\n",
      "Batch 22: loss = 0.3187550902366638\n",
      "Batch 23: loss = 0.33001720905303955\n",
      "Batch 24: loss = 0.26187863945961\n",
      "Batch 25: loss = 0.32078665494918823\n",
      "Batch 26: loss = 0.25113534927368164\n",
      "Batch 27: loss = 0.3120530843734741\n",
      "Batch 28: loss = 0.3013216555118561\n",
      "Batch 29: loss = 0.3123091459274292\n",
      "Batch 30: loss = 0.3220217823982239\n",
      "Batch 31: loss = 0.2865469753742218\n",
      "Batch 32: loss = 0.3148324191570282\n",
      "Batch 33: loss = 0.3220357894897461\n",
      "Batch 34: loss = 0.3243456482887268\n",
      "Batch 35: loss = 0.2894093990325928\n",
      "Batch 36: loss = 0.2649651765823364\n",
      "Batch 37: loss = 0.25450247526168823\n",
      "Batch 38: loss = 0.2677063047885895\n",
      "Batch 39: loss = 0.25963327288627625\n",
      "Batch 40: loss = 0.28028398752212524\n",
      "Batch 41: loss = 0.2800910472869873\n",
      "Batch 42: loss = 0.27880778908729553\n",
      "Batch 43: loss = 0.339596688747406\n",
      "Batch 44: loss = 0.27006685733795166\n",
      "Batch 45: loss = 0.2599363625049591\n",
      "Batch 46: loss = 0.2493332028388977\n",
      "Batch 47: loss = 0.25757071375846863\n",
      "Batch 48: loss = 0.2547330856323242\n",
      "Batch 49: loss = 0.2652131915092468\n",
      "Batch 50: loss = 0.25244128704071045\n",
      "Batch 51: loss = 0.27481991052627563\n",
      "Batch 52: loss = 0.31218284368515015\n",
      "Batch 53: loss = 0.2807956337928772\n",
      "Batch 54: loss = 0.21575278043746948\n",
      "Batch 55: loss = 0.2575930058956146\n",
      "Batch 56: loss = 0.2776103615760803\n",
      "Batch 57: loss = 0.306327223777771\n",
      "Batch 58: loss = 0.2949797809123993\n",
      "Batch 59: loss = 0.24415883421897888\n",
      "Batch 60: loss = 0.2725675702095032\n",
      "Batch 61: loss = 0.28099265694618225\n",
      "Batch 62: loss = 0.29508906602859497\n",
      "Batch 63: loss = 0.2759477496147156\n",
      "Batch 64: loss = 0.23361285030841827\n",
      "Batch 65: loss = 0.2509186267852783\n",
      "Batch 66: loss = 0.2852749824523926\n",
      "Batch 67: loss = 0.3034643530845642\n",
      "Batch 68: loss = 0.2931922674179077\n",
      "Batch 69: loss = 0.25319790840148926\n",
      "Batch 70: loss = 0.3353411853313446\n",
      "Batch 71: loss = 0.2911141514778137\n",
      "Batch 72: loss = 0.2605630159378052\n",
      "Batch 73: loss = 0.31446510553359985\n",
      "Batch 74: loss = 0.2813303768634796\n",
      "Batch 75: loss = 0.3079555034637451\n",
      "Batch 76: loss = 0.2899332046508789\n",
      "Batch 77: loss = 0.2800348699092865\n",
      "Batch 78: loss = 0.26930660009384155\n",
      "Batch 79: loss = 0.3054805397987366\n",
      "Batch 80: loss = 0.2794681489467621\n",
      "Batch 81: loss = 0.29129666090011597\n",
      "Batch 82: loss = 0.28310686349868774\n",
      "Batch 83: loss = 0.26216399669647217\n",
      "Batch 84: loss = 0.32949066162109375\n",
      "Batch 85: loss = 0.32529932260513306\n",
      "Batch 86: loss = 0.26692527532577515\n",
      "Batch 87: loss = 0.30760544538497925\n",
      "Batch 88: loss = 0.33549273014068604\n",
      "Batch 89: loss = 0.26948556303977966\n",
      "Batch 90: loss = 0.2952500581741333\n",
      "Batch 91: loss = 0.34609830379486084\n",
      "Batch 92: loss = 0.2937465012073517\n",
      "Batch 93: loss = 0.26829397678375244\n",
      "Batch 94: loss = 0.28465914726257324\n",
      "Batch 95: loss = 0.265951931476593\n",
      "Batch 96: loss = 0.34360334277153015\n",
      "Batch 97: loss = 0.2795320451259613\n",
      "Batch 98: loss = 0.2678636312484741\n",
      "Batch 99: loss = 0.31772947311401367\n"
     ]
    }
   ],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "num_epochs = 100\n",
    "save_freq = 20\n",
    "tr_loss = []\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'\\nEpoch {epoch + 1}/{num_epochs}')\n",
    "    epoch_loss = 0\n",
    "    h = model.init_hidden(BATCH_SIZE)\n",
    "    for idx, (X,Y) in enumerate(read_batches(T, BATCH_SIZE)):\n",
    "        x = X.to(device)\n",
    "        y = Y.view(-1, 86).to(device)\n",
    "        \n",
    "        outputs, h = model(x, h)\n",
    "        loss = criterion(outputs, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        h = (h[0].detach(), h[1].detach())\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        print(f\"Batch {idx+1}: loss = {loss.item()}\")\n",
    "    \n",
    "    tr_loss.append(epoch_loss)\n",
    "    if (epoch+1) % save_freq == 0:\n",
    "        save_weights(model, epoch+1)\n",
    "        print('Saved checkpoint to', f'weights.{epoch+1}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e54f4a2c-e1ef-4704-9846-0a856f6003b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.arange(100), tr_loss)\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Epoch Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "75581eca-8257-41c2-8598-eb22e4ecd1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 2494051370.8386993\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "print(f\"Perplexity: {math.pow(2, tr_loss[-1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e5402e76-3dc2-4323-807e-68ca326acb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CharLSTM()\n",
    "model = load_weights(model, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "64bc1b3a-2a7d-49e7-8fd2-0902a616faed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CharLSTM(\n",
       "  (emb): Embedding(86, 512)\n",
       "  (lstm): LSTM(512, 256, num_layers=3, batch_first=True, dropout=0.2)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=256, out_features=86, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c8dd7abc-80b9-4309-b318-31d75f283229",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_chars = 2000\n",
    "sampled = []\n",
    "h = model.init_hidden(1)\n",
    "for i in range(num_chars):\n",
    "    batch = torch.zeros((1, 1))\n",
    "    if sampled:\n",
    "        batch[0, 0] = sampled[-1]\n",
    "    else:\n",
    "        batch[0, 0] = torch.randint(0, vocab_size, (1,))\n",
    "    batch = batch.to(torch.int32)\n",
    "    x = batch.to(device)\n",
    "    result, h = model(x, h)\n",
    "    p = nn.Softmax(dim=1)(result)\n",
    "    sample = p.multinomial(num_samples=1, replacement=True)\n",
    "    sampled.append(sample.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6a20052f-b3e8-416e-aafc-8c0d50e5754c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Casher\n",
      "% Nottingham Music Database\n",
      "S:Trad, arr Phil Rowe\n",
      "M:6/8\n",
      "K:G\n",
      "G|:\"G\"GBc \"Em\"BAG|\"D7\"dcA ABc|\"G\"BGG G2D|\"G\"BAG \"C\"G2E|\"G\"DGG \"A7\"E2G|\"D7\"FAG FED|\n",
      "\"G\"GFG BAG|\"D\"FEF \"G\"GAB|\"Em\"AGF \"Am\"E2A|\"Em\"BGE E2:|\n",
      "\n",
      "\n",
      "X: 282\n",
      "T:Shafters Shindig\n",
      "% Nottingham Music Database\n",
      "S:Trad, arr Phil Rowe\n",
      "M:6/8\n",
      "K:G\n",
      "D|\"G\"G2G \"D7\"AGF|\"G\"G3 \"C\"g2e|\"G\"dBG E2D|\"C\"EFG \"D7\"AFD|\"G\"G3 -G2::\n",
      "c|\"G\"B2G \"D7\"AFD|\"G\"G3 -G2B|\"D7\"ABc a2A|\n",
      "\"G\"B2A G2B|\"A7\"A2G F2G|\"D7\"A3 -Adc|\n",
      "\"G\"B3 G3|\"G\"D2B c2B|\"Am\"A2G \"D7\"FED|\"G\"G2G \"D\"A2A|\"G\"B2c dBc|\\\n",
      "\"D7\"cBA \"G\"G3:|\n",
      "\n",
      "\n",
      "X: 303\n",
      "T:Swallort\n",
      "% Nottingham Music Database\n",
      "Y:AABB\n",
      "S:John Lagden, via EF\n",
      "M:6/8\n",
      "K:G\n",
      "P:A\n",
      "|:B/2c/2|\"G\"d2d \"C\"c2e|\"G\"dBG GAB|\"Em\"E3 E2:|\n",
      "P:B\n",
      "B/2c/2|\"G\"ded \"D7\"c2A|\"G\"BGG DGG|\"G\"BGB dcB|\"C\"cAG \"D7\"AFA|\n",
      "\"G\"GBc \"G\"DGB|\"C\"cdc \"G\"BAG|\"D7\"FGA A2G|\n",
      "\"G\"BAB GBd|\"C\"ece gfe|\"G\"d/2g3/2B \"D7\"dcA|\"G\"G3 G2:|\n",
      "P:B\n",
      "d/2d/2|\"G\"gfg \"D\"afd|\"C\"efg gfe|\"G\"dBg \"C\"ecg|\"G\"dcB \"Em\"G2:|\n",
      "\n",
      "\n",
      "X: 196\n",
      "T:The Lady Of The Lake\n",
      "% Nottingham Music Database\n",
      "S:Bob McQuillen Jan 1979, via Phil Rowe\n",
      "M:6/8\n",
      "K:D\n",
      "\"D\"DFA BAF|\"G\"DGB dBG|\"G\"B3 -B2c|\"G\"d2d dBd| \"G\"g3 -\"Em\"e^de|\\\n",
      "\"D\"d3 -d2||\n",
      "\n",
      "\n",
      "X: 149\n",
      "T:Jig For Chrt\n",
      "% Nottingham Music Database\n",
      "S:EF\n",
      "Y:AB\n",
      "M:6/8\n",
      "K:G\n",
      "P:A\n",
      "D|\"G\"G2G \"D7/a\"G2A|\"G/b\"BGB \"C\"AGE|\"G\"G2G GAB|\"G\"d2e d2B|\\\n",
      "\"D\"c2B \"Em\"G2E|\"G\"D2G G2:|\n",
      "P:B\n",
      "d|\"G\"g2g gag|\"D\"f2f fgf|\"C\"e2d efg|\"D7\"a2g fed|\"G\"g3 -g2:|\n",
      "\n",
      "\n",
      "X: 214\n",
      "T:Workshop Jig\n",
      "% Nottingham Music Database\n",
      "S:Trad, arr Phil Rowe\n",
      "M:6/8\n",
      "K:D\n",
      "(3A/2B/2c/2|\"D\"dcd f2e/2f/2|\"G\"gfg \"Em\"Bed|\"A7\"c3 ABc|\"D\"d3 d2:|\n",
      "\n",
      "\n",
      "X: 159\n",
      "T:Jopplety How\n",
      "% Nottingham Music Database\n",
      "S:EF\n",
      "Y:AB\n",
      "M:6/8\n",
      "K:G\n",
      "P:A\n",
      "d|\"G\"G2G dBG|\"G\"d2B G2d|\"C\"edB \"D7\"A2G|\n",
      "\"G\"GAG \"C\"g2e|\"G\"dBG \"D7\"A2G|\"G\"GAG \"C\"g2e|\"G\"dBG \"D7\"AFD|\n",
      "\"G\"G2G \"D7\"A2d|\"G\"BGG G2:|\n",
      "P:B\n",
      "|:B/2d/2|\"C\"g2g =c=ce|\"G\"dBG GAB|\"C\"cde \"D7\"d2c|\"G\"BAG \"D7\"AGF|\"G\"G3 G2||\n",
      "\n",
      "\n",
      "X: 274\n",
      "T:Scollys\n",
      "% Nottingham Music Database\n",
      "S:AA, via EF\n",
      "Y:AB\n",
      "M:6/8\n",
      "K:G\n",
      "P:A\n",
      "d|\"G\"G2G d2d|\"C\"edc \"G\"BAG|\"C\"A2G \"D7\"E2D|\n",
      "\"G\"G2G \"D7\"AGF|\"G\"G2B \"C\"c2e|\"G\"dBG \"D7\"A2d|\n",
      "\"G\"g2d \"D7\"cBA|\"G\"Bcd \"D\"AGF|\"Em\"E2B \"Am\"ABc|\"D\"d2c \"Em\"B2A|\"Em\"Bcd \"Am\"edc|\n",
      "\"D\"d2B \"Em\"B2d|\"Am\"e2c \"D7\"AAG|\"G\"B2c d\n"
     ]
    }
   ],
   "source": [
    "print(''.join(idx_to_char[c] for c in sampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18071ca8-8a03-4370-a6b9-49acd74d1d34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
